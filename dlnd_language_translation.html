<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />
<title>dlnd_language_translation</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.7 (http://getbootstrap.com)
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    color: #000 !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.2.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.2.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.2.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.2.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.2.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.2.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=1);
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2);
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=3);
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1);
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1);
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
@media (max-width: 991px) {
  #ipython_notebook {
    margin-left: 10px;
  }
}
[dir="rtl"] #ipython_notebook {
  float: right !important;
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#login_widget {
  float: right;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  text-align: center;
  vertical-align: middle;
  display: inline;
  opacity: 0;
  z-index: 2;
  width: 12ex;
  margin-right: -12ex;
}
.alternate_upload .btn-upload {
  height: 22px;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
[dir="rtl"] #tabs li {
  float: right;
}
ul#tabs {
  margin-bottom: 4px;
}
[dir="rtl"] ul#tabs {
  margin-right: 0px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
[dir="rtl"] .list_toolbar .tree-buttons {
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-right {
  padding-top: 1px;
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-left {
  float: right !important;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: baseline;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
#tree-selector {
  padding-right: 0px;
}
[dir="rtl"] #tree-selector a {
  float: right;
}
#button-select-all {
  min-width: 50px;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
[dir="rtl"] #new-menu {
  text-align: right;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
[dir="rtl"] #running .col-sm-8 {
  float: right !important;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI colors. */
.ansibold {
  font-weight: bold;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  border-left-width: 1px;
  padding-left: 5px;
  background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%);
}
div.cell.jupyter-soft-selected {
  border-left-color: #90CAF9;
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected {
  border-color: #ababab;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%);
}
@media print {
  div.cell.selected {
    border-color: transparent;
  }
}
div.cell.selected.jupyter-soft-selected {
  border-left-width: 0;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%);
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%);
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  padding: 0.4em;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */
  /* .CodeMirror-lines */
  padding: 0;
  border: 0;
  border-radius: 0;
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul {
  list-style: disc;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ul ul {
  list-style: square;
  margin: 0em 2em;
}
.rendered_html ul ul ul {
  list-style: circle;
  margin: 0em 2em;
}
.rendered_html ol {
  list-style: decimal;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
  margin: 0em 2em;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  background-color: #fff;
  color: #000;
  font-size: 100%;
  padding: 0px;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: 1px solid black;
  border-collapse: collapse;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  border: 1px solid black;
  border-collapse: collapse;
  margin: 1em 2em;
}
.rendered_html td,
.rendered_html th {
  text-align: left;
  vertical-align: middle;
  padding: 4px;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget {
  float: right !important;
  float: right;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 21ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  margin-top: 6px;
}
span.save_widget span.filename {
  height: 1em;
  line-height: 1em;
  padding: 3px;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  display: none;
}
.command-shortcut:before {
  content: "(command)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  width: 100%;
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal .xterm-rows {
  padding: 10px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>
<style type="text/css">
    
/* Temporary definitions which will become obsolete with Notebook release 5.0 */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }

    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Language-Translation">Language Translation<a class="anchor-link" href="#Language-Translation">&#182;</a></h1><p>In this project, youre going to take a peek into the realm of neural network machine translation.  Youll be training a sequence to sequence model on a dataset of English and French sentences that can translate new sentences from English to French.</p>
<h2 id="Get-the-Data">Get the Data<a class="anchor-link" href="#Get-the-Data">&#182;</a></h2><p>Since translating the whole language of English to French will take lots of time to train, we have provided you with a small portion of the English corpus.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">helper</span>
<span class="kn">import</span> <span class="nn">problem_unittests</span> <span class="k">as</span> <span class="nn">tests</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="n">source_path</span> <span class="o">=</span> <span class="s1">&#39;data/small_vocab_en&#39;</span>
<span class="n">target_path</span> <span class="o">=</span> <span class="s1">&#39;data/small_vocab_fr&#39;</span>
<span class="n">source_text</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">source_path</span><span class="p">)</span>
<span class="n">target_text</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">target_path</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Explore-the-Data">Explore the Data<a class="anchor-link" href="#Explore-the-Data">&#182;</a></h2><p>Play around with view_sentence_range to view different parts of the data.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">view_sentence_range</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Dataset Stats&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Roughly the number of unique words: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">({</span><span class="n">word</span><span class="p">:</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">source_text</span><span class="o">.</span><span class="n">split</span><span class="p">()})))</span>

<span class="n">sentences</span> <span class="o">=</span> <span class="n">source_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">word_counts</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">())</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Number of sentences: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sentences</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Average number of words in a sentence: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">word_counts</span><span class="p">)))</span>

<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;English sentences </span><span class="si">{}</span><span class="s1"> to </span><span class="si">{}</span><span class="s1">:&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">view_sentence_range</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">source_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)[</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]]))</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;French sentences </span><span class="si">{}</span><span class="s1"> to </span><span class="si">{}</span><span class="s1">:&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">view_sentence_range</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">target_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)[</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]]))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Dataset Stats
Roughly the number of unique words: 227
Number of sentences: 137861
Average number of words in a sentence: 13.225277634719028

English sentences 0 to 10:
new jersey is sometimes quiet during autumn , and it is snowy in april .
the united states is usually chilly during july , and it is usually freezing in november .
california is usually quiet during march , and it is usually hot in june .
the united states is sometimes mild during june , and it is cold in september .
your least liked fruit is the grape , but my least liked is the apple .
his favorite fruit is the orange , but my favorite is the grape .
paris is relaxing during december , but it is usually chilly in july .
new jersey is busy during spring , and it is never hot in march .
our least liked fruit is the lemon , but my least liked is the grape .
the united states is sometimes busy during january , and it is sometimes warm in november .

French sentences 0 to 10:
new jersey est parfois calme pendant l&#39; automne , et il est neigeux en avril .
les tats-unis est gnralement froid en juillet , et il gle habituellement en novembre .
california est gnralement calme en mars , et il est gnralement chaud en juin .
les tats-unis est parfois lgre en juin , et il fait froid en septembre .
votre moins aim fruit est le raisin , mais mon moins aim est la pomme .
son fruit prfr est l&#39;orange , mais mon prfr est le raisin .
paris est relaxant en dcembre , mais il est gnralement froid en juillet .
new jersey est occup au printemps , et il est jamais chaude en mars .
notre fruit est moins aim le citron , mais mon moins aim est le raisin .
les tats-unis est parfois occup en janvier , et il est parfois chaud en novembre .
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Implement-Preprocessing-Function">Implement Preprocessing Function<a class="anchor-link" href="#Implement-Preprocessing-Function">&#182;</a></h2><h3 id="Text-to-Word-Ids">Text to Word Ids<a class="anchor-link" href="#Text-to-Word-Ids">&#182;</a></h3><p>As you did with other RNNs, you must turn the text into a number so the computer can understand it. In the function <code>text_to_ids()</code>, you'll turn <code>source_text</code> and <code>target_text</code> from words to ids.  However, you need to add the <code>&lt;EOS&gt;</code> word id at the end of <code>target_text</code>.  This will help the neural network predict when the sentence should end.</p>
<p>You can get the <code>&lt;EOS&gt;</code> word id by doing:</p>
<div class="highlight"><pre><span></span><span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;EOS&gt;&#39;</span><span class="p">]</span>
</pre></div>
<p>You can get other word ids using <code>source_vocab_to_int</code> and <code>target_vocab_to_int</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">text_to_ids</span><span class="p">(</span><span class="n">source_text</span><span class="p">,</span> <span class="n">target_text</span><span class="p">,</span> <span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert source and target text to proper word ids</span>
<span class="sd">    :param source_text: String that contains all the source text.</span>
<span class="sd">    :param target_text: String that contains all the target text.</span>
<span class="sd">    :param source_vocab_to_int: Dictionary to go from the source words to an id</span>
<span class="sd">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span>
<span class="sd">    :return: A tuple of lists (source_id_text, target_id_text)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
<span class="c1">#     for text in source_text.split(&quot; &quot;):</span>
<span class="c1">#         print(text)</span>
    
    <span class="n">source_id_text</span> <span class="o">=</span> <span class="p">[[</span><span class="n">source_vocab_to_int</span><span class="p">[</span><span class="n">ch</span><span class="p">]</span> <span class="k">for</span> <span class="n">ch</span> <span class="ow">in</span> <span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">()]</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">source_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)]</span>
    <span class="n">target_id_text</span> <span class="o">=</span> <span class="p">[[</span><span class="n">target_vocab_to_int</span><span class="p">[</span><span class="n">ch</span><span class="p">]</span> <span class="k">for</span> <span class="n">ch</span> <span class="ow">in</span> <span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">()]</span> <span class="o">+</span> <span class="p">[</span><span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;EOS&gt;&#39;</span><span class="p">]]</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">target_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)]</span>
<span class="c1">#     print(target_id_text)</span>
<span class="c1">#     target_id_text = target_id_text + target_vocab_to_int[&#39;&lt;EOS&gt;&#39;]</span>

    <span class="k">return</span> <span class="n">source_id_text</span><span class="p">,</span> <span class="n">target_id_text</span> 

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_text_to_ids</span><span class="p">(</span><span class="n">text_to_ids</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Preprocess-all-the-data-and-save-it">Preprocess all the data and save it<a class="anchor-link" href="#Preprocess-all-the-data-and-save-it">&#182;</a></h3><p>Running the code cell below will preprocess all the data and save it to file.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">helper</span><span class="o">.</span><span class="n">preprocess_and_save_data</span><span class="p">(</span><span class="n">source_path</span><span class="p">,</span> <span class="n">target_path</span><span class="p">,</span> <span class="n">text_to_ids</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Check-Point">Check Point<a class="anchor-link" href="#Check-Point">&#182;</a></h1><p>This is your first checkpoint. If you ever decide to come back to this notebook or have to restart the notebook, you can start from here. The preprocessed data has been saved to disk.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">helper</span>
<span class="kn">import</span> <span class="nn">problem_unittests</span> <span class="k">as</span> <span class="nn">tests</span>

<span class="p">(</span><span class="n">source_int_text</span><span class="p">,</span> <span class="n">target_int_text</span><span class="p">),</span> <span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">),</span> <span class="n">_</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Check-the-Version-of-TensorFlow-and-Access-to-GPU">Check the Version of TensorFlow and Access to GPU<a class="anchor-link" href="#Check-the-Version-of-TensorFlow-and-Access-to-GPU">&#182;</a></h3><p>This will check to make sure you have the correct version of TensorFlow and access to a GPU</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">distutils.version</span> <span class="k">import</span> <span class="n">LooseVersion</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.layers.core</span> <span class="k">import</span> <span class="n">Dense</span>

<span class="c1"># Check TensorFlow Version</span>
<span class="k">assert</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="s1">&#39;1.1&#39;</span><span class="p">),</span> <span class="s1">&#39;Please use TensorFlow version 1.1 or newer&#39;</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;TensorFlow Version: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">))</span>

<span class="c1"># Check for a GPU</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">gpu_device_name</span><span class="p">():</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;No GPU found. Please use a GPU to train your neural network.&#39;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Default GPU Device: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">gpu_device_name</span><span class="p">()))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>TensorFlow Version: 1.3.0
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:15: UserWarning: No GPU found. Please use a GPU to train your neural network.
  from ipykernel import kernelapp as app
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Build-the-Neural-Network">Build the Neural Network<a class="anchor-link" href="#Build-the-Neural-Network">&#182;</a></h2><p>You'll build the components necessary to build a Sequence-to-Sequence model by implementing the following functions below:</p>
<ul>
<li><code>model_inputs</code></li>
<li><code>process_decoder_input</code></li>
<li><code>encoding_layer</code></li>
<li><code>decoding_layer_train</code></li>
<li><code>decoding_layer_infer</code></li>
<li><code>decoding_layer</code></li>
<li><code>seq2seq_model</code></li>
</ul>
<h3 id="Input">Input<a class="anchor-link" href="#Input">&#182;</a></h3><p>Implement the <code>model_inputs()</code> function to create TF Placeholders for the Neural Network. It should create the following placeholders:</p>
<ul>
<li>Input text placeholder named "input" using the TF Placeholder name parameter with rank 2.</li>
<li>Targets placeholder with rank 2.</li>
<li>Learning rate placeholder with rank 0.</li>
<li>Keep probability placeholder named "keep_prob" using the TF Placeholder name parameter with rank 0.</li>
<li>Target sequence length placeholder named "target_sequence_length" with rank 1</li>
<li>Max target sequence length tensor named "max_target_len" getting its value from applying tf.reduce_max on the target_sequence_length placeholder. Rank 0.</li>
<li>Source sequence length placeholder named "source_sequence_length" with rank 1</li>
</ul>
<p>Return the placeholders in the following the tuple (input, targets, learning rate, keep probability, target sequence length, max target sequence length, source sequence length)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">model_inputs</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create TF Placeholders for input, targets, learning rate, and lengths of source and target sequences.</span>
<span class="sd">    :return: Tuple (input, targets, learning rate, keep probability, target sequence length,</span>
<span class="sd">    max target sequence length, source sequence length)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="nb">input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;input&quot;</span><span class="p">)</span>
    <span class="n">targets</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;targets&quot;</span><span class="p">)</span>
    <span class="n">learning_rate</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">)</span>
    <span class="n">keep_prob</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;keep_prob&quot;</span><span class="p">)</span>
    
    <span class="n">target_sequence_length</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="p">(</span><span class="kc">None</span><span class="p">,),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;target_sequence_length&quot;</span><span class="p">)</span>
    <span class="n">max_target_len</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;max_target_len&quot;</span><span class="p">)</span>
    <span class="n">source_sequence_length</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="p">(</span><span class="kc">None</span><span class="p">,),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;source_sequence_length&quot;</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="nb">input</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_target_len</span><span class="p">,</span> <span class="n">source_sequence_length</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_model_inputs</span><span class="p">(</span><span class="n">model_inputs</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>ERROR:tensorflow:==================================
Object was never used (type &lt;class &#39;tensorflow.python.framework.ops.Operation&#39;&gt;):
&lt;tf.Operation &#39;assert_rank_2/Assert/Assert&#39; type=Assert&gt;
If you want to mark it as used call its &#34;mark_used()&#34; method.
It was originally created here:
[&#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/runpy.py&#34;, line 193, in _run_module_as_main\n    &#34;__main__&#34;, mod_spec)&#39;, &#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/runpy.py&#34;, line 85, in _run_code\n    exec(code, run_globals)&#39;, &#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py&#34;, line 16, in &lt;module&gt;\n    app.launch_new_instance()&#39;, &#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/site-packages/traitlets/config/application.py&#34;, line 658, in launch_instance\n    app.start()&#39;, &#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelapp.py&#34;, line 477, in start\n    ioloop.IOLoop.instance().start()&#39;, &#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/ioloop.py&#34;, line 177, in start\n    super(ZMQIOLoop, self).start()&#39;, &#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/site-packages/tornado/ioloop.py&#34;, line 888, in start\n    handler_func(fd_obj, events)&#39;, &#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/site-packages/tornado/stack_context.py&#34;, line 277, in null_wrapper\n    return fn(*args, **kwargs)&#39;, &#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py&#34;, line 440, in _handle_events\n    self._handle_recv()&#39;, &#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py&#34;, line 472, in _handle_recv\n    self._run_callback(callback, msg)&#39;, &#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py&#34;, line 414, in _run_callback\n    callback(*args, **kwargs)&#39;, &#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/site-packages/tornado/stack_context.py&#34;, line 277, in null_wrapper\n    return fn(*args, **kwargs)&#39;, &#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py&#34;, line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)&#39;, &#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py&#34;, line 235, in dispatch_shell\n    handler(stream, idents, msg)&#39;, &#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py&#34;, line 399, in execute_request\n    user_expressions, allow_stdin)&#39;, &#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel/ipkernel.py&#34;, line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)&#39;, &#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel/zmqshell.py&#34;, line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)&#39;, &#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py&#34;, line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)&#39;, &#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py&#34;, line 2808, in run_ast_nodes\n    if self.run_code(code, result):&#39;, &#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py&#34;, line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)&#39;, &#39;File &#34;&lt;ipython-input-11-c030a2066d66&gt;&#34;, line 23, in &lt;module&gt;\n    tests.test_model_inputs(model_inputs)&#39;, &#39;File &#34;/Users/MG/Desktop/deep_learning/p3/_project/language-translation/problem_unittests.py&#34;, line 106, in test_model_inputs\n    assert tf.assert_rank(lr, 0, message=\&#39;Learning Rate has wrong rank\&#39;)&#39;, &#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/check_ops.py&#34;, line 617, in assert_rank\n    dynamic_condition, data, summarize)&#39;, &#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/check_ops.py&#34;, line 571, in _assert_rank_condition\n    return control_flow_ops.Assert(condition, data, summarize=summarize)&#39;, &#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/util/tf_should_use.py&#34;, line 175, in wrapped\n    return _add_should_use_warning(fn(*args, **kwargs))&#39;, &#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/util/tf_should_use.py&#34;, line 144, in _add_should_use_warning\n    wrapped = TFShouldUseWarningWrapper(x)&#39;, &#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/util/tf_should_use.py&#34;, line 101, in __init__\n    stack = [s.strip() for s in traceback.format_stack()]&#39;]
==================================
ERROR:tensorflow:==================================
Object was never used (type &lt;class &#39;tensorflow.python.framework.ops.Operation&#39;&gt;):
&lt;tf.Operation &#39;assert_rank_3/Assert/Assert&#39; type=Assert&gt;
If you want to mark it as used call its &#34;mark_used()&#34; method.
It was originally created here:
[&#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/runpy.py&#34;, line 193, in _run_module_as_main\n    &#34;__main__&#34;, mod_spec)&#39;, &#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/runpy.py&#34;, line 85, in _run_code\n    exec(code, run_globals)&#39;, &#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py&#34;, line 16, in &lt;module&gt;\n    app.launch_new_instance()&#39;, &#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/site-packages/traitlets/config/application.py&#34;, line 658, in launch_instance\n    app.start()&#39;, &#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelapp.py&#34;, line 477, in start\n    ioloop.IOLoop.instance().start()&#39;, &#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/ioloop.py&#34;, line 177, in start\n    super(ZMQIOLoop, self).start()&#39;, &#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/site-packages/tornado/ioloop.py&#34;, line 888, in start\n    handler_func(fd_obj, events)&#39;, &#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/site-packages/tornado/stack_context.py&#34;, line 277, in null_wrapper\n    return fn(*args, **kwargs)&#39;, &#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py&#34;, line 440, in _handle_events\n    self._handle_recv()&#39;, &#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py&#34;, line 472, in _handle_recv\n    self._run_callback(callback, msg)&#39;, &#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py&#34;, line 414, in _run_callback\n    callback(*args, **kwargs)&#39;, &#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/site-packages/tornado/stack_context.py&#34;, line 277, in null_wrapper\n    return fn(*args, **kwargs)&#39;, &#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py&#34;, line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)&#39;, &#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py&#34;, line 235, in dispatch_shell\n    handler(stream, idents, msg)&#39;, &#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py&#34;, line 399, in execute_request\n    user_expressions, allow_stdin)&#39;, &#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel/ipkernel.py&#34;, line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)&#39;, &#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel/zmqshell.py&#34;, line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)&#39;, &#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py&#34;, line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)&#39;, &#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py&#34;, line 2808, in run_ast_nodes\n    if self.run_code(code, result):&#39;, &#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py&#34;, line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)&#39;, &#39;File &#34;&lt;ipython-input-11-c030a2066d66&gt;&#34;, line 23, in &lt;module&gt;\n    tests.test_model_inputs(model_inputs)&#39;, &#39;File &#34;/Users/MG/Desktop/deep_learning/p3/_project/language-translation/problem_unittests.py&#34;, line 107, in test_model_inputs\n    assert tf.assert_rank(keep_prob, 0, message=\&#39;Keep Probability has wrong rank\&#39;)&#39;, &#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/check_ops.py&#34;, line 617, in assert_rank\n    dynamic_condition, data, summarize)&#39;, &#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/check_ops.py&#34;, line 571, in _assert_rank_condition\n    return control_flow_ops.Assert(condition, data, summarize=summarize)&#39;, &#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/util/tf_should_use.py&#34;, line 175, in wrapped\n    return _add_should_use_warning(fn(*args, **kwargs))&#39;, &#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/util/tf_should_use.py&#34;, line 144, in _add_should_use_warning\n    wrapped = TFShouldUseWarningWrapper(x)&#39;, &#39;File &#34;/Users/MG/anaconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/util/tf_should_use.py&#34;, line 101, in __init__\n    stack = [s.strip() for s in traceback.format_stack()]&#39;]
==================================
Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Process-Decoder-Input">Process Decoder Input<a class="anchor-link" href="#Process-Decoder-Input">&#182;</a></h3><p>Implement <code>process_decoder_input</code> by removing the last word id from each batch in <code>target_data</code> and concat the GO ID to the begining of each batch.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">process_decoder_input</span><span class="p">(</span><span class="n">target_data</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Preprocess target data for encoding</span>
<span class="sd">    :param target_data: Target Placehoder</span>
<span class="sd">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span>
<span class="sd">    :param batch_size: Batch Size</span>
<span class="sd">    :return: Preprocessed target data</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">ending</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">strided_slice</span><span class="p">(</span><span class="n">target_data</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">dec_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">tf</span><span class="o">.</span><span class="n">fill</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;GO&gt;&#39;</span><span class="p">]),</span> <span class="n">ending</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">dec_input</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_process_encoding_input</span><span class="p">(</span><span class="n">process_decoder_input</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Encoding">Encoding<a class="anchor-link" href="#Encoding">&#182;</a></h3><p>Implement <code>encoding_layer()</code> to create a Encoder RNN layer:</p>
<ul>
<li>Embed the encoder input using <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/layers/embed_sequence"><code>tf.contrib.layers.embed_sequence</code></a></li>
<li>Construct a <a href="https://github.com/tensorflow/tensorflow/blob/6947f65a374ebf29e74bb71e36fd82760056d82c/tensorflow/docs_src/tutorials/recurrent.md#stacking-multiple-lstms">stacked</a> <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/LSTMCell"><code>tf.contrib.rnn.LSTMCell</code></a> wrapped in a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/DropoutWrapper"><code>tf.contrib.rnn.DropoutWrapper</code></a></li>
<li>Pass cell and embedded input to <a href="https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn"><code>tf.nn.dynamic_rnn()</code></a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[19]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">imp</span> <span class="k">import</span> <span class="n">reload</span>
<span class="n">reload</span><span class="p">(</span><span class="n">tests</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">encoding_layer</span><span class="p">(</span><span class="n">rnn_inputs</span><span class="p">,</span> <span class="n">rnn_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> 
                   <span class="n">source_sequence_length</span><span class="p">,</span> <span class="n">source_vocab_size</span><span class="p">,</span> 
                   <span class="n">encoding_embedding_size</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create encoding layer</span>
<span class="sd">    :param rnn_inputs: Inputs for the RNN</span>
<span class="sd">    :param rnn_size: RNN Size</span>
<span class="sd">    :param num_layers: Number of layers</span>
<span class="sd">    :param keep_prob: Dropout keep probability</span>
<span class="sd">    :param source_sequence_length: a list of the lengths of each sequence in the batch</span>
<span class="sd">    :param source_vocab_size: vocabulary size of source data</span>
<span class="sd">    :param encoding_embedding_size: embedding size of source data</span>
<span class="sd">    :return: tuple (RNN output, RNN state)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">enc_embed_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">embed_sequence</span><span class="p">(</span><span class="n">rnn_inputs</span><span class="p">,</span> <span class="n">source_vocab_size</span><span class="p">,</span> <span class="n">encoding_embedding_size</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">make_cell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">):</span>
        <span class="n">enc_cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">,</span>
                                          <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">random_uniform_initializer</span><span class="p">(</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
        <span class="n">enc_cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">DropoutWrapper</span><span class="p">(</span><span class="n">enc_cell</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">enc_cell</span>
    <span class="n">enc_cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">MultiRNNCell</span><span class="p">([</span><span class="n">make_cell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">)])</span>
    <span class="n">enc_output</span><span class="p">,</span> <span class="n">enc_state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dynamic_rnn</span><span class="p">(</span><span class="n">enc_cell</span><span class="p">,</span> <span class="n">enc_embed_input</span><span class="p">,</span> <span class="n">sequence_length</span><span class="o">=</span><span class="n">source_sequence_length</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">enc_output</span><span class="p">,</span> <span class="n">enc_state</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_encoding_layer</span><span class="p">(</span><span class="n">encoding_layer</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Decoding---Training">Decoding - Training<a class="anchor-link" href="#Decoding---Training">&#182;</a></h3><p>Create a training decoding layer:</p>
<ul>
<li>Create a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/TrainingHelper"><code>tf.contrib.seq2seq.TrainingHelper</code></a> </li>
<li>Create a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/BasicDecoder"><code>tf.contrib.seq2seq.BasicDecoder</code></a></li>
<li>Obtain the decoder outputs from <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_decode"><code>tf.contrib.seq2seq.dynamic_decode</code></a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[16]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">decoding_layer_train</span><span class="p">(</span><span class="n">encoder_state</span><span class="p">,</span> <span class="n">dec_cell</span><span class="p">,</span> <span class="n">dec_embed_input</span><span class="p">,</span> 
                         <span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_summary_length</span><span class="p">,</span> 
                         <span class="n">output_layer</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a decoding layer for training</span>
<span class="sd">    :param encoder_state: Encoder State</span>
<span class="sd">    :param dec_cell: Decoder RNN Cell</span>
<span class="sd">    :param dec_embed_input: Decoder embedded input</span>
<span class="sd">    :param target_sequence_length: The lengths of each sequence in the target batch</span>
<span class="sd">    :param max_summary_length: The length of the longest sequence in the batch</span>
<span class="sd">    :param output_layer: Function to apply the output layer</span>
<span class="sd">    :param keep_prob: Dropout keep probability</span>
<span class="sd">    :return: BasicDecoderOutput containing training logits and sample_id</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">training_helper</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">TrainingHelper</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">dec_embed_input</span><span class="p">,</span>
                                                       <span class="n">sequence_length</span><span class="o">=</span> <span class="n">target_sequence_length</span><span class="p">,</span>
                                                       <span class="n">time_major</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">training_decoder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">BasicDecoder</span><span class="p">(</span><span class="n">dec_cell</span><span class="p">,</span>
                                                      <span class="n">training_helper</span><span class="p">,</span>
                                                      <span class="n">encoder_state</span><span class="p">,</span>
                                                      <span class="n">output_layer</span><span class="p">)</span>
    <span class="n">training_decoder_output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">dynamic_decode</span><span class="p">(</span><span class="n">training_decoder</span><span class="p">,</span>
                                                               <span class="n">impute_finished</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                                               <span class="n">maximum_iterations</span><span class="o">=</span><span class="n">max_summary_length</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    
    <span class="k">return</span> <span class="n">training_decoder_output</span>



<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_decoding_layer_train</span><span class="p">(</span><span class="n">decoding_layer_train</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Decoding---Inference">Decoding - Inference<a class="anchor-link" href="#Decoding---Inference">&#182;</a></h3><p>Create inference decoder:</p>
<ul>
<li>Create a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/GreedyEmbeddingHelper"><code>tf.contrib.seq2seq.GreedyEmbeddingHelper</code></a></li>
<li>Create a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/BasicDecoder"><code>tf.contrib.seq2seq.BasicDecoder</code></a></li>
<li>Obtain the decoder outputs from <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_decode"><code>tf.contrib.seq2seq.dynamic_decode</code></a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[18]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">decoding_layer_infer</span><span class="p">(</span><span class="n">encoder_state</span><span class="p">,</span> <span class="n">dec_cell</span><span class="p">,</span> <span class="n">dec_embeddings</span><span class="p">,</span> <span class="n">start_of_sequence_id</span><span class="p">,</span>
                         <span class="n">end_of_sequence_id</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span>
                         <span class="n">vocab_size</span><span class="p">,</span> <span class="n">output_layer</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a decoding layer for inference</span>
<span class="sd">    :param encoder_state: Encoder state</span>
<span class="sd">    :param dec_cell: Decoder RNN Cell</span>
<span class="sd">    :param dec_embeddings: Decoder embeddings</span>
<span class="sd">    :param start_of_sequence_id: GO ID</span>
<span class="sd">    :param end_of_sequence_id: EOS Id</span>
<span class="sd">    :param max_target_sequence_length: Maximum length of target sequences</span>
<span class="sd">    :param vocab_size: Size of decoder/target vocabulary</span>
<span class="sd">    :param decoding_scope: TenorFlow Variable Scope for decoding</span>
<span class="sd">    :param output_layer: Function to apply the output layer</span>
<span class="sd">    :param batch_size: Batch size</span>
<span class="sd">    :param keep_prob: Dropout keep probability</span>
<span class="sd">    :return: BasicDecoderOutput containing inference logits and sample_id</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">start_tokens</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="n">start_of_sequence_id</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;start_tokens&#39;</span><span class="p">)</span>
    <span class="n">inference_helper</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">GreedyEmbeddingHelper</span><span class="p">(</span><span class="n">dec_embeddings</span><span class="p">,</span>
                                                               <span class="n">start_tokens</span><span class="p">,</span>
                                                               <span class="n">end_of_sequence_id</span><span class="p">)</span>
    <span class="n">inference_decoder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">BasicDecoder</span><span class="p">(</span><span class="n">dec_cell</span><span class="p">,</span>
                                                       <span class="n">inference_helper</span><span class="p">,</span>
                                                       <span class="n">encoder_state</span><span class="p">,</span>
                                                       <span class="n">output_layer</span><span class="p">)</span>
    <span class="n">inference_decoder_output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">dynamic_decode</span><span class="p">(</span><span class="n">inference_decoder</span><span class="p">,</span>
                                                                <span class="n">impute_finished</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                                                <span class="n">maximum_iterations</span><span class="o">=</span><span class="n">max_target_sequence_length</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">inference_decoder_output</span>



<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_decoding_layer_infer</span><span class="p">(</span><span class="n">decoding_layer_infer</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Build-the-Decoding-Layer">Build the Decoding Layer<a class="anchor-link" href="#Build-the-Decoding-Layer">&#182;</a></h3><p>Implement <code>decoding_layer()</code> to create a Decoder RNN layer.</p>
<ul>
<li>Embed the target sequences</li>
<li>Construct the decoder LSTM cell (just like you constructed the encoder cell above)</li>
<li>Create an output layer to map the outputs of the decoder to the elements of our vocabulary</li>
<li>Use the your <code>decoding_layer_train(encoder_state, dec_cell, dec_embed_input, target_sequence_length, max_target_sequence_length, output_layer, keep_prob)</code> function to get the training logits.</li>
<li>Use your <code>decoding_layer_infer(encoder_state, dec_cell, dec_embeddings, start_of_sequence_id, end_of_sequence_id, max_target_sequence_length, vocab_size, output_layer, batch_size, keep_prob)</code> function to get the inference logits.</li>
</ul>
<p>Note: You'll need to use <a href="https://www.tensorflow.org/api_docs/python/tf/variable_scope">tf.variable_scope</a> to share variables between training and inference.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[23]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">decoding_layer</span><span class="p">(</span><span class="n">dec_input</span><span class="p">,</span> <span class="n">encoder_state</span><span class="p">,</span>
                   <span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span>
                   <span class="n">rnn_size</span><span class="p">,</span>
                   <span class="n">num_layers</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">,</span>
                   <span class="n">batch_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">decoding_embedding_size</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create decoding layer</span>
<span class="sd">    :param dec_input: Decoder input</span>
<span class="sd">    :param encoder_state: Encoder state</span>
<span class="sd">    :param target_sequence_length: The lengths of each sequence in the target batch</span>
<span class="sd">    :param max_target_sequence_length: Maximum length of target sequences</span>
<span class="sd">    :param rnn_size: RNN Size</span>
<span class="sd">    :param num_layers: Number of layers</span>
<span class="sd">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span>
<span class="sd">    :param target_vocab_size: Size of target vocabulary</span>
<span class="sd">    :param batch_size: The size of the batch</span>
<span class="sd">    :param keep_prob: Dropout keep probability</span>
<span class="sd">    :param decoding_embedding_size: Decoding embedding size</span>
<span class="sd">    :return: Tuple of (Training BasicDecoderOutput, Inference BasicDecoderOutput)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">dec_embeddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_uniform</span><span class="p">([</span><span class="n">target_vocab_size</span><span class="p">,</span> <span class="n">decoding_embedding_size</span><span class="p">]))</span>
    <span class="n">dec_embed_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">embedding_lookup</span><span class="p">(</span><span class="n">dec_embeddings</span><span class="p">,</span> <span class="n">dec_input</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">make_cell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">):</span>
        <span class="n">dec_cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">,</span>
                                          <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">random_uniform_initializer</span><span class="p">(</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
        <span class="n">dec_cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">DropoutWrapper</span><span class="p">(</span><span class="n">dec_cell</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">dec_cell</span>
    
    <span class="n">dec_cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">MultiRNNCell</span><span class="p">([</span><span class="n">make_cell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">)])</span>
    
    <span class="n">output_layer</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">target_vocab_size</span><span class="p">,</span>
                        <span class="n">kernel_initializer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal_initializer</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.1</span><span class="p">))</span>
    
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s2">&quot;decode&quot;</span><span class="p">):</span>
        <span class="n">training_decoder_output</span> <span class="o">=</span> <span class="n">decoding_layer_train</span><span class="p">(</span><span class="n">encoder_state</span><span class="p">,</span> <span class="n">dec_cell</span><span class="p">,</span> <span class="n">dec_embed_input</span><span class="p">,</span> 
                                 <span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span> 
                                 <span class="n">output_layer</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>
    
    <span class="n">start_of_sequence_id</span> <span class="o">=</span> <span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;GO&gt;&#39;</span><span class="p">]</span>
    <span class="n">end_of_sequence_id</span> <span class="o">=</span> <span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;EOS&gt;&#39;</span><span class="p">]</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s2">&quot;decode&quot;</span><span class="p">,</span> <span class="n">reuse</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="n">inference_decoder_output</span> <span class="o">=</span> <span class="n">decoding_layer_infer</span><span class="p">(</span><span class="n">encoder_state</span><span class="p">,</span> <span class="n">dec_cell</span><span class="p">,</span> <span class="n">dec_embeddings</span><span class="p">,</span> <span class="n">start_of_sequence_id</span><span class="p">,</span>
                                 <span class="n">end_of_sequence_id</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span>
                                 <span class="n">target_vocab_size</span><span class="p">,</span> <span class="n">output_layer</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">training_decoder_output</span><span class="p">,</span> <span class="n">inference_decoder_output</span>



<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_decoding_layer</span><span class="p">(</span><span class="n">decoding_layer</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Build-the-Neural-Network">Build the Neural Network<a class="anchor-link" href="#Build-the-Neural-Network">&#182;</a></h3><p>Apply the functions you implemented above to:</p>
<ul>
<li>Encode the input using your <code>encoding_layer(rnn_inputs, rnn_size, num_layers, keep_prob,  source_sequence_length, source_vocab_size, encoding_embedding_size)</code>.</li>
<li>Process target data using your <code>process_decoder_input(target_data, target_vocab_to_int, batch_size)</code> function.</li>
<li>Decode the encoded input using your <code>decoding_layer(dec_input, enc_state, target_sequence_length, max_target_sentence_length, rnn_size, num_layers, target_vocab_to_int, target_vocab_size, batch_size, keep_prob, dec_embedding_size)</code> function.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[29]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">seq2seq_model</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="n">target_data</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span>
                  <span class="n">source_sequence_length</span><span class="p">,</span> <span class="n">target_sequence_length</span><span class="p">,</span>
                  <span class="n">max_target_sentence_length</span><span class="p">,</span>
                  <span class="n">source_vocab_size</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">,</span>
                  <span class="n">enc_embedding_size</span><span class="p">,</span> <span class="n">dec_embedding_size</span><span class="p">,</span>
                  <span class="n">rnn_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Build the Sequence-to-Sequence part of the neural network</span>
<span class="sd">    :param input_data: Input placeholder</span>
<span class="sd">    :param target_data: Target placeholder</span>
<span class="sd">    :param keep_prob: Dropout keep probability placeholder</span>
<span class="sd">    :param batch_size: Batch Size</span>
<span class="sd">    :param source_sequence_length: Sequence Lengths of source sequences in the batch</span>
<span class="sd">    :param target_sequence_length: Sequence Lengths of target sequences in the batch</span>
<span class="sd">    :param source_vocab_size: Source vocabulary size</span>
<span class="sd">    :param target_vocab_size: Target vocabulary size</span>
<span class="sd">    :param enc_embedding_size: Decoder embedding size</span>
<span class="sd">    :param dec_embedding_size: Encoder embedding size</span>
<span class="sd">    :param rnn_size: RNN Size</span>
<span class="sd">    :param num_layers: Number of layers</span>
<span class="sd">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span>
<span class="sd">    :return: Tuple of (Training BasicDecoderOutput, Inference BasicDecoderOutput)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">enc_state</span> <span class="o">=</span> <span class="n">encoding_layer</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="n">rnn_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> 
                   <span class="n">source_sequence_length</span><span class="p">,</span> <span class="n">source_vocab_size</span><span class="p">,</span> 
                   <span class="n">enc_embedding_size</span><span class="p">)</span>
    
    <span class="n">dec_input</span> <span class="o">=</span> <span class="n">process_decoder_input</span><span class="p">(</span><span class="n">target_data</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
    
    <span class="n">training_decoder_output</span><span class="p">,</span> <span class="n">inference_decoder_output</span> <span class="o">=</span> <span class="n">decoding_layer</span><span class="p">(</span><span class="n">dec_input</span><span class="p">,</span> <span class="n">enc_state</span><span class="p">,</span>
                   <span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_target_sentence_length</span><span class="p">,</span>
                   <span class="n">rnn_size</span><span class="p">,</span>
                   <span class="n">num_layers</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">,</span>
                   <span class="n">batch_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">dec_embedding_size</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">training_decoder_output</span><span class="p">,</span> <span class="n">inference_decoder_output</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_seq2seq_model</span><span class="p">(</span><span class="n">seq2seq_model</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Neural-Network-Training">Neural Network Training<a class="anchor-link" href="#Neural-Network-Training">&#182;</a></h2><h3 id="Hyperparameters">Hyperparameters<a class="anchor-link" href="#Hyperparameters">&#182;</a></h3><p>Tune the following parameters:</p>
<ul>
<li>Set <code>epochs</code> to the number of epochs.</li>
<li>Set <code>batch_size</code> to the batch size.</li>
<li>Set <code>rnn_size</code> to the size of the RNNs.</li>
<li>Set <code>num_layers</code> to the number of layers.</li>
<li>Set <code>encoding_embedding_size</code> to the size of the embedding for the encoder.</li>
<li>Set <code>decoding_embedding_size</code> to the size of the embedding for the decoder.</li>
<li>Set <code>learning_rate</code> to the learning rate.</li>
<li>Set <code>keep_probability</code> to the Dropout keep probability</li>
<li>Set <code>display_step</code> to state how many steps between each debug output statement</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Number of Epochs</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">60</span>
<span class="c1"># Batch Size</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="c1"># RNN Size</span>
<span class="n">rnn_size</span> <span class="o">=</span> <span class="mi">50</span>
<span class="c1"># Number of Layers</span>
<span class="n">num_layers</span> <span class="o">=</span> <span class="mi">2</span>
<span class="c1"># Embedding Size</span>
<span class="n">encoding_embedding_size</span> <span class="o">=</span> <span class="mi">15</span>
<span class="n">decoding_embedding_size</span> <span class="o">=</span> <span class="mi">15</span>
<span class="c1"># Learning Rate</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="c1"># Dropout Keep Probability</span>
<span class="n">keep_probability</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">display_step</span> <span class="o">=</span> <span class="mi">10</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Build-the-Graph">Build the Graph<a class="anchor-link" href="#Build-the-Graph">&#182;</a></h3><p>Build the graph using the neural network you implemented.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[31]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">save_path</span> <span class="o">=</span> <span class="s1">&#39;checkpoints/dev&#39;</span>
<span class="p">(</span><span class="n">source_int_text</span><span class="p">,</span> <span class="n">target_int_text</span><span class="p">),</span> <span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">),</span> <span class="n">_</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess</span><span class="p">()</span>
<span class="n">max_target_sentence_length</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">source_int_text</span><span class="p">])</span>

<span class="n">train_graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="k">with</span> <span class="n">train_graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
    <span class="n">input_data</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span> <span class="n">source_sequence_length</span> <span class="o">=</span> <span class="n">model_inputs</span><span class="p">()</span>

    <span class="c1">#sequence_length = tf.placeholder_with_default(max_target_sentence_length, None, name=&#39;sequence_length&#39;)</span>
    <span class="n">input_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>

    <span class="n">train_logits</span><span class="p">,</span> <span class="n">inference_logits</span> <span class="o">=</span> <span class="n">seq2seq_model</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reverse</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span>
                                                   <span class="n">targets</span><span class="p">,</span>
                                                   <span class="n">keep_prob</span><span class="p">,</span>
                                                   <span class="n">batch_size</span><span class="p">,</span>
                                                   <span class="n">source_sequence_length</span><span class="p">,</span>
                                                   <span class="n">target_sequence_length</span><span class="p">,</span>
                                                   <span class="n">max_target_sequence_length</span><span class="p">,</span>
                                                   <span class="nb">len</span><span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">),</span>
                                                   <span class="nb">len</span><span class="p">(</span><span class="n">target_vocab_to_int</span><span class="p">),</span>
                                                   <span class="n">encoding_embedding_size</span><span class="p">,</span>
                                                   <span class="n">decoding_embedding_size</span><span class="p">,</span>
                                                   <span class="n">rnn_size</span><span class="p">,</span>
                                                   <span class="n">num_layers</span><span class="p">,</span>
                                                   <span class="n">target_vocab_to_int</span><span class="p">)</span>


    <span class="n">training_logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">train_logits</span><span class="o">.</span><span class="n">rnn_output</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;logits&#39;</span><span class="p">)</span>
    <span class="n">inference_logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">inference_logits</span><span class="o">.</span><span class="n">sample_id</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;predictions&#39;</span><span class="p">)</span>

    <span class="n">masks</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sequence_mask</span><span class="p">(</span><span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;masks&#39;</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s2">&quot;optimization&quot;</span><span class="p">):</span>
        <span class="c1"># Loss function</span>
        <span class="n">cost</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">sequence_loss</span><span class="p">(</span>
            <span class="n">training_logits</span><span class="p">,</span>
            <span class="n">targets</span><span class="p">,</span>
            <span class="n">masks</span><span class="p">)</span>

        <span class="c1"># Optimizer</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span>

        <span class="c1"># Gradient Clipping</span>
        <span class="n">gradients</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">compute_gradients</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
        <span class="n">capped_gradients</span> <span class="o">=</span> <span class="p">[(</span><span class="n">tf</span><span class="o">.</span><span class="n">clip_by_value</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">),</span> <span class="n">var</span><span class="p">)</span> <span class="k">for</span> <span class="n">grad</span><span class="p">,</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">gradients</span> <span class="k">if</span> <span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">]</span>
        <span class="n">train_op</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="n">capped_gradients</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Batch and pad the source and target sequences</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[32]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="k">def</span> <span class="nf">pad_sentence_batch</span><span class="p">(</span><span class="n">sentence_batch</span><span class="p">,</span> <span class="n">pad_int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Pad sentences with &lt;PAD&gt; so that each sentence of a batch has the same length&quot;&quot;&quot;</span>
    <span class="n">max_sentence</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentence_batch</span><span class="p">])</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">sentence</span> <span class="o">+</span> <span class="p">[</span><span class="n">pad_int</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">max_sentence</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">))</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentence_batch</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">get_batches</span><span class="p">(</span><span class="n">sources</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">source_pad_int</span><span class="p">,</span> <span class="n">target_pad_int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Batch targets, sources, and the lengths of their sentences together&quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">batch_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">sources</span><span class="p">)</span><span class="o">//</span><span class="n">batch_size</span><span class="p">):</span>
        <span class="n">start_i</span> <span class="o">=</span> <span class="n">batch_i</span> <span class="o">*</span> <span class="n">batch_size</span>

        <span class="c1"># Slice the right amount for the batch</span>
        <span class="n">sources_batch</span> <span class="o">=</span> <span class="n">sources</span><span class="p">[</span><span class="n">start_i</span><span class="p">:</span><span class="n">start_i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>
        <span class="n">targets_batch</span> <span class="o">=</span> <span class="n">targets</span><span class="p">[</span><span class="n">start_i</span><span class="p">:</span><span class="n">start_i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>

        <span class="c1"># Pad</span>
        <span class="n">pad_sources_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">pad_sentence_batch</span><span class="p">(</span><span class="n">sources_batch</span><span class="p">,</span> <span class="n">source_pad_int</span><span class="p">))</span>
        <span class="n">pad_targets_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">pad_sentence_batch</span><span class="p">(</span><span class="n">targets_batch</span><span class="p">,</span> <span class="n">target_pad_int</span><span class="p">))</span>

        <span class="c1"># Need the lengths for the _lengths parameters</span>
        <span class="n">pad_targets_lengths</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">pad_targets_batch</span><span class="p">:</span>
            <span class="n">pad_targets_lengths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">target</span><span class="p">))</span>

        <span class="n">pad_source_lengths</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">source</span> <span class="ow">in</span> <span class="n">pad_sources_batch</span><span class="p">:</span>
            <span class="n">pad_source_lengths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">source</span><span class="p">))</span>

        <span class="k">yield</span> <span class="n">pad_sources_batch</span><span class="p">,</span> <span class="n">pad_targets_batch</span><span class="p">,</span> <span class="n">pad_source_lengths</span><span class="p">,</span> <span class="n">pad_targets_lengths</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Train">Train<a class="anchor-link" href="#Train">&#182;</a></h3><p>Train the neural network on the preprocessed data. If you have a hard time getting a good loss, check the forms to see if anyone is having the same problem.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[33]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="k">def</span> <span class="nf">get_accuracy</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">logits</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate accuracy</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">max_seq</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">max_seq</span> <span class="o">-</span> <span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
            <span class="n">target</span><span class="p">,</span>
            <span class="p">[(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="n">max_seq</span> <span class="o">-</span> <span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])],</span>
            <span class="s1">&#39;constant&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">max_seq</span> <span class="o">-</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
            <span class="n">logits</span><span class="p">,</span>
            <span class="p">[(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="n">max_seq</span> <span class="o">-</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])],</span>
            <span class="s1">&#39;constant&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">logits</span><span class="p">))</span>

<span class="c1"># Split data to training and validation sets</span>
<span class="n">train_source</span> <span class="o">=</span> <span class="n">source_int_text</span><span class="p">[</span><span class="n">batch_size</span><span class="p">:]</span>
<span class="n">train_target</span> <span class="o">=</span> <span class="n">target_int_text</span><span class="p">[</span><span class="n">batch_size</span><span class="p">:]</span>
<span class="n">valid_source</span> <span class="o">=</span> <span class="n">source_int_text</span><span class="p">[:</span><span class="n">batch_size</span><span class="p">]</span>
<span class="n">valid_target</span> <span class="o">=</span> <span class="n">target_int_text</span><span class="p">[:</span><span class="n">batch_size</span><span class="p">]</span>
<span class="p">(</span><span class="n">valid_sources_batch</span><span class="p">,</span> <span class="n">valid_targets_batch</span><span class="p">,</span> <span class="n">valid_sources_lengths</span><span class="p">,</span> <span class="n">valid_targets_lengths</span> <span class="p">)</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">get_batches</span><span class="p">(</span><span class="n">valid_source</span><span class="p">,</span>
                                                                                                             <span class="n">valid_target</span><span class="p">,</span>
                                                                                                             <span class="n">batch_size</span><span class="p">,</span>
                                                                                                             <span class="n">source_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;PAD&gt;&#39;</span><span class="p">],</span>
                                                                                                             <span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;PAD&gt;&#39;</span><span class="p">]))</span>                                                                                                  
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">train_graph</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>

    <span class="k">for</span> <span class="n">epoch_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">batch_i</span><span class="p">,</span> <span class="p">(</span><span class="n">source_batch</span><span class="p">,</span> <span class="n">target_batch</span><span class="p">,</span> <span class="n">sources_lengths</span><span class="p">,</span> <span class="n">targets_lengths</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span>
                <span class="n">get_batches</span><span class="p">(</span><span class="n">train_source</span><span class="p">,</span> <span class="n">train_target</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span>
                            <span class="n">source_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;PAD&gt;&#39;</span><span class="p">],</span>
                            <span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;PAD&gt;&#39;</span><span class="p">])):</span>

            <span class="n">_</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                <span class="p">[</span><span class="n">train_op</span><span class="p">,</span> <span class="n">cost</span><span class="p">],</span>
                <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="n">source_batch</span><span class="p">,</span>
                 <span class="n">targets</span><span class="p">:</span> <span class="n">target_batch</span><span class="p">,</span>
                 <span class="n">lr</span><span class="p">:</span> <span class="n">learning_rate</span><span class="p">,</span>
                 <span class="n">target_sequence_length</span><span class="p">:</span> <span class="n">targets_lengths</span><span class="p">,</span>
                 <span class="n">source_sequence_length</span><span class="p">:</span> <span class="n">sources_lengths</span><span class="p">,</span>
                 <span class="n">keep_prob</span><span class="p">:</span> <span class="n">keep_probability</span><span class="p">})</span>


            <span class="k">if</span> <span class="n">batch_i</span> <span class="o">%</span> <span class="n">display_step</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">batch_i</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>


                <span class="n">batch_train_logits</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                    <span class="n">inference_logits</span><span class="p">,</span>
                    <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="n">source_batch</span><span class="p">,</span>
                     <span class="n">source_sequence_length</span><span class="p">:</span> <span class="n">sources_lengths</span><span class="p">,</span>
                     <span class="n">target_sequence_length</span><span class="p">:</span> <span class="n">targets_lengths</span><span class="p">,</span>
                     <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})</span>


                <span class="n">batch_valid_logits</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                    <span class="n">inference_logits</span><span class="p">,</span>
                    <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="n">valid_sources_batch</span><span class="p">,</span>
                     <span class="n">source_sequence_length</span><span class="p">:</span> <span class="n">valid_sources_lengths</span><span class="p">,</span>
                     <span class="n">target_sequence_length</span><span class="p">:</span> <span class="n">valid_targets_lengths</span><span class="p">,</span>
                     <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})</span>

                <span class="n">train_acc</span> <span class="o">=</span> <span class="n">get_accuracy</span><span class="p">(</span><span class="n">target_batch</span><span class="p">,</span> <span class="n">batch_train_logits</span><span class="p">)</span>

                <span class="n">valid_acc</span> <span class="o">=</span> <span class="n">get_accuracy</span><span class="p">(</span><span class="n">valid_targets_batch</span><span class="p">,</span> <span class="n">batch_valid_logits</span><span class="p">)</span>

                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch </span><span class="si">{:&gt;3}</span><span class="s1"> Batch </span><span class="si">{:&gt;4}</span><span class="s1">/</span><span class="si">{}</span><span class="s1"> - Train Accuracy: </span><span class="si">{:&gt;6.4f}</span><span class="s1">, Validation Accuracy: </span><span class="si">{:&gt;6.4f}</span><span class="s1">, Loss: </span><span class="si">{:&gt;6.4f}</span><span class="s1">&#39;</span>
                      <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch_i</span><span class="p">,</span> <span class="n">batch_i</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">source_int_text</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">train_acc</span><span class="p">,</span> <span class="n">valid_acc</span><span class="p">,</span> <span class="n">loss</span><span class="p">))</span>

    <span class="c1"># Save Model</span>
    <span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span>
    <span class="n">saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">save_path</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Model Trained and Saved&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch   0 Batch   10/1077 - Train Accuracy: 0.2081, Validation Accuracy: 0.3153, Loss: 5.5769
Epoch   0 Batch   20/1077 - Train Accuracy: 0.2422, Validation Accuracy: 0.3185, Loss: 4.7171
Epoch   0 Batch   30/1077 - Train Accuracy: 0.2629, Validation Accuracy: 0.3349, Loss: 4.0412
Epoch   0 Batch   40/1077 - Train Accuracy: 0.2660, Validation Accuracy: 0.3363, Loss: 3.6907
Epoch   0 Batch   50/1077 - Train Accuracy: 0.2605, Validation Accuracy: 0.3366, Loss: 3.5677
Epoch   0 Batch   60/1077 - Train Accuracy: 0.2987, Validation Accuracy: 0.3366, Loss: 3.3236
Epoch   0 Batch   70/1077 - Train Accuracy: 0.2307, Validation Accuracy: 0.3366, Loss: 3.4878
Epoch   0 Batch   80/1077 - Train Accuracy: 0.2715, Validation Accuracy: 0.3363, Loss: 3.2583
Epoch   0 Batch   90/1077 - Train Accuracy: 0.2668, Validation Accuracy: 0.3366, Loss: 3.2462
Epoch   0 Batch  100/1077 - Train Accuracy: 0.2617, Validation Accuracy: 0.3366, Loss: 3.2098
Epoch   0 Batch  110/1077 - Train Accuracy: 0.3164, Validation Accuracy: 0.3622, Loss: 3.1052
Epoch   0 Batch  120/1077 - Train Accuracy: 0.3137, Validation Accuracy: 0.3704, Loss: 3.1210
Epoch   0 Batch  130/1077 - Train Accuracy: 0.3627, Validation Accuracy: 0.3984, Loss: 2.9658
Epoch   0 Batch  140/1077 - Train Accuracy: 0.3100, Validation Accuracy: 0.4006, Loss: 3.1994
Epoch   0 Batch  150/1077 - Train Accuracy: 0.3854, Validation Accuracy: 0.4034, Loss: 2.8886
Epoch   0 Batch  160/1077 - Train Accuracy: 0.3441, Validation Accuracy: 0.4009, Loss: 2.9668
Epoch   0 Batch  170/1077 - Train Accuracy: 0.3215, Validation Accuracy: 0.4020, Loss: 3.0541
Epoch   0 Batch  180/1077 - Train Accuracy: 0.3477, Validation Accuracy: 0.4031, Loss: 2.9521
Epoch   0 Batch  190/1077 - Train Accuracy: 0.3473, Validation Accuracy: 0.4041, Loss: 2.9590
Epoch   0 Batch  200/1077 - Train Accuracy: 0.3500, Validation Accuracy: 0.4080, Loss: 2.9138
Epoch   0 Batch  210/1077 - Train Accuracy: 0.3850, Validation Accuracy: 0.4165, Loss: 2.8129
Epoch   0 Batch  220/1077 - Train Accuracy: 0.3248, Validation Accuracy: 0.4105, Loss: 2.9709
Epoch   0 Batch  230/1077 - Train Accuracy: 0.3988, Validation Accuracy: 0.4226, Loss: 2.7139
Epoch   0 Batch  240/1077 - Train Accuracy: 0.3883, Validation Accuracy: 0.4339, Loss: 2.7665
Epoch   0 Batch  250/1077 - Train Accuracy: 0.4311, Validation Accuracy: 0.4471, Loss: 2.6028
Epoch   0 Batch  260/1077 - Train Accuracy: 0.4159, Validation Accuracy: 0.4503, Loss: 2.6528
Epoch   0 Batch  270/1077 - Train Accuracy: 0.3613, Validation Accuracy: 0.4428, Loss: 2.8615
Epoch   0 Batch  280/1077 - Train Accuracy: 0.3969, Validation Accuracy: 0.4453, Loss: 2.7178
Epoch   0 Batch  290/1077 - Train Accuracy: 0.3996, Validation Accuracy: 0.4485, Loss: 2.7084
Epoch   0 Batch  300/1077 - Train Accuracy: 0.3701, Validation Accuracy: 0.4521, Loss: 2.8192
Epoch   0 Batch  310/1077 - Train Accuracy: 0.3926, Validation Accuracy: 0.4581, Loss: 2.7048
Epoch   0 Batch  320/1077 - Train Accuracy: 0.4043, Validation Accuracy: 0.4567, Loss: 2.6588
Epoch   0 Batch  330/1077 - Train Accuracy: 0.4148, Validation Accuracy: 0.4574, Loss: 2.6136
Epoch   0 Batch  340/1077 - Train Accuracy: 0.3832, Validation Accuracy: 0.4609, Loss: 2.7370
Epoch   0 Batch  350/1077 - Train Accuracy: 0.3988, Validation Accuracy: 0.4634, Loss: 2.6857
Epoch   0 Batch  360/1077 - Train Accuracy: 0.4145, Validation Accuracy: 0.4627, Loss: 2.5734
Epoch   0 Batch  370/1077 - Train Accuracy: 0.4249, Validation Accuracy: 0.4680, Loss: 2.5003
Epoch   0 Batch  380/1077 - Train Accuracy: 0.4336, Validation Accuracy: 0.4691, Loss: 2.4956
Epoch   0 Batch  390/1077 - Train Accuracy: 0.3957, Validation Accuracy: 0.4730, Loss: 2.6115
Epoch   0 Batch  400/1077 - Train Accuracy: 0.4227, Validation Accuracy: 0.4727, Loss: 2.5260
Epoch   0 Batch  410/1077 - Train Accuracy: 0.3960, Validation Accuracy: 0.4787, Loss: 2.5872
Epoch   0 Batch  420/1077 - Train Accuracy: 0.4168, Validation Accuracy: 0.4787, Loss: 2.4679
Epoch   0 Batch  430/1077 - Train Accuracy: 0.4254, Validation Accuracy: 0.4858, Loss: 2.4484
Epoch   0 Batch  440/1077 - Train Accuracy: 0.4281, Validation Accuracy: 0.4798, Loss: 2.4283
Epoch   0 Batch  450/1077 - Train Accuracy: 0.4293, Validation Accuracy: 0.4787, Loss: 2.4304
Epoch   0 Batch  460/1077 - Train Accuracy: 0.4250, Validation Accuracy: 0.4929, Loss: 2.4436
Epoch   0 Batch  470/1077 - Train Accuracy: 0.4132, Validation Accuracy: 0.4734, Loss: 2.4850
Epoch   0 Batch  480/1077 - Train Accuracy: 0.4322, Validation Accuracy: 0.4929, Loss: 2.4279
Epoch   0 Batch  490/1077 - Train Accuracy: 0.4242, Validation Accuracy: 0.4826, Loss: 2.4116
Epoch   0 Batch  500/1077 - Train Accuracy: 0.4566, Validation Accuracy: 0.4947, Loss: 2.3233
Epoch   0 Batch  510/1077 - Train Accuracy: 0.4695, Validation Accuracy: 0.4964, Loss: 2.2967
Epoch   0 Batch  520/1077 - Train Accuracy: 0.4833, Validation Accuracy: 0.5011, Loss: 2.2385
Epoch   0 Batch  530/1077 - Train Accuracy: 0.4344, Validation Accuracy: 0.4893, Loss: 2.3718
Epoch   0 Batch  540/1077 - Train Accuracy: 0.4418, Validation Accuracy: 0.5032, Loss: 2.2184
Epoch   0 Batch  550/1077 - Train Accuracy: 0.4348, Validation Accuracy: 0.5028, Loss: 2.3831
Epoch   0 Batch  560/1077 - Train Accuracy: 0.4559, Validation Accuracy: 0.4986, Loss: 2.2472
Epoch   0 Batch  570/1077 - Train Accuracy: 0.4420, Validation Accuracy: 0.5039, Loss: 2.3541
Epoch   0 Batch  580/1077 - Train Accuracy: 0.4847, Validation Accuracy: 0.5085, Loss: 2.1576
Epoch   0 Batch  590/1077 - Train Accuracy: 0.4404, Validation Accuracy: 0.5089, Loss: 2.3389
Epoch   0 Batch  600/1077 - Train Accuracy: 0.4970, Validation Accuracy: 0.5078, Loss: 2.1069
Epoch   0 Batch  610/1077 - Train Accuracy: 0.4387, Validation Accuracy: 0.5075, Loss: 2.2941
Epoch   0 Batch  620/1077 - Train Accuracy: 0.4605, Validation Accuracy: 0.5085, Loss: 2.1924
Epoch   0 Batch  630/1077 - Train Accuracy: 0.4785, Validation Accuracy: 0.5089, Loss: 2.1508
Epoch   0 Batch  640/1077 - Train Accuracy: 0.4594, Validation Accuracy: 0.5082, Loss: 2.0913
Epoch   0 Batch  650/1077 - Train Accuracy: 0.4559, Validation Accuracy: 0.5085, Loss: 2.1616
Epoch   0 Batch  660/1077 - Train Accuracy: 0.4598, Validation Accuracy: 0.5053, Loss: 2.1297
Epoch   0 Batch  670/1077 - Train Accuracy: 0.5305, Validation Accuracy: 0.5124, Loss: 1.8656
Epoch   0 Batch  680/1077 - Train Accuracy: 0.4658, Validation Accuracy: 0.5103, Loss: 2.0186
Epoch   0 Batch  690/1077 - Train Accuracy: 0.4715, Validation Accuracy: 0.5067, Loss: 2.0074
Epoch   0 Batch  700/1077 - Train Accuracy: 0.4688, Validation Accuracy: 0.5146, Loss: 2.0111
Epoch   0 Batch  710/1077 - Train Accuracy: 0.4422, Validation Accuracy: 0.5117, Loss: 2.0317
Epoch   0 Batch  720/1077 - Train Accuracy: 0.4597, Validation Accuracy: 0.5170, Loss: 2.0944
Epoch   0 Batch  730/1077 - Train Accuracy: 0.4473, Validation Accuracy: 0.5000, Loss: 1.9860
Epoch   0 Batch  740/1077 - Train Accuracy: 0.4809, Validation Accuracy: 0.5124, Loss: 1.9436
Epoch   0 Batch  750/1077 - Train Accuracy: 0.4762, Validation Accuracy: 0.5114, Loss: 1.9275
Epoch   0 Batch  760/1077 - Train Accuracy: 0.4910, Validation Accuracy: 0.5167, Loss: 1.9297
Epoch   0 Batch  770/1077 - Train Accuracy: 0.4866, Validation Accuracy: 0.5103, Loss: 1.8608
Epoch   0 Batch  780/1077 - Train Accuracy: 0.4723, Validation Accuracy: 0.5135, Loss: 1.9395
Epoch   0 Batch  790/1077 - Train Accuracy: 0.4352, Validation Accuracy: 0.5170, Loss: 1.9981
Epoch   0 Batch  800/1077 - Train Accuracy: 0.4465, Validation Accuracy: 0.5167, Loss: 1.9151
Epoch   0 Batch  810/1077 - Train Accuracy: 0.4881, Validation Accuracy: 0.5075, Loss: 1.7497
Epoch   0 Batch  820/1077 - Train Accuracy: 0.4465, Validation Accuracy: 0.5192, Loss: 1.8974
Epoch   0 Batch  830/1077 - Train Accuracy: 0.4562, Validation Accuracy: 0.5121, Loss: 1.8134
Epoch   0 Batch  840/1077 - Train Accuracy: 0.4781, Validation Accuracy: 0.5238, Loss: 1.8318
Epoch   0 Batch  850/1077 - Train Accuracy: 0.4807, Validation Accuracy: 0.5213, Loss: 1.8212
Epoch   0 Batch  860/1077 - Train Accuracy: 0.4818, Validation Accuracy: 0.5195, Loss: 1.7465
Epoch   0 Batch  870/1077 - Train Accuracy: 0.4437, Validation Accuracy: 0.5138, Loss: 1.9122
Epoch   0 Batch  880/1077 - Train Accuracy: 0.5020, Validation Accuracy: 0.5181, Loss: 1.7074
Epoch   0 Batch  890/1077 - Train Accuracy: 0.5305, Validation Accuracy: 0.5067, Loss: 1.5832
Epoch   0 Batch  900/1077 - Train Accuracy: 0.4770, Validation Accuracy: 0.5178, Loss: 1.7893
Epoch   0 Batch  910/1077 - Train Accuracy: 0.4665, Validation Accuracy: 0.5057, Loss: 1.7001
Epoch   0 Batch  920/1077 - Train Accuracy: 0.4805, Validation Accuracy: 0.5199, Loss: 1.7342
Epoch   0 Batch  930/1077 - Train Accuracy: 0.4641, Validation Accuracy: 0.5039, Loss: 1.6643
Epoch   0 Batch  940/1077 - Train Accuracy: 0.4539, Validation Accuracy: 0.5131, Loss: 1.7475
Epoch   0 Batch  950/1077 - Train Accuracy: 0.4743, Validation Accuracy: 0.5110, Loss: 1.6634
Epoch   0 Batch  960/1077 - Train Accuracy: 0.4818, Validation Accuracy: 0.4972, Loss: 1.5801
Epoch   0 Batch  970/1077 - Train Accuracy: 0.4641, Validation Accuracy: 0.5032, Loss: 1.6687
Epoch   0 Batch  980/1077 - Train Accuracy: 0.4809, Validation Accuracy: 0.4972, Loss: 1.6059
Epoch   0 Batch  990/1077 - Train Accuracy: 0.4613, Validation Accuracy: 0.5096, Loss: 1.6985
Epoch   0 Batch 1000/1077 - Train Accuracy: 0.5060, Validation Accuracy: 0.4879, Loss: 1.5299
Epoch   0 Batch 1010/1077 - Train Accuracy: 0.4398, Validation Accuracy: 0.4918, Loss: 1.6442
Epoch   0 Batch 1020/1077 - Train Accuracy: 0.4586, Validation Accuracy: 0.4982, Loss: 1.5716
Epoch   0 Batch 1030/1077 - Train Accuracy: 0.4570, Validation Accuracy: 0.4883, Loss: 1.6206
Epoch   0 Batch 1040/1077 - Train Accuracy: 0.4334, Validation Accuracy: 0.4762, Loss: 1.6272
Epoch   0 Batch 1050/1077 - Train Accuracy: 0.4051, Validation Accuracy: 0.4808, Loss: 1.6435
Epoch   0 Batch 1060/1077 - Train Accuracy: 0.4594, Validation Accuracy: 0.4858, Loss: 1.5180
Epoch   0 Batch 1070/1077 - Train Accuracy: 0.4332, Validation Accuracy: 0.4734, Loss: 1.5607
Epoch   1 Batch   10/1077 - Train Accuracy: 0.3980, Validation Accuracy: 0.4688, Loss: 1.5792
Epoch   1 Batch   20/1077 - Train Accuracy: 0.4332, Validation Accuracy: 0.4737, Loss: 1.4411
Epoch   1 Batch   30/1077 - Train Accuracy: 0.4527, Validation Accuracy: 0.4847, Loss: 1.4481
Epoch   1 Batch   40/1077 - Train Accuracy: 0.4285, Validation Accuracy: 0.4666, Loss: 1.4846
Epoch   1 Batch   50/1077 - Train Accuracy: 0.4129, Validation Accuracy: 0.4648, Loss: 1.4924
Epoch   1 Batch   60/1077 - Train Accuracy: 0.4208, Validation Accuracy: 0.4549, Loss: 1.4039
Epoch   1 Batch   70/1077 - Train Accuracy: 0.3791, Validation Accuracy: 0.4634, Loss: 1.4900
Epoch   1 Batch   80/1077 - Train Accuracy: 0.4125, Validation Accuracy: 0.4602, Loss: 1.4129
Epoch   1 Batch   90/1077 - Train Accuracy: 0.4301, Validation Accuracy: 0.4741, Loss: 1.4548
Epoch   1 Batch  100/1077 - Train Accuracy: 0.4258, Validation Accuracy: 0.4680, Loss: 1.3876
Epoch   1 Batch  110/1077 - Train Accuracy: 0.4457, Validation Accuracy: 0.4652, Loss: 1.3404
Epoch   1 Batch  120/1077 - Train Accuracy: 0.4176, Validation Accuracy: 0.4545, Loss: 1.3697
Epoch   1 Batch  130/1077 - Train Accuracy: 0.4249, Validation Accuracy: 0.4585, Loss: 1.2733
Epoch   1 Batch  140/1077 - Train Accuracy: 0.4141, Validation Accuracy: 0.4762, Loss: 1.4271
Epoch   1 Batch  150/1077 - Train Accuracy: 0.4926, Validation Accuracy: 0.4822, Loss: 1.2727
Epoch   1 Batch  160/1077 - Train Accuracy: 0.4734, Validation Accuracy: 0.4908, Loss: 1.3058
Epoch   1 Batch  170/1077 - Train Accuracy: 0.4652, Validation Accuracy: 0.5327, Loss: 1.3438
Epoch   1 Batch  180/1077 - Train Accuracy: 0.4824, Validation Accuracy: 0.5256, Loss: 1.2794
Epoch   1 Batch  190/1077 - Train Accuracy: 0.5129, Validation Accuracy: 0.5359, Loss: 1.2786
Epoch   1 Batch  200/1077 - Train Accuracy: 0.4520, Validation Accuracy: 0.5174, Loss: 1.2855
Epoch   1 Batch  210/1077 - Train Accuracy: 0.4922, Validation Accuracy: 0.5224, Loss: 1.2755
Epoch   1 Batch  220/1077 - Train Accuracy: 0.4901, Validation Accuracy: 0.5419, Loss: 1.2808
Epoch   1 Batch  230/1077 - Train Accuracy: 0.4695, Validation Accuracy: 0.4808, Loss: 1.1683
Epoch   1 Batch  240/1077 - Train Accuracy: 0.4566, Validation Accuracy: 0.5036, Loss: 1.2114
Epoch   1 Batch  250/1077 - Train Accuracy: 0.4812, Validation Accuracy: 0.5249, Loss: 1.1509
Epoch   1 Batch  260/1077 - Train Accuracy: 0.4914, Validation Accuracy: 0.5231, Loss: 1.1761
Epoch   1 Batch  270/1077 - Train Accuracy: 0.4555, Validation Accuracy: 0.5408, Loss: 1.2861
Epoch   1 Batch  280/1077 - Train Accuracy: 0.4855, Validation Accuracy: 0.5295, Loss: 1.2354
Epoch   1 Batch  290/1077 - Train Accuracy: 0.4934, Validation Accuracy: 0.5487, Loss: 1.2301
Epoch   1 Batch  300/1077 - Train Accuracy: 0.4585, Validation Accuracy: 0.5316, Loss: 1.2400
Epoch   1 Batch  310/1077 - Train Accuracy: 0.4566, Validation Accuracy: 0.5373, Loss: 1.1970
Epoch   1 Batch  320/1077 - Train Accuracy: 0.4789, Validation Accuracy: 0.5302, Loss: 1.1947
Epoch   1 Batch  330/1077 - Train Accuracy: 0.4973, Validation Accuracy: 0.5263, Loss: 1.1745
Epoch   1 Batch  340/1077 - Train Accuracy: 0.4453, Validation Accuracy: 0.5114, Loss: 1.1910
Epoch   1 Batch  350/1077 - Train Accuracy: 0.4480, Validation Accuracy: 0.5153, Loss: 1.2377
Epoch   1 Batch  360/1077 - Train Accuracy: 0.4566, Validation Accuracy: 0.5245, Loss: 1.1489
Epoch   1 Batch  370/1077 - Train Accuracy: 0.4952, Validation Accuracy: 0.5312, Loss: 1.0865
Epoch   1 Batch  380/1077 - Train Accuracy: 0.4961, Validation Accuracy: 0.5149, Loss: 1.1270
Epoch   1 Batch  390/1077 - Train Accuracy: 0.4562, Validation Accuracy: 0.5263, Loss: 1.1893
Epoch   1 Batch  400/1077 - Train Accuracy: 0.4641, Validation Accuracy: 0.5320, Loss: 1.1550
Epoch   1 Batch  410/1077 - Train Accuracy: 0.4544, Validation Accuracy: 0.5270, Loss: 1.1699
Epoch   1 Batch  420/1077 - Train Accuracy: 0.4664, Validation Accuracy: 0.5156, Loss: 1.1179
Epoch   1 Batch  430/1077 - Train Accuracy: 0.4719, Validation Accuracy: 0.5149, Loss: 1.1356
Epoch   1 Batch  440/1077 - Train Accuracy: 0.4957, Validation Accuracy: 0.5344, Loss: 1.1259
Epoch   1 Batch  450/1077 - Train Accuracy: 0.4695, Validation Accuracy: 0.5249, Loss: 1.1199
Epoch   1 Batch  460/1077 - Train Accuracy: 0.3930, Validation Accuracy: 0.4961, Loss: 1.1255
Epoch   1 Batch  470/1077 - Train Accuracy: 0.4597, Validation Accuracy: 0.5224, Loss: 1.1315
Epoch   1 Batch  480/1077 - Train Accuracy: 0.4856, Validation Accuracy: 0.5128, Loss: 1.1213
Epoch   1 Batch  490/1077 - Train Accuracy: 0.4574, Validation Accuracy: 0.5156, Loss: 1.0978
Epoch   1 Batch  500/1077 - Train Accuracy: 0.5059, Validation Accuracy: 0.5291, Loss: 1.0787
Epoch   1 Batch  510/1077 - Train Accuracy: 0.5195, Validation Accuracy: 0.5220, Loss: 1.0625
Epoch   1 Batch  520/1077 - Train Accuracy: 0.5097, Validation Accuracy: 0.5199, Loss: 1.0141
Epoch   1 Batch  530/1077 - Train Accuracy: 0.4758, Validation Accuracy: 0.5309, Loss: 1.0593
Epoch   1 Batch  540/1077 - Train Accuracy: 0.4980, Validation Accuracy: 0.5227, Loss: 1.0413
Epoch   1 Batch  550/1077 - Train Accuracy: 0.4535, Validation Accuracy: 0.5167, Loss: 1.0959
Epoch   1 Batch  560/1077 - Train Accuracy: 0.4934, Validation Accuracy: 0.5273, Loss: 1.0504
Epoch   1 Batch  570/1077 - Train Accuracy: 0.4782, Validation Accuracy: 0.5252, Loss: 1.0839
Epoch   1 Batch  580/1077 - Train Accuracy: 0.5491, Validation Accuracy: 0.5270, Loss: 0.9818
Epoch   1 Batch  590/1077 - Train Accuracy: 0.4745, Validation Accuracy: 0.5256, Loss: 1.0816
Epoch   1 Batch  600/1077 - Train Accuracy: 0.5093, Validation Accuracy: 0.5252, Loss: 1.0077
Epoch   1 Batch  610/1077 - Train Accuracy: 0.4675, Validation Accuracy: 0.5153, Loss: 1.0849
Epoch   1 Batch  620/1077 - Train Accuracy: 0.4797, Validation Accuracy: 0.5202, Loss: 1.0353
Epoch   1 Batch  630/1077 - Train Accuracy: 0.5082, Validation Accuracy: 0.5270, Loss: 1.0130
Epoch   1 Batch  640/1077 - Train Accuracy: 0.4870, Validation Accuracy: 0.5344, Loss: 0.9996
Epoch   1 Batch  650/1077 - Train Accuracy: 0.4746, Validation Accuracy: 0.5277, Loss: 1.0405
Epoch   1 Batch  660/1077 - Train Accuracy: 0.4930, Validation Accuracy: 0.5156, Loss: 1.0503
Epoch   1 Batch  670/1077 - Train Accuracy: 0.5430, Validation Accuracy: 0.5153, Loss: 0.9296
Epoch   1 Batch  680/1077 - Train Accuracy: 0.5060, Validation Accuracy: 0.5227, Loss: 0.9954
Epoch   1 Batch  690/1077 - Train Accuracy: 0.5039, Validation Accuracy: 0.5234, Loss: 1.0008
Epoch   1 Batch  700/1077 - Train Accuracy: 0.5016, Validation Accuracy: 0.5284, Loss: 0.9901
Epoch   1 Batch  710/1077 - Train Accuracy: 0.4738, Validation Accuracy: 0.5220, Loss: 1.0005
Epoch   1 Batch  720/1077 - Train Accuracy: 0.4988, Validation Accuracy: 0.5199, Loss: 1.0634
Epoch   1 Batch  730/1077 - Train Accuracy: 0.5047, Validation Accuracy: 0.5241, Loss: 0.9814
Epoch   1 Batch  740/1077 - Train Accuracy: 0.5195, Validation Accuracy: 0.5252, Loss: 0.9700
Epoch   1 Batch  750/1077 - Train Accuracy: 0.4926, Validation Accuracy: 0.5234, Loss: 0.9694
Epoch   1 Batch  760/1077 - Train Accuracy: 0.5109, Validation Accuracy: 0.5305, Loss: 0.9991
Epoch   1 Batch  770/1077 - Train Accuracy: 0.5004, Validation Accuracy: 0.5238, Loss: 0.9538
Epoch   1 Batch  780/1077 - Train Accuracy: 0.4586, Validation Accuracy: 0.5163, Loss: 1.0143
Epoch   1 Batch  790/1077 - Train Accuracy: 0.4211, Validation Accuracy: 0.5156, Loss: 1.0273
Epoch   1 Batch  800/1077 - Train Accuracy: 0.4602, Validation Accuracy: 0.5270, Loss: 0.9791
Epoch   1 Batch  810/1077 - Train Accuracy: 0.5454, Validation Accuracy: 0.5288, Loss: 0.9173
Epoch   1 Batch  820/1077 - Train Accuracy: 0.4676, Validation Accuracy: 0.5366, Loss: 0.9808
Epoch   1 Batch  830/1077 - Train Accuracy: 0.4742, Validation Accuracy: 0.5295, Loss: 0.9485
Epoch   1 Batch  840/1077 - Train Accuracy: 0.4875, Validation Accuracy: 0.5142, Loss: 0.9380
Epoch   1 Batch  850/1077 - Train Accuracy: 0.4762, Validation Accuracy: 0.4979, Loss: 0.9865
Epoch   1 Batch  860/1077 - Train Accuracy: 0.5060, Validation Accuracy: 0.5295, Loss: 0.9448
Epoch   1 Batch  870/1077 - Train Accuracy: 0.4568, Validation Accuracy: 0.5046, Loss: 1.0426
Epoch   1 Batch  880/1077 - Train Accuracy: 0.5301, Validation Accuracy: 0.5220, Loss: 0.9303
Epoch   1 Batch  890/1077 - Train Accuracy: 0.5636, Validation Accuracy: 0.5430, Loss: 0.8654
Epoch   1 Batch  900/1077 - Train Accuracy: 0.4824, Validation Accuracy: 0.4986, Loss: 0.9582
Epoch   1 Batch  910/1077 - Train Accuracy: 0.5108, Validation Accuracy: 0.5309, Loss: 0.9458
Epoch   1 Batch  920/1077 - Train Accuracy: 0.4934, Validation Accuracy: 0.5298, Loss: 0.9510
Epoch   1 Batch  930/1077 - Train Accuracy: 0.5027, Validation Accuracy: 0.5348, Loss: 0.9347
Epoch   1 Batch  940/1077 - Train Accuracy: 0.4813, Validation Accuracy: 0.5302, Loss: 0.9617
Epoch   1 Batch  950/1077 - Train Accuracy: 0.4859, Validation Accuracy: 0.5188, Loss: 0.9163
Epoch   1 Batch  960/1077 - Train Accuracy: 0.5134, Validation Accuracy: 0.5298, Loss: 0.9060
Epoch   1 Batch  970/1077 - Train Accuracy: 0.5043, Validation Accuracy: 0.5192, Loss: 0.9552
Epoch   1 Batch  980/1077 - Train Accuracy: 0.5289, Validation Accuracy: 0.5334, Loss: 0.9203
Epoch   1 Batch  990/1077 - Train Accuracy: 0.5074, Validation Accuracy: 0.5472, Loss: 0.9756
Epoch   1 Batch 1000/1077 - Train Accuracy: 0.5428, Validation Accuracy: 0.5508, Loss: 0.8729
Epoch   1 Batch 1010/1077 - Train Accuracy: 0.5188, Validation Accuracy: 0.5518, Loss: 0.9402
Epoch   1 Batch 1020/1077 - Train Accuracy: 0.5090, Validation Accuracy: 0.5348, Loss: 0.8967
Epoch   1 Batch 1030/1077 - Train Accuracy: 0.4945, Validation Accuracy: 0.5302, Loss: 0.9238
Epoch   1 Batch 1040/1077 - Train Accuracy: 0.5119, Validation Accuracy: 0.5227, Loss: 0.9476
Epoch   1 Batch 1050/1077 - Train Accuracy: 0.4516, Validation Accuracy: 0.5295, Loss: 0.9479
Epoch   1 Batch 1060/1077 - Train Accuracy: 0.5012, Validation Accuracy: 0.5288, Loss: 0.9026
Epoch   1 Batch 1070/1077 - Train Accuracy: 0.4828, Validation Accuracy: 0.5380, Loss: 0.9227
Epoch   2 Batch   10/1077 - Train Accuracy: 0.4893, Validation Accuracy: 0.5391, Loss: 0.9398
Epoch   2 Batch   20/1077 - Train Accuracy: 0.4945, Validation Accuracy: 0.5334, Loss: 0.8627
Epoch   2 Batch   30/1077 - Train Accuracy: 0.4891, Validation Accuracy: 0.5227, Loss: 0.8819
Epoch   2 Batch   40/1077 - Train Accuracy: 0.4965, Validation Accuracy: 0.5423, Loss: 0.8951
Epoch   2 Batch   50/1077 - Train Accuracy: 0.4855, Validation Accuracy: 0.5487, Loss: 0.9220
Epoch   2 Batch   60/1077 - Train Accuracy: 0.5227, Validation Accuracy: 0.5476, Loss: 0.8555
Epoch   2 Batch   70/1077 - Train Accuracy: 0.5164, Validation Accuracy: 0.5636, Loss: 0.9168
Epoch   2 Batch   80/1077 - Train Accuracy: 0.4859, Validation Accuracy: 0.5494, Loss: 0.8908
Epoch   2 Batch   90/1077 - Train Accuracy: 0.5027, Validation Accuracy: 0.5494, Loss: 0.9163
Epoch   2 Batch  100/1077 - Train Accuracy: 0.4895, Validation Accuracy: 0.5476, Loss: 0.8889
Epoch   2 Batch  110/1077 - Train Accuracy: 0.5500, Validation Accuracy: 0.5643, Loss: 0.8463
Epoch   2 Batch  120/1077 - Train Accuracy: 0.4965, Validation Accuracy: 0.5494, Loss: 0.8946
Epoch   2 Batch  130/1077 - Train Accuracy: 0.5223, Validation Accuracy: 0.5440, Loss: 0.8339
Epoch   2 Batch  140/1077 - Train Accuracy: 0.4539, Validation Accuracy: 0.5494, Loss: 0.9233
Epoch   2 Batch  150/1077 - Train Accuracy: 0.5476, Validation Accuracy: 0.5504, Loss: 0.8412
Epoch   2 Batch  160/1077 - Train Accuracy: 0.4969, Validation Accuracy: 0.5494, Loss: 0.8424
Epoch   2 Batch  170/1077 - Train Accuracy: 0.4715, Validation Accuracy: 0.5472, Loss: 0.9123
Epoch   2 Batch  180/1077 - Train Accuracy: 0.5148, Validation Accuracy: 0.5664, Loss: 0.8764
Epoch   2 Batch  190/1077 - Train Accuracy: 0.5430, Validation Accuracy: 0.5462, Loss: 0.8567
Epoch   2 Batch  200/1077 - Train Accuracy: 0.4930, Validation Accuracy: 0.5490, Loss: 0.8855
Epoch   2 Batch  210/1077 - Train Accuracy: 0.5275, Validation Accuracy: 0.5501, Loss: 0.8737
Epoch   2 Batch  220/1077 - Train Accuracy: 0.4988, Validation Accuracy: 0.5440, Loss: 0.8691
Epoch   2 Batch  230/1077 - Train Accuracy: 0.5394, Validation Accuracy: 0.5497, Loss: 0.8337
Epoch   2 Batch  240/1077 - Train Accuracy: 0.5086, Validation Accuracy: 0.5455, Loss: 0.8416
Epoch   2 Batch  250/1077 - Train Accuracy: 0.5312, Validation Accuracy: 0.5543, Loss: 0.7841
Epoch   2 Batch  260/1077 - Train Accuracy: 0.5205, Validation Accuracy: 0.5529, Loss: 0.8055
Epoch   2 Batch  270/1077 - Train Accuracy: 0.4887, Validation Accuracy: 0.5387, Loss: 0.8904
Epoch   2 Batch  280/1077 - Train Accuracy: 0.4980, Validation Accuracy: 0.5423, Loss: 0.8796
Epoch   2 Batch  290/1077 - Train Accuracy: 0.5070, Validation Accuracy: 0.5465, Loss: 0.8770
Epoch   2 Batch  300/1077 - Train Accuracy: 0.4807, Validation Accuracy: 0.5554, Loss: 0.8742
Epoch   2 Batch  310/1077 - Train Accuracy: 0.5051, Validation Accuracy: 0.5646, Loss: 0.8534
Epoch   2 Batch  320/1077 - Train Accuracy: 0.5437, Validation Accuracy: 0.5593, Loss: 0.8586
Epoch   2 Batch  330/1077 - Train Accuracy: 0.5379, Validation Accuracy: 0.5550, Loss: 0.8382
Epoch   2 Batch  340/1077 - Train Accuracy: 0.4868, Validation Accuracy: 0.5600, Loss: 0.8530
Epoch   2 Batch  350/1077 - Train Accuracy: 0.4938, Validation Accuracy: 0.5749, Loss: 0.8739
Epoch   2 Batch  360/1077 - Train Accuracy: 0.5383, Validation Accuracy: 0.5799, Loss: 0.8494
Epoch   2 Batch  370/1077 - Train Accuracy: 0.5141, Validation Accuracy: 0.5724, Loss: 0.8048
Epoch   2 Batch  380/1077 - Train Accuracy: 0.5250, Validation Accuracy: 0.5668, Loss: 0.8175
Epoch   2 Batch  390/1077 - Train Accuracy: 0.4938, Validation Accuracy: 0.5689, Loss: 0.8708
Epoch   2 Batch  400/1077 - Train Accuracy: 0.5285, Validation Accuracy: 0.5724, Loss: 0.8534
Epoch   2 Batch  410/1077 - Train Accuracy: 0.4848, Validation Accuracy: 0.5600, Loss: 0.8646
Epoch   2 Batch  420/1077 - Train Accuracy: 0.5020, Validation Accuracy: 0.5604, Loss: 0.8278
Epoch   2 Batch  430/1077 - Train Accuracy: 0.5152, Validation Accuracy: 0.5568, Loss: 0.8306
Epoch   2 Batch  440/1077 - Train Accuracy: 0.5523, Validation Accuracy: 0.5785, Loss: 0.8483
Epoch   2 Batch  450/1077 - Train Accuracy: 0.5352, Validation Accuracy: 0.5685, Loss: 0.8211
Epoch   2 Batch  460/1077 - Train Accuracy: 0.5000, Validation Accuracy: 0.5643, Loss: 0.8361
Epoch   2 Batch  470/1077 - Train Accuracy: 0.4914, Validation Accuracy: 0.5550, Loss: 0.8579
Epoch   2 Batch  480/1077 - Train Accuracy: 0.5354, Validation Accuracy: 0.5710, Loss: 0.8520
Epoch   2 Batch  490/1077 - Train Accuracy: 0.5109, Validation Accuracy: 0.5664, Loss: 0.8286
Epoch   2 Batch  500/1077 - Train Accuracy: 0.5430, Validation Accuracy: 0.5785, Loss: 0.8311
Epoch   2 Batch  510/1077 - Train Accuracy: 0.5738, Validation Accuracy: 0.5774, Loss: 0.8108
Epoch   2 Batch  520/1077 - Train Accuracy: 0.5692, Validation Accuracy: 0.5771, Loss: 0.7792
Epoch   2 Batch  530/1077 - Train Accuracy: 0.5355, Validation Accuracy: 0.5806, Loss: 0.8427
Epoch   2 Batch  540/1077 - Train Accuracy: 0.5082, Validation Accuracy: 0.5728, Loss: 0.7979
Epoch   2 Batch  550/1077 - Train Accuracy: 0.5125, Validation Accuracy: 0.5778, Loss: 0.8373
Epoch   2 Batch  560/1077 - Train Accuracy: 0.5375, Validation Accuracy: 0.5810, Loss: 0.8045
Epoch   2 Batch  570/1077 - Train Accuracy: 0.5185, Validation Accuracy: 0.5746, Loss: 0.8434
Epoch   2 Batch  580/1077 - Train Accuracy: 0.5536, Validation Accuracy: 0.5774, Loss: 0.7422
Epoch   2 Batch  590/1077 - Train Accuracy: 0.5448, Validation Accuracy: 0.5863, Loss: 0.8320
Epoch   2 Batch  600/1077 - Train Accuracy: 0.5647, Validation Accuracy: 0.5803, Loss: 0.7895
Epoch   2 Batch  610/1077 - Train Accuracy: 0.5177, Validation Accuracy: 0.5824, Loss: 0.8478
Epoch   2 Batch  620/1077 - Train Accuracy: 0.5320, Validation Accuracy: 0.5767, Loss: 0.8101
Epoch   2 Batch  630/1077 - Train Accuracy: 0.5617, Validation Accuracy: 0.5774, Loss: 0.8144
Epoch   2 Batch  640/1077 - Train Accuracy: 0.5406, Validation Accuracy: 0.5849, Loss: 0.7832
Epoch   2 Batch  650/1077 - Train Accuracy: 0.5176, Validation Accuracy: 0.5813, Loss: 0.8024
Epoch   2 Batch  660/1077 - Train Accuracy: 0.5473, Validation Accuracy: 0.5945, Loss: 0.8217
Epoch   2 Batch  670/1077 - Train Accuracy: 0.5771, Validation Accuracy: 0.5778, Loss: 0.7415
Epoch   2 Batch  680/1077 - Train Accuracy: 0.5465, Validation Accuracy: 0.5852, Loss: 0.7957
Epoch   2 Batch  690/1077 - Train Accuracy: 0.5687, Validation Accuracy: 0.5891, Loss: 0.7904
Epoch   2 Batch  700/1077 - Train Accuracy: 0.5348, Validation Accuracy: 0.5888, Loss: 0.7970
Epoch   2 Batch  710/1077 - Train Accuracy: 0.5277, Validation Accuracy: 0.5795, Loss: 0.7982
Epoch   2 Batch  720/1077 - Train Accuracy: 0.5395, Validation Accuracy: 0.5806, Loss: 0.8507
Epoch   2 Batch  730/1077 - Train Accuracy: 0.5613, Validation Accuracy: 0.5874, Loss: 0.7881
Epoch   2 Batch  740/1077 - Train Accuracy: 0.5645, Validation Accuracy: 0.5820, Loss: 0.7865
Epoch   2 Batch  750/1077 - Train Accuracy: 0.5520, Validation Accuracy: 0.5859, Loss: 0.7751
Epoch   2 Batch  760/1077 - Train Accuracy: 0.5512, Validation Accuracy: 0.5891, Loss: 0.7949
Epoch   2 Batch  770/1077 - Train Accuracy: 0.5551, Validation Accuracy: 0.5884, Loss: 0.7621
Epoch   2 Batch  780/1077 - Train Accuracy: 0.5309, Validation Accuracy: 0.5870, Loss: 0.8183
Epoch   2 Batch  790/1077 - Train Accuracy: 0.4875, Validation Accuracy: 0.5959, Loss: 0.8244
Epoch   2 Batch  800/1077 - Train Accuracy: 0.4965, Validation Accuracy: 0.5881, Loss: 0.7808
Epoch   2 Batch  810/1077 - Train Accuracy: 0.5725, Validation Accuracy: 0.5930, Loss: 0.7391
Epoch   2 Batch  820/1077 - Train Accuracy: 0.5148, Validation Accuracy: 0.5849, Loss: 0.8204
Epoch   2 Batch  830/1077 - Train Accuracy: 0.5441, Validation Accuracy: 0.5916, Loss: 0.7864
Epoch   2 Batch  840/1077 - Train Accuracy: 0.5598, Validation Accuracy: 0.5863, Loss: 0.7614
Epoch   2 Batch  850/1077 - Train Accuracy: 0.5443, Validation Accuracy: 0.5859, Loss: 0.8070
Epoch   2 Batch  860/1077 - Train Accuracy: 0.5450, Validation Accuracy: 0.5849, Loss: 0.7680
Epoch   2 Batch  870/1077 - Train Accuracy: 0.5062, Validation Accuracy: 0.5827, Loss: 0.8460
Epoch   2 Batch  880/1077 - Train Accuracy: 0.5762, Validation Accuracy: 0.5866, Loss: 0.7683
Epoch   2 Batch  890/1077 - Train Accuracy: 0.6473, Validation Accuracy: 0.5881, Loss: 0.7251
Epoch   2 Batch  900/1077 - Train Accuracy: 0.5582, Validation Accuracy: 0.5831, Loss: 0.7740
Epoch   2 Batch  910/1077 - Train Accuracy: 0.5714, Validation Accuracy: 0.5874, Loss: 0.7793
Epoch   2 Batch  920/1077 - Train Accuracy: 0.5457, Validation Accuracy: 0.5845, Loss: 0.7828
Epoch   2 Batch  930/1077 - Train Accuracy: 0.5797, Validation Accuracy: 0.5845, Loss: 0.7649
Epoch   2 Batch  940/1077 - Train Accuracy: 0.5316, Validation Accuracy: 0.5838, Loss: 0.7743
Epoch   2 Batch  950/1077 - Train Accuracy: 0.5484, Validation Accuracy: 0.5877, Loss: 0.7424
Epoch   2 Batch  960/1077 - Train Accuracy: 0.5815, Validation Accuracy: 0.5874, Loss: 0.7433
Epoch   2 Batch  970/1077 - Train Accuracy: 0.5883, Validation Accuracy: 0.6037, Loss: 0.7880
Epoch   2 Batch  980/1077 - Train Accuracy: 0.5703, Validation Accuracy: 0.6058, Loss: 0.7457
Epoch   2 Batch  990/1077 - Train Accuracy: 0.5477, Validation Accuracy: 0.5866, Loss: 0.8065
Epoch   2 Batch 1000/1077 - Train Accuracy: 0.6057, Validation Accuracy: 0.5973, Loss: 0.7146
Epoch   2 Batch 1010/1077 - Train Accuracy: 0.5785, Validation Accuracy: 0.6019, Loss: 0.7567
Epoch   2 Batch 1020/1077 - Train Accuracy: 0.5574, Validation Accuracy: 0.6037, Loss: 0.7379
Epoch   2 Batch 1030/1077 - Train Accuracy: 0.5668, Validation Accuracy: 0.6051, Loss: 0.7669
Epoch   2 Batch 1040/1077 - Train Accuracy: 0.5728, Validation Accuracy: 0.5877, Loss: 0.7996
Epoch   2 Batch 1050/1077 - Train Accuracy: 0.5293, Validation Accuracy: 0.5952, Loss: 0.7771
Epoch   2 Batch 1060/1077 - Train Accuracy: 0.5605, Validation Accuracy: 0.5891, Loss: 0.7447
Epoch   2 Batch 1070/1077 - Train Accuracy: 0.5363, Validation Accuracy: 0.5923, Loss: 0.7829
Epoch   3 Batch   10/1077 - Train Accuracy: 0.5530, Validation Accuracy: 0.5898, Loss: 0.7820
Epoch   3 Batch   20/1077 - Train Accuracy: 0.5473, Validation Accuracy: 0.5916, Loss: 0.7295
Epoch   3 Batch   30/1077 - Train Accuracy: 0.5750, Validation Accuracy: 0.5902, Loss: 0.7428
Epoch   3 Batch   40/1077 - Train Accuracy: 0.5594, Validation Accuracy: 0.5884, Loss: 0.7532
Epoch   3 Batch   50/1077 - Train Accuracy: 0.5441, Validation Accuracy: 0.5895, Loss: 0.7621
Epoch   3 Batch   60/1077 - Train Accuracy: 0.5804, Validation Accuracy: 0.5881, Loss: 0.7211
Epoch   3 Batch   70/1077 - Train Accuracy: 0.5666, Validation Accuracy: 0.5898, Loss: 0.7669
Epoch   3 Batch   80/1077 - Train Accuracy: 0.5578, Validation Accuracy: 0.6001, Loss: 0.7527
Epoch   3 Batch   90/1077 - Train Accuracy: 0.5695, Validation Accuracy: 0.6037, Loss: 0.7774
Epoch   3 Batch  100/1077 - Train Accuracy: 0.5902, Validation Accuracy: 0.6026, Loss: 0.7429
Epoch   3 Batch  110/1077 - Train Accuracy: 0.6055, Validation Accuracy: 0.6058, Loss: 0.7084
Epoch   3 Batch  120/1077 - Train Accuracy: 0.5777, Validation Accuracy: 0.5934, Loss: 0.7525
Epoch   3 Batch  130/1077 - Train Accuracy: 0.5729, Validation Accuracy: 0.5898, Loss: 0.7036
Epoch   3 Batch  140/1077 - Train Accuracy: 0.5345, Validation Accuracy: 0.5955, Loss: 0.7728
Epoch   3 Batch  150/1077 - Train Accuracy: 0.6042, Validation Accuracy: 0.5916, Loss: 0.7034
Epoch   3 Batch  160/1077 - Train Accuracy: 0.5898, Validation Accuracy: 0.5945, Loss: 0.7223
Epoch   3 Batch  170/1077 - Train Accuracy: 0.5316, Validation Accuracy: 0.5945, Loss: 0.7728
Epoch   3 Batch  180/1077 - Train Accuracy: 0.5582, Validation Accuracy: 0.5877, Loss: 0.7377
Epoch   3 Batch  190/1077 - Train Accuracy: 0.6027, Validation Accuracy: 0.5902, Loss: 0.7162
Epoch   3 Batch  200/1077 - Train Accuracy: 0.5531, Validation Accuracy: 0.5916, Loss: 0.7530
Epoch   3 Batch  210/1077 - Train Accuracy: 0.5952, Validation Accuracy: 0.5909, Loss: 0.7242
Epoch   3 Batch  220/1077 - Train Accuracy: 0.5473, Validation Accuracy: 0.5881, Loss: 0.7434
Epoch   3 Batch  230/1077 - Train Accuracy: 0.5867, Validation Accuracy: 0.5891, Loss: 0.7119
Epoch   3 Batch  240/1077 - Train Accuracy: 0.5938, Validation Accuracy: 0.6051, Loss: 0.7226
Epoch   3 Batch  250/1077 - Train Accuracy: 0.5643, Validation Accuracy: 0.6048, Loss: 0.6766
Epoch   3 Batch  260/1077 - Train Accuracy: 0.5889, Validation Accuracy: 0.6030, Loss: 0.6837
Epoch   3 Batch  270/1077 - Train Accuracy: 0.5543, Validation Accuracy: 0.6087, Loss: 0.7573
Epoch   3 Batch  280/1077 - Train Accuracy: 0.6023, Validation Accuracy: 0.6058, Loss: 0.7525
Epoch   3 Batch  290/1077 - Train Accuracy: 0.5582, Validation Accuracy: 0.5923, Loss: 0.7527
Epoch   3 Batch  300/1077 - Train Accuracy: 0.5613, Validation Accuracy: 0.5941, Loss: 0.7478
Epoch   3 Batch  310/1077 - Train Accuracy: 0.5684, Validation Accuracy: 0.5966, Loss: 0.7425
Epoch   3 Batch  320/1077 - Train Accuracy: 0.5750, Validation Accuracy: 0.6009, Loss: 0.7461
Epoch   3 Batch  330/1077 - Train Accuracy: 0.6172, Validation Accuracy: 0.6072, Loss: 0.7234
Epoch   3 Batch  340/1077 - Train Accuracy: 0.5428, Validation Accuracy: 0.5909, Loss: 0.7471
Epoch   3 Batch  350/1077 - Train Accuracy: 0.5535, Validation Accuracy: 0.6108, Loss: 0.7562
Epoch   3 Batch  360/1077 - Train Accuracy: 0.5723, Validation Accuracy: 0.6140, Loss: 0.7304
Epoch   3 Batch  370/1077 - Train Accuracy: 0.5882, Validation Accuracy: 0.6143, Loss: 0.6892
Epoch   3 Batch  380/1077 - Train Accuracy: 0.5750, Validation Accuracy: 0.6040, Loss: 0.7153
Epoch   3 Batch  390/1077 - Train Accuracy: 0.5395, Validation Accuracy: 0.6065, Loss: 0.7490
Epoch   3 Batch  400/1077 - Train Accuracy: 0.5832, Validation Accuracy: 0.5962, Loss: 0.7313
Epoch   3 Batch  410/1077 - Train Accuracy: 0.5428, Validation Accuracy: 0.6016, Loss: 0.7497
Epoch   3 Batch  420/1077 - Train Accuracy: 0.5762, Validation Accuracy: 0.5969, Loss: 0.7003
Epoch   3 Batch  430/1077 - Train Accuracy: 0.5641, Validation Accuracy: 0.6012, Loss: 0.7289
Epoch   3 Batch  440/1077 - Train Accuracy: 0.5613, Validation Accuracy: 0.6119, Loss: 0.7386
Epoch   3 Batch  450/1077 - Train Accuracy: 0.5672, Validation Accuracy: 0.5888, Loss: 0.7027
Epoch   3 Batch  460/1077 - Train Accuracy: 0.5621, Validation Accuracy: 0.6044, Loss: 0.7270
Epoch   3 Batch  470/1077 - Train Accuracy: 0.5493, Validation Accuracy: 0.6072, Loss: 0.7496
Epoch   3 Batch  480/1077 - Train Accuracy: 0.5831, Validation Accuracy: 0.5945, Loss: 0.7265
Epoch   3 Batch  490/1077 - Train Accuracy: 0.5664, Validation Accuracy: 0.5948, Loss: 0.7412
Epoch   3 Batch  500/1077 - Train Accuracy: 0.5766, Validation Accuracy: 0.6058, Loss: 0.7188
Epoch   3 Batch  510/1077 - Train Accuracy: 0.6062, Validation Accuracy: 0.6048, Loss: 0.7003
Epoch   3 Batch  520/1077 - Train Accuracy: 0.6101, Validation Accuracy: 0.6048, Loss: 0.6860
Epoch   3 Batch  530/1077 - Train Accuracy: 0.5730, Validation Accuracy: 0.6055, Loss: 0.7182
Epoch   3 Batch  540/1077 - Train Accuracy: 0.5734, Validation Accuracy: 0.6058, Loss: 0.6722
Epoch   3 Batch  550/1077 - Train Accuracy: 0.5563, Validation Accuracy: 0.6055, Loss: 0.7525
Epoch   3 Batch  560/1077 - Train Accuracy: 0.5645, Validation Accuracy: 0.6033, Loss: 0.7020
Epoch   3 Batch  570/1077 - Train Accuracy: 0.5773, Validation Accuracy: 0.6040, Loss: 0.7536
Epoch   3 Batch  580/1077 - Train Accuracy: 0.6336, Validation Accuracy: 0.6119, Loss: 0.6542
Epoch   3 Batch  590/1077 - Train Accuracy: 0.5789, Validation Accuracy: 0.6009, Loss: 0.7358
Epoch   3 Batch  600/1077 - Train Accuracy: 0.6060, Validation Accuracy: 0.5984, Loss: 0.6731
Epoch   3 Batch  610/1077 - Train Accuracy: 0.5637, Validation Accuracy: 0.6058, Loss: 0.7436
Epoch   3 Batch  620/1077 - Train Accuracy: 0.5773, Validation Accuracy: 0.6058, Loss: 0.6923
Epoch   3 Batch  630/1077 - Train Accuracy: 0.5953, Validation Accuracy: 0.6058, Loss: 0.7118
Epoch   3 Batch  640/1077 - Train Accuracy: 0.5718, Validation Accuracy: 0.6037, Loss: 0.6856
Epoch   3 Batch  650/1077 - Train Accuracy: 0.5785, Validation Accuracy: 0.6037, Loss: 0.7171
Epoch   3 Batch  660/1077 - Train Accuracy: 0.5816, Validation Accuracy: 0.6097, Loss: 0.7253
Epoch   3 Batch  670/1077 - Train Accuracy: 0.6364, Validation Accuracy: 0.6055, Loss: 0.6548
Epoch   3 Batch  680/1077 - Train Accuracy: 0.5815, Validation Accuracy: 0.6037, Loss: 0.7054
Epoch   3 Batch  690/1077 - Train Accuracy: 0.6133, Validation Accuracy: 0.5998, Loss: 0.7122
Epoch   3 Batch  700/1077 - Train Accuracy: 0.5516, Validation Accuracy: 0.6037, Loss: 0.7026
Epoch   3 Batch  710/1077 - Train Accuracy: 0.5523, Validation Accuracy: 0.6030, Loss: 0.7120
Epoch   3 Batch  720/1077 - Train Accuracy: 0.5798, Validation Accuracy: 0.6037, Loss: 0.7440
Epoch   3 Batch  730/1077 - Train Accuracy: 0.5883, Validation Accuracy: 0.6048, Loss: 0.7078
Epoch   3 Batch  740/1077 - Train Accuracy: 0.5863, Validation Accuracy: 0.6062, Loss: 0.7022
Epoch   3 Batch  750/1077 - Train Accuracy: 0.5805, Validation Accuracy: 0.6083, Loss: 0.6959
Epoch   3 Batch  760/1077 - Train Accuracy: 0.6020, Validation Accuracy: 0.6122, Loss: 0.7104
Epoch   3 Batch  770/1077 - Train Accuracy: 0.6064, Validation Accuracy: 0.6072, Loss: 0.6591
Epoch   3 Batch  780/1077 - Train Accuracy: 0.5742, Validation Accuracy: 0.5966, Loss: 0.7356
Epoch   3 Batch  790/1077 - Train Accuracy: 0.5133, Validation Accuracy: 0.6065, Loss: 0.7421
Epoch   3 Batch  800/1077 - Train Accuracy: 0.5531, Validation Accuracy: 0.6051, Loss: 0.6946
Epoch   3 Batch  810/1077 - Train Accuracy: 0.6127, Validation Accuracy: 0.6080, Loss: 0.6607
Epoch   3 Batch  820/1077 - Train Accuracy: 0.5492, Validation Accuracy: 0.6094, Loss: 0.7484
Epoch   3 Batch  830/1077 - Train Accuracy: 0.5836, Validation Accuracy: 0.6112, Loss: 0.6948
Epoch   3 Batch  840/1077 - Train Accuracy: 0.5875, Validation Accuracy: 0.6104, Loss: 0.6771
Epoch   3 Batch  850/1077 - Train Accuracy: 0.5759, Validation Accuracy: 0.6069, Loss: 0.7214
Epoch   3 Batch  860/1077 - Train Accuracy: 0.5867, Validation Accuracy: 0.6065, Loss: 0.6812
Epoch   3 Batch  870/1077 - Train Accuracy: 0.5444, Validation Accuracy: 0.6129, Loss: 0.7324
Epoch   3 Batch  880/1077 - Train Accuracy: 0.6277, Validation Accuracy: 0.6175, Loss: 0.6843
Epoch   3 Batch  890/1077 - Train Accuracy: 0.6637, Validation Accuracy: 0.6083, Loss: 0.6418
Epoch   3 Batch  900/1077 - Train Accuracy: 0.5770, Validation Accuracy: 0.6090, Loss: 0.6854
Epoch   3 Batch  910/1077 - Train Accuracy: 0.5837, Validation Accuracy: 0.6048, Loss: 0.6826
Epoch   3 Batch  920/1077 - Train Accuracy: 0.5824, Validation Accuracy: 0.6044, Loss: 0.6977
Epoch   3 Batch  930/1077 - Train Accuracy: 0.6035, Validation Accuracy: 0.6080, Loss: 0.6801
Epoch   3 Batch  940/1077 - Train Accuracy: 0.5563, Validation Accuracy: 0.6104, Loss: 0.6839
Epoch   3 Batch  950/1077 - Train Accuracy: 0.5763, Validation Accuracy: 0.6087, Loss: 0.6623
Epoch   3 Batch  960/1077 - Train Accuracy: 0.5990, Validation Accuracy: 0.6069, Loss: 0.6604
Epoch   3 Batch  970/1077 - Train Accuracy: 0.6137, Validation Accuracy: 0.6129, Loss: 0.6945
Epoch   3 Batch  980/1077 - Train Accuracy: 0.5793, Validation Accuracy: 0.6058, Loss: 0.6768
Epoch   3 Batch  990/1077 - Train Accuracy: 0.5798, Validation Accuracy: 0.6083, Loss: 0.7260
Epoch   3 Batch 1000/1077 - Train Accuracy: 0.6339, Validation Accuracy: 0.6062, Loss: 0.6314
Epoch   3 Batch 1010/1077 - Train Accuracy: 0.5953, Validation Accuracy: 0.6101, Loss: 0.6895
Epoch   3 Batch 1020/1077 - Train Accuracy: 0.5723, Validation Accuracy: 0.6083, Loss: 0.6668
Epoch   3 Batch 1030/1077 - Train Accuracy: 0.5746, Validation Accuracy: 0.6080, Loss: 0.6860
Epoch   3 Batch 1040/1077 - Train Accuracy: 0.5913, Validation Accuracy: 0.6044, Loss: 0.7058
Epoch   3 Batch 1050/1077 - Train Accuracy: 0.5383, Validation Accuracy: 0.6104, Loss: 0.6929
Epoch   3 Batch 1060/1077 - Train Accuracy: 0.5926, Validation Accuracy: 0.6094, Loss: 0.6561
Epoch   3 Batch 1070/1077 - Train Accuracy: 0.5430, Validation Accuracy: 0.6133, Loss: 0.6906
Epoch   4 Batch   10/1077 - Train Accuracy: 0.5798, Validation Accuracy: 0.6108, Loss: 0.7188
Epoch   4 Batch   20/1077 - Train Accuracy: 0.5617, Validation Accuracy: 0.6101, Loss: 0.6587
Epoch   4 Batch   30/1077 - Train Accuracy: 0.5879, Validation Accuracy: 0.6154, Loss: 0.6708
Epoch   4 Batch   40/1077 - Train Accuracy: 0.5793, Validation Accuracy: 0.6062, Loss: 0.6730
Epoch   4 Batch   50/1077 - Train Accuracy: 0.5625, Validation Accuracy: 0.6097, Loss: 0.6810
Epoch   4 Batch   60/1077 - Train Accuracy: 0.5926, Validation Accuracy: 0.6133, Loss: 0.6514
Epoch   4 Batch   70/1077 - Train Accuracy: 0.5720, Validation Accuracy: 0.5906, Loss: 0.6890
Epoch   4 Batch   80/1077 - Train Accuracy: 0.5859, Validation Accuracy: 0.6104, Loss: 0.6822
Epoch   4 Batch   90/1077 - Train Accuracy: 0.5988, Validation Accuracy: 0.6069, Loss: 0.6928
Epoch   4 Batch  100/1077 - Train Accuracy: 0.6074, Validation Accuracy: 0.6072, Loss: 0.6815
Epoch   4 Batch  110/1077 - Train Accuracy: 0.6312, Validation Accuracy: 0.6154, Loss: 0.6398
Epoch   4 Batch  120/1077 - Train Accuracy: 0.6117, Validation Accuracy: 0.6136, Loss: 0.6824
Epoch   4 Batch  130/1077 - Train Accuracy: 0.5964, Validation Accuracy: 0.6126, Loss: 0.6428
Epoch   4 Batch  140/1077 - Train Accuracy: 0.5711, Validation Accuracy: 0.6140, Loss: 0.6891
Epoch   4 Batch  150/1077 - Train Accuracy: 0.6425, Validation Accuracy: 0.6126, Loss: 0.6311
Epoch   4 Batch  160/1077 - Train Accuracy: 0.6102, Validation Accuracy: 0.6122, Loss: 0.6580
Epoch   4 Batch  170/1077 - Train Accuracy: 0.5566, Validation Accuracy: 0.6097, Loss: 0.7021
Epoch   4 Batch  180/1077 - Train Accuracy: 0.5734, Validation Accuracy: 0.6033, Loss: 0.6698
Epoch   4 Batch  190/1077 - Train Accuracy: 0.6328, Validation Accuracy: 0.6023, Loss: 0.6459
Epoch   4 Batch  200/1077 - Train Accuracy: 0.5707, Validation Accuracy: 0.6062, Loss: 0.6782
Epoch   4 Batch  210/1077 - Train Accuracy: 0.6250, Validation Accuracy: 0.6175, Loss: 0.6585
Epoch   4 Batch  220/1077 - Train Accuracy: 0.5896, Validation Accuracy: 0.6168, Loss: 0.6797
Epoch   4 Batch  230/1077 - Train Accuracy: 0.6086, Validation Accuracy: 0.6161, Loss: 0.6543
Epoch   4 Batch  240/1077 - Train Accuracy: 0.6160, Validation Accuracy: 0.5952, Loss: 0.6398
Epoch   4 Batch  250/1077 - Train Accuracy: 0.5913, Validation Accuracy: 0.6136, Loss: 0.6102
Epoch   4 Batch  260/1077 - Train Accuracy: 0.6254, Validation Accuracy: 0.6126, Loss: 0.6091
Epoch   4 Batch  270/1077 - Train Accuracy: 0.5668, Validation Accuracy: 0.6037, Loss: 0.6822
Epoch   4 Batch  280/1077 - Train Accuracy: 0.6176, Validation Accuracy: 0.6183, Loss: 0.6763
Epoch   4 Batch  290/1077 - Train Accuracy: 0.5883, Validation Accuracy: 0.6122, Loss: 0.6671
Epoch   4 Batch  300/1077 - Train Accuracy: 0.5983, Validation Accuracy: 0.6147, Loss: 0.6741
Epoch   4 Batch  310/1077 - Train Accuracy: 0.5828, Validation Accuracy: 0.6055, Loss: 0.6856
Epoch   4 Batch  320/1077 - Train Accuracy: 0.6141, Validation Accuracy: 0.6140, Loss: 0.6694
Epoch   4 Batch  330/1077 - Train Accuracy: 0.6293, Validation Accuracy: 0.6147, Loss: 0.6479
Epoch   4 Batch  340/1077 - Train Accuracy: 0.5781, Validation Accuracy: 0.6133, Loss: 0.6659
Epoch   4 Batch  350/1077 - Train Accuracy: 0.5738, Validation Accuracy: 0.6080, Loss: 0.6710
Epoch   4 Batch  360/1077 - Train Accuracy: 0.5934, Validation Accuracy: 0.6168, Loss: 0.6575
Epoch   4 Batch  370/1077 - Train Accuracy: 0.6034, Validation Accuracy: 0.6009, Loss: 0.6215
Epoch   4 Batch  380/1077 - Train Accuracy: 0.5789, Validation Accuracy: 0.6001, Loss: 0.6486
Epoch   4 Batch  390/1077 - Train Accuracy: 0.5555, Validation Accuracy: 0.6126, Loss: 0.6750
Epoch   4 Batch  400/1077 - Train Accuracy: 0.6242, Validation Accuracy: 0.6055, Loss: 0.6662
Epoch   4 Batch  410/1077 - Train Accuracy: 0.5752, Validation Accuracy: 0.6143, Loss: 0.6756
Epoch   4 Batch  420/1077 - Train Accuracy: 0.6043, Validation Accuracy: 0.6133, Loss: 0.6345
Epoch   4 Batch  430/1077 - Train Accuracy: 0.5762, Validation Accuracy: 0.6055, Loss: 0.6530
Epoch   4 Batch  440/1077 - Train Accuracy: 0.5684, Validation Accuracy: 0.6143, Loss: 0.6751
Epoch   4 Batch  450/1077 - Train Accuracy: 0.5805, Validation Accuracy: 0.6165, Loss: 0.6308
Epoch   4 Batch  460/1077 - Train Accuracy: 0.5797, Validation Accuracy: 0.6076, Loss: 0.6620
Epoch   4 Batch  470/1077 - Train Accuracy: 0.5633, Validation Accuracy: 0.6129, Loss: 0.6882
Epoch   4 Batch  480/1077 - Train Accuracy: 0.6106, Validation Accuracy: 0.6122, Loss: 0.6597
Epoch   4 Batch  490/1077 - Train Accuracy: 0.5832, Validation Accuracy: 0.5994, Loss: 0.6580
Epoch   4 Batch  500/1077 - Train Accuracy: 0.5875, Validation Accuracy: 0.6083, Loss: 0.6517
Epoch   4 Batch  510/1077 - Train Accuracy: 0.6055, Validation Accuracy: 0.6129, Loss: 0.6339
Epoch   4 Batch  520/1077 - Train Accuracy: 0.6410, Validation Accuracy: 0.6197, Loss: 0.6043
Epoch   4 Batch  530/1077 - Train Accuracy: 0.5918, Validation Accuracy: 0.6211, Loss: 0.6597
Epoch   4 Batch  540/1077 - Train Accuracy: 0.5984, Validation Accuracy: 0.6168, Loss: 0.6087
Epoch   4 Batch  550/1077 - Train Accuracy: 0.5742, Validation Accuracy: 0.6207, Loss: 0.6818
Epoch   4 Batch  560/1077 - Train Accuracy: 0.5824, Validation Accuracy: 0.6239, Loss: 0.6331
Epoch   4 Batch  570/1077 - Train Accuracy: 0.6098, Validation Accuracy: 0.6168, Loss: 0.6789
Epoch   4 Batch  580/1077 - Train Accuracy: 0.6380, Validation Accuracy: 0.6026, Loss: 0.5880
Epoch   4 Batch  590/1077 - Train Accuracy: 0.5921, Validation Accuracy: 0.6136, Loss: 0.6646
Epoch   4 Batch  600/1077 - Train Accuracy: 0.6213, Validation Accuracy: 0.6147, Loss: 0.6087
Epoch   4 Batch  610/1077 - Train Accuracy: 0.5695, Validation Accuracy: 0.6062, Loss: 0.6748
Epoch   4 Batch  620/1077 - Train Accuracy: 0.5957, Validation Accuracy: 0.6122, Loss: 0.6313
Epoch   4 Batch  630/1077 - Train Accuracy: 0.6051, Validation Accuracy: 0.6175, Loss: 0.6440
Epoch   4 Batch  640/1077 - Train Accuracy: 0.5945, Validation Accuracy: 0.6165, Loss: 0.6239
Epoch   4 Batch  650/1077 - Train Accuracy: 0.5988, Validation Accuracy: 0.6214, Loss: 0.6572
Epoch   4 Batch  660/1077 - Train Accuracy: 0.6059, Validation Accuracy: 0.6175, Loss: 0.6472
Epoch   4 Batch  670/1077 - Train Accuracy: 0.6406, Validation Accuracy: 0.6122, Loss: 0.5876
Epoch   4 Batch  680/1077 - Train Accuracy: 0.5911, Validation Accuracy: 0.6055, Loss: 0.6382
Epoch   4 Batch  690/1077 - Train Accuracy: 0.6246, Validation Accuracy: 0.6087, Loss: 0.6480
Epoch   4 Batch  700/1077 - Train Accuracy: 0.5598, Validation Accuracy: 0.6080, Loss: 0.6392
Epoch   4 Batch  710/1077 - Train Accuracy: 0.5711, Validation Accuracy: 0.6218, Loss: 0.6533
Epoch   4 Batch  720/1077 - Train Accuracy: 0.5979, Validation Accuracy: 0.6009, Loss: 0.6720
Epoch   4 Batch  730/1077 - Train Accuracy: 0.5973, Validation Accuracy: 0.6158, Loss: 0.6497
Epoch   4 Batch  740/1077 - Train Accuracy: 0.5891, Validation Accuracy: 0.6080, Loss: 0.6335
Epoch   4 Batch  750/1077 - Train Accuracy: 0.5957, Validation Accuracy: 0.6051, Loss: 0.6267
Epoch   4 Batch  760/1077 - Train Accuracy: 0.6051, Validation Accuracy: 0.6126, Loss: 0.6414
Epoch   4 Batch  770/1077 - Train Accuracy: 0.6283, Validation Accuracy: 0.6193, Loss: 0.5981
Epoch   4 Batch  780/1077 - Train Accuracy: 0.5859, Validation Accuracy: 0.5991, Loss: 0.6621
Epoch   4 Batch  790/1077 - Train Accuracy: 0.5230, Validation Accuracy: 0.6172, Loss: 0.6701
Epoch   4 Batch  800/1077 - Train Accuracy: 0.5598, Validation Accuracy: 0.6133, Loss: 0.6265
Epoch   4 Batch  810/1077 - Train Accuracy: 0.6220, Validation Accuracy: 0.6158, Loss: 0.5971
Epoch   4 Batch  820/1077 - Train Accuracy: 0.5703, Validation Accuracy: 0.6168, Loss: 0.6762
Epoch   4 Batch  830/1077 - Train Accuracy: 0.5867, Validation Accuracy: 0.6104, Loss: 0.6411
Epoch   4 Batch  840/1077 - Train Accuracy: 0.6059, Validation Accuracy: 0.6190, Loss: 0.6128
Epoch   4 Batch  850/1077 - Train Accuracy: 0.5785, Validation Accuracy: 0.6154, Loss: 0.6606
Epoch   4 Batch  860/1077 - Train Accuracy: 0.5930, Validation Accuracy: 0.6222, Loss: 0.6205
Epoch   4 Batch  870/1077 - Train Accuracy: 0.5720, Validation Accuracy: 0.6218, Loss: 0.6756
Epoch   4 Batch  880/1077 - Train Accuracy: 0.6324, Validation Accuracy: 0.6229, Loss: 0.6274
Epoch   4 Batch  890/1077 - Train Accuracy: 0.6726, Validation Accuracy: 0.6236, Loss: 0.5837
Epoch   4 Batch  900/1077 - Train Accuracy: 0.6059, Validation Accuracy: 0.6193, Loss: 0.6296
Epoch   4 Batch  910/1077 - Train Accuracy: 0.5856, Validation Accuracy: 0.6101, Loss: 0.6228
Epoch   4 Batch  920/1077 - Train Accuracy: 0.5898, Validation Accuracy: 0.6193, Loss: 0.6401
Epoch   4 Batch  930/1077 - Train Accuracy: 0.6121, Validation Accuracy: 0.6129, Loss: 0.6100
Epoch   4 Batch  940/1077 - Train Accuracy: 0.5813, Validation Accuracy: 0.6193, Loss: 0.6224
Epoch   4 Batch  950/1077 - Train Accuracy: 0.5967, Validation Accuracy: 0.6236, Loss: 0.6024
Epoch   4 Batch  960/1077 - Train Accuracy: 0.6138, Validation Accuracy: 0.6126, Loss: 0.6085
Epoch   4 Batch  970/1077 - Train Accuracy: 0.6137, Validation Accuracy: 0.6129, Loss: 0.6512
Epoch   4 Batch  980/1077 - Train Accuracy: 0.5938, Validation Accuracy: 0.6207, Loss: 0.6226
Epoch   4 Batch  990/1077 - Train Accuracy: 0.5720, Validation Accuracy: 0.6193, Loss: 0.6570
Epoch   4 Batch 1000/1077 - Train Accuracy: 0.6499, Validation Accuracy: 0.6190, Loss: 0.5756
Epoch   4 Batch 1010/1077 - Train Accuracy: 0.6078, Validation Accuracy: 0.6183, Loss: 0.6225
Epoch   4 Batch 1020/1077 - Train Accuracy: 0.5742, Validation Accuracy: 0.6080, Loss: 0.6141
Epoch   4 Batch 1030/1077 - Train Accuracy: 0.5918, Validation Accuracy: 0.6197, Loss: 0.6298
Epoch   4 Batch 1040/1077 - Train Accuracy: 0.5975, Validation Accuracy: 0.6175, Loss: 0.6417
Epoch   4 Batch 1050/1077 - Train Accuracy: 0.5406, Validation Accuracy: 0.6293, Loss: 0.6352
Epoch   4 Batch 1060/1077 - Train Accuracy: 0.6121, Validation Accuracy: 0.6314, Loss: 0.6135
Epoch   4 Batch 1070/1077 - Train Accuracy: 0.5594, Validation Accuracy: 0.6293, Loss: 0.6361
Epoch   5 Batch   10/1077 - Train Accuracy: 0.5970, Validation Accuracy: 0.6236, Loss: 0.6536
Epoch   5 Batch   20/1077 - Train Accuracy: 0.5816, Validation Accuracy: 0.6289, Loss: 0.6115
Epoch   5 Batch   30/1077 - Train Accuracy: 0.5934, Validation Accuracy: 0.6236, Loss: 0.6157
Epoch   5 Batch   40/1077 - Train Accuracy: 0.5922, Validation Accuracy: 0.6179, Loss: 0.6283
Epoch   5 Batch   50/1077 - Train Accuracy: 0.5699, Validation Accuracy: 0.6190, Loss: 0.6289
Epoch   5 Batch   60/1077 - Train Accuracy: 0.6023, Validation Accuracy: 0.6214, Loss: 0.5860
Epoch   5 Batch   70/1077 - Train Accuracy: 0.5831, Validation Accuracy: 0.6104, Loss: 0.6476
Epoch   5 Batch   80/1077 - Train Accuracy: 0.6066, Validation Accuracy: 0.6179, Loss: 0.6303
Epoch   5 Batch   90/1077 - Train Accuracy: 0.5965, Validation Accuracy: 0.6136, Loss: 0.6318
Epoch   5 Batch  100/1077 - Train Accuracy: 0.6180, Validation Accuracy: 0.6236, Loss: 0.6195
Epoch   5 Batch  110/1077 - Train Accuracy: 0.6430, Validation Accuracy: 0.6225, Loss: 0.5911
Epoch   5 Batch  120/1077 - Train Accuracy: 0.5977, Validation Accuracy: 0.6229, Loss: 0.6358
Epoch   5 Batch  130/1077 - Train Accuracy: 0.6068, Validation Accuracy: 0.6257, Loss: 0.5923
Epoch   5 Batch  140/1077 - Train Accuracy: 0.5818, Validation Accuracy: 0.6278, Loss: 0.6324
Epoch   5 Batch  150/1077 - Train Accuracy: 0.6380, Validation Accuracy: 0.6236, Loss: 0.5869
Epoch   5 Batch  160/1077 - Train Accuracy: 0.6332, Validation Accuracy: 0.6278, Loss: 0.5981
Epoch   5 Batch  170/1077 - Train Accuracy: 0.5742, Validation Accuracy: 0.6250, Loss: 0.6497
Epoch   5 Batch  180/1077 - Train Accuracy: 0.5809, Validation Accuracy: 0.6154, Loss: 0.6077
Epoch   5 Batch  190/1077 - Train Accuracy: 0.6457, Validation Accuracy: 0.6218, Loss: 0.5972
Epoch   5 Batch  200/1077 - Train Accuracy: 0.5727, Validation Accuracy: 0.6229, Loss: 0.6277
Epoch   5 Batch  210/1077 - Train Accuracy: 0.6235, Validation Accuracy: 0.6268, Loss: 0.5983
Epoch   5 Batch  220/1077 - Train Accuracy: 0.5950, Validation Accuracy: 0.6214, Loss: 0.6320
Epoch   5 Batch  230/1077 - Train Accuracy: 0.6190, Validation Accuracy: 0.6271, Loss: 0.6070
Epoch   5 Batch  240/1077 - Train Accuracy: 0.6281, Validation Accuracy: 0.6257, Loss: 0.5937
Epoch   5 Batch  250/1077 - Train Accuracy: 0.6012, Validation Accuracy: 0.6271, Loss: 0.5667
Epoch   5 Batch  260/1077 - Train Accuracy: 0.6339, Validation Accuracy: 0.6254, Loss: 0.5762
Epoch   5 Batch  270/1077 - Train Accuracy: 0.5746, Validation Accuracy: 0.6278, Loss: 0.6326
Epoch   5 Batch  280/1077 - Train Accuracy: 0.6277, Validation Accuracy: 0.6264, Loss: 0.6101
Epoch   5 Batch  290/1077 - Train Accuracy: 0.6027, Validation Accuracy: 0.6300, Loss: 0.6146
Epoch   5 Batch  300/1077 - Train Accuracy: 0.6139, Validation Accuracy: 0.6278, Loss: 0.6225
Epoch   5 Batch  310/1077 - Train Accuracy: 0.5816, Validation Accuracy: 0.6151, Loss: 0.6341
Epoch   5 Batch  320/1077 - Train Accuracy: 0.6188, Validation Accuracy: 0.6289, Loss: 0.6146
Epoch   5 Batch  330/1077 - Train Accuracy: 0.6453, Validation Accuracy: 0.6250, Loss: 0.6044
Epoch   5 Batch  340/1077 - Train Accuracy: 0.5929, Validation Accuracy: 0.6214, Loss: 0.6156
Epoch   5 Batch  350/1077 - Train Accuracy: 0.5797, Validation Accuracy: 0.6218, Loss: 0.6120
Epoch   5 Batch  360/1077 - Train Accuracy: 0.6059, Validation Accuracy: 0.6346, Loss: 0.6122
Epoch   5 Batch  370/1077 - Train Accuracy: 0.6164, Validation Accuracy: 0.6307, Loss: 0.5800
Epoch   5 Batch  380/1077 - Train Accuracy: 0.6008, Validation Accuracy: 0.6335, Loss: 0.6012
Epoch   5 Batch  390/1077 - Train Accuracy: 0.5785, Validation Accuracy: 0.6275, Loss: 0.6261
Epoch   5 Batch  400/1077 - Train Accuracy: 0.6336, Validation Accuracy: 0.6300, Loss: 0.6089
Epoch   5 Batch  410/1077 - Train Accuracy: 0.5822, Validation Accuracy: 0.6239, Loss: 0.6214
Epoch   5 Batch  420/1077 - Train Accuracy: 0.6137, Validation Accuracy: 0.6186, Loss: 0.5830
Epoch   5 Batch  430/1077 - Train Accuracy: 0.5879, Validation Accuracy: 0.6293, Loss: 0.6029
Epoch   5 Batch  440/1077 - Train Accuracy: 0.5813, Validation Accuracy: 0.6197, Loss: 0.6248
Epoch   5 Batch  450/1077 - Train Accuracy: 0.5840, Validation Accuracy: 0.6232, Loss: 0.5837
Epoch   5 Batch  460/1077 - Train Accuracy: 0.5875, Validation Accuracy: 0.6286, Loss: 0.6135
Epoch   5 Batch  470/1077 - Train Accuracy: 0.5678, Validation Accuracy: 0.6293, Loss: 0.6395
Epoch   5 Batch  480/1077 - Train Accuracy: 0.6279, Validation Accuracy: 0.6183, Loss: 0.6171
Epoch   5 Batch  490/1077 - Train Accuracy: 0.5906, Validation Accuracy: 0.6232, Loss: 0.6087
Epoch   5 Batch  500/1077 - Train Accuracy: 0.6012, Validation Accuracy: 0.6282, Loss: 0.5933
Epoch   5 Batch  510/1077 - Train Accuracy: 0.6109, Validation Accuracy: 0.6186, Loss: 0.5835
Epoch   5 Batch  520/1077 - Train Accuracy: 0.6529, Validation Accuracy: 0.6303, Loss: 0.5591
Epoch   5 Batch  530/1077 - Train Accuracy: 0.5988, Validation Accuracy: 0.6310, Loss: 0.6122
Epoch   5 Batch  540/1077 - Train Accuracy: 0.6004, Validation Accuracy: 0.6310, Loss: 0.5660
Epoch   5 Batch  550/1077 - Train Accuracy: 0.5785, Validation Accuracy: 0.6321, Loss: 0.6243
Epoch   5 Batch  560/1077 - Train Accuracy: 0.5844, Validation Accuracy: 0.6307, Loss: 0.5841
Epoch   5 Batch  570/1077 - Train Accuracy: 0.6180, Validation Accuracy: 0.6317, Loss: 0.6247
Epoch   5 Batch  580/1077 - Train Accuracy: 0.6477, Validation Accuracy: 0.6140, Loss: 0.5449
Epoch   5 Batch  590/1077 - Train Accuracy: 0.5942, Validation Accuracy: 0.6289, Loss: 0.6145
Epoch   5 Batch  600/1077 - Train Accuracy: 0.6276, Validation Accuracy: 0.6243, Loss: 0.5559
Epoch   5 Batch  610/1077 - Train Accuracy: 0.5970, Validation Accuracy: 0.6261, Loss: 0.6247
Epoch   5 Batch  620/1077 - Train Accuracy: 0.6039, Validation Accuracy: 0.6232, Loss: 0.5753
Epoch   5 Batch  630/1077 - Train Accuracy: 0.6078, Validation Accuracy: 0.6275, Loss: 0.6064
Epoch   5 Batch  640/1077 - Train Accuracy: 0.6071, Validation Accuracy: 0.6293, Loss: 0.5715
Epoch   5 Batch  650/1077 - Train Accuracy: 0.5988, Validation Accuracy: 0.6218, Loss: 0.5975
Epoch   5 Batch  660/1077 - Train Accuracy: 0.6102, Validation Accuracy: 0.6307, Loss: 0.6114
Epoch   5 Batch  670/1077 - Train Accuracy: 0.6587, Validation Accuracy: 0.6342, Loss: 0.5517
Epoch   5 Batch  680/1077 - Train Accuracy: 0.6120, Validation Accuracy: 0.6296, Loss: 0.6018
Epoch   5 Batch  690/1077 - Train Accuracy: 0.6152, Validation Accuracy: 0.6239, Loss: 0.6313
Epoch   5 Batch  700/1077 - Train Accuracy: 0.5602, Validation Accuracy: 0.6243, Loss: 0.5981
Epoch   5 Batch  710/1077 - Train Accuracy: 0.5754, Validation Accuracy: 0.6282, Loss: 0.6329
Epoch   5 Batch  720/1077 - Train Accuracy: 0.6040, Validation Accuracy: 0.6161, Loss: 0.6373
Epoch   5 Batch  730/1077 - Train Accuracy: 0.5828, Validation Accuracy: 0.6154, Loss: 0.6044
Epoch   5 Batch  740/1077 - Train Accuracy: 0.6023, Validation Accuracy: 0.6175, Loss: 0.5886
Epoch   5 Batch  750/1077 - Train Accuracy: 0.6102, Validation Accuracy: 0.6250, Loss: 0.5836
Epoch   5 Batch  760/1077 - Train Accuracy: 0.6105, Validation Accuracy: 0.6264, Loss: 0.5941
Epoch   5 Batch  770/1077 - Train Accuracy: 0.6298, Validation Accuracy: 0.6254, Loss: 0.5627
Epoch   5 Batch  780/1077 - Train Accuracy: 0.5848, Validation Accuracy: 0.6122, Loss: 0.6156
Epoch   5 Batch  790/1077 - Train Accuracy: 0.5418, Validation Accuracy: 0.6239, Loss: 0.6316
Epoch   5 Batch  800/1077 - Train Accuracy: 0.5574, Validation Accuracy: 0.6268, Loss: 0.5839
Epoch   5 Batch  810/1077 - Train Accuracy: 0.6257, Validation Accuracy: 0.6278, Loss: 0.5532
Epoch   5 Batch  820/1077 - Train Accuracy: 0.5746, Validation Accuracy: 0.6328, Loss: 0.6271
Epoch   5 Batch  830/1077 - Train Accuracy: 0.5859, Validation Accuracy: 0.6161, Loss: 0.5960
Epoch   5 Batch  840/1077 - Train Accuracy: 0.6090, Validation Accuracy: 0.6257, Loss: 0.5674
Epoch   5 Batch  850/1077 - Train Accuracy: 0.5852, Validation Accuracy: 0.6250, Loss: 0.6146
Epoch   5 Batch  860/1077 - Train Accuracy: 0.5982, Validation Accuracy: 0.6271, Loss: 0.5798
Epoch   5 Batch  870/1077 - Train Accuracy: 0.5847, Validation Accuracy: 0.6328, Loss: 0.6165
Epoch   5 Batch  880/1077 - Train Accuracy: 0.6301, Validation Accuracy: 0.6275, Loss: 0.5802
Epoch   5 Batch  890/1077 - Train Accuracy: 0.6804, Validation Accuracy: 0.6296, Loss: 0.5452
Epoch   5 Batch  900/1077 - Train Accuracy: 0.6160, Validation Accuracy: 0.6307, Loss: 0.5891
Epoch   5 Batch  910/1077 - Train Accuracy: 0.5986, Validation Accuracy: 0.6325, Loss: 0.5985
Epoch   5 Batch  920/1077 - Train Accuracy: 0.6031, Validation Accuracy: 0.6222, Loss: 0.5929
Epoch   5 Batch  930/1077 - Train Accuracy: 0.6254, Validation Accuracy: 0.6300, Loss: 0.5728
Epoch   5 Batch  940/1077 - Train Accuracy: 0.5941, Validation Accuracy: 0.6296, Loss: 0.5771
Epoch   5 Batch  950/1077 - Train Accuracy: 0.5919, Validation Accuracy: 0.6275, Loss: 0.5586
Epoch   5 Batch  960/1077 - Train Accuracy: 0.6257, Validation Accuracy: 0.6357, Loss: 0.5674
Epoch   5 Batch  970/1077 - Train Accuracy: 0.6316, Validation Accuracy: 0.6289, Loss: 0.5986
Epoch   5 Batch  980/1077 - Train Accuracy: 0.6070, Validation Accuracy: 0.6335, Loss: 0.5804
Epoch   5 Batch  990/1077 - Train Accuracy: 0.5868, Validation Accuracy: 0.6296, Loss: 0.6174
Epoch   5 Batch 1000/1077 - Train Accuracy: 0.6644, Validation Accuracy: 0.6296, Loss: 0.5349
Epoch   5 Batch 1010/1077 - Train Accuracy: 0.6219, Validation Accuracy: 0.6296, Loss: 0.5788
Epoch   5 Batch 1020/1077 - Train Accuracy: 0.5918, Validation Accuracy: 0.6346, Loss: 0.5746
Epoch   5 Batch 1030/1077 - Train Accuracy: 0.6098, Validation Accuracy: 0.6321, Loss: 0.5816
Epoch   5 Batch 1040/1077 - Train Accuracy: 0.5954, Validation Accuracy: 0.6332, Loss: 0.6023
Epoch   5 Batch 1050/1077 - Train Accuracy: 0.5426, Validation Accuracy: 0.6385, Loss: 0.5949
Epoch   5 Batch 1060/1077 - Train Accuracy: 0.6141, Validation Accuracy: 0.6360, Loss: 0.5558
Epoch   5 Batch 1070/1077 - Train Accuracy: 0.5730, Validation Accuracy: 0.6339, Loss: 0.5987
Epoch   6 Batch   10/1077 - Train Accuracy: 0.5991, Validation Accuracy: 0.6317, Loss: 0.6137
Epoch   6 Batch   20/1077 - Train Accuracy: 0.5801, Validation Accuracy: 0.6335, Loss: 0.5695
Epoch   6 Batch   30/1077 - Train Accuracy: 0.6043, Validation Accuracy: 0.6314, Loss: 0.5796
Epoch   6 Batch   40/1077 - Train Accuracy: 0.6074, Validation Accuracy: 0.6275, Loss: 0.5789
Epoch   6 Batch   50/1077 - Train Accuracy: 0.5918, Validation Accuracy: 0.6310, Loss: 0.5823
Epoch   6 Batch   60/1077 - Train Accuracy: 0.6031, Validation Accuracy: 0.6286, Loss: 0.5488
Epoch   6 Batch   70/1077 - Train Accuracy: 0.5938, Validation Accuracy: 0.6250, Loss: 0.5985
Epoch   6 Batch   80/1077 - Train Accuracy: 0.6121, Validation Accuracy: 0.6328, Loss: 0.5985
Epoch   6 Batch   90/1077 - Train Accuracy: 0.6062, Validation Accuracy: 0.6335, Loss: 0.5896
Epoch   6 Batch  100/1077 - Train Accuracy: 0.6164, Validation Accuracy: 0.6360, Loss: 0.5821
Epoch   6 Batch  110/1077 - Train Accuracy: 0.6531, Validation Accuracy: 0.6321, Loss: 0.5481
Epoch   6 Batch  120/1077 - Train Accuracy: 0.6168, Validation Accuracy: 0.6328, Loss: 0.5940
Epoch   6 Batch  130/1077 - Train Accuracy: 0.6131, Validation Accuracy: 0.6367, Loss: 0.5519
Epoch   6 Batch  140/1077 - Train Accuracy: 0.5888, Validation Accuracy: 0.6349, Loss: 0.5881
Epoch   6 Batch  150/1077 - Train Accuracy: 0.6350, Validation Accuracy: 0.6321, Loss: 0.5553
Epoch   6 Batch  160/1077 - Train Accuracy: 0.6469, Validation Accuracy: 0.6264, Loss: 0.5646
Epoch   6 Batch  170/1077 - Train Accuracy: 0.5762, Validation Accuracy: 0.6271, Loss: 0.5983
Epoch   6 Batch  180/1077 - Train Accuracy: 0.5941, Validation Accuracy: 0.6232, Loss: 0.5755
Epoch   6 Batch  190/1077 - Train Accuracy: 0.6535, Validation Accuracy: 0.6300, Loss: 0.5527
Epoch   6 Batch  200/1077 - Train Accuracy: 0.5770, Validation Accuracy: 0.6353, Loss: 0.5801
Epoch   6 Batch  210/1077 - Train Accuracy: 0.6354, Validation Accuracy: 0.6360, Loss: 0.5516
Epoch   6 Batch  220/1077 - Train Accuracy: 0.6003, Validation Accuracy: 0.6374, Loss: 0.5835
Epoch   6 Batch  230/1077 - Train Accuracy: 0.6313, Validation Accuracy: 0.6381, Loss: 0.5467
Epoch   6 Batch  240/1077 - Train Accuracy: 0.6406, Validation Accuracy: 0.6364, Loss: 0.5615
Epoch   6 Batch  250/1077 - Train Accuracy: 0.5913, Validation Accuracy: 0.6339, Loss: 0.5323
Epoch   6 Batch  260/1077 - Train Accuracy: 0.6205, Validation Accuracy: 0.6310, Loss: 0.5341
Epoch   6 Batch  270/1077 - Train Accuracy: 0.5828, Validation Accuracy: 0.6317, Loss: 0.5947
Epoch   6 Batch  280/1077 - Train Accuracy: 0.6281, Validation Accuracy: 0.6346, Loss: 0.5792
Epoch   6 Batch  290/1077 - Train Accuracy: 0.5984, Validation Accuracy: 0.6293, Loss: 0.5893
Epoch   6 Batch  300/1077 - Train Accuracy: 0.6131, Validation Accuracy: 0.6346, Loss: 0.5821
Epoch   6 Batch  310/1077 - Train Accuracy: 0.5965, Validation Accuracy: 0.6300, Loss: 0.5838
Epoch   6 Batch  320/1077 - Train Accuracy: 0.6234, Validation Accuracy: 0.6406, Loss: 0.5785
Epoch   6 Batch  330/1077 - Train Accuracy: 0.6539, Validation Accuracy: 0.6349, Loss: 0.5597
Epoch   6 Batch  340/1077 - Train Accuracy: 0.5839, Validation Accuracy: 0.6257, Loss: 0.5792
Epoch   6 Batch  350/1077 - Train Accuracy: 0.5953, Validation Accuracy: 0.6385, Loss: 0.5657
Epoch   6 Batch  360/1077 - Train Accuracy: 0.6023, Validation Accuracy: 0.6381, Loss: 0.5599
Epoch   6 Batch  370/1077 - Train Accuracy: 0.6287, Validation Accuracy: 0.6310, Loss: 0.5528
Epoch   6 Batch  380/1077 - Train Accuracy: 0.6105, Validation Accuracy: 0.6293, Loss: 0.5523
Epoch   6 Batch  390/1077 - Train Accuracy: 0.5742, Validation Accuracy: 0.6275, Loss: 0.5984
Epoch   6 Batch  400/1077 - Train Accuracy: 0.6402, Validation Accuracy: 0.6325, Loss: 0.5766
Epoch   6 Batch  410/1077 - Train Accuracy: 0.5863, Validation Accuracy: 0.6353, Loss: 0.5885
Epoch   6 Batch  420/1077 - Train Accuracy: 0.6102, Validation Accuracy: 0.6360, Loss: 0.5450
Epoch   6 Batch  430/1077 - Train Accuracy: 0.5957, Validation Accuracy: 0.6357, Loss: 0.5693
Epoch   6 Batch  440/1077 - Train Accuracy: 0.6008, Validation Accuracy: 0.6357, Loss: 0.5954
Epoch   6 Batch  450/1077 - Train Accuracy: 0.5926, Validation Accuracy: 0.6289, Loss: 0.5536
Epoch   6 Batch  460/1077 - Train Accuracy: 0.6035, Validation Accuracy: 0.6197, Loss: 0.5784
Epoch   6 Batch  470/1077 - Train Accuracy: 0.5650, Validation Accuracy: 0.6222, Loss: 0.6007
Epoch   6 Batch  480/1077 - Train Accuracy: 0.6340, Validation Accuracy: 0.6367, Loss: 0.5753
Epoch   6 Batch  490/1077 - Train Accuracy: 0.5980, Validation Accuracy: 0.6179, Loss: 0.5800
Epoch   6 Batch  500/1077 - Train Accuracy: 0.5988, Validation Accuracy: 0.6360, Loss: 0.5561
Epoch   6 Batch  510/1077 - Train Accuracy: 0.6277, Validation Accuracy: 0.6357, Loss: 0.5468
Epoch   6 Batch  520/1077 - Train Accuracy: 0.6548, Validation Accuracy: 0.6314, Loss: 0.5277
Epoch   6 Batch  530/1077 - Train Accuracy: 0.6051, Validation Accuracy: 0.6335, Loss: 0.5689
Epoch   6 Batch  540/1077 - Train Accuracy: 0.6031, Validation Accuracy: 0.6403, Loss: 0.5285
Epoch   6 Batch  550/1077 - Train Accuracy: 0.5945, Validation Accuracy: 0.6371, Loss: 0.5817
Epoch   6 Batch  560/1077 - Train Accuracy: 0.5926, Validation Accuracy: 0.6371, Loss: 0.5577
Epoch   6 Batch  570/1077 - Train Accuracy: 0.6180, Validation Accuracy: 0.6317, Loss: 0.5952
Epoch   6 Batch  580/1077 - Train Accuracy: 0.6443, Validation Accuracy: 0.6392, Loss: 0.5088
Epoch   6 Batch  590/1077 - Train Accuracy: 0.5995, Validation Accuracy: 0.6346, Loss: 0.5814
Epoch   6 Batch  600/1077 - Train Accuracy: 0.6425, Validation Accuracy: 0.6307, Loss: 0.5254
Epoch   6 Batch  610/1077 - Train Accuracy: 0.6028, Validation Accuracy: 0.6378, Loss: 0.5837
Epoch   6 Batch  620/1077 - Train Accuracy: 0.6195, Validation Accuracy: 0.6357, Loss: 0.5425
Epoch   6 Batch  630/1077 - Train Accuracy: 0.6137, Validation Accuracy: 0.6339, Loss: 0.5636
Epoch   6 Batch  640/1077 - Train Accuracy: 0.6105, Validation Accuracy: 0.6328, Loss: 0.5370
Epoch   6 Batch  650/1077 - Train Accuracy: 0.6066, Validation Accuracy: 0.6325, Loss: 0.5674
Epoch   6 Batch  660/1077 - Train Accuracy: 0.6156, Validation Accuracy: 0.6303, Loss: 0.5632
Epoch   6 Batch  670/1077 - Train Accuracy: 0.6570, Validation Accuracy: 0.6357, Loss: 0.5247
Epoch   6 Batch  680/1077 - Train Accuracy: 0.6179, Validation Accuracy: 0.6342, Loss: 0.5629
Epoch   6 Batch  690/1077 - Train Accuracy: 0.6379, Validation Accuracy: 0.6317, Loss: 0.5641
Epoch   6 Batch  700/1077 - Train Accuracy: 0.5828, Validation Accuracy: 0.6328, Loss: 0.5533
Epoch   6 Batch  710/1077 - Train Accuracy: 0.5793, Validation Accuracy: 0.6229, Loss: 0.5612
Epoch   6 Batch  720/1077 - Train Accuracy: 0.6069, Validation Accuracy: 0.6204, Loss: 0.5893
Epoch   6 Batch  730/1077 - Train Accuracy: 0.5957, Validation Accuracy: 0.6293, Loss: 0.5627
Epoch   6 Batch  740/1077 - Train Accuracy: 0.6152, Validation Accuracy: 0.6332, Loss: 0.5616
Epoch   6 Batch  750/1077 - Train Accuracy: 0.6145, Validation Accuracy: 0.6325, Loss: 0.5528
Epoch   6 Batch  760/1077 - Train Accuracy: 0.6262, Validation Accuracy: 0.6300, Loss: 0.5665
Epoch   6 Batch  770/1077 - Train Accuracy: 0.6414, Validation Accuracy: 0.6328, Loss: 0.5172
Epoch   6 Batch  780/1077 - Train Accuracy: 0.6121, Validation Accuracy: 0.6275, Loss: 0.5669
Epoch   6 Batch  790/1077 - Train Accuracy: 0.5406, Validation Accuracy: 0.6378, Loss: 0.5883
Epoch   6 Batch  800/1077 - Train Accuracy: 0.5844, Validation Accuracy: 0.6357, Loss: 0.5474
Epoch   6 Batch  810/1077 - Train Accuracy: 0.6347, Validation Accuracy: 0.6367, Loss: 0.5162
Epoch   6 Batch  820/1077 - Train Accuracy: 0.5785, Validation Accuracy: 0.6278, Loss: 0.5914
Epoch   6 Batch  830/1077 - Train Accuracy: 0.5980, Validation Accuracy: 0.6296, Loss: 0.5601
Epoch   6 Batch  840/1077 - Train Accuracy: 0.6090, Validation Accuracy: 0.6314, Loss: 0.5344
Epoch   6 Batch  850/1077 - Train Accuracy: 0.5911, Validation Accuracy: 0.6307, Loss: 0.5706
Epoch   6 Batch  860/1077 - Train Accuracy: 0.6090, Validation Accuracy: 0.6300, Loss: 0.5514
Epoch   6 Batch  870/1077 - Train Accuracy: 0.5868, Validation Accuracy: 0.6364, Loss: 0.5789
Epoch   6 Batch  880/1077 - Train Accuracy: 0.6418, Validation Accuracy: 0.6360, Loss: 0.5590
Epoch   6 Batch  890/1077 - Train Accuracy: 0.6827, Validation Accuracy: 0.6374, Loss: 0.5102
Epoch   6 Batch  900/1077 - Train Accuracy: 0.6195, Validation Accuracy: 0.6381, Loss: 0.5440
Epoch   6 Batch  910/1077 - Train Accuracy: 0.6060, Validation Accuracy: 0.6357, Loss: 0.5504
Epoch   6 Batch  920/1077 - Train Accuracy: 0.6043, Validation Accuracy: 0.6300, Loss: 0.5656
Epoch   6 Batch  930/1077 - Train Accuracy: 0.6363, Validation Accuracy: 0.6360, Loss: 0.5392
Epoch   6 Batch  940/1077 - Train Accuracy: 0.5984, Validation Accuracy: 0.6378, Loss: 0.5423
Epoch   6 Batch  950/1077 - Train Accuracy: 0.5919, Validation Accuracy: 0.6385, Loss: 0.5206
Epoch   6 Batch  960/1077 - Train Accuracy: 0.6391, Validation Accuracy: 0.6374, Loss: 0.5219
Epoch   6 Batch  970/1077 - Train Accuracy: 0.6391, Validation Accuracy: 0.6303, Loss: 0.5572
Epoch   6 Batch  980/1077 - Train Accuracy: 0.6125, Validation Accuracy: 0.6250, Loss: 0.5453
Epoch   6 Batch  990/1077 - Train Accuracy: 0.6057, Validation Accuracy: 0.6328, Loss: 0.5971
Epoch   6 Batch 1000/1077 - Train Accuracy: 0.6775, Validation Accuracy: 0.6357, Loss: 0.5084
Epoch   6 Batch 1010/1077 - Train Accuracy: 0.6250, Validation Accuracy: 0.6335, Loss: 0.5437
Epoch   6 Batch 1020/1077 - Train Accuracy: 0.5992, Validation Accuracy: 0.6360, Loss: 0.5317
Epoch   6 Batch 1030/1077 - Train Accuracy: 0.6098, Validation Accuracy: 0.6385, Loss: 0.5500
Epoch   6 Batch 1040/1077 - Train Accuracy: 0.6102, Validation Accuracy: 0.6399, Loss: 0.5552
Epoch   6 Batch 1050/1077 - Train Accuracy: 0.5559, Validation Accuracy: 0.6399, Loss: 0.5626
Epoch   6 Batch 1060/1077 - Train Accuracy: 0.6242, Validation Accuracy: 0.6353, Loss: 0.5285
Epoch   6 Batch 1070/1077 - Train Accuracy: 0.5867, Validation Accuracy: 0.6381, Loss: 0.5698
Epoch   7 Batch   10/1077 - Train Accuracy: 0.6077, Validation Accuracy: 0.6321, Loss: 0.5720
Epoch   7 Batch   20/1077 - Train Accuracy: 0.5848, Validation Accuracy: 0.6303, Loss: 0.5447
Epoch   7 Batch   30/1077 - Train Accuracy: 0.6059, Validation Accuracy: 0.6335, Loss: 0.5503
Epoch   7 Batch   40/1077 - Train Accuracy: 0.6141, Validation Accuracy: 0.6367, Loss: 0.5504
Epoch   7 Batch   50/1077 - Train Accuracy: 0.5914, Validation Accuracy: 0.6339, Loss: 0.5521
Epoch   7 Batch   60/1077 - Train Accuracy: 0.6138, Validation Accuracy: 0.6342, Loss: 0.5232
Epoch   7 Batch   70/1077 - Train Accuracy: 0.6036, Validation Accuracy: 0.6353, Loss: 0.5726
Epoch   7 Batch   80/1077 - Train Accuracy: 0.6094, Validation Accuracy: 0.6388, Loss: 0.5583
Epoch   7 Batch   90/1077 - Train Accuracy: 0.6262, Validation Accuracy: 0.6360, Loss: 0.5587
Epoch   7 Batch  100/1077 - Train Accuracy: 0.6258, Validation Accuracy: 0.6392, Loss: 0.5581
Epoch   7 Batch  110/1077 - Train Accuracy: 0.6516, Validation Accuracy: 0.6403, Loss: 0.5168
Epoch   7 Batch  120/1077 - Train Accuracy: 0.6285, Validation Accuracy: 0.6378, Loss: 0.5533
Epoch   7 Batch  130/1077 - Train Accuracy: 0.6220, Validation Accuracy: 0.6364, Loss: 0.5236
Epoch   7 Batch  140/1077 - Train Accuracy: 0.5966, Validation Accuracy: 0.6456, Loss: 0.5641
Epoch   7 Batch  150/1077 - Train Accuracy: 0.6600, Validation Accuracy: 0.6335, Loss: 0.5276
Epoch   7 Batch  160/1077 - Train Accuracy: 0.6488, Validation Accuracy: 0.6378, Loss: 0.5418
Epoch   7 Batch  170/1077 - Train Accuracy: 0.5711, Validation Accuracy: 0.6332, Loss: 0.5784
Epoch   7 Batch  180/1077 - Train Accuracy: 0.6004, Validation Accuracy: 0.6381, Loss: 0.5462
Epoch   7 Batch  190/1077 - Train Accuracy: 0.6621, Validation Accuracy: 0.6321, Loss: 0.5293
Epoch   7 Batch  200/1077 - Train Accuracy: 0.5918, Validation Accuracy: 0.6360, Loss: 0.5573
Epoch   7 Batch  210/1077 - Train Accuracy: 0.6406, Validation Accuracy: 0.6392, Loss: 0.5136
Epoch   7 Batch  220/1077 - Train Accuracy: 0.6114, Validation Accuracy: 0.6388, Loss: 0.5554
Epoch   7 Batch  230/1077 - Train Accuracy: 0.6298, Validation Accuracy: 0.6417, Loss: 0.5225
Epoch   7 Batch  240/1077 - Train Accuracy: 0.6781, Validation Accuracy: 0.6442, Loss: 0.5268
Epoch   7 Batch  250/1077 - Train Accuracy: 0.6133, Validation Accuracy: 0.6353, Loss: 0.5006
Epoch   7 Batch  260/1077 - Train Accuracy: 0.6417, Validation Accuracy: 0.6332, Loss: 0.5011
Epoch   7 Batch  270/1077 - Train Accuracy: 0.5863, Validation Accuracy: 0.6410, Loss: 0.5605
Epoch   7 Batch  280/1077 - Train Accuracy: 0.6383, Validation Accuracy: 0.6381, Loss: 0.5392
Epoch   7 Batch  290/1077 - Train Accuracy: 0.6145, Validation Accuracy: 0.6364, Loss: 0.5448
Epoch   7 Batch  300/1077 - Train Accuracy: 0.6192, Validation Accuracy: 0.6403, Loss: 0.5474
Epoch   7 Batch  310/1077 - Train Accuracy: 0.6125, Validation Accuracy: 0.6321, Loss: 0.5616
Epoch   7 Batch  320/1077 - Train Accuracy: 0.6422, Validation Accuracy: 0.6385, Loss: 0.5518
Epoch   7 Batch  330/1077 - Train Accuracy: 0.6613, Validation Accuracy: 0.6314, Loss: 0.5246
Epoch   7 Batch  340/1077 - Train Accuracy: 0.6020, Validation Accuracy: 0.6328, Loss: 0.5504
Epoch   7 Batch  350/1077 - Train Accuracy: 0.5922, Validation Accuracy: 0.6286, Loss: 0.5305
Epoch   7 Batch  360/1077 - Train Accuracy: 0.6320, Validation Accuracy: 0.6346, Loss: 0.5351
Epoch   7 Batch  370/1077 - Train Accuracy: 0.6399, Validation Accuracy: 0.6232, Loss: 0.5277
Epoch   7 Batch  380/1077 - Train Accuracy: 0.6230, Validation Accuracy: 0.6225, Loss: 0.5276
Epoch   7 Batch  390/1077 - Train Accuracy: 0.5785, Validation Accuracy: 0.6303, Loss: 0.5653
Epoch   7 Batch  400/1077 - Train Accuracy: 0.6500, Validation Accuracy: 0.6410, Loss: 0.5434
Epoch   7 Batch  410/1077 - Train Accuracy: 0.6081, Validation Accuracy: 0.6385, Loss: 0.5475
Epoch   7 Batch  420/1077 - Train Accuracy: 0.6184, Validation Accuracy: 0.6417, Loss: 0.5201
Epoch   7 Batch  430/1077 - Train Accuracy: 0.6070, Validation Accuracy: 0.6339, Loss: 0.5531
Epoch   7 Batch  440/1077 - Train Accuracy: 0.6047, Validation Accuracy: 0.6328, Loss: 0.5514
Epoch   7 Batch  450/1077 - Train Accuracy: 0.6000, Validation Accuracy: 0.6417, Loss: 0.5117
Epoch   7 Batch  460/1077 - Train Accuracy: 0.6207, Validation Accuracy: 0.6282, Loss: 0.5438
Epoch   7 Batch  470/1077 - Train Accuracy: 0.5954, Validation Accuracy: 0.6307, Loss: 0.5756
Epoch   7 Batch  480/1077 - Train Accuracy: 0.6373, Validation Accuracy: 0.6307, Loss: 0.5435
Epoch   7 Batch  490/1077 - Train Accuracy: 0.6090, Validation Accuracy: 0.6264, Loss: 0.5588
Epoch   7 Batch  500/1077 - Train Accuracy: 0.6145, Validation Accuracy: 0.6296, Loss: 0.5380
Epoch   7 Batch  510/1077 - Train Accuracy: 0.6336, Validation Accuracy: 0.6449, Loss: 0.5219
Epoch   7 Batch  520/1077 - Train Accuracy: 0.6715, Validation Accuracy: 0.6371, Loss: 0.4922
Epoch   7 Batch  530/1077 - Train Accuracy: 0.6133, Validation Accuracy: 0.6410, Loss: 0.5451
Epoch   7 Batch  540/1077 - Train Accuracy: 0.6148, Validation Accuracy: 0.6403, Loss: 0.5002
Epoch   7 Batch  550/1077 - Train Accuracy: 0.6043, Validation Accuracy: 0.6438, Loss: 0.5620
Epoch   7 Batch  560/1077 - Train Accuracy: 0.6027, Validation Accuracy: 0.6438, Loss: 0.5219
Epoch   7 Batch  570/1077 - Train Accuracy: 0.6254, Validation Accuracy: 0.6346, Loss: 0.5603
Epoch   7 Batch  580/1077 - Train Accuracy: 0.6737, Validation Accuracy: 0.6378, Loss: 0.4817
Epoch   7 Batch  590/1077 - Train Accuracy: 0.6139, Validation Accuracy: 0.6353, Loss: 0.5598
Epoch   7 Batch  600/1077 - Train Accuracy: 0.6574, Validation Accuracy: 0.6364, Loss: 0.4971
Epoch   7 Batch  610/1077 - Train Accuracy: 0.5933, Validation Accuracy: 0.6449, Loss: 0.5572
Epoch   7 Batch  620/1077 - Train Accuracy: 0.6270, Validation Accuracy: 0.6406, Loss: 0.5130
Epoch   7 Batch  630/1077 - Train Accuracy: 0.6328, Validation Accuracy: 0.6388, Loss: 0.5337
Epoch   7 Batch  640/1077 - Train Accuracy: 0.6231, Validation Accuracy: 0.6406, Loss: 0.5187
Epoch   7 Batch  650/1077 - Train Accuracy: 0.6246, Validation Accuracy: 0.6381, Loss: 0.5420
Epoch   7 Batch  660/1077 - Train Accuracy: 0.6312, Validation Accuracy: 0.6413, Loss: 0.5454
Epoch   7 Batch  670/1077 - Train Accuracy: 0.6694, Validation Accuracy: 0.6392, Loss: 0.4878
Epoch   7 Batch  680/1077 - Train Accuracy: 0.6235, Validation Accuracy: 0.6403, Loss: 0.5250
Epoch   7 Batch  690/1077 - Train Accuracy: 0.6527, Validation Accuracy: 0.6378, Loss: 0.5466
Epoch   7 Batch  700/1077 - Train Accuracy: 0.5949, Validation Accuracy: 0.6420, Loss: 0.5183
Epoch   7 Batch  710/1077 - Train Accuracy: 0.5813, Validation Accuracy: 0.6300, Loss: 0.5301
Epoch   7 Batch  720/1077 - Train Accuracy: 0.6192, Validation Accuracy: 0.6321, Loss: 0.5775
Epoch   7 Batch  730/1077 - Train Accuracy: 0.6070, Validation Accuracy: 0.6261, Loss: 0.5389
Epoch   7 Batch  740/1077 - Train Accuracy: 0.6254, Validation Accuracy: 0.6413, Loss: 0.5280
Epoch   7 Batch  750/1077 - Train Accuracy: 0.6348, Validation Accuracy: 0.6396, Loss: 0.5241
Epoch   7 Batch  760/1077 - Train Accuracy: 0.6352, Validation Accuracy: 0.6367, Loss: 0.5358
Epoch   7 Batch  770/1077 - Train Accuracy: 0.6447, Validation Accuracy: 0.6374, Loss: 0.4904
Epoch   7 Batch  780/1077 - Train Accuracy: 0.6281, Validation Accuracy: 0.6307, Loss: 0.5440
Epoch   7 Batch  790/1077 - Train Accuracy: 0.5547, Validation Accuracy: 0.6332, Loss: 0.5588
Epoch   7 Batch  800/1077 - Train Accuracy: 0.6117, Validation Accuracy: 0.6278, Loss: 0.5195
Epoch   7 Batch  810/1077 - Train Accuracy: 0.6417, Validation Accuracy: 0.6321, Loss: 0.4978
Epoch   7 Batch  820/1077 - Train Accuracy: 0.5902, Validation Accuracy: 0.6406, Loss: 0.5590
Epoch   7 Batch  830/1077 - Train Accuracy: 0.6141, Validation Accuracy: 0.6417, Loss: 0.5409
Epoch   7 Batch  840/1077 - Train Accuracy: 0.6223, Validation Accuracy: 0.6399, Loss: 0.5149
Epoch   7 Batch  850/1077 - Train Accuracy: 0.6019, Validation Accuracy: 0.6399, Loss: 0.5500
Epoch   7 Batch  860/1077 - Train Accuracy: 0.6202, Validation Accuracy: 0.6403, Loss: 0.5259
Epoch   7 Batch  870/1077 - Train Accuracy: 0.5950, Validation Accuracy: 0.6403, Loss: 0.5514
Epoch   7 Batch  880/1077 - Train Accuracy: 0.6484, Validation Accuracy: 0.6474, Loss: 0.5267
Epoch   7 Batch  890/1077 - Train Accuracy: 0.6845, Validation Accuracy: 0.6424, Loss: 0.4924
Epoch   7 Batch  900/1077 - Train Accuracy: 0.6422, Validation Accuracy: 0.6371, Loss: 0.5203
Epoch   7 Batch  910/1077 - Train Accuracy: 0.6198, Validation Accuracy: 0.6403, Loss: 0.5217
Epoch   7 Batch  920/1077 - Train Accuracy: 0.6316, Validation Accuracy: 0.6339, Loss: 0.5249
Epoch   7 Batch  930/1077 - Train Accuracy: 0.6504, Validation Accuracy: 0.6392, Loss: 0.5099
Epoch   7 Batch  940/1077 - Train Accuracy: 0.6129, Validation Accuracy: 0.6403, Loss: 0.5116
Epoch   7 Batch  950/1077 - Train Accuracy: 0.6224, Validation Accuracy: 0.6399, Loss: 0.5112
Epoch   7 Batch  960/1077 - Train Accuracy: 0.6410, Validation Accuracy: 0.6420, Loss: 0.5094
Epoch   7 Batch  970/1077 - Train Accuracy: 0.6484, Validation Accuracy: 0.6445, Loss: 0.5300
Epoch   7 Batch  980/1077 - Train Accuracy: 0.6168, Validation Accuracy: 0.6254, Loss: 0.5445
Epoch   7 Batch  990/1077 - Train Accuracy: 0.6164, Validation Accuracy: 0.6396, Loss: 0.5727
Epoch   7 Batch 1000/1077 - Train Accuracy: 0.6789, Validation Accuracy: 0.6357, Loss: 0.4822
Epoch   7 Batch 1010/1077 - Train Accuracy: 0.6395, Validation Accuracy: 0.6403, Loss: 0.5220
Epoch   7 Batch 1020/1077 - Train Accuracy: 0.6047, Validation Accuracy: 0.6388, Loss: 0.5120
Epoch   7 Batch 1030/1077 - Train Accuracy: 0.6195, Validation Accuracy: 0.6424, Loss: 0.5310
Epoch   7 Batch 1040/1077 - Train Accuracy: 0.6345, Validation Accuracy: 0.6399, Loss: 0.5374
Epoch   7 Batch 1050/1077 - Train Accuracy: 0.5570, Validation Accuracy: 0.6449, Loss: 0.5247
Epoch   7 Batch 1060/1077 - Train Accuracy: 0.6262, Validation Accuracy: 0.6456, Loss: 0.5184
Epoch   7 Batch 1070/1077 - Train Accuracy: 0.6012, Validation Accuracy: 0.6428, Loss: 0.5331
Epoch   8 Batch   10/1077 - Train Accuracy: 0.6287, Validation Accuracy: 0.6445, Loss: 0.5548
Epoch   8 Batch   20/1077 - Train Accuracy: 0.6062, Validation Accuracy: 0.6452, Loss: 0.5235
Epoch   8 Batch   30/1077 - Train Accuracy: 0.6262, Validation Accuracy: 0.6449, Loss: 0.5327
Epoch   8 Batch   40/1077 - Train Accuracy: 0.6156, Validation Accuracy: 0.6403, Loss: 0.5284
Epoch   8 Batch   50/1077 - Train Accuracy: 0.6059, Validation Accuracy: 0.6399, Loss: 0.5280
Epoch   8 Batch   60/1077 - Train Accuracy: 0.6321, Validation Accuracy: 0.6420, Loss: 0.5021
Epoch   8 Batch   70/1077 - Train Accuracy: 0.6135, Validation Accuracy: 0.6499, Loss: 0.5424
Epoch   8 Batch   80/1077 - Train Accuracy: 0.6328, Validation Accuracy: 0.6499, Loss: 0.5300
Epoch   8 Batch   90/1077 - Train Accuracy: 0.6242, Validation Accuracy: 0.6477, Loss: 0.5358
Epoch   8 Batch  100/1077 - Train Accuracy: 0.6383, Validation Accuracy: 0.6442, Loss: 0.5245
Epoch   8 Batch  110/1077 - Train Accuracy: 0.6637, Validation Accuracy: 0.6449, Loss: 0.4894
Epoch   8 Batch  120/1077 - Train Accuracy: 0.6379, Validation Accuracy: 0.6463, Loss: 0.5489
Epoch   8 Batch  130/1077 - Train Accuracy: 0.6310, Validation Accuracy: 0.6431, Loss: 0.4994
Epoch   8 Batch  140/1077 - Train Accuracy: 0.6143, Validation Accuracy: 0.6367, Loss: 0.5394
Epoch   8 Batch  150/1077 - Train Accuracy: 0.6544, Validation Accuracy: 0.6275, Loss: 0.4941
Epoch   8 Batch  160/1077 - Train Accuracy: 0.6539, Validation Accuracy: 0.6303, Loss: 0.5199
Epoch   8 Batch  170/1077 - Train Accuracy: 0.5984, Validation Accuracy: 0.6371, Loss: 0.5510
Epoch   8 Batch  180/1077 - Train Accuracy: 0.6234, Validation Accuracy: 0.6428, Loss: 0.5249
Epoch   8 Batch  190/1077 - Train Accuracy: 0.6734, Validation Accuracy: 0.6413, Loss: 0.4972
Epoch   8 Batch  200/1077 - Train Accuracy: 0.6090, Validation Accuracy: 0.6477, Loss: 0.5271
Epoch   8 Batch  210/1077 - Train Accuracy: 0.6358, Validation Accuracy: 0.6477, Loss: 0.5007
Epoch   8 Batch  220/1077 - Train Accuracy: 0.6197, Validation Accuracy: 0.6477, Loss: 0.5397
Epoch   8 Batch  230/1077 - Train Accuracy: 0.6350, Validation Accuracy: 0.6452, Loss: 0.5037
Epoch   8 Batch  240/1077 - Train Accuracy: 0.6758, Validation Accuracy: 0.6445, Loss: 0.4887
Epoch   8 Batch  250/1077 - Train Accuracy: 0.6268, Validation Accuracy: 0.6463, Loss: 0.4784
Epoch   8 Batch  260/1077 - Train Accuracy: 0.6529, Validation Accuracy: 0.6435, Loss: 0.4836
Epoch   8 Batch  270/1077 - Train Accuracy: 0.5844, Validation Accuracy: 0.6385, Loss: 0.5352
Epoch   8 Batch  280/1077 - Train Accuracy: 0.6480, Validation Accuracy: 0.6445, Loss: 0.5251
Epoch   8 Batch  290/1077 - Train Accuracy: 0.6176, Validation Accuracy: 0.6431, Loss: 0.5317
Epoch   8 Batch  300/1077 - Train Accuracy: 0.6332, Validation Accuracy: 0.6431, Loss: 0.5215
Epoch   8 Batch  310/1077 - Train Accuracy: 0.6207, Validation Accuracy: 0.6520, Loss: 0.5260
Epoch   8 Batch  320/1077 - Train Accuracy: 0.6633, Validation Accuracy: 0.6506, Loss: 0.5309
Epoch   8 Batch  330/1077 - Train Accuracy: 0.6676, Validation Accuracy: 0.6445, Loss: 0.5129
Epoch   8 Batch  340/1077 - Train Accuracy: 0.6266, Validation Accuracy: 0.6388, Loss: 0.5213
Epoch   8 Batch  350/1077 - Train Accuracy: 0.6160, Validation Accuracy: 0.6388, Loss: 0.4985
Epoch   8 Batch  360/1077 - Train Accuracy: 0.6312, Validation Accuracy: 0.6428, Loss: 0.5023
Epoch   8 Batch  370/1077 - Train Accuracy: 0.6462, Validation Accuracy: 0.6399, Loss: 0.4981
Epoch   8 Batch  380/1077 - Train Accuracy: 0.6219, Validation Accuracy: 0.6357, Loss: 0.4975
Epoch   8 Batch  390/1077 - Train Accuracy: 0.5773, Validation Accuracy: 0.6428, Loss: 0.5329
Epoch   8 Batch  400/1077 - Train Accuracy: 0.6527, Validation Accuracy: 0.6442, Loss: 0.5285
Epoch   8 Batch  410/1077 - Train Accuracy: 0.6061, Validation Accuracy: 0.6499, Loss: 0.5340
Epoch   8 Batch  420/1077 - Train Accuracy: 0.6348, Validation Accuracy: 0.6509, Loss: 0.4965
Epoch   8 Batch  430/1077 - Train Accuracy: 0.6082, Validation Accuracy: 0.6438, Loss: 0.5183
Epoch   8 Batch  440/1077 - Train Accuracy: 0.6062, Validation Accuracy: 0.6470, Loss: 0.5414
Epoch   8 Batch  450/1077 - Train Accuracy: 0.6098, Validation Accuracy: 0.6499, Loss: 0.4948
Epoch   8 Batch  460/1077 - Train Accuracy: 0.6070, Validation Accuracy: 0.6392, Loss: 0.5134
Epoch   8 Batch  470/1077 - Train Accuracy: 0.5946, Validation Accuracy: 0.6385, Loss: 0.5409
Epoch   8 Batch  480/1077 - Train Accuracy: 0.6542, Validation Accuracy: 0.6374, Loss: 0.5166
Epoch   8 Batch  490/1077 - Train Accuracy: 0.6203, Validation Accuracy: 0.6278, Loss: 0.5357
Epoch   8 Batch  500/1077 - Train Accuracy: 0.6188, Validation Accuracy: 0.6520, Loss: 0.5047
Epoch   8 Batch  510/1077 - Train Accuracy: 0.6395, Validation Accuracy: 0.6499, Loss: 0.4973
Epoch   8 Batch  520/1077 - Train Accuracy: 0.6789, Validation Accuracy: 0.6470, Loss: 0.4666
Epoch   8 Batch  530/1077 - Train Accuracy: 0.6262, Validation Accuracy: 0.6491, Loss: 0.5250
Epoch   8 Batch  540/1077 - Train Accuracy: 0.6250, Validation Accuracy: 0.6467, Loss: 0.4853
Epoch   8 Batch  550/1077 - Train Accuracy: 0.6121, Validation Accuracy: 0.6531, Loss: 0.5445
Epoch   8 Batch  560/1077 - Train Accuracy: 0.6086, Validation Accuracy: 0.6424, Loss: 0.4962
Epoch   8 Batch  570/1077 - Train Accuracy: 0.6345, Validation Accuracy: 0.6342, Loss: 0.5431
Epoch   8 Batch  580/1077 - Train Accuracy: 0.6685, Validation Accuracy: 0.6371, Loss: 0.4648
Epoch   8 Batch  590/1077 - Train Accuracy: 0.6094, Validation Accuracy: 0.6349, Loss: 0.5384
Epoch   8 Batch  600/1077 - Train Accuracy: 0.6633, Validation Accuracy: 0.6403, Loss: 0.4793
Epoch   8 Batch  610/1077 - Train Accuracy: 0.6160, Validation Accuracy: 0.6460, Loss: 0.5287
Epoch   8 Batch  620/1077 - Train Accuracy: 0.6375, Validation Accuracy: 0.6477, Loss: 0.4950
Epoch   8 Batch  630/1077 - Train Accuracy: 0.6414, Validation Accuracy: 0.6467, Loss: 0.5065
Epoch   8 Batch  640/1077 - Train Accuracy: 0.6336, Validation Accuracy: 0.6484, Loss: 0.4866
Epoch   8 Batch  650/1077 - Train Accuracy: 0.6301, Validation Accuracy: 0.6545, Loss: 0.5135
Epoch   8 Batch  660/1077 - Train Accuracy: 0.6352, Validation Accuracy: 0.6509, Loss: 0.5163
Epoch   8 Batch  670/1077 - Train Accuracy: 0.6754, Validation Accuracy: 0.6474, Loss: 0.4672
Epoch   8 Batch  680/1077 - Train Accuracy: 0.6291, Validation Accuracy: 0.6531, Loss: 0.5010
Epoch   8 Batch  690/1077 - Train Accuracy: 0.6430, Validation Accuracy: 0.6452, Loss: 0.5162
Epoch   8 Batch  700/1077 - Train Accuracy: 0.6039, Validation Accuracy: 0.6499, Loss: 0.4934
Epoch   8 Batch  710/1077 - Train Accuracy: 0.5965, Validation Accuracy: 0.6470, Loss: 0.5053
Epoch   8 Batch  720/1077 - Train Accuracy: 0.6287, Validation Accuracy: 0.6317, Loss: 0.5345
Epoch   8 Batch  730/1077 - Train Accuracy: 0.6137, Validation Accuracy: 0.6438, Loss: 0.5071
Epoch   8 Batch  740/1077 - Train Accuracy: 0.6176, Validation Accuracy: 0.6456, Loss: 0.4926
Epoch   8 Batch  750/1077 - Train Accuracy: 0.6371, Validation Accuracy: 0.6445, Loss: 0.5178
Epoch   8 Batch  760/1077 - Train Accuracy: 0.6410, Validation Accuracy: 0.6438, Loss: 0.5046
Epoch   8 Batch  770/1077 - Train Accuracy: 0.6481, Validation Accuracy: 0.6396, Loss: 0.4693
Epoch   8 Batch  780/1077 - Train Accuracy: 0.6379, Validation Accuracy: 0.6484, Loss: 0.5068
Epoch   8 Batch  790/1077 - Train Accuracy: 0.5609, Validation Accuracy: 0.6449, Loss: 0.5400
Epoch   8 Batch  800/1077 - Train Accuracy: 0.6238, Validation Accuracy: 0.6406, Loss: 0.5066
Epoch   8 Batch  810/1077 - Train Accuracy: 0.6429, Validation Accuracy: 0.6442, Loss: 0.4734
Epoch   8 Batch  820/1077 - Train Accuracy: 0.5977, Validation Accuracy: 0.6527, Loss: 0.5395
Epoch   8 Batch  830/1077 - Train Accuracy: 0.6234, Validation Accuracy: 0.6474, Loss: 0.5070
Epoch   8 Batch  840/1077 - Train Accuracy: 0.6297, Validation Accuracy: 0.6491, Loss: 0.4860
Epoch   8 Batch  850/1077 - Train Accuracy: 0.6116, Validation Accuracy: 0.6481, Loss: 0.5245
Epoch   8 Batch  860/1077 - Train Accuracy: 0.6276, Validation Accuracy: 0.6527, Loss: 0.5047
Epoch   8 Batch  870/1077 - Train Accuracy: 0.5999, Validation Accuracy: 0.6520, Loss: 0.5184
Epoch   8 Batch  880/1077 - Train Accuracy: 0.6590, Validation Accuracy: 0.6566, Loss: 0.4986
Epoch   8 Batch  890/1077 - Train Accuracy: 0.6912, Validation Accuracy: 0.6531, Loss: 0.4739
Epoch   8 Batch  900/1077 - Train Accuracy: 0.6504, Validation Accuracy: 0.6534, Loss: 0.4986
Epoch   8 Batch  910/1077 - Train Accuracy: 0.6246, Validation Accuracy: 0.6474, Loss: 0.4990
Epoch   8 Batch  920/1077 - Train Accuracy: 0.6320, Validation Accuracy: 0.6491, Loss: 0.5124
Epoch   8 Batch  930/1077 - Train Accuracy: 0.6465, Validation Accuracy: 0.6470, Loss: 0.4861
Epoch   8 Batch  940/1077 - Train Accuracy: 0.6258, Validation Accuracy: 0.6460, Loss: 0.4934
Epoch   8 Batch  950/1077 - Train Accuracy: 0.6231, Validation Accuracy: 0.6488, Loss: 0.4662
Epoch   8 Batch  960/1077 - Train Accuracy: 0.6577, Validation Accuracy: 0.6499, Loss: 0.4805
Epoch   8 Batch  970/1077 - Train Accuracy: 0.6520, Validation Accuracy: 0.6463, Loss: 0.4972
Epoch   8 Batch  980/1077 - Train Accuracy: 0.6348, Validation Accuracy: 0.6477, Loss: 0.5013
Epoch   8 Batch  990/1077 - Train Accuracy: 0.6287, Validation Accuracy: 0.6456, Loss: 0.5345
Epoch   8 Batch 1000/1077 - Train Accuracy: 0.6864, Validation Accuracy: 0.6438, Loss: 0.4575
Epoch   8 Batch 1010/1077 - Train Accuracy: 0.6477, Validation Accuracy: 0.6495, Loss: 0.5065
Epoch   8 Batch 1020/1077 - Train Accuracy: 0.6137, Validation Accuracy: 0.6445, Loss: 0.4736
Epoch   8 Batch 1030/1077 - Train Accuracy: 0.6309, Validation Accuracy: 0.6449, Loss: 0.5008
Epoch   8 Batch 1040/1077 - Train Accuracy: 0.6373, Validation Accuracy: 0.6417, Loss: 0.5124
Epoch   8 Batch 1050/1077 - Train Accuracy: 0.5734, Validation Accuracy: 0.6413, Loss: 0.4965
Epoch   8 Batch 1060/1077 - Train Accuracy: 0.6254, Validation Accuracy: 0.6428, Loss: 0.4761
Epoch   8 Batch 1070/1077 - Train Accuracy: 0.6117, Validation Accuracy: 0.6452, Loss: 0.5020
Epoch   9 Batch   10/1077 - Train Accuracy: 0.6262, Validation Accuracy: 0.6442, Loss: 0.5230
Epoch   9 Batch   20/1077 - Train Accuracy: 0.6062, Validation Accuracy: 0.6474, Loss: 0.4949
Epoch   9 Batch   30/1077 - Train Accuracy: 0.6316, Validation Accuracy: 0.6491, Loss: 0.5065
Epoch   9 Batch   40/1077 - Train Accuracy: 0.6262, Validation Accuracy: 0.6431, Loss: 0.5069
Epoch   9 Batch   50/1077 - Train Accuracy: 0.6086, Validation Accuracy: 0.6452, Loss: 0.4989
Epoch   9 Batch   60/1077 - Train Accuracy: 0.6425, Validation Accuracy: 0.6484, Loss: 0.4747
Epoch   9 Batch   70/1077 - Train Accuracy: 0.6188, Validation Accuracy: 0.6463, Loss: 0.5257
Epoch   9 Batch   80/1077 - Train Accuracy: 0.6457, Validation Accuracy: 0.6520, Loss: 0.5070
Epoch   9 Batch   90/1077 - Train Accuracy: 0.6465, Validation Accuracy: 0.6513, Loss: 0.5118
Epoch   9 Batch  100/1077 - Train Accuracy: 0.6391, Validation Accuracy: 0.6484, Loss: 0.4977
Epoch   9 Batch  110/1077 - Train Accuracy: 0.6699, Validation Accuracy: 0.6488, Loss: 0.4645
Epoch   9 Batch  120/1077 - Train Accuracy: 0.6430, Validation Accuracy: 0.6477, Loss: 0.5099
Epoch   9 Batch  130/1077 - Train Accuracy: 0.6350, Validation Accuracy: 0.6516, Loss: 0.4716
Epoch   9 Batch  140/1077 - Train Accuracy: 0.6180, Validation Accuracy: 0.6587, Loss: 0.5056
Epoch   9 Batch  150/1077 - Train Accuracy: 0.6611, Validation Accuracy: 0.6499, Loss: 0.4675
Epoch   9 Batch  160/1077 - Train Accuracy: 0.6586, Validation Accuracy: 0.6449, Loss: 0.4845
Epoch   9 Batch  170/1077 - Train Accuracy: 0.6008, Validation Accuracy: 0.6548, Loss: 0.5175
Epoch   9 Batch  180/1077 - Train Accuracy: 0.6281, Validation Accuracy: 0.6591, Loss: 0.4989
Epoch   9 Batch  190/1077 - Train Accuracy: 0.6773, Validation Accuracy: 0.6456, Loss: 0.4755
Epoch   9 Batch  200/1077 - Train Accuracy: 0.6152, Validation Accuracy: 0.6488, Loss: 0.5045
Epoch   9 Batch  210/1077 - Train Accuracy: 0.6652, Validation Accuracy: 0.6435, Loss: 0.4778
Epoch   9 Batch  220/1077 - Train Accuracy: 0.6312, Validation Accuracy: 0.6481, Loss: 0.5020
Epoch   9 Batch  230/1077 - Train Accuracy: 0.6484, Validation Accuracy: 0.6484, Loss: 0.4723
Epoch   9 Batch  240/1077 - Train Accuracy: 0.6781, Validation Accuracy: 0.6470, Loss: 0.4701
Epoch   9 Batch  250/1077 - Train Accuracy: 0.6310, Validation Accuracy: 0.6488, Loss: 0.4660
Epoch   9 Batch  260/1077 - Train Accuracy: 0.6529, Validation Accuracy: 0.6513, Loss: 0.4557
Epoch   9 Batch  270/1077 - Train Accuracy: 0.5941, Validation Accuracy: 0.6509, Loss: 0.5164
Epoch   9 Batch  280/1077 - Train Accuracy: 0.6523, Validation Accuracy: 0.6488, Loss: 0.5016
Epoch   9 Batch  290/1077 - Train Accuracy: 0.6242, Validation Accuracy: 0.6499, Loss: 0.5023
Epoch   9 Batch  300/1077 - Train Accuracy: 0.6340, Validation Accuracy: 0.6541, Loss: 0.5017
Epoch   9 Batch  310/1077 - Train Accuracy: 0.6312, Validation Accuracy: 0.6541, Loss: 0.5090
Epoch   9 Batch  320/1077 - Train Accuracy: 0.6703, Validation Accuracy: 0.6520, Loss: 0.5030
Epoch   9 Batch  330/1077 - Train Accuracy: 0.6816, Validation Accuracy: 0.6484, Loss: 0.4848
Epoch   9 Batch  340/1077 - Train Accuracy: 0.6234, Validation Accuracy: 0.6381, Loss: 0.5015
Epoch   9 Batch  350/1077 - Train Accuracy: 0.6141, Validation Accuracy: 0.6541, Loss: 0.4775
Epoch   9 Batch  360/1077 - Train Accuracy: 0.6434, Validation Accuracy: 0.6577, Loss: 0.4930
Epoch   9 Batch  370/1077 - Train Accuracy: 0.6492, Validation Accuracy: 0.6378, Loss: 0.4864
Epoch   9 Batch  380/1077 - Train Accuracy: 0.6309, Validation Accuracy: 0.6509, Loss: 0.4792
Epoch   9 Batch  390/1077 - Train Accuracy: 0.5961, Validation Accuracy: 0.6460, Loss: 0.5107
Epoch   9 Batch  400/1077 - Train Accuracy: 0.6613, Validation Accuracy: 0.6520, Loss: 0.4956
Epoch   9 Batch  410/1077 - Train Accuracy: 0.6250, Validation Accuracy: 0.6545, Loss: 0.4963
Epoch   9 Batch  420/1077 - Train Accuracy: 0.6367, Validation Accuracy: 0.6527, Loss: 0.4669
Epoch   9 Batch  430/1077 - Train Accuracy: 0.6137, Validation Accuracy: 0.6474, Loss: 0.4999
Epoch   9 Batch  440/1077 - Train Accuracy: 0.6191, Validation Accuracy: 0.6488, Loss: 0.4942
Epoch   9 Batch  450/1077 - Train Accuracy: 0.6207, Validation Accuracy: 0.6506, Loss: 0.4729
Epoch   9 Batch  460/1077 - Train Accuracy: 0.6316, Validation Accuracy: 0.6509, Loss: 0.4977
Epoch   9 Batch  470/1077 - Train Accuracy: 0.6127, Validation Accuracy: 0.6410, Loss: 0.5141
Epoch   9 Batch  480/1077 - Train Accuracy: 0.6595, Validation Accuracy: 0.6410, Loss: 0.4913
Epoch   9 Batch  490/1077 - Train Accuracy: 0.6277, Validation Accuracy: 0.6413, Loss: 0.5121
Epoch   9 Batch  500/1077 - Train Accuracy: 0.6281, Validation Accuracy: 0.6406, Loss: 0.4871
Epoch   9 Batch  510/1077 - Train Accuracy: 0.6457, Validation Accuracy: 0.6573, Loss: 0.4674
Epoch   9 Batch  520/1077 - Train Accuracy: 0.6801, Validation Accuracy: 0.6520, Loss: 0.4567
Epoch   9 Batch  530/1077 - Train Accuracy: 0.6406, Validation Accuracy: 0.6573, Loss: 0.5098
Epoch   9 Batch  540/1077 - Train Accuracy: 0.6430, Validation Accuracy: 0.6609, Loss: 0.4678
Epoch   9 Batch  550/1077 - Train Accuracy: 0.6160, Validation Accuracy: 0.6602, Loss: 0.5216
Epoch   9 Batch  560/1077 - Train Accuracy: 0.6168, Validation Accuracy: 0.6502, Loss: 0.4675
Epoch   9 Batch  570/1077 - Train Accuracy: 0.6530, Validation Accuracy: 0.6460, Loss: 0.5152
Epoch   9 Batch  580/1077 - Train Accuracy: 0.6875, Validation Accuracy: 0.6541, Loss: 0.4377
Epoch   9 Batch  590/1077 - Train Accuracy: 0.6271, Validation Accuracy: 0.6364, Loss: 0.5285
Epoch   9 Batch  600/1077 - Train Accuracy: 0.6663, Validation Accuracy: 0.6534, Loss: 0.4564
Epoch   9 Batch  610/1077 - Train Accuracy: 0.6312, Validation Accuracy: 0.6516, Loss: 0.5098
Epoch   9 Batch  620/1077 - Train Accuracy: 0.6445, Validation Accuracy: 0.6566, Loss: 0.4731
Epoch   9 Batch  630/1077 - Train Accuracy: 0.6492, Validation Accuracy: 0.6555, Loss: 0.4855
Epoch   9 Batch  640/1077 - Train Accuracy: 0.6339, Validation Accuracy: 0.6541, Loss: 0.4613
Epoch   9 Batch  650/1077 - Train Accuracy: 0.6434, Validation Accuracy: 0.6598, Loss: 0.4959
Epoch   9 Batch  660/1077 - Train Accuracy: 0.6535, Validation Accuracy: 0.6630, Loss: 0.4964
Epoch   9 Batch  670/1077 - Train Accuracy: 0.6864, Validation Accuracy: 0.6591, Loss: 0.4528
Epoch   9 Batch  680/1077 - Train Accuracy: 0.6358, Validation Accuracy: 0.6612, Loss: 0.4933
Epoch   9 Batch  690/1077 - Train Accuracy: 0.6695, Validation Accuracy: 0.6477, Loss: 0.4920
Epoch   9 Batch  700/1077 - Train Accuracy: 0.6258, Validation Accuracy: 0.6516, Loss: 0.4729
Epoch   9 Batch  710/1077 - Train Accuracy: 0.6109, Validation Accuracy: 0.6481, Loss: 0.4910
Epoch   9 Batch  720/1077 - Train Accuracy: 0.6353, Validation Accuracy: 0.6513, Loss: 0.5095
Epoch   9 Batch  730/1077 - Train Accuracy: 0.6176, Validation Accuracy: 0.6495, Loss: 0.4926
Epoch   9 Batch  740/1077 - Train Accuracy: 0.6395, Validation Accuracy: 0.6484, Loss: 0.4804
Epoch   9 Batch  750/1077 - Train Accuracy: 0.6508, Validation Accuracy: 0.6502, Loss: 0.4802
Epoch   9 Batch  760/1077 - Train Accuracy: 0.6484, Validation Accuracy: 0.6516, Loss: 0.4866
Epoch   9 Batch  770/1077 - Train Accuracy: 0.6522, Validation Accuracy: 0.6516, Loss: 0.4527
Epoch   9 Batch  780/1077 - Train Accuracy: 0.6512, Validation Accuracy: 0.6474, Loss: 0.4803
Epoch   9 Batch  790/1077 - Train Accuracy: 0.5773, Validation Accuracy: 0.6545, Loss: 0.5022
Epoch   9 Batch  800/1077 - Train Accuracy: 0.6227, Validation Accuracy: 0.6562, Loss: 0.4718
Epoch   9 Batch  810/1077 - Train Accuracy: 0.6596, Validation Accuracy: 0.6541, Loss: 0.4499
Epoch   9 Batch  820/1077 - Train Accuracy: 0.6090, Validation Accuracy: 0.6562, Loss: 0.5117
Epoch   9 Batch  830/1077 - Train Accuracy: 0.6316, Validation Accuracy: 0.6562, Loss: 0.4839
Epoch   9 Batch  840/1077 - Train Accuracy: 0.6457, Validation Accuracy: 0.6566, Loss: 0.4682
Epoch   9 Batch  850/1077 - Train Accuracy: 0.6161, Validation Accuracy: 0.6538, Loss: 0.5091
Epoch   9 Batch  860/1077 - Train Accuracy: 0.6328, Validation Accuracy: 0.6502, Loss: 0.4845
Epoch   9 Batch  870/1077 - Train Accuracy: 0.6106, Validation Accuracy: 0.6527, Loss: 0.5081
Epoch   9 Batch  880/1077 - Train Accuracy: 0.6715, Validation Accuracy: 0.6580, Loss: 0.4733
Epoch   9 Batch  890/1077 - Train Accuracy: 0.7016, Validation Accuracy: 0.6520, Loss: 0.4496
Epoch   9 Batch  900/1077 - Train Accuracy: 0.6605, Validation Accuracy: 0.6573, Loss: 0.4810
Epoch   9 Batch  910/1077 - Train Accuracy: 0.6287, Validation Accuracy: 0.6555, Loss: 0.4720
Epoch   9 Batch  920/1077 - Train Accuracy: 0.6582, Validation Accuracy: 0.6587, Loss: 0.4863
Epoch   9 Batch  930/1077 - Train Accuracy: 0.6582, Validation Accuracy: 0.6531, Loss: 0.4639
Epoch   9 Batch  940/1077 - Train Accuracy: 0.6379, Validation Accuracy: 0.6559, Loss: 0.4698
Epoch   9 Batch  950/1077 - Train Accuracy: 0.6265, Validation Accuracy: 0.6602, Loss: 0.4586
Epoch   9 Batch  960/1077 - Train Accuracy: 0.6637, Validation Accuracy: 0.6591, Loss: 0.4635
Epoch   9 Batch  970/1077 - Train Accuracy: 0.6539, Validation Accuracy: 0.6527, Loss: 0.4804
Epoch   9 Batch  980/1077 - Train Accuracy: 0.6402, Validation Accuracy: 0.6481, Loss: 0.4782
Epoch   9 Batch  990/1077 - Train Accuracy: 0.6468, Validation Accuracy: 0.6552, Loss: 0.5131
Epoch   9 Batch 1000/1077 - Train Accuracy: 0.6998, Validation Accuracy: 0.6605, Loss: 0.4372
Epoch   9 Batch 1010/1077 - Train Accuracy: 0.6547, Validation Accuracy: 0.6502, Loss: 0.4749
Epoch   9 Batch 1020/1077 - Train Accuracy: 0.6172, Validation Accuracy: 0.6555, Loss: 0.4735
Epoch   9 Batch 1030/1077 - Train Accuracy: 0.6461, Validation Accuracy: 0.6577, Loss: 0.4826
Epoch   9 Batch 1040/1077 - Train Accuracy: 0.6484, Validation Accuracy: 0.6587, Loss: 0.4875
Epoch   9 Batch 1050/1077 - Train Accuracy: 0.5801, Validation Accuracy: 0.6580, Loss: 0.4854
Epoch   9 Batch 1060/1077 - Train Accuracy: 0.6309, Validation Accuracy: 0.6509, Loss: 0.4558
Epoch   9 Batch 1070/1077 - Train Accuracy: 0.6145, Validation Accuracy: 0.6502, Loss: 0.4815
Epoch  10 Batch   10/1077 - Train Accuracy: 0.6349, Validation Accuracy: 0.6552, Loss: 0.5022
Epoch  10 Batch   20/1077 - Train Accuracy: 0.6219, Validation Accuracy: 0.6591, Loss: 0.4740
Epoch  10 Batch   30/1077 - Train Accuracy: 0.6367, Validation Accuracy: 0.6552, Loss: 0.4911
Epoch  10 Batch   40/1077 - Train Accuracy: 0.6512, Validation Accuracy: 0.6523, Loss: 0.4708
Epoch  10 Batch   50/1077 - Train Accuracy: 0.6207, Validation Accuracy: 0.6488, Loss: 0.4777
Epoch  10 Batch   60/1077 - Train Accuracy: 0.6536, Validation Accuracy: 0.6541, Loss: 0.4657
Epoch  10 Batch   70/1077 - Train Accuracy: 0.6312, Validation Accuracy: 0.6570, Loss: 0.5015
Epoch  10 Batch   80/1077 - Train Accuracy: 0.6445, Validation Accuracy: 0.6609, Loss: 0.4872
Epoch  10 Batch   90/1077 - Train Accuracy: 0.6523, Validation Accuracy: 0.6605, Loss: 0.4887
Epoch  10 Batch  100/1077 - Train Accuracy: 0.6543, Validation Accuracy: 0.6612, Loss: 0.4862
Epoch  10 Batch  110/1077 - Train Accuracy: 0.6859, Validation Accuracy: 0.6619, Loss: 0.4351
Epoch  10 Batch  120/1077 - Train Accuracy: 0.6578, Validation Accuracy: 0.6573, Loss: 0.5050
Epoch  10 Batch  130/1077 - Train Accuracy: 0.6488, Validation Accuracy: 0.6474, Loss: 0.4580
Epoch  10 Batch  140/1077 - Train Accuracy: 0.6308, Validation Accuracy: 0.6577, Loss: 0.4851
Epoch  10 Batch  150/1077 - Train Accuracy: 0.6804, Validation Accuracy: 0.6662, Loss: 0.4532
Epoch  10 Batch  160/1077 - Train Accuracy: 0.6715, Validation Accuracy: 0.6648, Loss: 0.4657
Epoch  10 Batch  170/1077 - Train Accuracy: 0.6195, Validation Accuracy: 0.6641, Loss: 0.4848
Epoch  10 Batch  180/1077 - Train Accuracy: 0.6527, Validation Accuracy: 0.6623, Loss: 0.4729
Epoch  10 Batch  190/1077 - Train Accuracy: 0.6844, Validation Accuracy: 0.6577, Loss: 0.4582
Epoch  10 Batch  200/1077 - Train Accuracy: 0.6238, Validation Accuracy: 0.6591, Loss: 0.4718
Epoch  10 Batch  210/1077 - Train Accuracy: 0.6663, Validation Accuracy: 0.6566, Loss: 0.4561
Epoch  10 Batch  220/1077 - Train Accuracy: 0.6435, Validation Accuracy: 0.6541, Loss: 0.4838
Epoch  10 Batch  230/1077 - Train Accuracy: 0.6548, Validation Accuracy: 0.6516, Loss: 0.4523
Epoch  10 Batch  240/1077 - Train Accuracy: 0.6813, Validation Accuracy: 0.6602, Loss: 0.4415
Epoch  10 Batch  250/1077 - Train Accuracy: 0.6385, Validation Accuracy: 0.6651, Loss: 0.4392
Epoch  10 Batch  260/1077 - Train Accuracy: 0.6760, Validation Accuracy: 0.6680, Loss: 0.4275
Epoch  10 Batch  270/1077 - Train Accuracy: 0.6031, Validation Accuracy: 0.6602, Loss: 0.4868
Epoch  10 Batch  280/1077 - Train Accuracy: 0.6637, Validation Accuracy: 0.6648, Loss: 0.4765
Epoch  10 Batch  290/1077 - Train Accuracy: 0.6367, Validation Accuracy: 0.6641, Loss: 0.4803
Epoch  10 Batch  300/1077 - Train Accuracy: 0.6414, Validation Accuracy: 0.6634, Loss: 0.4620
Epoch  10 Batch  310/1077 - Train Accuracy: 0.6355, Validation Accuracy: 0.6566, Loss: 0.4897
Epoch  10 Batch  320/1077 - Train Accuracy: 0.6785, Validation Accuracy: 0.6697, Loss: 0.4953
Epoch  10 Batch  330/1077 - Train Accuracy: 0.6840, Validation Accuracy: 0.6577, Loss: 0.4661
Epoch  10 Batch  340/1077 - Train Accuracy: 0.6394, Validation Accuracy: 0.6577, Loss: 0.4772
Epoch  10 Batch  350/1077 - Train Accuracy: 0.6363, Validation Accuracy: 0.6637, Loss: 0.4504
Epoch  10 Batch  360/1077 - Train Accuracy: 0.6527, Validation Accuracy: 0.6577, Loss: 0.4620
Epoch  10 Batch  370/1077 - Train Accuracy: 0.6615, Validation Accuracy: 0.6516, Loss: 0.4627
Epoch  10 Batch  380/1077 - Train Accuracy: 0.6285, Validation Accuracy: 0.6403, Loss: 0.4595
Epoch  10 Batch  390/1077 - Train Accuracy: 0.6105, Validation Accuracy: 0.6516, Loss: 0.4829
Epoch  10 Batch  400/1077 - Train Accuracy: 0.6676, Validation Accuracy: 0.6626, Loss: 0.4711
Epoch  10 Batch  410/1077 - Train Accuracy: 0.6295, Validation Accuracy: 0.6648, Loss: 0.4726
Epoch  10 Batch  420/1077 - Train Accuracy: 0.6480, Validation Accuracy: 0.6630, Loss: 0.4546
Epoch  10 Batch  430/1077 - Train Accuracy: 0.6305, Validation Accuracy: 0.6616, Loss: 0.4702
Epoch  10 Batch  440/1077 - Train Accuracy: 0.6246, Validation Accuracy: 0.6584, Loss: 0.4717
Epoch  10 Batch  450/1077 - Train Accuracy: 0.6340, Validation Accuracy: 0.6623, Loss: 0.4568
Epoch  10 Batch  460/1077 - Train Accuracy: 0.6293, Validation Accuracy: 0.6470, Loss: 0.4760
Epoch  10 Batch  470/1077 - Train Accuracy: 0.6147, Validation Accuracy: 0.6538, Loss: 0.4850
Epoch  10 Batch  480/1077 - Train Accuracy: 0.6690, Validation Accuracy: 0.6541, Loss: 0.4697
Epoch  10 Batch  490/1077 - Train Accuracy: 0.6289, Validation Accuracy: 0.6495, Loss: 0.4735
Epoch  10 Batch  500/1077 - Train Accuracy: 0.6484, Validation Accuracy: 0.6648, Loss: 0.4518
Epoch  10 Batch  510/1077 - Train Accuracy: 0.6543, Validation Accuracy: 0.6644, Loss: 0.4469
Epoch  10 Batch  520/1077 - Train Accuracy: 0.6916, Validation Accuracy: 0.6683, Loss: 0.4240
Epoch  10 Batch  530/1077 - Train Accuracy: 0.6477, Validation Accuracy: 0.6609, Loss: 0.4732
Epoch  10 Batch  540/1077 - Train Accuracy: 0.6453, Validation Accuracy: 0.6658, Loss: 0.4292
Epoch  10 Batch  550/1077 - Train Accuracy: 0.6199, Validation Accuracy: 0.6651, Loss: 0.4827
Epoch  10 Batch  560/1077 - Train Accuracy: 0.6289, Validation Accuracy: 0.6705, Loss: 0.4490
Epoch  10 Batch  570/1077 - Train Accuracy: 0.6554, Validation Accuracy: 0.6587, Loss: 0.4973
Epoch  10 Batch  580/1077 - Train Accuracy: 0.6879, Validation Accuracy: 0.6545, Loss: 0.4149
Epoch  10 Batch  590/1077 - Train Accuracy: 0.6365, Validation Accuracy: 0.6570, Loss: 0.4949
Epoch  10 Batch  600/1077 - Train Accuracy: 0.6763, Validation Accuracy: 0.6669, Loss: 0.4369
Epoch  10 Batch  610/1077 - Train Accuracy: 0.6373, Validation Accuracy: 0.6669, Loss: 0.4727
Epoch  10 Batch  620/1077 - Train Accuracy: 0.6445, Validation Accuracy: 0.6630, Loss: 0.4457
Epoch  10 Batch  630/1077 - Train Accuracy: 0.6613, Validation Accuracy: 0.6655, Loss: 0.4561
Epoch  10 Batch  640/1077 - Train Accuracy: 0.6451, Validation Accuracy: 0.6669, Loss: 0.4392
Epoch  10 Batch  650/1077 - Train Accuracy: 0.6445, Validation Accuracy: 0.6680, Loss: 0.4678
Epoch  10 Batch  660/1077 - Train Accuracy: 0.6574, Validation Accuracy: 0.6669, Loss: 0.4714
Epoch  10 Batch  670/1077 - Train Accuracy: 0.6932, Validation Accuracy: 0.6644, Loss: 0.4201
Epoch  10 Batch  680/1077 - Train Accuracy: 0.6440, Validation Accuracy: 0.6687, Loss: 0.4663
Epoch  10 Batch  690/1077 - Train Accuracy: 0.6652, Validation Accuracy: 0.6605, Loss: 0.4588
Epoch  10 Batch  700/1077 - Train Accuracy: 0.6344, Validation Accuracy: 0.6594, Loss: 0.4581
Epoch  10 Batch  710/1077 - Train Accuracy: 0.6160, Validation Accuracy: 0.6573, Loss: 0.4654
Epoch  10 Batch  720/1077 - Train Accuracy: 0.6517, Validation Accuracy: 0.6474, Loss: 0.4874
Epoch  10 Batch  730/1077 - Train Accuracy: 0.6363, Validation Accuracy: 0.6580, Loss: 0.4722
Epoch  10 Batch  740/1077 - Train Accuracy: 0.6441, Validation Accuracy: 0.6655, Loss: 0.4552
Epoch  10 Batch  750/1077 - Train Accuracy: 0.6609, Validation Accuracy: 0.6612, Loss: 0.4548
Epoch  10 Batch  760/1077 - Train Accuracy: 0.6609, Validation Accuracy: 0.6602, Loss: 0.4612
Epoch  10 Batch  770/1077 - Train Accuracy: 0.6663, Validation Accuracy: 0.6612, Loss: 0.4312
Epoch  10 Batch  780/1077 - Train Accuracy: 0.6605, Validation Accuracy: 0.6580, Loss: 0.4704
Epoch  10 Batch  790/1077 - Train Accuracy: 0.5891, Validation Accuracy: 0.6580, Loss: 0.4844
Epoch  10 Batch  800/1077 - Train Accuracy: 0.6305, Validation Accuracy: 0.6648, Loss: 0.4566
Epoch  10 Batch  810/1077 - Train Accuracy: 0.6562, Validation Accuracy: 0.6658, Loss: 0.4265
Epoch  10 Batch  820/1077 - Train Accuracy: 0.6145, Validation Accuracy: 0.6676, Loss: 0.4918
Epoch  10 Batch  830/1077 - Train Accuracy: 0.6426, Validation Accuracy: 0.6641, Loss: 0.4786
Epoch  10 Batch  840/1077 - Train Accuracy: 0.6582, Validation Accuracy: 0.6562, Loss: 0.4398
Epoch  10 Batch  850/1077 - Train Accuracy: 0.6350, Validation Accuracy: 0.6616, Loss: 0.4727
Epoch  10 Batch  860/1077 - Train Accuracy: 0.6403, Validation Accuracy: 0.6616, Loss: 0.4427
Epoch  10 Batch  870/1077 - Train Accuracy: 0.6176, Validation Accuracy: 0.6662, Loss: 0.4707
Epoch  10 Batch  880/1077 - Train Accuracy: 0.6750, Validation Accuracy: 0.6630, Loss: 0.4575
Epoch  10 Batch  890/1077 - Train Accuracy: 0.7169, Validation Accuracy: 0.6665, Loss: 0.4327
Epoch  10 Batch  900/1077 - Train Accuracy: 0.6730, Validation Accuracy: 0.6609, Loss: 0.4428
Epoch  10 Batch  910/1077 - Train Accuracy: 0.6473, Validation Accuracy: 0.6658, Loss: 0.4527
Epoch  10 Batch  920/1077 - Train Accuracy: 0.6551, Validation Accuracy: 0.6591, Loss: 0.4793
Epoch  10 Batch  930/1077 - Train Accuracy: 0.6707, Validation Accuracy: 0.6598, Loss: 0.4368
Epoch  10 Batch  940/1077 - Train Accuracy: 0.6465, Validation Accuracy: 0.6658, Loss: 0.4402
Epoch  10 Batch  950/1077 - Train Accuracy: 0.6343, Validation Accuracy: 0.6680, Loss: 0.4266
Epoch  10 Batch  960/1077 - Train Accuracy: 0.6722, Validation Accuracy: 0.6548, Loss: 0.4427
Epoch  10 Batch  970/1077 - Train Accuracy: 0.6594, Validation Accuracy: 0.6502, Loss: 0.4511
Epoch  10 Batch  980/1077 - Train Accuracy: 0.6484, Validation Accuracy: 0.6545, Loss: 0.4533
Epoch  10 Batch  990/1077 - Train Accuracy: 0.6509, Validation Accuracy: 0.6644, Loss: 0.4842
Epoch  10 Batch 1000/1077 - Train Accuracy: 0.7046, Validation Accuracy: 0.6651, Loss: 0.4121
Epoch  10 Batch 1010/1077 - Train Accuracy: 0.6617, Validation Accuracy: 0.6559, Loss: 0.4432
Epoch  10 Batch 1020/1077 - Train Accuracy: 0.6230, Validation Accuracy: 0.6545, Loss: 0.4366
Epoch  10 Batch 1030/1077 - Train Accuracy: 0.6508, Validation Accuracy: 0.6630, Loss: 0.4623
Epoch  10 Batch 1040/1077 - Train Accuracy: 0.6591, Validation Accuracy: 0.6580, Loss: 0.4511
Epoch  10 Batch 1050/1077 - Train Accuracy: 0.5953, Validation Accuracy: 0.6602, Loss: 0.4548
Epoch  10 Batch 1060/1077 - Train Accuracy: 0.6387, Validation Accuracy: 0.6555, Loss: 0.4402
Epoch  10 Batch 1070/1077 - Train Accuracy: 0.6168, Validation Accuracy: 0.6655, Loss: 0.4510
Epoch  11 Batch   10/1077 - Train Accuracy: 0.6488, Validation Accuracy: 0.6651, Loss: 0.4729
Epoch  11 Batch   20/1077 - Train Accuracy: 0.6332, Validation Accuracy: 0.6584, Loss: 0.4495
Epoch  11 Batch   30/1077 - Train Accuracy: 0.6379, Validation Accuracy: 0.6538, Loss: 0.4604
Epoch  11 Batch   40/1077 - Train Accuracy: 0.6543, Validation Accuracy: 0.6630, Loss: 0.4513
Epoch  11 Batch   50/1077 - Train Accuracy: 0.6129, Validation Accuracy: 0.6584, Loss: 0.4656
Epoch  11 Batch   60/1077 - Train Accuracy: 0.6529, Validation Accuracy: 0.6612, Loss: 0.4348
Epoch  11 Batch   70/1077 - Train Accuracy: 0.6328, Validation Accuracy: 0.6609, Loss: 0.4790
Epoch  11 Batch   80/1077 - Train Accuracy: 0.6559, Validation Accuracy: 0.6577, Loss: 0.4598
Epoch  11 Batch   90/1077 - Train Accuracy: 0.6523, Validation Accuracy: 0.6612, Loss: 0.4688
Epoch  11 Batch  100/1077 - Train Accuracy: 0.6562, Validation Accuracy: 0.6655, Loss: 0.4589
Epoch  11 Batch  110/1077 - Train Accuracy: 0.6832, Validation Accuracy: 0.6651, Loss: 0.4345
Epoch  11 Batch  120/1077 - Train Accuracy: 0.6664, Validation Accuracy: 0.6594, Loss: 0.4776
Epoch  11 Batch  130/1077 - Train Accuracy: 0.6540, Validation Accuracy: 0.6634, Loss: 0.4433
Epoch  11 Batch  140/1077 - Train Accuracy: 0.6377, Validation Accuracy: 0.6580, Loss: 0.4611
Epoch  11 Batch  150/1077 - Train Accuracy: 0.6782, Validation Accuracy: 0.6612, Loss: 0.4355
Epoch  11 Batch  160/1077 - Train Accuracy: 0.6684, Validation Accuracy: 0.6605, Loss: 0.4509
Epoch  11 Batch  170/1077 - Train Accuracy: 0.6316, Validation Accuracy: 0.6623, Loss: 0.4695
Epoch  11 Batch  180/1077 - Train Accuracy: 0.6562, Validation Accuracy: 0.6648, Loss: 0.4579
Epoch  11 Batch  190/1077 - Train Accuracy: 0.6895, Validation Accuracy: 0.6651, Loss: 0.4312
Epoch  11 Batch  200/1077 - Train Accuracy: 0.6188, Validation Accuracy: 0.6641, Loss: 0.4609
Epoch  11 Batch  210/1077 - Train Accuracy: 0.6752, Validation Accuracy: 0.6605, Loss: 0.4416
Epoch  11 Batch  220/1077 - Train Accuracy: 0.6558, Validation Accuracy: 0.6591, Loss: 0.4512
Epoch  11 Batch  230/1077 - Train Accuracy: 0.6648, Validation Accuracy: 0.6665, Loss: 0.4270
Epoch  11 Batch  240/1077 - Train Accuracy: 0.6777, Validation Accuracy: 0.6648, Loss: 0.4271
Epoch  11 Batch  250/1077 - Train Accuracy: 0.6456, Validation Accuracy: 0.6669, Loss: 0.4169
Epoch  11 Batch  260/1077 - Train Accuracy: 0.6845, Validation Accuracy: 0.6665, Loss: 0.4086
Epoch  11 Batch  270/1077 - Train Accuracy: 0.6066, Validation Accuracy: 0.6559, Loss: 0.4616
Epoch  11 Batch  280/1077 - Train Accuracy: 0.6711, Validation Accuracy: 0.6737, Loss: 0.4517
Epoch  11 Batch  290/1077 - Train Accuracy: 0.6434, Validation Accuracy: 0.6687, Loss: 0.4605
Epoch  11 Batch  300/1077 - Train Accuracy: 0.6497, Validation Accuracy: 0.6665, Loss: 0.4466
Epoch  11 Batch  310/1077 - Train Accuracy: 0.6254, Validation Accuracy: 0.6559, Loss: 0.4623
Epoch  11 Batch  320/1077 - Train Accuracy: 0.6668, Validation Accuracy: 0.6626, Loss: 0.4762
Epoch  11 Batch  330/1077 - Train Accuracy: 0.6941, Validation Accuracy: 0.6619, Loss: 0.4347
Epoch  11 Batch  340/1077 - Train Accuracy: 0.6312, Validation Accuracy: 0.6538, Loss: 0.4519
Epoch  11 Batch  350/1077 - Train Accuracy: 0.6352, Validation Accuracy: 0.6609, Loss: 0.4380
Epoch  11 Batch  360/1077 - Train Accuracy: 0.6562, Validation Accuracy: 0.6577, Loss: 0.4425
Epoch  11 Batch  370/1077 - Train Accuracy: 0.6577, Validation Accuracy: 0.6531, Loss: 0.4335
Epoch  11 Batch  380/1077 - Train Accuracy: 0.6508, Validation Accuracy: 0.6559, Loss: 0.4408
Epoch  11 Batch  390/1077 - Train Accuracy: 0.6250, Validation Accuracy: 0.6545, Loss: 0.4687
Epoch  11 Batch  400/1077 - Train Accuracy: 0.6707, Validation Accuracy: 0.6602, Loss: 0.4530
Epoch  11 Batch  410/1077 - Train Accuracy: 0.6320, Validation Accuracy: 0.6573, Loss: 0.4633
Epoch  11 Batch  420/1077 - Train Accuracy: 0.6512, Validation Accuracy: 0.6602, Loss: 0.4225
Epoch  11 Batch  430/1077 - Train Accuracy: 0.6359, Validation Accuracy: 0.6548, Loss: 0.4515
Epoch  11 Batch  440/1077 - Train Accuracy: 0.6258, Validation Accuracy: 0.6616, Loss: 0.4547
Epoch  11 Batch  450/1077 - Train Accuracy: 0.6426, Validation Accuracy: 0.6570, Loss: 0.4325
Epoch  11 Batch  460/1077 - Train Accuracy: 0.6359, Validation Accuracy: 0.6513, Loss: 0.4660
Epoch  11 Batch  470/1077 - Train Accuracy: 0.6271, Validation Accuracy: 0.6587, Loss: 0.4751
Epoch  11 Batch  480/1077 - Train Accuracy: 0.6752, Validation Accuracy: 0.6555, Loss: 0.4543
Epoch  11 Batch  490/1077 - Train Accuracy: 0.6402, Validation Accuracy: 0.6566, Loss: 0.4528
Epoch  11 Batch  500/1077 - Train Accuracy: 0.6578, Validation Accuracy: 0.6591, Loss: 0.4500
Epoch  11 Batch  510/1077 - Train Accuracy: 0.6570, Validation Accuracy: 0.6637, Loss: 0.4376
Epoch  11 Batch  520/1077 - Train Accuracy: 0.6916, Validation Accuracy: 0.6694, Loss: 0.4063
Epoch  11 Batch  530/1077 - Train Accuracy: 0.6469, Validation Accuracy: 0.6669, Loss: 0.4504
Epoch  11 Batch  540/1077 - Train Accuracy: 0.6547, Validation Accuracy: 0.6705, Loss: 0.4141
Epoch  11 Batch  550/1077 - Train Accuracy: 0.6348, Validation Accuracy: 0.6669, Loss: 0.4776
Epoch  11 Batch  560/1077 - Train Accuracy: 0.6293, Validation Accuracy: 0.6658, Loss: 0.4379
Epoch  11 Batch  570/1077 - Train Accuracy: 0.6719, Validation Accuracy: 0.6626, Loss: 0.4832
Epoch  11 Batch  580/1077 - Train Accuracy: 0.7013, Validation Accuracy: 0.6591, Loss: 0.4126
Epoch  11 Batch  590/1077 - Train Accuracy: 0.6353, Validation Accuracy: 0.6552, Loss: 0.4698
Epoch  11 Batch  600/1077 - Train Accuracy: 0.6830, Validation Accuracy: 0.6701, Loss: 0.4123
Epoch  11 Batch  610/1077 - Train Accuracy: 0.6427, Validation Accuracy: 0.6609, Loss: 0.4560
Epoch  11 Batch  620/1077 - Train Accuracy: 0.6555, Validation Accuracy: 0.6580, Loss: 0.4427
Epoch  11 Batch  630/1077 - Train Accuracy: 0.6551, Validation Accuracy: 0.6580, Loss: 0.4368
Epoch  11 Batch  640/1077 - Train Accuracy: 0.6458, Validation Accuracy: 0.6562, Loss: 0.4207
Epoch  11 Batch  650/1077 - Train Accuracy: 0.6566, Validation Accuracy: 0.6573, Loss: 0.4581
Epoch  11 Batch  660/1077 - Train Accuracy: 0.6629, Validation Accuracy: 0.6637, Loss: 0.4603
Epoch  11 Batch  670/1077 - Train Accuracy: 0.6911, Validation Accuracy: 0.6605, Loss: 0.4227
Epoch  11 Batch  680/1077 - Train Accuracy: 0.6507, Validation Accuracy: 0.6594, Loss: 0.4368
Epoch  11 Batch  690/1077 - Train Accuracy: 0.6687, Validation Accuracy: 0.6548, Loss: 0.4541
Epoch  11 Batch  700/1077 - Train Accuracy: 0.6371, Validation Accuracy: 0.6573, Loss: 0.4241
Epoch  11 Batch  710/1077 - Train Accuracy: 0.6246, Validation Accuracy: 0.6594, Loss: 0.4489
Epoch  11 Batch  720/1077 - Train Accuracy: 0.6509, Validation Accuracy: 0.6587, Loss: 0.4712
Epoch  11 Batch  730/1077 - Train Accuracy: 0.6383, Validation Accuracy: 0.6609, Loss: 0.4609
Epoch  11 Batch  740/1077 - Train Accuracy: 0.6512, Validation Accuracy: 0.6598, Loss: 0.4371
Epoch  11 Batch  750/1077 - Train Accuracy: 0.6738, Validation Accuracy: 0.6616, Loss: 0.4349
Epoch  11 Batch  760/1077 - Train Accuracy: 0.6559, Validation Accuracy: 0.6634, Loss: 0.4553
Epoch  11 Batch  770/1077 - Train Accuracy: 0.6719, Validation Accuracy: 0.6566, Loss: 0.4107
Epoch  11 Batch  780/1077 - Train Accuracy: 0.6613, Validation Accuracy: 0.6555, Loss: 0.4517
Epoch  11 Batch  790/1077 - Train Accuracy: 0.5934, Validation Accuracy: 0.6566, Loss: 0.4705
Epoch  11 Batch  800/1077 - Train Accuracy: 0.6453, Validation Accuracy: 0.6531, Loss: 0.4359
Epoch  11 Batch  810/1077 - Train Accuracy: 0.6760, Validation Accuracy: 0.6644, Loss: 0.4128
Epoch  11 Batch  820/1077 - Train Accuracy: 0.6246, Validation Accuracy: 0.6701, Loss: 0.4823
Epoch  11 Batch  830/1077 - Train Accuracy: 0.6480, Validation Accuracy: 0.6680, Loss: 0.4461
Epoch  11 Batch  840/1077 - Train Accuracy: 0.6656, Validation Accuracy: 0.6644, Loss: 0.4373
Epoch  11 Batch  850/1077 - Train Accuracy: 0.6276, Validation Accuracy: 0.6648, Loss: 0.4760
Epoch  11 Batch  860/1077 - Train Accuracy: 0.6510, Validation Accuracy: 0.6687, Loss: 0.4375
Epoch  11 Batch  870/1077 - Train Accuracy: 0.6316, Validation Accuracy: 0.6630, Loss: 0.4541
Epoch  11 Batch  880/1077 - Train Accuracy: 0.6871, Validation Accuracy: 0.6616, Loss: 0.4419
Epoch  11 Batch  890/1077 - Train Accuracy: 0.7214, Validation Accuracy: 0.6658, Loss: 0.4143
Epoch  11 Batch  900/1077 - Train Accuracy: 0.6730, Validation Accuracy: 0.6690, Loss: 0.4436
Epoch  11 Batch  910/1077 - Train Accuracy: 0.6492, Validation Accuracy: 0.6726, Loss: 0.4483
Epoch  11 Batch  920/1077 - Train Accuracy: 0.6633, Validation Accuracy: 0.6665, Loss: 0.4531
Epoch  11 Batch  930/1077 - Train Accuracy: 0.6762, Validation Accuracy: 0.6676, Loss: 0.4247
Epoch  11 Batch  940/1077 - Train Accuracy: 0.6504, Validation Accuracy: 0.6701, Loss: 0.4311
Epoch  11 Batch  950/1077 - Train Accuracy: 0.6440, Validation Accuracy: 0.6637, Loss: 0.4193
Epoch  11 Batch  960/1077 - Train Accuracy: 0.6678, Validation Accuracy: 0.6566, Loss: 0.4376
Epoch  11 Batch  970/1077 - Train Accuracy: 0.6645, Validation Accuracy: 0.6584, Loss: 0.4481
Epoch  11 Batch  980/1077 - Train Accuracy: 0.6605, Validation Accuracy: 0.6626, Loss: 0.4450
Epoch  11 Batch  990/1077 - Train Accuracy: 0.6579, Validation Accuracy: 0.6701, Loss: 0.4614
Epoch  11 Batch 1000/1077 - Train Accuracy: 0.7046, Validation Accuracy: 0.6655, Loss: 0.4048
Epoch  11 Batch 1010/1077 - Train Accuracy: 0.6734, Validation Accuracy: 0.6641, Loss: 0.4497
Epoch  11 Batch 1020/1077 - Train Accuracy: 0.6383, Validation Accuracy: 0.6634, Loss: 0.4313
Epoch  11 Batch 1030/1077 - Train Accuracy: 0.6570, Validation Accuracy: 0.6630, Loss: 0.4484
Epoch  11 Batch 1040/1077 - Train Accuracy: 0.6628, Validation Accuracy: 0.6641, Loss: 0.4489
Epoch  11 Batch 1050/1077 - Train Accuracy: 0.6062, Validation Accuracy: 0.6665, Loss: 0.4379
Epoch  11 Batch 1060/1077 - Train Accuracy: 0.6527, Validation Accuracy: 0.6584, Loss: 0.4105
Epoch  11 Batch 1070/1077 - Train Accuracy: 0.6277, Validation Accuracy: 0.6591, Loss: 0.4409
Epoch  12 Batch   10/1077 - Train Accuracy: 0.6571, Validation Accuracy: 0.6651, Loss: 0.4605
Epoch  12 Batch   20/1077 - Train Accuracy: 0.6461, Validation Accuracy: 0.6655, Loss: 0.4299
Epoch  12 Batch   30/1077 - Train Accuracy: 0.6473, Validation Accuracy: 0.6609, Loss: 0.4505
Epoch  12 Batch   40/1077 - Train Accuracy: 0.6754, Validation Accuracy: 0.6658, Loss: 0.4294
Epoch  12 Batch   50/1077 - Train Accuracy: 0.6266, Validation Accuracy: 0.6680, Loss: 0.4409
Epoch  12 Batch   60/1077 - Train Accuracy: 0.6540, Validation Accuracy: 0.6683, Loss: 0.4240
Epoch  12 Batch   70/1077 - Train Accuracy: 0.6377, Validation Accuracy: 0.6619, Loss: 0.4615
Epoch  12 Batch   80/1077 - Train Accuracy: 0.6660, Validation Accuracy: 0.6765, Loss: 0.4400
Epoch  12 Batch   90/1077 - Train Accuracy: 0.6527, Validation Accuracy: 0.6651, Loss: 0.4544
Epoch  12 Batch  100/1077 - Train Accuracy: 0.6746, Validation Accuracy: 0.6669, Loss: 0.4312
Epoch  12 Batch  110/1077 - Train Accuracy: 0.6965, Validation Accuracy: 0.6687, Loss: 0.4087
Epoch  12 Batch  120/1077 - Train Accuracy: 0.6766, Validation Accuracy: 0.6694, Loss: 0.4532
Epoch  12 Batch  130/1077 - Train Accuracy: 0.6618, Validation Accuracy: 0.6676, Loss: 0.4201
Epoch  12 Batch  140/1077 - Train Accuracy: 0.6451, Validation Accuracy: 0.6665, Loss: 0.4534
Epoch  12 Batch  150/1077 - Train Accuracy: 0.6871, Validation Accuracy: 0.6768, Loss: 0.4180
Epoch  12 Batch  160/1077 - Train Accuracy: 0.6695, Validation Accuracy: 0.6680, Loss: 0.4266
Epoch  12 Batch  170/1077 - Train Accuracy: 0.6387, Validation Accuracy: 0.6641, Loss: 0.4565
Epoch  12 Batch  180/1077 - Train Accuracy: 0.6699, Validation Accuracy: 0.6680, Loss: 0.4352
Epoch  12 Batch  190/1077 - Train Accuracy: 0.6961, Validation Accuracy: 0.6669, Loss: 0.4201
Epoch  12 Batch  200/1077 - Train Accuracy: 0.6398, Validation Accuracy: 0.6708, Loss: 0.4393
Epoch  12 Batch  210/1077 - Train Accuracy: 0.6793, Validation Accuracy: 0.6758, Loss: 0.4278
Epoch  12 Batch  220/1077 - Train Accuracy: 0.6608, Validation Accuracy: 0.6772, Loss: 0.4429
Epoch  12 Batch  230/1077 - Train Accuracy: 0.6589, Validation Accuracy: 0.6793, Loss: 0.4218
Epoch  12 Batch  240/1077 - Train Accuracy: 0.6852, Validation Accuracy: 0.6776, Loss: 0.4097
Epoch  12 Batch  250/1077 - Train Accuracy: 0.6499, Validation Accuracy: 0.6747, Loss: 0.4183
Epoch  12 Batch  260/1077 - Train Accuracy: 0.6771, Validation Accuracy: 0.6811, Loss: 0.4032
Epoch  12 Batch  270/1077 - Train Accuracy: 0.6254, Validation Accuracy: 0.6832, Loss: 0.4518
Epoch  12 Batch  280/1077 - Train Accuracy: 0.6805, Validation Accuracy: 0.6800, Loss: 0.4431
Epoch  12 Batch  290/1077 - Train Accuracy: 0.6512, Validation Accuracy: 0.6715, Loss: 0.4476
Epoch  12 Batch  300/1077 - Train Accuracy: 0.6534, Validation Accuracy: 0.6676, Loss: 0.4294
Epoch  12 Batch  310/1077 - Train Accuracy: 0.6438, Validation Accuracy: 0.6680, Loss: 0.4494
Epoch  12 Batch  320/1077 - Train Accuracy: 0.6785, Validation Accuracy: 0.6665, Loss: 0.4590
Epoch  12 Batch  330/1077 - Train Accuracy: 0.6937, Validation Accuracy: 0.6719, Loss: 0.4245
Epoch  12 Batch  340/1077 - Train Accuracy: 0.6562, Validation Accuracy: 0.6733, Loss: 0.4493
Epoch  12 Batch  350/1077 - Train Accuracy: 0.6473, Validation Accuracy: 0.6694, Loss: 0.4213
Epoch  12 Batch  360/1077 - Train Accuracy: 0.6578, Validation Accuracy: 0.6715, Loss: 0.4266
Epoch  12 Batch  370/1077 - Train Accuracy: 0.6637, Validation Accuracy: 0.6701, Loss: 0.4257
Epoch  12 Batch  380/1077 - Train Accuracy: 0.6574, Validation Accuracy: 0.6619, Loss: 0.4234
Epoch  12 Batch  390/1077 - Train Accuracy: 0.6375, Validation Accuracy: 0.6737, Loss: 0.4559
Epoch  12 Batch  400/1077 - Train Accuracy: 0.6797, Validation Accuracy: 0.6658, Loss: 0.4358
Epoch  12 Batch  410/1077 - Train Accuracy: 0.6406, Validation Accuracy: 0.6676, Loss: 0.4445
Epoch  12 Batch  420/1077 - Train Accuracy: 0.6707, Validation Accuracy: 0.6665, Loss: 0.4245
Epoch  12 Batch  430/1077 - Train Accuracy: 0.6418, Validation Accuracy: 0.6722, Loss: 0.4315
Epoch  12 Batch  440/1077 - Train Accuracy: 0.6422, Validation Accuracy: 0.6783, Loss: 0.4427
Epoch  12 Batch  450/1077 - Train Accuracy: 0.6566, Validation Accuracy: 0.6875, Loss: 0.4131
Epoch  12 Batch  460/1077 - Train Accuracy: 0.6516, Validation Accuracy: 0.6786, Loss: 0.4396
Epoch  12 Batch  470/1077 - Train Accuracy: 0.6369, Validation Accuracy: 0.6733, Loss: 0.4548
Epoch  12 Batch  480/1077 - Train Accuracy: 0.6867, Validation Accuracy: 0.6701, Loss: 0.4387
Epoch  12 Batch  490/1077 - Train Accuracy: 0.6324, Validation Accuracy: 0.6694, Loss: 0.4407
Epoch  12 Batch  500/1077 - Train Accuracy: 0.6820, Validation Accuracy: 0.6811, Loss: 0.4192
Epoch  12 Batch  510/1077 - Train Accuracy: 0.6848, Validation Accuracy: 0.6779, Loss: 0.4127
Epoch  12 Batch  520/1077 - Train Accuracy: 0.7147, Validation Accuracy: 0.6761, Loss: 0.3926
Epoch  12 Batch  530/1077 - Train Accuracy: 0.6703, Validation Accuracy: 0.6779, Loss: 0.4458
Epoch  12 Batch  540/1077 - Train Accuracy: 0.6734, Validation Accuracy: 0.6893, Loss: 0.4097
Epoch  12 Batch  550/1077 - Train Accuracy: 0.6512, Validation Accuracy: 0.6861, Loss: 0.4556
Epoch  12 Batch  560/1077 - Train Accuracy: 0.6504, Validation Accuracy: 0.6850, Loss: 0.4154
Epoch  12 Batch  570/1077 - Train Accuracy: 0.6748, Validation Accuracy: 0.6786, Loss: 0.4624
Epoch  12 Batch  580/1077 - Train Accuracy: 0.7042, Validation Accuracy: 0.6832, Loss: 0.3950
Epoch  12 Batch  590/1077 - Train Accuracy: 0.6505, Validation Accuracy: 0.6843, Loss: 0.4616
Epoch  12 Batch  600/1077 - Train Accuracy: 0.6897, Validation Accuracy: 0.6871, Loss: 0.4019
Epoch  12 Batch  610/1077 - Train Accuracy: 0.6587, Validation Accuracy: 0.6871, Loss: 0.4454
Epoch  12 Batch  620/1077 - Train Accuracy: 0.6562, Validation Accuracy: 0.6822, Loss: 0.4270
Epoch  12 Batch  630/1077 - Train Accuracy: 0.6703, Validation Accuracy: 0.6829, Loss: 0.4333
Epoch  12 Batch  640/1077 - Train Accuracy: 0.6778, Validation Accuracy: 0.6800, Loss: 0.4140
Epoch  12 Batch  650/1077 - Train Accuracy: 0.6668, Validation Accuracy: 0.6751, Loss: 0.4409
Epoch  12 Batch  660/1077 - Train Accuracy: 0.6750, Validation Accuracy: 0.6797, Loss: 0.4392
Epoch  12 Batch  670/1077 - Train Accuracy: 0.7109, Validation Accuracy: 0.6751, Loss: 0.3974
Epoch  12 Batch  680/1077 - Train Accuracy: 0.6775, Validation Accuracy: 0.6854, Loss: 0.4309
Epoch  12 Batch  690/1077 - Train Accuracy: 0.7016, Validation Accuracy: 0.6811, Loss: 0.4320
Epoch  12 Batch  700/1077 - Train Accuracy: 0.6652, Validation Accuracy: 0.6818, Loss: 0.4100
Epoch  12 Batch  710/1077 - Train Accuracy: 0.6340, Validation Accuracy: 0.6825, Loss: 0.4220
Epoch  12 Batch  720/1077 - Train Accuracy: 0.6723, Validation Accuracy: 0.6786, Loss: 0.4529
Epoch  12 Batch  730/1077 - Train Accuracy: 0.6398, Validation Accuracy: 0.6815, Loss: 0.4410
Epoch  12 Batch  740/1077 - Train Accuracy: 0.6723, Validation Accuracy: 0.6875, Loss: 0.4148
Epoch  12 Batch  750/1077 - Train Accuracy: 0.6945, Validation Accuracy: 0.6914, Loss: 0.4240
Epoch  12 Batch  760/1077 - Train Accuracy: 0.6793, Validation Accuracy: 0.6854, Loss: 0.4397
Epoch  12 Batch  770/1077 - Train Accuracy: 0.6782, Validation Accuracy: 0.6871, Loss: 0.4096
Epoch  12 Batch  780/1077 - Train Accuracy: 0.6766, Validation Accuracy: 0.6839, Loss: 0.4461
Epoch  12 Batch  790/1077 - Train Accuracy: 0.6176, Validation Accuracy: 0.6829, Loss: 0.4506
Epoch  12 Batch  800/1077 - Train Accuracy: 0.6508, Validation Accuracy: 0.6797, Loss: 0.4210
Epoch  12 Batch  810/1077 - Train Accuracy: 0.6815, Validation Accuracy: 0.6864, Loss: 0.3960
Epoch  12 Batch  820/1077 - Train Accuracy: 0.6402, Validation Accuracy: 0.6903, Loss: 0.4577
Epoch  12 Batch  830/1077 - Train Accuracy: 0.6613, Validation Accuracy: 0.6850, Loss: 0.4280
Epoch  12 Batch  840/1077 - Train Accuracy: 0.6867, Validation Accuracy: 0.6871, Loss: 0.4106
Epoch  12 Batch  850/1077 - Train Accuracy: 0.6440, Validation Accuracy: 0.6889, Loss: 0.4469
Epoch  12 Batch  860/1077 - Train Accuracy: 0.6659, Validation Accuracy: 0.6847, Loss: 0.4439
Epoch  12 Batch  870/1077 - Train Accuracy: 0.6550, Validation Accuracy: 0.6797, Loss: 0.4442
Epoch  12 Batch  880/1077 - Train Accuracy: 0.7000, Validation Accuracy: 0.6783, Loss: 0.4349
Epoch  12 Batch  890/1077 - Train Accuracy: 0.7292, Validation Accuracy: 0.6886, Loss: 0.4091
Epoch  12 Batch  900/1077 - Train Accuracy: 0.6844, Validation Accuracy: 0.6850, Loss: 0.4303
Epoch  12 Batch  910/1077 - Train Accuracy: 0.6589, Validation Accuracy: 0.6907, Loss: 0.4229
Epoch  12 Batch  920/1077 - Train Accuracy: 0.6926, Validation Accuracy: 0.6886, Loss: 0.4391
Epoch  12 Batch  930/1077 - Train Accuracy: 0.6844, Validation Accuracy: 0.6907, Loss: 0.4006
Epoch  12 Batch  940/1077 - Train Accuracy: 0.6645, Validation Accuracy: 0.6822, Loss: 0.4110
Epoch  12 Batch  950/1077 - Train Accuracy: 0.6518, Validation Accuracy: 0.6783, Loss: 0.3992
Epoch  12 Batch  960/1077 - Train Accuracy: 0.6927, Validation Accuracy: 0.6783, Loss: 0.4033
Epoch  12 Batch  970/1077 - Train Accuracy: 0.6937, Validation Accuracy: 0.6825, Loss: 0.4188
Epoch  12 Batch  980/1077 - Train Accuracy: 0.6797, Validation Accuracy: 0.6800, Loss: 0.4252
Epoch  12 Batch  990/1077 - Train Accuracy: 0.6628, Validation Accuracy: 0.6896, Loss: 0.4519
Epoch  12 Batch 1000/1077 - Train Accuracy: 0.7135, Validation Accuracy: 0.6911, Loss: 0.3933
Epoch  12 Batch 1010/1077 - Train Accuracy: 0.6766, Validation Accuracy: 0.6875, Loss: 0.4237
Epoch  12 Batch 1020/1077 - Train Accuracy: 0.6703, Validation Accuracy: 0.6875, Loss: 0.4178
Epoch  12 Batch 1030/1077 - Train Accuracy: 0.6547, Validation Accuracy: 0.6921, Loss: 0.4276
Epoch  12 Batch 1040/1077 - Train Accuracy: 0.6912, Validation Accuracy: 0.6893, Loss: 0.4326
Epoch  12 Batch 1050/1077 - Train Accuracy: 0.6129, Validation Accuracy: 0.6857, Loss: 0.4349
Epoch  12 Batch 1060/1077 - Train Accuracy: 0.6699, Validation Accuracy: 0.6815, Loss: 0.4011
Epoch  12 Batch 1070/1077 - Train Accuracy: 0.6348, Validation Accuracy: 0.6900, Loss: 0.4229
Epoch  13 Batch   10/1077 - Train Accuracy: 0.6678, Validation Accuracy: 0.6847, Loss: 0.4425
Epoch  13 Batch   20/1077 - Train Accuracy: 0.6813, Validation Accuracy: 0.6896, Loss: 0.4124
Epoch  13 Batch   30/1077 - Train Accuracy: 0.6676, Validation Accuracy: 0.6903, Loss: 0.4213
Epoch  13 Batch   40/1077 - Train Accuracy: 0.7051, Validation Accuracy: 0.6847, Loss: 0.4211
Epoch  13 Batch   50/1077 - Train Accuracy: 0.6609, Validation Accuracy: 0.6935, Loss: 0.4297
Epoch  13 Batch   60/1077 - Train Accuracy: 0.6734, Validation Accuracy: 0.6886, Loss: 0.4089
Epoch  13 Batch   70/1077 - Train Accuracy: 0.6451, Validation Accuracy: 0.6967, Loss: 0.4535
Epoch  13 Batch   80/1077 - Train Accuracy: 0.6961, Validation Accuracy: 0.6999, Loss: 0.4236
Epoch  13 Batch   90/1077 - Train Accuracy: 0.6656, Validation Accuracy: 0.6804, Loss: 0.4357
Epoch  13 Batch  100/1077 - Train Accuracy: 0.6918, Validation Accuracy: 0.6861, Loss: 0.4238
Epoch  13 Batch  110/1077 - Train Accuracy: 0.7117, Validation Accuracy: 0.6953, Loss: 0.4028
Epoch  13 Batch  120/1077 - Train Accuracy: 0.6906, Validation Accuracy: 0.6839, Loss: 0.4363
Epoch  13 Batch  130/1077 - Train Accuracy: 0.6763, Validation Accuracy: 0.6882, Loss: 0.3983
Epoch  13 Batch  140/1077 - Train Accuracy: 0.6554, Validation Accuracy: 0.6967, Loss: 0.4322
Epoch  13 Batch  150/1077 - Train Accuracy: 0.6879, Validation Accuracy: 0.6886, Loss: 0.3958
Epoch  13 Batch  160/1077 - Train Accuracy: 0.6934, Validation Accuracy: 0.6893, Loss: 0.4102
Epoch  13 Batch  170/1077 - Train Accuracy: 0.6578, Validation Accuracy: 0.6921, Loss: 0.4451
Epoch  13 Batch  180/1077 - Train Accuracy: 0.6746, Validation Accuracy: 0.6854, Loss: 0.4138
Epoch  13 Batch  190/1077 - Train Accuracy: 0.7055, Validation Accuracy: 0.6907, Loss: 0.4066
Epoch  13 Batch  200/1077 - Train Accuracy: 0.6590, Validation Accuracy: 0.6868, Loss: 0.4393
Epoch  13 Batch  210/1077 - Train Accuracy: 0.6946, Validation Accuracy: 0.6875, Loss: 0.4134
Epoch  13 Batch  220/1077 - Train Accuracy: 0.6743, Validation Accuracy: 0.6815, Loss: 0.4209
Epoch  13 Batch  230/1077 - Train Accuracy: 0.6834, Validation Accuracy: 0.6825, Loss: 0.3936
Epoch  13 Batch  240/1077 - Train Accuracy: 0.7031, Validation Accuracy: 0.6854, Loss: 0.4056
Epoch  13 Batch  250/1077 - Train Accuracy: 0.6619, Validation Accuracy: 0.6783, Loss: 0.3890
Epoch  13 Batch  260/1077 - Train Accuracy: 0.6957, Validation Accuracy: 0.6985, Loss: 0.3792
Epoch  13 Batch  270/1077 - Train Accuracy: 0.6445, Validation Accuracy: 0.6886, Loss: 0.4229
Epoch  13 Batch  280/1077 - Train Accuracy: 0.6910, Validation Accuracy: 0.6847, Loss: 0.4374
Epoch  13 Batch  290/1077 - Train Accuracy: 0.6617, Validation Accuracy: 0.6896, Loss: 0.4204
Epoch  13 Batch  300/1077 - Train Accuracy: 0.6711, Validation Accuracy: 0.6942, Loss: 0.4190
Epoch  13 Batch  310/1077 - Train Accuracy: 0.6613, Validation Accuracy: 0.6914, Loss: 0.4314
Epoch  13 Batch  320/1077 - Train Accuracy: 0.6984, Validation Accuracy: 0.6850, Loss: 0.4279
Epoch  13 Batch  330/1077 - Train Accuracy: 0.7172, Validation Accuracy: 0.6822, Loss: 0.4164
Epoch  13 Batch  340/1077 - Train Accuracy: 0.6546, Validation Accuracy: 0.6871, Loss: 0.4149
Epoch  13 Batch  350/1077 - Train Accuracy: 0.6672, Validation Accuracy: 0.6903, Loss: 0.4121
Epoch  13 Batch  360/1077 - Train Accuracy: 0.6629, Validation Accuracy: 0.6868, Loss: 0.4076
Epoch  13 Batch  370/1077 - Train Accuracy: 0.6838, Validation Accuracy: 0.6800, Loss: 0.4115
Epoch  13 Batch  380/1077 - Train Accuracy: 0.6562, Validation Accuracy: 0.6868, Loss: 0.4070
Epoch  13 Batch  390/1077 - Train Accuracy: 0.6473, Validation Accuracy: 0.6850, Loss: 0.4260
Epoch  13 Batch  400/1077 - Train Accuracy: 0.6906, Validation Accuracy: 0.6804, Loss: 0.4219
Epoch  13 Batch  410/1077 - Train Accuracy: 0.6604, Validation Accuracy: 0.6783, Loss: 0.4244
Epoch  13 Batch  420/1077 - Train Accuracy: 0.6844, Validation Accuracy: 0.6825, Loss: 0.4047
Epoch  13 Batch  430/1077 - Train Accuracy: 0.6590, Validation Accuracy: 0.6832, Loss: 0.4158
Epoch  13 Batch  440/1077 - Train Accuracy: 0.6578, Validation Accuracy: 0.6850, Loss: 0.4271
Epoch  13 Batch  450/1077 - Train Accuracy: 0.6770, Validation Accuracy: 0.6786, Loss: 0.4050
Epoch  13 Batch  460/1077 - Train Accuracy: 0.6687, Validation Accuracy: 0.6839, Loss: 0.4231
Epoch  13 Batch  470/1077 - Train Accuracy: 0.6542, Validation Accuracy: 0.6868, Loss: 0.4215
Epoch  13 Batch  480/1077 - Train Accuracy: 0.7122, Validation Accuracy: 0.6847, Loss: 0.4235
Epoch  13 Batch  490/1077 - Train Accuracy: 0.6434, Validation Accuracy: 0.6857, Loss: 0.4251
Epoch  13 Batch  500/1077 - Train Accuracy: 0.6859, Validation Accuracy: 0.6829, Loss: 0.4050
Epoch  13 Batch  510/1077 - Train Accuracy: 0.6879, Validation Accuracy: 0.6786, Loss: 0.4026
Epoch  13 Batch  520/1077 - Train Accuracy: 0.7217, Validation Accuracy: 0.6868, Loss: 0.3877
Epoch  13 Batch  530/1077 - Train Accuracy: 0.6770, Validation Accuracy: 0.6822, Loss: 0.4225
Epoch  13 Batch  540/1077 - Train Accuracy: 0.6781, Validation Accuracy: 0.6829, Loss: 0.3938
Epoch  13 Batch  550/1077 - Train Accuracy: 0.6785, Validation Accuracy: 0.6864, Loss: 0.4493
Epoch  13 Batch  560/1077 - Train Accuracy: 0.6684, Validation Accuracy: 0.6882, Loss: 0.4094
Epoch  13 Batch  570/1077 - Train Accuracy: 0.6871, Validation Accuracy: 0.6868, Loss: 0.4306
Epoch  13 Batch  580/1077 - Train Accuracy: 0.7072, Validation Accuracy: 0.6907, Loss: 0.3754
Epoch  13 Batch  590/1077 - Train Accuracy: 0.6624, Validation Accuracy: 0.6932, Loss: 0.4398
Epoch  13 Batch  600/1077 - Train Accuracy: 0.7009, Validation Accuracy: 0.6861, Loss: 0.3886
Epoch  13 Batch  610/1077 - Train Accuracy: 0.6739, Validation Accuracy: 0.6843, Loss: 0.4293
Epoch  13 Batch  620/1077 - Train Accuracy: 0.6707, Validation Accuracy: 0.6857, Loss: 0.3969
Epoch  13 Batch  630/1077 - Train Accuracy: 0.6945, Validation Accuracy: 0.6896, Loss: 0.4093
Epoch  13 Batch  640/1077 - Train Accuracy: 0.6715, Validation Accuracy: 0.6935, Loss: 0.4052
Epoch  13 Batch  650/1077 - Train Accuracy: 0.6695, Validation Accuracy: 0.6907, Loss: 0.4207
Epoch  13 Batch  660/1077 - Train Accuracy: 0.6754, Validation Accuracy: 0.6900, Loss: 0.4304
Epoch  13 Batch  670/1077 - Train Accuracy: 0.7202, Validation Accuracy: 0.6832, Loss: 0.3818
Epoch  13 Batch  680/1077 - Train Accuracy: 0.6849, Validation Accuracy: 0.6850, Loss: 0.4120
Epoch  13 Batch  690/1077 - Train Accuracy: 0.7086, Validation Accuracy: 0.6871, Loss: 0.4143
Epoch  13 Batch  700/1077 - Train Accuracy: 0.6730, Validation Accuracy: 0.6875, Loss: 0.3984
Epoch  13 Batch  710/1077 - Train Accuracy: 0.6473, Validation Accuracy: 0.6829, Loss: 0.4125
Epoch  13 Batch  720/1077 - Train Accuracy: 0.6780, Validation Accuracy: 0.6822, Loss: 0.4400
Epoch  13 Batch  730/1077 - Train Accuracy: 0.6574, Validation Accuracy: 0.6839, Loss: 0.4153
Epoch  13 Batch  740/1077 - Train Accuracy: 0.6824, Validation Accuracy: 0.6857, Loss: 0.3984
Epoch  13 Batch  750/1077 - Train Accuracy: 0.6875, Validation Accuracy: 0.6879, Loss: 0.4041
Epoch  13 Batch  760/1077 - Train Accuracy: 0.6824, Validation Accuracy: 0.6854, Loss: 0.4161
Epoch  13 Batch  770/1077 - Train Accuracy: 0.6897, Validation Accuracy: 0.6847, Loss: 0.3807
Epoch  13 Batch  780/1077 - Train Accuracy: 0.6820, Validation Accuracy: 0.6871, Loss: 0.4190
Epoch  13 Batch  790/1077 - Train Accuracy: 0.6301, Validation Accuracy: 0.6847, Loss: 0.4342
Epoch  13 Batch  800/1077 - Train Accuracy: 0.6543, Validation Accuracy: 0.6864, Loss: 0.4095
Epoch  13 Batch  810/1077 - Train Accuracy: 0.6838, Validation Accuracy: 0.6868, Loss: 0.3895
Epoch  13 Batch  820/1077 - Train Accuracy: 0.6484, Validation Accuracy: 0.6832, Loss: 0.4369
Epoch  13 Batch  830/1077 - Train Accuracy: 0.6715, Validation Accuracy: 0.6928, Loss: 0.4196
Epoch  13 Batch  840/1077 - Train Accuracy: 0.6820, Validation Accuracy: 0.6896, Loss: 0.3946
Epoch  13 Batch  850/1077 - Train Accuracy: 0.6536, Validation Accuracy: 0.6868, Loss: 0.4296
Epoch  13 Batch  860/1077 - Train Accuracy: 0.6782, Validation Accuracy: 0.6918, Loss: 0.4118
Epoch  13 Batch  870/1077 - Train Accuracy: 0.6649, Validation Accuracy: 0.6843, Loss: 0.4236
Epoch  13 Batch  880/1077 - Train Accuracy: 0.7195, Validation Accuracy: 0.6854, Loss: 0.4144
Epoch  13 Batch  890/1077 - Train Accuracy: 0.7374, Validation Accuracy: 0.6825, Loss: 0.3847
Epoch  13 Batch  900/1077 - Train Accuracy: 0.6937, Validation Accuracy: 0.6886, Loss: 0.4056
Epoch  13 Batch  910/1077 - Train Accuracy: 0.6581, Validation Accuracy: 0.6861, Loss: 0.4079
Epoch  13 Batch  920/1077 - Train Accuracy: 0.6961, Validation Accuracy: 0.6854, Loss: 0.4239
Epoch  13 Batch  930/1077 - Train Accuracy: 0.6910, Validation Accuracy: 0.6839, Loss: 0.4127
Epoch  13 Batch  940/1077 - Train Accuracy: 0.6699, Validation Accuracy: 0.6896, Loss: 0.3923
Epoch  13 Batch  950/1077 - Train Accuracy: 0.6663, Validation Accuracy: 0.6790, Loss: 0.3827
Epoch  13 Batch  960/1077 - Train Accuracy: 0.6994, Validation Accuracy: 0.6850, Loss: 0.3974
Epoch  13 Batch  970/1077 - Train Accuracy: 0.6953, Validation Accuracy: 0.6850, Loss: 0.3995
Epoch  13 Batch  980/1077 - Train Accuracy: 0.6828, Validation Accuracy: 0.6818, Loss: 0.4047
Epoch  13 Batch  990/1077 - Train Accuracy: 0.6789, Validation Accuracy: 0.6868, Loss: 0.4405
Epoch  13 Batch 1000/1077 - Train Accuracy: 0.7195, Validation Accuracy: 0.6889, Loss: 0.3715
Epoch  13 Batch 1010/1077 - Train Accuracy: 0.6855, Validation Accuracy: 0.6893, Loss: 0.4110
Epoch  13 Batch 1020/1077 - Train Accuracy: 0.6633, Validation Accuracy: 0.6847, Loss: 0.3891
Epoch  13 Batch 1030/1077 - Train Accuracy: 0.6598, Validation Accuracy: 0.6879, Loss: 0.4154
Epoch  13 Batch 1040/1077 - Train Accuracy: 0.6822, Validation Accuracy: 0.6871, Loss: 0.4143
Epoch  13 Batch 1050/1077 - Train Accuracy: 0.6215, Validation Accuracy: 0.6882, Loss: 0.4005
Epoch  13 Batch 1060/1077 - Train Accuracy: 0.6820, Validation Accuracy: 0.6793, Loss: 0.3856
Epoch  13 Batch 1070/1077 - Train Accuracy: 0.6555, Validation Accuracy: 0.6861, Loss: 0.4086
Epoch  14 Batch   10/1077 - Train Accuracy: 0.6863, Validation Accuracy: 0.6939, Loss: 0.4261
Epoch  14 Batch   20/1077 - Train Accuracy: 0.6648, Validation Accuracy: 0.6928, Loss: 0.3962
Epoch  14 Batch   30/1077 - Train Accuracy: 0.6727, Validation Accuracy: 0.6932, Loss: 0.4115
Epoch  14 Batch   40/1077 - Train Accuracy: 0.7074, Validation Accuracy: 0.6893, Loss: 0.3971
Epoch  14 Batch   50/1077 - Train Accuracy: 0.6594, Validation Accuracy: 0.6939, Loss: 0.4112
Epoch  14 Batch   60/1077 - Train Accuracy: 0.6760, Validation Accuracy: 0.6907, Loss: 0.3900
Epoch  14 Batch   70/1077 - Train Accuracy: 0.6534, Validation Accuracy: 0.6960, Loss: 0.4281
Epoch  14 Batch   80/1077 - Train Accuracy: 0.6777, Validation Accuracy: 0.6822, Loss: 0.4114
Epoch  14 Batch   90/1077 - Train Accuracy: 0.6687, Validation Accuracy: 0.6861, Loss: 0.4149
Epoch  14 Batch  100/1077 - Train Accuracy: 0.6906, Validation Accuracy: 0.6882, Loss: 0.3989
Epoch  14 Batch  110/1077 - Train Accuracy: 0.7125, Validation Accuracy: 0.6978, Loss: 0.3894
Epoch  14 Batch  120/1077 - Train Accuracy: 0.6875, Validation Accuracy: 0.6914, Loss: 0.4252
Epoch  14 Batch  130/1077 - Train Accuracy: 0.6782, Validation Accuracy: 0.6939, Loss: 0.3813
Epoch  14 Batch  140/1077 - Train Accuracy: 0.6657, Validation Accuracy: 0.6953, Loss: 0.4177
Epoch  14 Batch  150/1077 - Train Accuracy: 0.6972, Validation Accuracy: 0.6928, Loss: 0.3836
Epoch  14 Batch  160/1077 - Train Accuracy: 0.6996, Validation Accuracy: 0.6907, Loss: 0.3984
Epoch  14 Batch  170/1077 - Train Accuracy: 0.6633, Validation Accuracy: 0.6889, Loss: 0.4254
Epoch  14 Batch  180/1077 - Train Accuracy: 0.6754, Validation Accuracy: 0.6882, Loss: 0.4065
Epoch  14 Batch  190/1077 - Train Accuracy: 0.7051, Validation Accuracy: 0.6918, Loss: 0.4001
Epoch  14 Batch  200/1077 - Train Accuracy: 0.6609, Validation Accuracy: 0.6857, Loss: 0.4189
Epoch  14 Batch  210/1077 - Train Accuracy: 0.6935, Validation Accuracy: 0.6946, Loss: 0.3957
Epoch  14 Batch  220/1077 - Train Accuracy: 0.6789, Validation Accuracy: 0.6960, Loss: 0.4146
Epoch  14 Batch  230/1077 - Train Accuracy: 0.6815, Validation Accuracy: 0.6960, Loss: 0.3848
Epoch  14 Batch  240/1077 - Train Accuracy: 0.7219, Validation Accuracy: 0.6871, Loss: 0.3810
Epoch  14 Batch  250/1077 - Train Accuracy: 0.6570, Validation Accuracy: 0.6907, Loss: 0.3792
Epoch  14 Batch  260/1077 - Train Accuracy: 0.6983, Validation Accuracy: 0.6918, Loss: 0.3678
Epoch  14 Batch  270/1077 - Train Accuracy: 0.6508, Validation Accuracy: 0.6903, Loss: 0.4063
Epoch  14 Batch  280/1077 - Train Accuracy: 0.7004, Validation Accuracy: 0.6903, Loss: 0.4128
Epoch  14 Batch  290/1077 - Train Accuracy: 0.6621, Validation Accuracy: 0.6918, Loss: 0.4151
Epoch  14 Batch  300/1077 - Train Accuracy: 0.6772, Validation Accuracy: 0.6918, Loss: 0.4015
Epoch  14 Batch  310/1077 - Train Accuracy: 0.6730, Validation Accuracy: 0.6800, Loss: 0.4268
Epoch  14 Batch  320/1077 - Train Accuracy: 0.7039, Validation Accuracy: 0.6889, Loss: 0.4165
Epoch  14 Batch  330/1077 - Train Accuracy: 0.7148, Validation Accuracy: 0.6850, Loss: 0.4010
Epoch  14 Batch  340/1077 - Train Accuracy: 0.6702, Validation Accuracy: 0.6847, Loss: 0.4089
Epoch  14 Batch  350/1077 - Train Accuracy: 0.6660, Validation Accuracy: 0.6896, Loss: 0.3837
Epoch  14 Batch  360/1077 - Train Accuracy: 0.6602, Validation Accuracy: 0.6896, Loss: 0.3946
Epoch  14 Batch  370/1077 - Train Accuracy: 0.6856, Validation Accuracy: 0.6939, Loss: 0.3909
Epoch  14 Batch  380/1077 - Train Accuracy: 0.6680, Validation Accuracy: 0.6935, Loss: 0.3824
Epoch  14 Batch  390/1077 - Train Accuracy: 0.6570, Validation Accuracy: 0.6879, Loss: 0.4191
Epoch  14 Batch  400/1077 - Train Accuracy: 0.7012, Validation Accuracy: 0.6829, Loss: 0.4095
Epoch  14 Batch  410/1077 - Train Accuracy: 0.6637, Validation Accuracy: 0.6808, Loss: 0.4056
Epoch  14 Batch  420/1077 - Train Accuracy: 0.6855, Validation Accuracy: 0.6843, Loss: 0.3867
Epoch  14 Batch  430/1077 - Train Accuracy: 0.6578, Validation Accuracy: 0.6776, Loss: 0.4005
Epoch  14 Batch  440/1077 - Train Accuracy: 0.6590, Validation Accuracy: 0.6875, Loss: 0.3991
Epoch  14 Batch  450/1077 - Train Accuracy: 0.6734, Validation Accuracy: 0.6829, Loss: 0.3909
Epoch  14 Batch  460/1077 - Train Accuracy: 0.6699, Validation Accuracy: 0.6864, Loss: 0.4133
Epoch  14 Batch  470/1077 - Train Accuracy: 0.6538, Validation Accuracy: 0.6896, Loss: 0.4101
Epoch  14 Batch  480/1077 - Train Accuracy: 0.7159, Validation Accuracy: 0.6850, Loss: 0.4044
Epoch  14 Batch  490/1077 - Train Accuracy: 0.6762, Validation Accuracy: 0.6879, Loss: 0.4154
Epoch  14 Batch  500/1077 - Train Accuracy: 0.7051, Validation Accuracy: 0.6889, Loss: 0.3817
Epoch  14 Batch  510/1077 - Train Accuracy: 0.6887, Validation Accuracy: 0.6900, Loss: 0.3964
Epoch  14 Batch  520/1077 - Train Accuracy: 0.7180, Validation Accuracy: 0.6911, Loss: 0.3629
Epoch  14 Batch  530/1077 - Train Accuracy: 0.6805, Validation Accuracy: 0.6815, Loss: 0.4008
Epoch  14 Batch  540/1077 - Train Accuracy: 0.6727, Validation Accuracy: 0.6864, Loss: 0.3833
Epoch  14 Batch  550/1077 - Train Accuracy: 0.6723, Validation Accuracy: 0.6914, Loss: 0.4278
Epoch  14 Batch  560/1077 - Train Accuracy: 0.6734, Validation Accuracy: 0.6864, Loss: 0.3977
Epoch  14 Batch  570/1077 - Train Accuracy: 0.6920, Validation Accuracy: 0.6903, Loss: 0.4394
Epoch  14 Batch  580/1077 - Train Accuracy: 0.7150, Validation Accuracy: 0.6918, Loss: 0.3762
Epoch  14 Batch  590/1077 - Train Accuracy: 0.6460, Validation Accuracy: 0.6882, Loss: 0.4268
Epoch  14 Batch  600/1077 - Train Accuracy: 0.7042, Validation Accuracy: 0.6889, Loss: 0.3786
Epoch  14 Batch  610/1077 - Train Accuracy: 0.6706, Validation Accuracy: 0.6875, Loss: 0.4153
Epoch  14 Batch  620/1077 - Train Accuracy: 0.6723, Validation Accuracy: 0.6921, Loss: 0.3949
Epoch  14 Batch  630/1077 - Train Accuracy: 0.6996, Validation Accuracy: 0.6882, Loss: 0.4038
Epoch  14 Batch  640/1077 - Train Accuracy: 0.6815, Validation Accuracy: 0.6925, Loss: 0.3850
Epoch  14 Batch  650/1077 - Train Accuracy: 0.6805, Validation Accuracy: 0.6928, Loss: 0.4076
Epoch  14 Batch  660/1077 - Train Accuracy: 0.6875, Validation Accuracy: 0.6893, Loss: 0.4111
Epoch  14 Batch  670/1077 - Train Accuracy: 0.7248, Validation Accuracy: 0.6925, Loss: 0.3634
Epoch  14 Batch  680/1077 - Train Accuracy: 0.6942, Validation Accuracy: 0.6935, Loss: 0.3922
Epoch  14 Batch  690/1077 - Train Accuracy: 0.7039, Validation Accuracy: 0.6957, Loss: 0.4087
Epoch  14 Batch  700/1077 - Train Accuracy: 0.6887, Validation Accuracy: 0.6882, Loss: 0.3796
Epoch  14 Batch  710/1077 - Train Accuracy: 0.6484, Validation Accuracy: 0.6889, Loss: 0.3971
Epoch  14 Batch  720/1077 - Train Accuracy: 0.6859, Validation Accuracy: 0.6882, Loss: 0.4257
Epoch  14 Batch  730/1077 - Train Accuracy: 0.6609, Validation Accuracy: 0.6889, Loss: 0.4160
Epoch  14 Batch  740/1077 - Train Accuracy: 0.6918, Validation Accuracy: 0.6868, Loss: 0.3911
Epoch  14 Batch  750/1077 - Train Accuracy: 0.7027, Validation Accuracy: 0.6861, Loss: 0.3868
Epoch  14 Batch  760/1077 - Train Accuracy: 0.6902, Validation Accuracy: 0.6907, Loss: 0.4059
Epoch  14 Batch  770/1077 - Train Accuracy: 0.7005, Validation Accuracy: 0.6900, Loss: 0.3657
Epoch  14 Batch  780/1077 - Train Accuracy: 0.6727, Validation Accuracy: 0.6864, Loss: 0.4171
Epoch  14 Batch  790/1077 - Train Accuracy: 0.6379, Validation Accuracy: 0.6868, Loss: 0.4270
Epoch  14 Batch  800/1077 - Train Accuracy: 0.6547, Validation Accuracy: 0.6918, Loss: 0.3946
Epoch  14 Batch  810/1077 - Train Accuracy: 0.6912, Validation Accuracy: 0.6942, Loss: 0.3745
Epoch  14 Batch  820/1077 - Train Accuracy: 0.6562, Validation Accuracy: 0.6978, Loss: 0.4204
Epoch  14 Batch  830/1077 - Train Accuracy: 0.6598, Validation Accuracy: 0.6964, Loss: 0.4016
Epoch  14 Batch  840/1077 - Train Accuracy: 0.6883, Validation Accuracy: 0.6925, Loss: 0.3872
Epoch  14 Batch  850/1077 - Train Accuracy: 0.6752, Validation Accuracy: 0.6925, Loss: 0.4215
Epoch  14 Batch  860/1077 - Train Accuracy: 0.6752, Validation Accuracy: 0.6925, Loss: 0.3899
Epoch  14 Batch  870/1077 - Train Accuracy: 0.6702, Validation Accuracy: 0.6932, Loss: 0.4060
Epoch  14 Batch  880/1077 - Train Accuracy: 0.7355, Validation Accuracy: 0.6911, Loss: 0.3917
Epoch  14 Batch  890/1077 - Train Accuracy: 0.7467, Validation Accuracy: 0.6889, Loss: 0.3648
Epoch  14 Batch  900/1077 - Train Accuracy: 0.7004, Validation Accuracy: 0.6839, Loss: 0.3958
Epoch  14 Batch  910/1077 - Train Accuracy: 0.6577, Validation Accuracy: 0.6900, Loss: 0.3946
Epoch  14 Batch  920/1077 - Train Accuracy: 0.6980, Validation Accuracy: 0.6903, Loss: 0.4048
Epoch  14 Batch  930/1077 - Train Accuracy: 0.6789, Validation Accuracy: 0.6875, Loss: 0.3869
Epoch  14 Batch  940/1077 - Train Accuracy: 0.6711, Validation Accuracy: 0.6836, Loss: 0.3850
Epoch  14 Batch  950/1077 - Train Accuracy: 0.6715, Validation Accuracy: 0.6839, Loss: 0.3719
Epoch  14 Batch  960/1077 - Train Accuracy: 0.7031, Validation Accuracy: 0.6879, Loss: 0.3823
Epoch  14 Batch  970/1077 - Train Accuracy: 0.6863, Validation Accuracy: 0.6850, Loss: 0.4162
Epoch  14 Batch  980/1077 - Train Accuracy: 0.6996, Validation Accuracy: 0.6907, Loss: 0.3975
Epoch  14 Batch  990/1077 - Train Accuracy: 0.6928, Validation Accuracy: 0.6935, Loss: 0.4309
Epoch  14 Batch 1000/1077 - Train Accuracy: 0.7288, Validation Accuracy: 0.6935, Loss: 0.3609
Epoch  14 Batch 1010/1077 - Train Accuracy: 0.6789, Validation Accuracy: 0.6985, Loss: 0.3889
Epoch  14 Batch 1020/1077 - Train Accuracy: 0.6695, Validation Accuracy: 0.6914, Loss: 0.3773
Epoch  14 Batch 1030/1077 - Train Accuracy: 0.6660, Validation Accuracy: 0.6946, Loss: 0.3999
Epoch  14 Batch 1040/1077 - Train Accuracy: 0.6863, Validation Accuracy: 0.6864, Loss: 0.3965
Epoch  14 Batch 1050/1077 - Train Accuracy: 0.6277, Validation Accuracy: 0.6839, Loss: 0.3893
Epoch  14 Batch 1060/1077 - Train Accuracy: 0.6898, Validation Accuracy: 0.6900, Loss: 0.3611
Epoch  14 Batch 1070/1077 - Train Accuracy: 0.6633, Validation Accuracy: 0.6864, Loss: 0.3939
Epoch  15 Batch   10/1077 - Train Accuracy: 0.6838, Validation Accuracy: 0.6939, Loss: 0.4140
Epoch  15 Batch   20/1077 - Train Accuracy: 0.6695, Validation Accuracy: 0.6964, Loss: 0.3973
Epoch  15 Batch   30/1077 - Train Accuracy: 0.6805, Validation Accuracy: 0.6946, Loss: 0.3978
Epoch  15 Batch   40/1077 - Train Accuracy: 0.6980, Validation Accuracy: 0.6928, Loss: 0.3976
Epoch  15 Batch   50/1077 - Train Accuracy: 0.6574, Validation Accuracy: 0.6886, Loss: 0.3919
Epoch  15 Batch   60/1077 - Train Accuracy: 0.6737, Validation Accuracy: 0.6822, Loss: 0.3822
Epoch  15 Batch   70/1077 - Train Accuracy: 0.6488, Validation Accuracy: 0.6857, Loss: 0.4089
Epoch  15 Batch   80/1077 - Train Accuracy: 0.6949, Validation Accuracy: 0.6854, Loss: 0.4052
Epoch  15 Batch   90/1077 - Train Accuracy: 0.6809, Validation Accuracy: 0.6868, Loss: 0.4103
Epoch  15 Batch  100/1077 - Train Accuracy: 0.6918, Validation Accuracy: 0.6864, Loss: 0.3984
Epoch  15 Batch  110/1077 - Train Accuracy: 0.7004, Validation Accuracy: 0.6875, Loss: 0.3657
Epoch  15 Batch  120/1077 - Train Accuracy: 0.7008, Validation Accuracy: 0.6935, Loss: 0.4084
Epoch  15 Batch  130/1077 - Train Accuracy: 0.6842, Validation Accuracy: 0.6932, Loss: 0.3734
Epoch  15 Batch  140/1077 - Train Accuracy: 0.6731, Validation Accuracy: 0.6999, Loss: 0.4041
Epoch  15 Batch  150/1077 - Train Accuracy: 0.7009, Validation Accuracy: 0.6932, Loss: 0.3717
Epoch  15 Batch  160/1077 - Train Accuracy: 0.7078, Validation Accuracy: 0.6985, Loss: 0.3795
Epoch  15 Batch  170/1077 - Train Accuracy: 0.6598, Validation Accuracy: 0.6960, Loss: 0.4090
Epoch  15 Batch  180/1077 - Train Accuracy: 0.6762, Validation Accuracy: 0.6879, Loss: 0.3964
Epoch  15 Batch  190/1077 - Train Accuracy: 0.7141, Validation Accuracy: 0.6911, Loss: 0.3818
Epoch  15 Batch  200/1077 - Train Accuracy: 0.6625, Validation Accuracy: 0.6875, Loss: 0.4029
Epoch  15 Batch  210/1077 - Train Accuracy: 0.6998, Validation Accuracy: 0.6911, Loss: 0.3777
Epoch  15 Batch  220/1077 - Train Accuracy: 0.6912, Validation Accuracy: 0.6861, Loss: 0.3990
Epoch  15 Batch  230/1077 - Train Accuracy: 0.6942, Validation Accuracy: 0.6921, Loss: 0.3683
Epoch  15 Batch  240/1077 - Train Accuracy: 0.7148, Validation Accuracy: 0.6907, Loss: 0.3708
Epoch  15 Batch  250/1077 - Train Accuracy: 0.6623, Validation Accuracy: 0.6925, Loss: 0.3704
Epoch  15 Batch  260/1077 - Train Accuracy: 0.6998, Validation Accuracy: 0.6882, Loss: 0.3599
Epoch  15 Batch  270/1077 - Train Accuracy: 0.6703, Validation Accuracy: 0.6893, Loss: 0.3939
Epoch  15 Batch  280/1077 - Train Accuracy: 0.7074, Validation Accuracy: 0.6928, Loss: 0.3923
Epoch  15 Batch  290/1077 - Train Accuracy: 0.6645, Validation Accuracy: 0.6925, Loss: 0.3905
Epoch  15 Batch  300/1077 - Train Accuracy: 0.6817, Validation Accuracy: 0.6921, Loss: 0.3869
Epoch  15 Batch  310/1077 - Train Accuracy: 0.6684, Validation Accuracy: 0.6900, Loss: 0.4138
Epoch  15 Batch  320/1077 - Train Accuracy: 0.7051, Validation Accuracy: 0.6939, Loss: 0.4146
Epoch  15 Batch  330/1077 - Train Accuracy: 0.7230, Validation Accuracy: 0.6896, Loss: 0.3738
Epoch  15 Batch  340/1077 - Train Accuracy: 0.6817, Validation Accuracy: 0.6967, Loss: 0.3831
Epoch  15 Batch  350/1077 - Train Accuracy: 0.6711, Validation Accuracy: 0.6960, Loss: 0.3857
Epoch  15 Batch  360/1077 - Train Accuracy: 0.6480, Validation Accuracy: 0.6935, Loss: 0.3969
Epoch  15 Batch  370/1077 - Train Accuracy: 0.6912, Validation Accuracy: 0.6925, Loss: 0.3769
Epoch  15 Batch  380/1077 - Train Accuracy: 0.6805, Validation Accuracy: 0.6886, Loss: 0.3716
Epoch  15 Batch  390/1077 - Train Accuracy: 0.6551, Validation Accuracy: 0.6893, Loss: 0.4014
Epoch  15 Batch  400/1077 - Train Accuracy: 0.7031, Validation Accuracy: 0.6907, Loss: 0.4052
Epoch  15 Batch  410/1077 - Train Accuracy: 0.6624, Validation Accuracy: 0.6864, Loss: 0.4043
Epoch  15 Batch  420/1077 - Train Accuracy: 0.6965, Validation Accuracy: 0.6847, Loss: 0.3762
Epoch  15 Batch  430/1077 - Train Accuracy: 0.6695, Validation Accuracy: 0.6864, Loss: 0.3861
Epoch  15 Batch  440/1077 - Train Accuracy: 0.6551, Validation Accuracy: 0.6875, Loss: 0.3923
Epoch  15 Batch  450/1077 - Train Accuracy: 0.6902, Validation Accuracy: 0.6832, Loss: 0.3739
Epoch  15 Batch  460/1077 - Train Accuracy: 0.6937, Validation Accuracy: 0.6825, Loss: 0.3967
Epoch  15 Batch  470/1077 - Train Accuracy: 0.6612, Validation Accuracy: 0.6921, Loss: 0.4007
Epoch  15 Batch  480/1077 - Train Accuracy: 0.7229, Validation Accuracy: 0.6939, Loss: 0.4100
Epoch  15 Batch  490/1077 - Train Accuracy: 0.6781, Validation Accuracy: 0.6964, Loss: 0.4018
Epoch  15 Batch  500/1077 - Train Accuracy: 0.6879, Validation Accuracy: 0.6903, Loss: 0.3868
Epoch  15 Batch  510/1077 - Train Accuracy: 0.6957, Validation Accuracy: 0.6935, Loss: 0.3738
Epoch  15 Batch  520/1077 - Train Accuracy: 0.7176, Validation Accuracy: 0.6942, Loss: 0.3490
Epoch  15 Batch  530/1077 - Train Accuracy: 0.6723, Validation Accuracy: 0.6921, Loss: 0.4063
Epoch  15 Batch  540/1077 - Train Accuracy: 0.6867, Validation Accuracy: 0.6843, Loss: 0.3656
Epoch  15 Batch  550/1077 - Train Accuracy: 0.6871, Validation Accuracy: 0.6992, Loss: 0.4073
Epoch  15 Batch  560/1077 - Train Accuracy: 0.6809, Validation Accuracy: 0.6992, Loss: 0.3864
Epoch  15 Batch  570/1077 - Train Accuracy: 0.6891, Validation Accuracy: 0.7042, Loss: 0.4155
Epoch  15 Batch  580/1077 - Train Accuracy: 0.7281, Validation Accuracy: 0.7031, Loss: 0.3527
Epoch  15 Batch  590/1077 - Train Accuracy: 0.6608, Validation Accuracy: 0.6974, Loss: 0.4130
Epoch  15 Batch  600/1077 - Train Accuracy: 0.7206, Validation Accuracy: 0.6960, Loss: 0.3584
Epoch  15 Batch  610/1077 - Train Accuracy: 0.6813, Validation Accuracy: 0.6957, Loss: 0.3982
Epoch  15 Batch  620/1077 - Train Accuracy: 0.6809, Validation Accuracy: 0.6942, Loss: 0.3739
Epoch  15 Batch  630/1077 - Train Accuracy: 0.7102, Validation Accuracy: 0.6953, Loss: 0.3926
Epoch  15 Batch  640/1077 - Train Accuracy: 0.6864, Validation Accuracy: 0.6925, Loss: 0.3692
Epoch  15 Batch  650/1077 - Train Accuracy: 0.6750, Validation Accuracy: 0.6978, Loss: 0.3927
Epoch  15 Batch  660/1077 - Train Accuracy: 0.6840, Validation Accuracy: 0.6950, Loss: 0.4026
Epoch  15 Batch  670/1077 - Train Accuracy: 0.7234, Validation Accuracy: 0.6957, Loss: 0.3531
Epoch  15 Batch  680/1077 - Train Accuracy: 0.7057, Validation Accuracy: 0.6886, Loss: 0.3923
Epoch  15 Batch  690/1077 - Train Accuracy: 0.7148, Validation Accuracy: 0.6914, Loss: 0.3963
Epoch  15 Batch  700/1077 - Train Accuracy: 0.6937, Validation Accuracy: 0.6960, Loss: 0.3669
Epoch  15 Batch  710/1077 - Train Accuracy: 0.6660, Validation Accuracy: 0.6999, Loss: 0.3848
Epoch  15 Batch  720/1077 - Train Accuracy: 0.6850, Validation Accuracy: 0.6914, Loss: 0.4113
Epoch  15 Batch  730/1077 - Train Accuracy: 0.6672, Validation Accuracy: 0.6960, Loss: 0.4075
Epoch  15 Batch  740/1077 - Train Accuracy: 0.6910, Validation Accuracy: 0.6950, Loss: 0.3794
Epoch  15 Batch  750/1077 - Train Accuracy: 0.7102, Validation Accuracy: 0.6893, Loss: 0.3783
Epoch  15 Batch  760/1077 - Train Accuracy: 0.7012, Validation Accuracy: 0.7006, Loss: 0.3835
Epoch  15 Batch  770/1077 - Train Accuracy: 0.7102, Validation Accuracy: 0.6974, Loss: 0.3572
Epoch  15 Batch  780/1077 - Train Accuracy: 0.6742, Validation Accuracy: 0.6857, Loss: 0.4048
Epoch  15 Batch  790/1077 - Train Accuracy: 0.6355, Validation Accuracy: 0.6864, Loss: 0.4221
Epoch  15 Batch  800/1077 - Train Accuracy: 0.6574, Validation Accuracy: 0.6893, Loss: 0.3789
Epoch  15 Batch  810/1077 - Train Accuracy: 0.6953, Validation Accuracy: 0.6953, Loss: 0.3609
Epoch  15 Batch  820/1077 - Train Accuracy: 0.6559, Validation Accuracy: 0.7021, Loss: 0.4177
Epoch  15 Batch  830/1077 - Train Accuracy: 0.6699, Validation Accuracy: 0.7042, Loss: 0.3862
Epoch  15 Batch  840/1077 - Train Accuracy: 0.6945, Validation Accuracy: 0.6974, Loss: 0.3705
Epoch  15 Batch  850/1077 - Train Accuracy: 0.6730, Validation Accuracy: 0.6967, Loss: 0.4181
Epoch  15 Batch  860/1077 - Train Accuracy: 0.6763, Validation Accuracy: 0.6989, Loss: 0.3828
Epoch  15 Batch  870/1077 - Train Accuracy: 0.6665, Validation Accuracy: 0.6935, Loss: 0.4033
Epoch  15 Batch  880/1077 - Train Accuracy: 0.7203, Validation Accuracy: 0.6911, Loss: 0.3807
Epoch  15 Batch  890/1077 - Train Accuracy: 0.7485, Validation Accuracy: 0.6896, Loss: 0.3676
Epoch  15 Batch  900/1077 - Train Accuracy: 0.7012, Validation Accuracy: 0.6900, Loss: 0.3850
Epoch  15 Batch  910/1077 - Train Accuracy: 0.6711, Validation Accuracy: 0.6982, Loss: 0.3704
Epoch  15 Batch  920/1077 - Train Accuracy: 0.7129, Validation Accuracy: 0.6950, Loss: 0.3893
Epoch  15 Batch  930/1077 - Train Accuracy: 0.6871, Validation Accuracy: 0.6850, Loss: 0.3735
Epoch  15 Batch  940/1077 - Train Accuracy: 0.6777, Validation Accuracy: 0.6832, Loss: 0.3794
Epoch  15 Batch  950/1077 - Train Accuracy: 0.6890, Validation Accuracy: 0.6871, Loss: 0.3645
Epoch  15 Batch  960/1077 - Train Accuracy: 0.7076, Validation Accuracy: 0.6900, Loss: 0.3691
Epoch  15 Batch  970/1077 - Train Accuracy: 0.6801, Validation Accuracy: 0.6907, Loss: 0.3824
Epoch  15 Batch  980/1077 - Train Accuracy: 0.7141, Validation Accuracy: 0.6914, Loss: 0.3828
Epoch  15 Batch  990/1077 - Train Accuracy: 0.6887, Validation Accuracy: 0.6935, Loss: 0.4075
Epoch  15 Batch 1000/1077 - Train Accuracy: 0.7362, Validation Accuracy: 0.6928, Loss: 0.3357
Epoch  15 Batch 1010/1077 - Train Accuracy: 0.6848, Validation Accuracy: 0.6882, Loss: 0.3831
Epoch  15 Batch 1020/1077 - Train Accuracy: 0.6883, Validation Accuracy: 0.6911, Loss: 0.3564
Epoch  15 Batch 1030/1077 - Train Accuracy: 0.6734, Validation Accuracy: 0.7021, Loss: 0.3999
Epoch  15 Batch 1040/1077 - Train Accuracy: 0.6813, Validation Accuracy: 0.6907, Loss: 0.3908
Epoch  15 Batch 1050/1077 - Train Accuracy: 0.6352, Validation Accuracy: 0.7038, Loss: 0.3889
Epoch  15 Batch 1060/1077 - Train Accuracy: 0.6941, Validation Accuracy: 0.6882, Loss: 0.3617
Epoch  15 Batch 1070/1077 - Train Accuracy: 0.6648, Validation Accuracy: 0.6932, Loss: 0.3878
Epoch  16 Batch   10/1077 - Train Accuracy: 0.6879, Validation Accuracy: 0.6974, Loss: 0.3911
Epoch  16 Batch   20/1077 - Train Accuracy: 0.6703, Validation Accuracy: 0.6974, Loss: 0.3698
Epoch  16 Batch   30/1077 - Train Accuracy: 0.6910, Validation Accuracy: 0.6974, Loss: 0.3760
Epoch  16 Batch   40/1077 - Train Accuracy: 0.7008, Validation Accuracy: 0.6992, Loss: 0.3813
Epoch  16 Batch   50/1077 - Train Accuracy: 0.6723, Validation Accuracy: 0.6978, Loss: 0.3759
Epoch  16 Batch   60/1077 - Train Accuracy: 0.6804, Validation Accuracy: 0.6946, Loss: 0.3674
Epoch  16 Batch   70/1077 - Train Accuracy: 0.6706, Validation Accuracy: 0.6900, Loss: 0.4046
Epoch  16 Batch   80/1077 - Train Accuracy: 0.6863, Validation Accuracy: 0.6861, Loss: 0.3785
Epoch  16 Batch   90/1077 - Train Accuracy: 0.6937, Validation Accuracy: 0.6950, Loss: 0.3959
Epoch  16 Batch  100/1077 - Train Accuracy: 0.6918, Validation Accuracy: 0.6921, Loss: 0.3764
Epoch  16 Batch  110/1077 - Train Accuracy: 0.7191, Validation Accuracy: 0.7045, Loss: 0.3621
Epoch  16 Batch  120/1077 - Train Accuracy: 0.7082, Validation Accuracy: 0.7003, Loss: 0.3971
Epoch  16 Batch  130/1077 - Train Accuracy: 0.6845, Validation Accuracy: 0.7056, Loss: 0.3547
Epoch  16 Batch  140/1077 - Train Accuracy: 0.6731, Validation Accuracy: 0.6967, Loss: 0.3909
Epoch  16 Batch  150/1077 - Train Accuracy: 0.7031, Validation Accuracy: 0.6996, Loss: 0.3653
Epoch  16 Batch  160/1077 - Train Accuracy: 0.7117, Validation Accuracy: 0.6918, Loss: 0.3762
Epoch  16 Batch  170/1077 - Train Accuracy: 0.6676, Validation Accuracy: 0.6967, Loss: 0.3943
Epoch  16 Batch  180/1077 - Train Accuracy: 0.6797, Validation Accuracy: 0.7006, Loss: 0.3715
Epoch  16 Batch  190/1077 - Train Accuracy: 0.7156, Validation Accuracy: 0.6928, Loss: 0.3685
Epoch  16 Batch  200/1077 - Train Accuracy: 0.6687, Validation Accuracy: 0.6957, Loss: 0.3794
Epoch  16 Batch  210/1077 - Train Accuracy: 0.7057, Validation Accuracy: 0.7031, Loss: 0.3632
Epoch  16 Batch  220/1077 - Train Accuracy: 0.6900, Validation Accuracy: 0.6939, Loss: 0.3805
Epoch  16 Batch  230/1077 - Train Accuracy: 0.7113, Validation Accuracy: 0.7003, Loss: 0.3538
Epoch  16 Batch  240/1077 - Train Accuracy: 0.7227, Validation Accuracy: 0.6985, Loss: 0.3716
Epoch  16 Batch  250/1077 - Train Accuracy: 0.6712, Validation Accuracy: 0.6928, Loss: 0.3538
Epoch  16 Batch  260/1077 - Train Accuracy: 0.7106, Validation Accuracy: 0.6964, Loss: 0.3470
Epoch  16 Batch  270/1077 - Train Accuracy: 0.6875, Validation Accuracy: 0.6879, Loss: 0.3847
Epoch  16 Batch  280/1077 - Train Accuracy: 0.7191, Validation Accuracy: 0.6903, Loss: 0.3799
Epoch  16 Batch  290/1077 - Train Accuracy: 0.6699, Validation Accuracy: 0.6942, Loss: 0.3901
Epoch  16 Batch  300/1077 - Train Accuracy: 0.6846, Validation Accuracy: 0.6914, Loss: 0.3719
Epoch  16 Batch  310/1077 - Train Accuracy: 0.6734, Validation Accuracy: 0.6882, Loss: 0.3934
Epoch  16 Batch  320/1077 - Train Accuracy: 0.7121, Validation Accuracy: 0.6967, Loss: 0.3993
Epoch  16 Batch  330/1077 - Train Accuracy: 0.7277, Validation Accuracy: 0.6974, Loss: 0.3768
Epoch  16 Batch  340/1077 - Train Accuracy: 0.6957, Validation Accuracy: 0.6953, Loss: 0.3740
Epoch  16 Batch  350/1077 - Train Accuracy: 0.6816, Validation Accuracy: 0.7006, Loss: 0.3626
Epoch  16 Batch  360/1077 - Train Accuracy: 0.6613, Validation Accuracy: 0.6882, Loss: 0.3825
Epoch  16 Batch  370/1077 - Train Accuracy: 0.7013, Validation Accuracy: 0.7006, Loss: 0.3720
Epoch  16 Batch  380/1077 - Train Accuracy: 0.6859, Validation Accuracy: 0.6939, Loss: 0.3811
Epoch  16 Batch  390/1077 - Train Accuracy: 0.6430, Validation Accuracy: 0.6903, Loss: 0.4091
Epoch  16 Batch  400/1077 - Train Accuracy: 0.6934, Validation Accuracy: 0.6882, Loss: 0.4263
Epoch  16 Batch  410/1077 - Train Accuracy: 0.6727, Validation Accuracy: 0.6811, Loss: 0.4144
Epoch  16 Batch  420/1077 - Train Accuracy: 0.7090, Validation Accuracy: 0.6871, Loss: 0.3607
Epoch  16 Batch  430/1077 - Train Accuracy: 0.6773, Validation Accuracy: 0.6850, Loss: 0.3812
Epoch  16 Batch  440/1077 - Train Accuracy: 0.6520, Validation Accuracy: 0.6800, Loss: 0.3898
Epoch  16 Batch  450/1077 - Train Accuracy: 0.6984, Validation Accuracy: 0.6900, Loss: 0.3677
Epoch  16 Batch  460/1077 - Train Accuracy: 0.6969, Validation Accuracy: 0.6864, Loss: 0.3991
Epoch  16 Batch  470/1077 - Train Accuracy: 0.6649, Validation Accuracy: 0.6967, Loss: 0.3927
Epoch  16 Batch  480/1077 - Train Accuracy: 0.7237, Validation Accuracy: 0.6992, Loss: 0.3789
Epoch  16 Batch  490/1077 - Train Accuracy: 0.6836, Validation Accuracy: 0.6957, Loss: 0.3851
Epoch  16 Batch  500/1077 - Train Accuracy: 0.7035, Validation Accuracy: 0.6967, Loss: 0.3643
Epoch  16 Batch  510/1077 - Train Accuracy: 0.6992, Validation Accuracy: 0.6953, Loss: 0.3742
Epoch  16 Batch  520/1077 - Train Accuracy: 0.7247, Validation Accuracy: 0.6967, Loss: 0.3365
Epoch  16 Batch  530/1077 - Train Accuracy: 0.6770, Validation Accuracy: 0.6939, Loss: 0.3747
Epoch  16 Batch  540/1077 - Train Accuracy: 0.6918, Validation Accuracy: 0.6939, Loss: 0.3487
Epoch  16 Batch  550/1077 - Train Accuracy: 0.7027, Validation Accuracy: 0.7010, Loss: 0.3826
Epoch  16 Batch  560/1077 - Train Accuracy: 0.6895, Validation Accuracy: 0.6928, Loss: 0.3590
Epoch  16 Batch  570/1077 - Train Accuracy: 0.7056, Validation Accuracy: 0.7035, Loss: 0.4011
Epoch  16 Batch  580/1077 - Train Accuracy: 0.7281, Validation Accuracy: 0.7013, Loss: 0.3431
Epoch  16 Batch  590/1077 - Train Accuracy: 0.6632, Validation Accuracy: 0.7003, Loss: 0.3952
Epoch  16 Batch  600/1077 - Train Accuracy: 0.7199, Validation Accuracy: 0.6957, Loss: 0.3455
Epoch  16 Batch  610/1077 - Train Accuracy: 0.6826, Validation Accuracy: 0.6935, Loss: 0.3838
Epoch  16 Batch  620/1077 - Train Accuracy: 0.6906, Validation Accuracy: 0.6982, Loss: 0.3501
Epoch  16 Batch  630/1077 - Train Accuracy: 0.7117, Validation Accuracy: 0.6999, Loss: 0.3666
Epoch  16 Batch  640/1077 - Train Accuracy: 0.6897, Validation Accuracy: 0.6957, Loss: 0.3528
Epoch  16 Batch  650/1077 - Train Accuracy: 0.6797, Validation Accuracy: 0.7024, Loss: 0.3740
Epoch  16 Batch  660/1077 - Train Accuracy: 0.6918, Validation Accuracy: 0.6985, Loss: 0.3905
Epoch  16 Batch  670/1077 - Train Accuracy: 0.7116, Validation Accuracy: 0.6950, Loss: 0.3457
Epoch  16 Batch  680/1077 - Train Accuracy: 0.7132, Validation Accuracy: 0.6974, Loss: 0.3726
Epoch  16 Batch  690/1077 - Train Accuracy: 0.7227, Validation Accuracy: 0.7021, Loss: 0.3768
Epoch  16 Batch  700/1077 - Train Accuracy: 0.6891, Validation Accuracy: 0.6942, Loss: 0.3445
Epoch  16 Batch  710/1077 - Train Accuracy: 0.6551, Validation Accuracy: 0.6960, Loss: 0.3629
Epoch  16 Batch  720/1077 - Train Accuracy: 0.7023, Validation Accuracy: 0.6967, Loss: 0.3869
Epoch  16 Batch  730/1077 - Train Accuracy: 0.6695, Validation Accuracy: 0.6953, Loss: 0.3616
Epoch  16 Batch  740/1077 - Train Accuracy: 0.7039, Validation Accuracy: 0.6960, Loss: 0.3623
Epoch  16 Batch  750/1077 - Train Accuracy: 0.7141, Validation Accuracy: 0.6939, Loss: 0.3681
Epoch  16 Batch  760/1077 - Train Accuracy: 0.7074, Validation Accuracy: 0.6928, Loss: 0.3619
Epoch  16 Batch  770/1077 - Train Accuracy: 0.7188, Validation Accuracy: 0.6985, Loss: 0.3400
Epoch  16 Batch  780/1077 - Train Accuracy: 0.6898, Validation Accuracy: 0.6978, Loss: 0.3952
Epoch  16 Batch  790/1077 - Train Accuracy: 0.6406, Validation Accuracy: 0.6953, Loss: 0.3902
Epoch  16 Batch  800/1077 - Train Accuracy: 0.6680, Validation Accuracy: 0.6911, Loss: 0.3596
Epoch  16 Batch  810/1077 - Train Accuracy: 0.6964, Validation Accuracy: 0.6999, Loss: 0.3359
Epoch  16 Batch  820/1077 - Train Accuracy: 0.6672, Validation Accuracy: 0.7031, Loss: 0.3891
Epoch  16 Batch  830/1077 - Train Accuracy: 0.6758, Validation Accuracy: 0.6999, Loss: 0.3722
Epoch  16 Batch  840/1077 - Train Accuracy: 0.7000, Validation Accuracy: 0.6992, Loss: 0.3600
Epoch  16 Batch  850/1077 - Train Accuracy: 0.6827, Validation Accuracy: 0.6999, Loss: 0.3883
Epoch  16 Batch  860/1077 - Train Accuracy: 0.6894, Validation Accuracy: 0.6939, Loss: 0.3521
Epoch  16 Batch  870/1077 - Train Accuracy: 0.6748, Validation Accuracy: 0.6946, Loss: 0.3799
Epoch  16 Batch  880/1077 - Train Accuracy: 0.7379, Validation Accuracy: 0.6960, Loss: 0.3854
Epoch  16 Batch  890/1077 - Train Accuracy: 0.7515, Validation Accuracy: 0.6964, Loss: 0.3478
Epoch  16 Batch  900/1077 - Train Accuracy: 0.7082, Validation Accuracy: 0.6999, Loss: 0.3632
Epoch  16 Batch  910/1077 - Train Accuracy: 0.6808, Validation Accuracy: 0.7010, Loss: 0.3647
Epoch  16 Batch  920/1077 - Train Accuracy: 0.7004, Validation Accuracy: 0.7013, Loss: 0.3759
Epoch  16 Batch  930/1077 - Train Accuracy: 0.6836, Validation Accuracy: 0.6896, Loss: 0.3549
Epoch  16 Batch  940/1077 - Train Accuracy: 0.6754, Validation Accuracy: 0.6971, Loss: 0.3528
Epoch  16 Batch  950/1077 - Train Accuracy: 0.6734, Validation Accuracy: 0.6889, Loss: 0.3386
Epoch  16 Batch  960/1077 - Train Accuracy: 0.7176, Validation Accuracy: 0.6942, Loss: 0.3559
Epoch  16 Batch  970/1077 - Train Accuracy: 0.6957, Validation Accuracy: 0.6907, Loss: 0.3557
Epoch  16 Batch  980/1077 - Train Accuracy: 0.7191, Validation Accuracy: 0.6946, Loss: 0.3669
Epoch  16 Batch  990/1077 - Train Accuracy: 0.7015, Validation Accuracy: 0.6957, Loss: 0.3967
Epoch  16 Batch 1000/1077 - Train Accuracy: 0.7500, Validation Accuracy: 0.6999, Loss: 0.3333
Epoch  16 Batch 1010/1077 - Train Accuracy: 0.6988, Validation Accuracy: 0.6982, Loss: 0.3724
Epoch  16 Batch 1020/1077 - Train Accuracy: 0.6965, Validation Accuracy: 0.6985, Loss: 0.3462
Epoch  16 Batch 1030/1077 - Train Accuracy: 0.6816, Validation Accuracy: 0.6960, Loss: 0.3788
Epoch  16 Batch 1040/1077 - Train Accuracy: 0.7056, Validation Accuracy: 0.6925, Loss: 0.3831
Epoch  16 Batch 1050/1077 - Train Accuracy: 0.6309, Validation Accuracy: 0.6886, Loss: 0.3606
Epoch  16 Batch 1060/1077 - Train Accuracy: 0.7047, Validation Accuracy: 0.6911, Loss: 0.3367
Epoch  16 Batch 1070/1077 - Train Accuracy: 0.6695, Validation Accuracy: 0.6996, Loss: 0.3675
Epoch  17 Batch   10/1077 - Train Accuracy: 0.6978, Validation Accuracy: 0.6992, Loss: 0.3756
Epoch  17 Batch   20/1077 - Train Accuracy: 0.7000, Validation Accuracy: 0.6974, Loss: 0.3640
Epoch  17 Batch   30/1077 - Train Accuracy: 0.6969, Validation Accuracy: 0.6932, Loss: 0.3660
Epoch  17 Batch   40/1077 - Train Accuracy: 0.7117, Validation Accuracy: 0.6985, Loss: 0.3736
Epoch  17 Batch   50/1077 - Train Accuracy: 0.6863, Validation Accuracy: 0.6985, Loss: 0.3649
Epoch  17 Batch   60/1077 - Train Accuracy: 0.6916, Validation Accuracy: 0.6999, Loss: 0.3448
Epoch  17 Batch   70/1077 - Train Accuracy: 0.6859, Validation Accuracy: 0.6957, Loss: 0.3728
Epoch  17 Batch   80/1077 - Train Accuracy: 0.6996, Validation Accuracy: 0.6911, Loss: 0.3676
Epoch  17 Batch   90/1077 - Train Accuracy: 0.6918, Validation Accuracy: 0.6971, Loss: 0.3735
Epoch  17 Batch  100/1077 - Train Accuracy: 0.6945, Validation Accuracy: 0.7021, Loss: 0.3565
Epoch  17 Batch  110/1077 - Train Accuracy: 0.7230, Validation Accuracy: 0.7028, Loss: 0.3379
Epoch  17 Batch  120/1077 - Train Accuracy: 0.7191, Validation Accuracy: 0.7049, Loss: 0.3838
Epoch  17 Batch  130/1077 - Train Accuracy: 0.6949, Validation Accuracy: 0.7049, Loss: 0.3463
Epoch  17 Batch  140/1077 - Train Accuracy: 0.6801, Validation Accuracy: 0.7024, Loss: 0.3685
Epoch  17 Batch  150/1077 - Train Accuracy: 0.7061, Validation Accuracy: 0.7060, Loss: 0.3417
Epoch  17 Batch  160/1077 - Train Accuracy: 0.7066, Validation Accuracy: 0.7013, Loss: 0.3558
Epoch  17 Batch  170/1077 - Train Accuracy: 0.6785, Validation Accuracy: 0.7010, Loss: 0.3756
Epoch  17 Batch  180/1077 - Train Accuracy: 0.6926, Validation Accuracy: 0.6953, Loss: 0.3581
Epoch  17 Batch  190/1077 - Train Accuracy: 0.7203, Validation Accuracy: 0.6950, Loss: 0.3500
Epoch  17 Batch  200/1077 - Train Accuracy: 0.6715, Validation Accuracy: 0.6907, Loss: 0.3628
Epoch  17 Batch  210/1077 - Train Accuracy: 0.7072, Validation Accuracy: 0.6982, Loss: 0.3711
Epoch  17 Batch  220/1077 - Train Accuracy: 0.6970, Validation Accuracy: 0.7013, Loss: 0.3717
Epoch  17 Batch  230/1077 - Train Accuracy: 0.7087, Validation Accuracy: 0.6925, Loss: 0.3488
Epoch  17 Batch  240/1077 - Train Accuracy: 0.7301, Validation Accuracy: 0.6932, Loss: 0.3509
Epoch  17 Batch  250/1077 - Train Accuracy: 0.6790, Validation Accuracy: 0.6967, Loss: 0.3356
Epoch  17 Batch  260/1077 - Train Accuracy: 0.7143, Validation Accuracy: 0.6914, Loss: 0.3333
Epoch  17 Batch  270/1077 - Train Accuracy: 0.6695, Validation Accuracy: 0.6928, Loss: 0.3752
Epoch  17 Batch  280/1077 - Train Accuracy: 0.7129, Validation Accuracy: 0.6950, Loss: 0.3734
Epoch  17 Batch  290/1077 - Train Accuracy: 0.6727, Validation Accuracy: 0.7102, Loss: 0.3716
Epoch  17 Batch  300/1077 - Train Accuracy: 0.6875, Validation Accuracy: 0.6946, Loss: 0.3672
Epoch  17 Batch  310/1077 - Train Accuracy: 0.6734, Validation Accuracy: 0.7010, Loss: 0.3775
Epoch  17 Batch  320/1077 - Train Accuracy: 0.7246, Validation Accuracy: 0.6982, Loss: 0.3871
Epoch  17 Batch  330/1077 - Train Accuracy: 0.7395, Validation Accuracy: 0.7003, Loss: 0.3562
Epoch  17 Batch  340/1077 - Train Accuracy: 0.6965, Validation Accuracy: 0.7024, Loss: 0.3674
Epoch  17 Batch  350/1077 - Train Accuracy: 0.6801, Validation Accuracy: 0.6921, Loss: 0.3446
Epoch  17 Batch  360/1077 - Train Accuracy: 0.6543, Validation Accuracy: 0.6928, Loss: 0.3647
Epoch  17 Batch  370/1077 - Train Accuracy: 0.7124, Validation Accuracy: 0.7042, Loss: 0.3543
Epoch  17 Batch  380/1077 - Train Accuracy: 0.6859, Validation Accuracy: 0.6935, Loss: 0.3568
Epoch  17 Batch  390/1077 - Train Accuracy: 0.6516, Validation Accuracy: 0.6893, Loss: 0.3635
Epoch  17 Batch  400/1077 - Train Accuracy: 0.7090, Validation Accuracy: 0.6978, Loss: 0.3822
Epoch  17 Batch  410/1077 - Train Accuracy: 0.6711, Validation Accuracy: 0.6925, Loss: 0.3684
Epoch  17 Batch  420/1077 - Train Accuracy: 0.7230, Validation Accuracy: 0.6942, Loss: 0.3296
Epoch  17 Batch  430/1077 - Train Accuracy: 0.6715, Validation Accuracy: 0.6999, Loss: 0.3581
Epoch  17 Batch  440/1077 - Train Accuracy: 0.6699, Validation Accuracy: 0.6939, Loss: 0.3718
Epoch  17 Batch  450/1077 - Train Accuracy: 0.6922, Validation Accuracy: 0.7024, Loss: 0.3478
Epoch  17 Batch  460/1077 - Train Accuracy: 0.6961, Validation Accuracy: 0.6935, Loss: 0.3733
Epoch  17 Batch  470/1077 - Train Accuracy: 0.6780, Validation Accuracy: 0.7021, Loss: 0.3731
Epoch  17 Batch  480/1077 - Train Accuracy: 0.7225, Validation Accuracy: 0.7013, Loss: 0.3810
Epoch  17 Batch  490/1077 - Train Accuracy: 0.7031, Validation Accuracy: 0.6946, Loss: 0.3632
Epoch  17 Batch  500/1077 - Train Accuracy: 0.7246, Validation Accuracy: 0.6985, Loss: 0.3465
Epoch  17 Batch  510/1077 - Train Accuracy: 0.7168, Validation Accuracy: 0.6960, Loss: 0.3489
Epoch  17 Batch  520/1077 - Train Accuracy: 0.7329, Validation Accuracy: 0.7088, Loss: 0.3282
Epoch  17 Batch  530/1077 - Train Accuracy: 0.6719, Validation Accuracy: 0.6939, Loss: 0.3698
Epoch  17 Batch  540/1077 - Train Accuracy: 0.6992, Validation Accuracy: 0.6957, Loss: 0.3407
Epoch  17 Batch  550/1077 - Train Accuracy: 0.6945, Validation Accuracy: 0.6999, Loss: 0.3837
Epoch  17 Batch  560/1077 - Train Accuracy: 0.6992, Validation Accuracy: 0.6978, Loss: 0.3863
Epoch  17 Batch  570/1077 - Train Accuracy: 0.6994, Validation Accuracy: 0.7074, Loss: 0.3895
Epoch  17 Batch  580/1077 - Train Accuracy: 0.7299, Validation Accuracy: 0.7074, Loss: 0.3326
Epoch  17 Batch  590/1077 - Train Accuracy: 0.6637, Validation Accuracy: 0.7006, Loss: 0.3782
Epoch  17 Batch  600/1077 - Train Accuracy: 0.7344, Validation Accuracy: 0.6996, Loss: 0.3379
Epoch  17 Batch  610/1077 - Train Accuracy: 0.6908, Validation Accuracy: 0.7010, Loss: 0.3647
Epoch  17 Batch  620/1077 - Train Accuracy: 0.6898, Validation Accuracy: 0.7006, Loss: 0.3506
Epoch  17 Batch  630/1077 - Train Accuracy: 0.7109, Validation Accuracy: 0.7006, Loss: 0.3582
Epoch  17 Batch  640/1077 - Train Accuracy: 0.7009, Validation Accuracy: 0.7063, Loss: 0.3502
Epoch  17 Batch  650/1077 - Train Accuracy: 0.6926, Validation Accuracy: 0.7067, Loss: 0.3627
Epoch  17 Batch  660/1077 - Train Accuracy: 0.6840, Validation Accuracy: 0.7003, Loss: 0.3818
Epoch  17 Batch  670/1077 - Train Accuracy: 0.7166, Validation Accuracy: 0.6875, Loss: 0.3228
Epoch  17 Batch  680/1077 - Train Accuracy: 0.7195, Validation Accuracy: 0.6939, Loss: 0.3614
Epoch  17 Batch  690/1077 - Train Accuracy: 0.7254, Validation Accuracy: 0.7006, Loss: 0.3520
Epoch  17 Batch  700/1077 - Train Accuracy: 0.6988, Validation Accuracy: 0.7003, Loss: 0.3350
Epoch  17 Batch  710/1077 - Train Accuracy: 0.6605, Validation Accuracy: 0.7006, Loss: 0.3577
Epoch  17 Batch  720/1077 - Train Accuracy: 0.7097, Validation Accuracy: 0.6967, Loss: 0.3775
Epoch  17 Batch  730/1077 - Train Accuracy: 0.6734, Validation Accuracy: 0.6978, Loss: 0.3744
Epoch  17 Batch  740/1077 - Train Accuracy: 0.7109, Validation Accuracy: 0.6914, Loss: 0.3498
Epoch  17 Batch  750/1077 - Train Accuracy: 0.7141, Validation Accuracy: 0.7003, Loss: 0.3479
Epoch  17 Batch  760/1077 - Train Accuracy: 0.7059, Validation Accuracy: 0.6967, Loss: 0.3596
Epoch  17 Batch  770/1077 - Train Accuracy: 0.7258, Validation Accuracy: 0.6932, Loss: 0.3348
Epoch  17 Batch  780/1077 - Train Accuracy: 0.7059, Validation Accuracy: 0.6964, Loss: 0.3689
Epoch  17 Batch  790/1077 - Train Accuracy: 0.6355, Validation Accuracy: 0.7045, Loss: 0.3854
Epoch  17 Batch  800/1077 - Train Accuracy: 0.6660, Validation Accuracy: 0.7003, Loss: 0.3537
Epoch  17 Batch  810/1077 - Train Accuracy: 0.7061, Validation Accuracy: 0.7010, Loss: 0.3300
Epoch  17 Batch  820/1077 - Train Accuracy: 0.6699, Validation Accuracy: 0.7095, Loss: 0.3777
Epoch  17 Batch  830/1077 - Train Accuracy: 0.6734, Validation Accuracy: 0.7021, Loss: 0.3573
Epoch  17 Batch  840/1077 - Train Accuracy: 0.7043, Validation Accuracy: 0.6985, Loss: 0.3423
Epoch  17 Batch  850/1077 - Train Accuracy: 0.6830, Validation Accuracy: 0.7077, Loss: 0.3773
Epoch  17 Batch  860/1077 - Train Accuracy: 0.7013, Validation Accuracy: 0.7024, Loss: 0.3495
Epoch  17 Batch  870/1077 - Train Accuracy: 0.6776, Validation Accuracy: 0.7010, Loss: 0.3697
Epoch  17 Batch  880/1077 - Train Accuracy: 0.7410, Validation Accuracy: 0.7013, Loss: 0.3511
Epoch  17 Batch  890/1077 - Train Accuracy: 0.7656, Validation Accuracy: 0.7049, Loss: 0.3328
Epoch  17 Batch  900/1077 - Train Accuracy: 0.7113, Validation Accuracy: 0.7024, Loss: 0.3557
Epoch  17 Batch  910/1077 - Train Accuracy: 0.6890, Validation Accuracy: 0.7045, Loss: 0.3492
Epoch  17 Batch  920/1077 - Train Accuracy: 0.7051, Validation Accuracy: 0.7024, Loss: 0.3653
Epoch  17 Batch  930/1077 - Train Accuracy: 0.6910, Validation Accuracy: 0.6896, Loss: 0.3484
Epoch  17 Batch  940/1077 - Train Accuracy: 0.6828, Validation Accuracy: 0.7021, Loss: 0.3576
Epoch  17 Batch  950/1077 - Train Accuracy: 0.6942, Validation Accuracy: 0.6999, Loss: 0.3362
Epoch  17 Batch  960/1077 - Train Accuracy: 0.7165, Validation Accuracy: 0.6964, Loss: 0.3430
Epoch  17 Batch  970/1077 - Train Accuracy: 0.6867, Validation Accuracy: 0.6903, Loss: 0.3622
Epoch  17 Batch  980/1077 - Train Accuracy: 0.7203, Validation Accuracy: 0.7056, Loss: 0.3547
Epoch  17 Batch  990/1077 - Train Accuracy: 0.6961, Validation Accuracy: 0.7038, Loss: 0.3790
Epoch  17 Batch 1000/1077 - Train Accuracy: 0.7485, Validation Accuracy: 0.6992, Loss: 0.3342
Epoch  17 Batch 1010/1077 - Train Accuracy: 0.6996, Validation Accuracy: 0.6932, Loss: 0.3555
Epoch  17 Batch 1020/1077 - Train Accuracy: 0.6926, Validation Accuracy: 0.7010, Loss: 0.3392
Epoch  17 Batch 1030/1077 - Train Accuracy: 0.6832, Validation Accuracy: 0.7056, Loss: 0.3703
Epoch  17 Batch 1040/1077 - Train Accuracy: 0.7039, Validation Accuracy: 0.6992, Loss: 0.3628
Epoch  17 Batch 1050/1077 - Train Accuracy: 0.6430, Validation Accuracy: 0.7067, Loss: 0.3460
Epoch  17 Batch 1060/1077 - Train Accuracy: 0.7207, Validation Accuracy: 0.7106, Loss: 0.3358
Epoch  17 Batch 1070/1077 - Train Accuracy: 0.6691, Validation Accuracy: 0.7095, Loss: 0.3541
Epoch  18 Batch   10/1077 - Train Accuracy: 0.7072, Validation Accuracy: 0.6992, Loss: 0.3613
Epoch  18 Batch   20/1077 - Train Accuracy: 0.6793, Validation Accuracy: 0.7021, Loss: 0.3469
Epoch  18 Batch   30/1077 - Train Accuracy: 0.7016, Validation Accuracy: 0.6978, Loss: 0.3547
Epoch  18 Batch   40/1077 - Train Accuracy: 0.7102, Validation Accuracy: 0.7049, Loss: 0.3498
Epoch  18 Batch   50/1077 - Train Accuracy: 0.6711, Validation Accuracy: 0.7010, Loss: 0.3500
Epoch  18 Batch   60/1077 - Train Accuracy: 0.6789, Validation Accuracy: 0.7031, Loss: 0.3307
Epoch  18 Batch   70/1077 - Train Accuracy: 0.7056, Validation Accuracy: 0.7067, Loss: 0.3736
Epoch  18 Batch   80/1077 - Train Accuracy: 0.7047, Validation Accuracy: 0.6939, Loss: 0.3570
Epoch  18 Batch   90/1077 - Train Accuracy: 0.6867, Validation Accuracy: 0.7035, Loss: 0.3614
Epoch  18 Batch  100/1077 - Train Accuracy: 0.7031, Validation Accuracy: 0.7010, Loss: 0.3572
Epoch  18 Batch  110/1077 - Train Accuracy: 0.7254, Validation Accuracy: 0.7028, Loss: 0.3345
Epoch  18 Batch  120/1077 - Train Accuracy: 0.7125, Validation Accuracy: 0.6992, Loss: 0.3677
Epoch  18 Batch  130/1077 - Train Accuracy: 0.6923, Validation Accuracy: 0.7099, Loss: 0.3330
Epoch  18 Batch  140/1077 - Train Accuracy: 0.6883, Validation Accuracy: 0.7081, Loss: 0.3590
Epoch  18 Batch  150/1077 - Train Accuracy: 0.7158, Validation Accuracy: 0.7070, Loss: 0.3325
Epoch  18 Batch  160/1077 - Train Accuracy: 0.7141, Validation Accuracy: 0.7116, Loss: 0.3554
Epoch  18 Batch  170/1077 - Train Accuracy: 0.6836, Validation Accuracy: 0.7081, Loss: 0.3669
Epoch  18 Batch  180/1077 - Train Accuracy: 0.7039, Validation Accuracy: 0.7021, Loss: 0.3515
Epoch  18 Batch  190/1077 - Train Accuracy: 0.7293, Validation Accuracy: 0.7053, Loss: 0.3398
Epoch  18 Batch  200/1077 - Train Accuracy: 0.6750, Validation Accuracy: 0.7053, Loss: 0.3613
Epoch  18 Batch  210/1077 - Train Accuracy: 0.7154, Validation Accuracy: 0.7060, Loss: 0.3398
Epoch  18 Batch  220/1077 - Train Accuracy: 0.7031, Validation Accuracy: 0.7021, Loss: 0.3555
Epoch  18 Batch  230/1077 - Train Accuracy: 0.7117, Validation Accuracy: 0.7106, Loss: 0.3295
Epoch  18 Batch  240/1077 - Train Accuracy: 0.7375, Validation Accuracy: 0.6971, Loss: 0.3444
Epoch  18 Batch  250/1077 - Train Accuracy: 0.6811, Validation Accuracy: 0.6985, Loss: 0.3255
Epoch  18 Batch  260/1077 - Train Accuracy: 0.7173, Validation Accuracy: 0.7109, Loss: 0.3256
Epoch  18 Batch  270/1077 - Train Accuracy: 0.6605, Validation Accuracy: 0.7010, Loss: 0.3705
Epoch  18 Batch  280/1077 - Train Accuracy: 0.7199, Validation Accuracy: 0.7063, Loss: 0.3645
Epoch  18 Batch  290/1077 - Train Accuracy: 0.6836, Validation Accuracy: 0.7138, Loss: 0.3582
Epoch  18 Batch  300/1077 - Train Accuracy: 0.6920, Validation Accuracy: 0.7021, Loss: 0.3533
Epoch  18 Batch  310/1077 - Train Accuracy: 0.6813, Validation Accuracy: 0.6978, Loss: 0.3708
Epoch  18 Batch  320/1077 - Train Accuracy: 0.7172, Validation Accuracy: 0.7070, Loss: 0.3688
Epoch  18 Batch  330/1077 - Train Accuracy: 0.7375, Validation Accuracy: 0.7070, Loss: 0.3494
Epoch  18 Batch  340/1077 - Train Accuracy: 0.7056, Validation Accuracy: 0.7038, Loss: 0.3459
Epoch  18 Batch  350/1077 - Train Accuracy: 0.6879, Validation Accuracy: 0.6964, Loss: 0.3488
Epoch  18 Batch  360/1077 - Train Accuracy: 0.6676, Validation Accuracy: 0.6914, Loss: 0.3570
Epoch  18 Batch  370/1077 - Train Accuracy: 0.7083, Validation Accuracy: 0.7035, Loss: 0.3455
Epoch  18 Batch  380/1077 - Train Accuracy: 0.6871, Validation Accuracy: 0.7013, Loss: 0.3478
Epoch  18 Batch  390/1077 - Train Accuracy: 0.6703, Validation Accuracy: 0.7031, Loss: 0.3693
Epoch  18 Batch  400/1077 - Train Accuracy: 0.7129, Validation Accuracy: 0.7042, Loss: 0.3682
Epoch  18 Batch  410/1077 - Train Accuracy: 0.6797, Validation Accuracy: 0.7031, Loss: 0.3740
Epoch  18 Batch  420/1077 - Train Accuracy: 0.7059, Validation Accuracy: 0.7003, Loss: 0.3277
Epoch  18 Batch  430/1077 - Train Accuracy: 0.6867, Validation Accuracy: 0.7063, Loss: 0.3526
Epoch  18 Batch  440/1077 - Train Accuracy: 0.6793, Validation Accuracy: 0.7003, Loss: 0.3573
Epoch  18 Batch  450/1077 - Train Accuracy: 0.6996, Validation Accuracy: 0.6921, Loss: 0.3549
Epoch  18 Batch  460/1077 - Train Accuracy: 0.7086, Validation Accuracy: 0.7006, Loss: 0.3669
Epoch  18 Batch  470/1077 - Train Accuracy: 0.6801, Validation Accuracy: 0.7017, Loss: 0.3636
Epoch  18 Batch  480/1077 - Train Accuracy: 0.7381, Validation Accuracy: 0.7042, Loss: 0.3544
Epoch  18 Batch  490/1077 - Train Accuracy: 0.7129, Validation Accuracy: 0.7060, Loss: 0.3514
Epoch  18 Batch  500/1077 - Train Accuracy: 0.7293, Validation Accuracy: 0.6971, Loss: 0.3382
Epoch  18 Batch  510/1077 - Train Accuracy: 0.7207, Validation Accuracy: 0.7049, Loss: 0.3463
Epoch  18 Batch  520/1077 - Train Accuracy: 0.7281, Validation Accuracy: 0.7195, Loss: 0.3174
Epoch  18 Batch  530/1077 - Train Accuracy: 0.6832, Validation Accuracy: 0.7035, Loss: 0.3741
Epoch  18 Batch  540/1077 - Train Accuracy: 0.7035, Validation Accuracy: 0.7102, Loss: 0.3270
Epoch  18 Batch  550/1077 - Train Accuracy: 0.6984, Validation Accuracy: 0.7056, Loss: 0.3628
Epoch  18 Batch  560/1077 - Train Accuracy: 0.7016, Validation Accuracy: 0.7060, Loss: 0.3384
Epoch  18 Batch  570/1077 - Train Accuracy: 0.6965, Validation Accuracy: 0.7085, Loss: 0.3879
Epoch  18 Batch  580/1077 - Train Accuracy: 0.7370, Validation Accuracy: 0.7092, Loss: 0.3179
Epoch  18 Batch  590/1077 - Train Accuracy: 0.6706, Validation Accuracy: 0.7056, Loss: 0.3780
Epoch  18 Batch  600/1077 - Train Accuracy: 0.7396, Validation Accuracy: 0.7067, Loss: 0.3224
Epoch  18 Batch  610/1077 - Train Accuracy: 0.6961, Validation Accuracy: 0.7113, Loss: 0.3665
Epoch  18 Batch  620/1077 - Train Accuracy: 0.6891, Validation Accuracy: 0.7056, Loss: 0.3382
Epoch  18 Batch  630/1077 - Train Accuracy: 0.7180, Validation Accuracy: 0.7067, Loss: 0.3414
Epoch  18 Batch  640/1077 - Train Accuracy: 0.7039, Validation Accuracy: 0.7081, Loss: 0.3342
Epoch  18 Batch  650/1077 - Train Accuracy: 0.6887, Validation Accuracy: 0.7077, Loss: 0.3621
Epoch  18 Batch  660/1077 - Train Accuracy: 0.6977, Validation Accuracy: 0.6989, Loss: 0.3538
Epoch  18 Batch  670/1077 - Train Accuracy: 0.7166, Validation Accuracy: 0.6999, Loss: 0.3239
Epoch  18 Batch  680/1077 - Train Accuracy: 0.7165, Validation Accuracy: 0.7024, Loss: 0.3402
Epoch  18 Batch  690/1077 - Train Accuracy: 0.7316, Validation Accuracy: 0.6942, Loss: 0.3436
Epoch  18 Batch  700/1077 - Train Accuracy: 0.6969, Validation Accuracy: 0.7088, Loss: 0.3297
Epoch  18 Batch  710/1077 - Train Accuracy: 0.6598, Validation Accuracy: 0.7074, Loss: 0.3414
Epoch  18 Batch  720/1077 - Train Accuracy: 0.7060, Validation Accuracy: 0.7131, Loss: 0.3740
Epoch  18 Batch  730/1077 - Train Accuracy: 0.6773, Validation Accuracy: 0.7056, Loss: 0.3601
Epoch  18 Batch  740/1077 - Train Accuracy: 0.6973, Validation Accuracy: 0.6982, Loss: 0.3461
Epoch  18 Batch  750/1077 - Train Accuracy: 0.7211, Validation Accuracy: 0.7116, Loss: 0.3411
Epoch  18 Batch  760/1077 - Train Accuracy: 0.7281, Validation Accuracy: 0.7159, Loss: 0.3563
Epoch  18 Batch  770/1077 - Train Accuracy: 0.7374, Validation Accuracy: 0.6971, Loss: 0.3265
Epoch  18 Batch  780/1077 - Train Accuracy: 0.7199, Validation Accuracy: 0.7024, Loss: 0.3702
Epoch  18 Batch  790/1077 - Train Accuracy: 0.6445, Validation Accuracy: 0.7081, Loss: 0.3753
Epoch  18 Batch  800/1077 - Train Accuracy: 0.6898, Validation Accuracy: 0.7138, Loss: 0.3466
Epoch  18 Batch  810/1077 - Train Accuracy: 0.6886, Validation Accuracy: 0.7038, Loss: 0.3244
Epoch  18 Batch  820/1077 - Train Accuracy: 0.6887, Validation Accuracy: 0.7013, Loss: 0.3723
Epoch  18 Batch  830/1077 - Train Accuracy: 0.6754, Validation Accuracy: 0.7063, Loss: 0.3508
Epoch  18 Batch  840/1077 - Train Accuracy: 0.7023, Validation Accuracy: 0.7042, Loss: 0.3342
Epoch  18 Batch  850/1077 - Train Accuracy: 0.6812, Validation Accuracy: 0.7049, Loss: 0.3783
Epoch  18 Batch  860/1077 - Train Accuracy: 0.6908, Validation Accuracy: 0.7056, Loss: 0.3498
Epoch  18 Batch  870/1077 - Train Accuracy: 0.6834, Validation Accuracy: 0.7049, Loss: 0.3567
Epoch  18 Batch  880/1077 - Train Accuracy: 0.7480, Validation Accuracy: 0.6942, Loss: 0.3514
Epoch  18 Batch  890/1077 - Train Accuracy: 0.7708, Validation Accuracy: 0.6893, Loss: 0.3436
Epoch  18 Batch  900/1077 - Train Accuracy: 0.7184, Validation Accuracy: 0.7053, Loss: 0.3520
Epoch  18 Batch  910/1077 - Train Accuracy: 0.6920, Validation Accuracy: 0.7060, Loss: 0.3311
Epoch  18 Batch  920/1077 - Train Accuracy: 0.7180, Validation Accuracy: 0.6999, Loss: 0.3567
Epoch  18 Batch  930/1077 - Train Accuracy: 0.6918, Validation Accuracy: 0.6974, Loss: 0.3414
Epoch  18 Batch  940/1077 - Train Accuracy: 0.6937, Validation Accuracy: 0.6999, Loss: 0.3444
Epoch  18 Batch  950/1077 - Train Accuracy: 0.6968, Validation Accuracy: 0.7028, Loss: 0.3215
Epoch  18 Batch  960/1077 - Train Accuracy: 0.7225, Validation Accuracy: 0.7067, Loss: 0.3383
Epoch  18 Batch  970/1077 - Train Accuracy: 0.6824, Validation Accuracy: 0.6978, Loss: 0.3542
Epoch  18 Batch  980/1077 - Train Accuracy: 0.7105, Validation Accuracy: 0.7021, Loss: 0.3468
Epoch  18 Batch  990/1077 - Train Accuracy: 0.7076, Validation Accuracy: 0.7127, Loss: 0.3662
Epoch  18 Batch 1000/1077 - Train Accuracy: 0.7429, Validation Accuracy: 0.7074, Loss: 0.3170
Epoch  18 Batch 1010/1077 - Train Accuracy: 0.6910, Validation Accuracy: 0.7152, Loss: 0.3485
Epoch  18 Batch 1020/1077 - Train Accuracy: 0.6957, Validation Accuracy: 0.7085, Loss: 0.3205
Epoch  18 Batch 1030/1077 - Train Accuracy: 0.6813, Validation Accuracy: 0.7141, Loss: 0.3478
Epoch  18 Batch 1040/1077 - Train Accuracy: 0.6916, Validation Accuracy: 0.7131, Loss: 0.3458
Epoch  18 Batch 1050/1077 - Train Accuracy: 0.6512, Validation Accuracy: 0.7049, Loss: 0.3444
Epoch  18 Batch 1060/1077 - Train Accuracy: 0.7234, Validation Accuracy: 0.7163, Loss: 0.3175
Epoch  18 Batch 1070/1077 - Train Accuracy: 0.6816, Validation Accuracy: 0.7127, Loss: 0.3479
Epoch  19 Batch   10/1077 - Train Accuracy: 0.6998, Validation Accuracy: 0.7006, Loss: 0.3696
Epoch  19 Batch   20/1077 - Train Accuracy: 0.7004, Validation Accuracy: 0.7013, Loss: 0.3363
Epoch  19 Batch   30/1077 - Train Accuracy: 0.7023, Validation Accuracy: 0.7035, Loss: 0.3430
Epoch  19 Batch   40/1077 - Train Accuracy: 0.7277, Validation Accuracy: 0.6921, Loss: 0.3427
Epoch  19 Batch   50/1077 - Train Accuracy: 0.6867, Validation Accuracy: 0.7053, Loss: 0.3389
Epoch  19 Batch   60/1077 - Train Accuracy: 0.7005, Validation Accuracy: 0.7031, Loss: 0.3335
Epoch  19 Batch   70/1077 - Train Accuracy: 0.7060, Validation Accuracy: 0.7060, Loss: 0.3485
Epoch  19 Batch   80/1077 - Train Accuracy: 0.6855, Validation Accuracy: 0.7113, Loss: 0.3530
Epoch  19 Batch   90/1077 - Train Accuracy: 0.6922, Validation Accuracy: 0.6978, Loss: 0.3582
Epoch  19 Batch  100/1077 - Train Accuracy: 0.7098, Validation Accuracy: 0.7148, Loss: 0.3450
Epoch  19 Batch  110/1077 - Train Accuracy: 0.7371, Validation Accuracy: 0.7148, Loss: 0.3170
Epoch  19 Batch  120/1077 - Train Accuracy: 0.7043, Validation Accuracy: 0.7049, Loss: 0.3573
Epoch  19 Batch  130/1077 - Train Accuracy: 0.7054, Validation Accuracy: 0.7188, Loss: 0.3319
Epoch  19 Batch  140/1077 - Train Accuracy: 0.6933, Validation Accuracy: 0.7024, Loss: 0.3520
Epoch  19 Batch  150/1077 - Train Accuracy: 0.7161, Validation Accuracy: 0.7109, Loss: 0.3374
Epoch  19 Batch  160/1077 - Train Accuracy: 0.7090, Validation Accuracy: 0.7070, Loss: 0.3411
Epoch  19 Batch  170/1077 - Train Accuracy: 0.6785, Validation Accuracy: 0.7134, Loss: 0.3523
Epoch  19 Batch  180/1077 - Train Accuracy: 0.6992, Validation Accuracy: 0.7028, Loss: 0.3491
Epoch  19 Batch  190/1077 - Train Accuracy: 0.7305, Validation Accuracy: 0.7056, Loss: 0.3381
Epoch  19 Batch  200/1077 - Train Accuracy: 0.6785, Validation Accuracy: 0.7070, Loss: 0.3561
Epoch  19 Batch  210/1077 - Train Accuracy: 0.6983, Validation Accuracy: 0.7077, Loss: 0.3367
Epoch  19 Batch  220/1077 - Train Accuracy: 0.7048, Validation Accuracy: 0.7021, Loss: 0.3641
Epoch  19 Batch  230/1077 - Train Accuracy: 0.7176, Validation Accuracy: 0.7127, Loss: 0.3169
Epoch  19 Batch  240/1077 - Train Accuracy: 0.7441, Validation Accuracy: 0.7063, Loss: 0.3209
Epoch  19 Batch  250/1077 - Train Accuracy: 0.6793, Validation Accuracy: 0.7074, Loss: 0.3152
Epoch  19 Batch  260/1077 - Train Accuracy: 0.7180, Validation Accuracy: 0.7159, Loss: 0.3063
Epoch  19 Batch  270/1077 - Train Accuracy: 0.6789, Validation Accuracy: 0.7074, Loss: 0.3541
Epoch  19 Batch  280/1077 - Train Accuracy: 0.7242, Validation Accuracy: 0.7095, Loss: 0.3415
Epoch  19 Batch  290/1077 - Train Accuracy: 0.6906, Validation Accuracy: 0.7095, Loss: 0.3570
Epoch  19 Batch  300/1077 - Train Accuracy: 0.6965, Validation Accuracy: 0.7188, Loss: 0.3423
Epoch  19 Batch  310/1077 - Train Accuracy: 0.6676, Validation Accuracy: 0.7070, Loss: 0.3639
Epoch  19 Batch  320/1077 - Train Accuracy: 0.7523, Validation Accuracy: 0.7021, Loss: 0.3628
Epoch  19 Batch  330/1077 - Train Accuracy: 0.7441, Validation Accuracy: 0.7067, Loss: 0.3377
Epoch  19 Batch  340/1077 - Train Accuracy: 0.7118, Validation Accuracy: 0.7102, Loss: 0.3352
Epoch  19 Batch  350/1077 - Train Accuracy: 0.6758, Validation Accuracy: 0.7006, Loss: 0.3331
Epoch  19 Batch  360/1077 - Train Accuracy: 0.6770, Validation Accuracy: 0.7045, Loss: 0.3388
Epoch  19 Batch  370/1077 - Train Accuracy: 0.7072, Validation Accuracy: 0.7049, Loss: 0.3419
Epoch  19 Batch  380/1077 - Train Accuracy: 0.6902, Validation Accuracy: 0.7013, Loss: 0.3213
Epoch  19 Batch  390/1077 - Train Accuracy: 0.6645, Validation Accuracy: 0.7013, Loss: 0.3559
Epoch  19 Batch  400/1077 - Train Accuracy: 0.7203, Validation Accuracy: 0.7049, Loss: 0.3517
Epoch  19 Batch  410/1077 - Train Accuracy: 0.6941, Validation Accuracy: 0.7092, Loss: 0.3500
Epoch  19 Batch  420/1077 - Train Accuracy: 0.7266, Validation Accuracy: 0.6989, Loss: 0.3203
Epoch  19 Batch  430/1077 - Train Accuracy: 0.6770, Validation Accuracy: 0.7148, Loss: 0.3392
Epoch  19 Batch  440/1077 - Train Accuracy: 0.6832, Validation Accuracy: 0.7163, Loss: 0.3460
Epoch  19 Batch  450/1077 - Train Accuracy: 0.7039, Validation Accuracy: 0.7028, Loss: 0.3372
Epoch  19 Batch  460/1077 - Train Accuracy: 0.7066, Validation Accuracy: 0.6985, Loss: 0.3530
Epoch  19 Batch  470/1077 - Train Accuracy: 0.7023, Validation Accuracy: 0.7024, Loss: 0.3777
Epoch  19 Batch  480/1077 - Train Accuracy: 0.7381, Validation Accuracy: 0.7159, Loss: 0.3526
Epoch  19 Batch  490/1077 - Train Accuracy: 0.7109, Validation Accuracy: 0.7124, Loss: 0.3624
Epoch  19 Batch  500/1077 - Train Accuracy: 0.7395, Validation Accuracy: 0.7060, Loss: 0.3390
Epoch  19 Batch  510/1077 - Train Accuracy: 0.7223, Validation Accuracy: 0.7099, Loss: 0.3285
Epoch  19 Batch  520/1077 - Train Accuracy: 0.7385, Validation Accuracy: 0.7145, Loss: 0.3106
Epoch  19 Batch  530/1077 - Train Accuracy: 0.6797, Validation Accuracy: 0.7095, Loss: 0.3548
Epoch  19 Batch  540/1077 - Train Accuracy: 0.7055, Validation Accuracy: 0.7188, Loss: 0.3260
Epoch  19 Batch  550/1077 - Train Accuracy: 0.6930, Validation Accuracy: 0.7049, Loss: 0.3523
Epoch  19 Batch  560/1077 - Train Accuracy: 0.7000, Validation Accuracy: 0.7152, Loss: 0.3278
Epoch  19 Batch  570/1077 - Train Accuracy: 0.6994, Validation Accuracy: 0.7124, Loss: 0.3773
Epoch  19 Batch  580/1077 - Train Accuracy: 0.7321, Validation Accuracy: 0.7184, Loss: 0.3065
Epoch  19 Batch  590/1077 - Train Accuracy: 0.6739, Validation Accuracy: 0.7106, Loss: 0.3630
Epoch  19 Batch  600/1077 - Train Accuracy: 0.7381, Validation Accuracy: 0.7081, Loss: 0.3165
Epoch  19 Batch  610/1077 - Train Accuracy: 0.7039, Validation Accuracy: 0.7049, Loss: 0.3495
Epoch  19 Batch  620/1077 - Train Accuracy: 0.7063, Validation Accuracy: 0.7106, Loss: 0.3279
Epoch  19 Batch  630/1077 - Train Accuracy: 0.7125, Validation Accuracy: 0.7120, Loss: 0.3358
Epoch  19 Batch  640/1077 - Train Accuracy: 0.7094, Validation Accuracy: 0.7049, Loss: 0.3403
Epoch  19 Batch  650/1077 - Train Accuracy: 0.6926, Validation Accuracy: 0.7095, Loss: 0.3519
Epoch  19 Batch  660/1077 - Train Accuracy: 0.7020, Validation Accuracy: 0.7028, Loss: 0.3397
Epoch  19 Batch  670/1077 - Train Accuracy: 0.7212, Validation Accuracy: 0.7074, Loss: 0.3072
Epoch  19 Batch  680/1077 - Train Accuracy: 0.7188, Validation Accuracy: 0.7074, Loss: 0.3425
Epoch  19 Batch  690/1077 - Train Accuracy: 0.7336, Validation Accuracy: 0.6985, Loss: 0.3438
Epoch  19 Batch  700/1077 - Train Accuracy: 0.7141, Validation Accuracy: 0.7067, Loss: 0.3243
Epoch  19 Batch  710/1077 - Train Accuracy: 0.6582, Validation Accuracy: 0.7116, Loss: 0.3308
Epoch  19 Batch  720/1077 - Train Accuracy: 0.7105, Validation Accuracy: 0.7109, Loss: 0.3616
Epoch  19 Batch  730/1077 - Train Accuracy: 0.6914, Validation Accuracy: 0.7099, Loss: 0.3522
Epoch  19 Batch  740/1077 - Train Accuracy: 0.7105, Validation Accuracy: 0.7063, Loss: 0.3235
Epoch  19 Batch  750/1077 - Train Accuracy: 0.7270, Validation Accuracy: 0.7148, Loss: 0.3424
Epoch  19 Batch  760/1077 - Train Accuracy: 0.7293, Validation Accuracy: 0.7156, Loss: 0.3428
Epoch  19 Batch  770/1077 - Train Accuracy: 0.7407, Validation Accuracy: 0.7102, Loss: 0.3065
Epoch  19 Batch  780/1077 - Train Accuracy: 0.7199, Validation Accuracy: 0.7116, Loss: 0.3535
Epoch  19 Batch  790/1077 - Train Accuracy: 0.6512, Validation Accuracy: 0.7088, Loss: 0.3694
Epoch  19 Batch  800/1077 - Train Accuracy: 0.6902, Validation Accuracy: 0.7092, Loss: 0.3388
Epoch  19 Batch  810/1077 - Train Accuracy: 0.7109, Validation Accuracy: 0.7159, Loss: 0.3127
Epoch  19 Batch  820/1077 - Train Accuracy: 0.6895, Validation Accuracy: 0.7148, Loss: 0.3627
Epoch  19 Batch  830/1077 - Train Accuracy: 0.6797, Validation Accuracy: 0.7081, Loss: 0.3412
Epoch  19 Batch  840/1077 - Train Accuracy: 0.7023, Validation Accuracy: 0.7070, Loss: 0.3260
Epoch  19 Batch  850/1077 - Train Accuracy: 0.6875, Validation Accuracy: 0.7053, Loss: 0.3617
Epoch  19 Batch  860/1077 - Train Accuracy: 0.6942, Validation Accuracy: 0.7148, Loss: 0.3354
Epoch  19 Batch  870/1077 - Train Accuracy: 0.6957, Validation Accuracy: 0.7166, Loss: 0.3478
Epoch  19 Batch  880/1077 - Train Accuracy: 0.7516, Validation Accuracy: 0.7013, Loss: 0.3479
Epoch  19 Batch  890/1077 - Train Accuracy: 0.7742, Validation Accuracy: 0.7028, Loss: 0.3194
Epoch  19 Batch  900/1077 - Train Accuracy: 0.7281, Validation Accuracy: 0.7074, Loss: 0.3370
Epoch  19 Batch  910/1077 - Train Accuracy: 0.6912, Validation Accuracy: 0.7106, Loss: 0.3273
Epoch  19 Batch  920/1077 - Train Accuracy: 0.7188, Validation Accuracy: 0.7042, Loss: 0.3463
Epoch  19 Batch  930/1077 - Train Accuracy: 0.7184, Validation Accuracy: 0.7074, Loss: 0.3344
Epoch  19 Batch  940/1077 - Train Accuracy: 0.6980, Validation Accuracy: 0.7035, Loss: 0.3259
Epoch  19 Batch  950/1077 - Train Accuracy: 0.7061, Validation Accuracy: 0.7053, Loss: 0.3097
Epoch  19 Batch  960/1077 - Train Accuracy: 0.7057, Validation Accuracy: 0.7173, Loss: 0.3225
Epoch  19 Batch  970/1077 - Train Accuracy: 0.6797, Validation Accuracy: 0.7195, Loss: 0.3356
Epoch  19 Batch  980/1077 - Train Accuracy: 0.7102, Validation Accuracy: 0.7127, Loss: 0.3406
Epoch  19 Batch  990/1077 - Train Accuracy: 0.7146, Validation Accuracy: 0.7195, Loss: 0.3523
Epoch  19 Batch 1000/1077 - Train Accuracy: 0.7496, Validation Accuracy: 0.7138, Loss: 0.3135
Epoch  19 Batch 1010/1077 - Train Accuracy: 0.6902, Validation Accuracy: 0.6996, Loss: 0.3674
Epoch  19 Batch 1020/1077 - Train Accuracy: 0.6992, Validation Accuracy: 0.7156, Loss: 0.3163
Epoch  19 Batch 1030/1077 - Train Accuracy: 0.6875, Validation Accuracy: 0.7145, Loss: 0.3429
Epoch  19 Batch 1040/1077 - Train Accuracy: 0.6920, Validation Accuracy: 0.7148, Loss: 0.3430
Epoch  19 Batch 1050/1077 - Train Accuracy: 0.6551, Validation Accuracy: 0.7060, Loss: 0.3417
Epoch  19 Batch 1060/1077 - Train Accuracy: 0.7105, Validation Accuracy: 0.7109, Loss: 0.3194
Epoch  19 Batch 1070/1077 - Train Accuracy: 0.6824, Validation Accuracy: 0.7106, Loss: 0.3300
Epoch  20 Batch   10/1077 - Train Accuracy: 0.7183, Validation Accuracy: 0.7148, Loss: 0.3454
Epoch  20 Batch   20/1077 - Train Accuracy: 0.7004, Validation Accuracy: 0.7099, Loss: 0.3290
Epoch  20 Batch   30/1077 - Train Accuracy: 0.7035, Validation Accuracy: 0.7152, Loss: 0.3404
Epoch  20 Batch   40/1077 - Train Accuracy: 0.7285, Validation Accuracy: 0.7095, Loss: 0.3340
Epoch  20 Batch   50/1077 - Train Accuracy: 0.6863, Validation Accuracy: 0.7148, Loss: 0.3244
Epoch  20 Batch   60/1077 - Train Accuracy: 0.7013, Validation Accuracy: 0.7113, Loss: 0.3279
Epoch  20 Batch   70/1077 - Train Accuracy: 0.7068, Validation Accuracy: 0.6996, Loss: 0.3461
Epoch  20 Batch   80/1077 - Train Accuracy: 0.7078, Validation Accuracy: 0.7003, Loss: 0.3422
Epoch  20 Batch   90/1077 - Train Accuracy: 0.7008, Validation Accuracy: 0.7095, Loss: 0.3438
Epoch  20 Batch  100/1077 - Train Accuracy: 0.7125, Validation Accuracy: 0.7120, Loss: 0.3314
Epoch  20 Batch  110/1077 - Train Accuracy: 0.7312, Validation Accuracy: 0.7131, Loss: 0.3132
Epoch  20 Batch  120/1077 - Train Accuracy: 0.7160, Validation Accuracy: 0.7212, Loss: 0.3514
Epoch  20 Batch  130/1077 - Train Accuracy: 0.7020, Validation Accuracy: 0.7170, Loss: 0.3231
Epoch  20 Batch  140/1077 - Train Accuracy: 0.6920, Validation Accuracy: 0.7102, Loss: 0.3423
Epoch  20 Batch  150/1077 - Train Accuracy: 0.7214, Validation Accuracy: 0.7124, Loss: 0.3215
Epoch  20 Batch  160/1077 - Train Accuracy: 0.7152, Validation Accuracy: 0.7145, Loss: 0.3307
Epoch  20 Batch  170/1077 - Train Accuracy: 0.6840, Validation Accuracy: 0.7209, Loss: 0.3379
Epoch  20 Batch  180/1077 - Train Accuracy: 0.7063, Validation Accuracy: 0.7273, Loss: 0.3444
Epoch  20 Batch  190/1077 - Train Accuracy: 0.7293, Validation Accuracy: 0.7124, Loss: 0.3468
Epoch  20 Batch  200/1077 - Train Accuracy: 0.7000, Validation Accuracy: 0.7230, Loss: 0.3543
Epoch  20 Batch  210/1077 - Train Accuracy: 0.7195, Validation Accuracy: 0.7141, Loss: 0.3395
Epoch  20 Batch  220/1077 - Train Accuracy: 0.7011, Validation Accuracy: 0.7166, Loss: 0.3471
Epoch  20 Batch  230/1077 - Train Accuracy: 0.7106, Validation Accuracy: 0.7109, Loss: 0.3141
Epoch  20 Batch  240/1077 - Train Accuracy: 0.7445, Validation Accuracy: 0.7092, Loss: 0.3194
Epoch  20 Batch  250/1077 - Train Accuracy: 0.6847, Validation Accuracy: 0.7088, Loss: 0.3129
Epoch  20 Batch  260/1077 - Train Accuracy: 0.7202, Validation Accuracy: 0.7180, Loss: 0.3098
Epoch  20 Batch  270/1077 - Train Accuracy: 0.7031, Validation Accuracy: 0.7134, Loss: 0.3506
Epoch  20 Batch  280/1077 - Train Accuracy: 0.7293, Validation Accuracy: 0.7116, Loss: 0.3466
Epoch  20 Batch  290/1077 - Train Accuracy: 0.6848, Validation Accuracy: 0.7085, Loss: 0.3536
Epoch  20 Batch  300/1077 - Train Accuracy: 0.6965, Validation Accuracy: 0.7085, Loss: 0.3302
Epoch  20 Batch  310/1077 - Train Accuracy: 0.6715, Validation Accuracy: 0.7095, Loss: 0.3656
Epoch  20 Batch  320/1077 - Train Accuracy: 0.7480, Validation Accuracy: 0.7088, Loss: 0.3590
Epoch  20 Batch  330/1077 - Train Accuracy: 0.7465, Validation Accuracy: 0.7056, Loss: 0.3244
Epoch  20 Batch  340/1077 - Train Accuracy: 0.7031, Validation Accuracy: 0.7070, Loss: 0.3456
Epoch  20 Batch  350/1077 - Train Accuracy: 0.6762, Validation Accuracy: 0.7003, Loss: 0.3360
Epoch  20 Batch  360/1077 - Train Accuracy: 0.6953, Validation Accuracy: 0.7045, Loss: 0.3227
Epoch  20 Batch  370/1077 - Train Accuracy: 0.7176, Validation Accuracy: 0.7038, Loss: 0.3415
Epoch  20 Batch  380/1077 - Train Accuracy: 0.6848, Validation Accuracy: 0.7159, Loss: 0.3268
Epoch  20 Batch  390/1077 - Train Accuracy: 0.6766, Validation Accuracy: 0.7092, Loss: 0.3497
Epoch  20 Batch  400/1077 - Train Accuracy: 0.7074, Validation Accuracy: 0.7053, Loss: 0.3399
Epoch  20 Batch  410/1077 - Train Accuracy: 0.6920, Validation Accuracy: 0.7124, Loss: 0.3451
Epoch  20 Batch  420/1077 - Train Accuracy: 0.7328, Validation Accuracy: 0.7045, Loss: 0.3100
Epoch  20 Batch  430/1077 - Train Accuracy: 0.6734, Validation Accuracy: 0.7170, Loss: 0.3327
Epoch  20 Batch  440/1077 - Train Accuracy: 0.6844, Validation Accuracy: 0.7074, Loss: 0.3360
Epoch  20 Batch  450/1077 - Train Accuracy: 0.7125, Validation Accuracy: 0.7148, Loss: 0.3322
Epoch  20 Batch  460/1077 - Train Accuracy: 0.7305, Validation Accuracy: 0.7106, Loss: 0.3387
Epoch  20 Batch  470/1077 - Train Accuracy: 0.6957, Validation Accuracy: 0.7045, Loss: 0.3420
Epoch  20 Batch  480/1077 - Train Accuracy: 0.7393, Validation Accuracy: 0.7131, Loss: 0.3306
Epoch  20 Batch  490/1077 - Train Accuracy: 0.7141, Validation Accuracy: 0.7053, Loss: 0.3350
Epoch  20 Batch  500/1077 - Train Accuracy: 0.7406, Validation Accuracy: 0.7120, Loss: 0.3308
Epoch  20 Batch  510/1077 - Train Accuracy: 0.7191, Validation Accuracy: 0.7085, Loss: 0.3321
Epoch  20 Batch  520/1077 - Train Accuracy: 0.7258, Validation Accuracy: 0.7070, Loss: 0.3087
Epoch  20 Batch  530/1077 - Train Accuracy: 0.6918, Validation Accuracy: 0.7116, Loss: 0.3472
Epoch  20 Batch  540/1077 - Train Accuracy: 0.7195, Validation Accuracy: 0.7163, Loss: 0.3173
Epoch  20 Batch  550/1077 - Train Accuracy: 0.7148, Validation Accuracy: 0.7106, Loss: 0.3534
Epoch  20 Batch  560/1077 - Train Accuracy: 0.6992, Validation Accuracy: 0.7255, Loss: 0.3270
Epoch  20 Batch  570/1077 - Train Accuracy: 0.7019, Validation Accuracy: 0.7202, Loss: 0.3543
Epoch  20 Batch  580/1077 - Train Accuracy: 0.7411, Validation Accuracy: 0.7152, Loss: 0.3061
Epoch  20 Batch  590/1077 - Train Accuracy: 0.6842, Validation Accuracy: 0.7152, Loss: 0.3500
Epoch  20 Batch  600/1077 - Train Accuracy: 0.7452, Validation Accuracy: 0.7124, Loss: 0.3107
Epoch  20 Batch  610/1077 - Train Accuracy: 0.6998, Validation Accuracy: 0.7113, Loss: 0.3450
Epoch  20 Batch  620/1077 - Train Accuracy: 0.7102, Validation Accuracy: 0.7095, Loss: 0.3324
Epoch  20 Batch  630/1077 - Train Accuracy: 0.7063, Validation Accuracy: 0.7195, Loss: 0.3211
Epoch  20 Batch  640/1077 - Train Accuracy: 0.7046, Validation Accuracy: 0.7177, Loss: 0.3165
Epoch  20 Batch  650/1077 - Train Accuracy: 0.6969, Validation Accuracy: 0.7074, Loss: 0.3385
Epoch  20 Batch  660/1077 - Train Accuracy: 0.7035, Validation Accuracy: 0.7166, Loss: 0.3379
Epoch  20 Batch  670/1077 - Train Accuracy: 0.7113, Validation Accuracy: 0.7173, Loss: 0.3167
Epoch  20 Batch  680/1077 - Train Accuracy: 0.7202, Validation Accuracy: 0.7095, Loss: 0.3387
Epoch  20 Batch  690/1077 - Train Accuracy: 0.7340, Validation Accuracy: 0.7120, Loss: 0.3325
Epoch  20 Batch  700/1077 - Train Accuracy: 0.7172, Validation Accuracy: 0.7099, Loss: 0.3277
Epoch  20 Batch  710/1077 - Train Accuracy: 0.6637, Validation Accuracy: 0.7060, Loss: 0.3246
Epoch  20 Batch  720/1077 - Train Accuracy: 0.7023, Validation Accuracy: 0.6953, Loss: 0.3629
Epoch  20 Batch  730/1077 - Train Accuracy: 0.6836, Validation Accuracy: 0.7138, Loss: 0.3458
Epoch  20 Batch  740/1077 - Train Accuracy: 0.7137, Validation Accuracy: 0.7120, Loss: 0.3315
Epoch  20 Batch  750/1077 - Train Accuracy: 0.7262, Validation Accuracy: 0.7188, Loss: 0.3479
Epoch  20 Batch  760/1077 - Train Accuracy: 0.7348, Validation Accuracy: 0.7188, Loss: 0.3182
Epoch  20 Batch  770/1077 - Train Accuracy: 0.7571, Validation Accuracy: 0.7124, Loss: 0.3102
Epoch  20 Batch  780/1077 - Train Accuracy: 0.7223, Validation Accuracy: 0.7116, Loss: 0.3493
Epoch  20 Batch  790/1077 - Train Accuracy: 0.6664, Validation Accuracy: 0.7166, Loss: 0.3619
Epoch  20 Batch  800/1077 - Train Accuracy: 0.6871, Validation Accuracy: 0.7053, Loss: 0.3369
Epoch  20 Batch  810/1077 - Train Accuracy: 0.7061, Validation Accuracy: 0.6971, Loss: 0.3095
Epoch  20 Batch  820/1077 - Train Accuracy: 0.6898, Validation Accuracy: 0.7092, Loss: 0.3518
Epoch  20 Batch  830/1077 - Train Accuracy: 0.6727, Validation Accuracy: 0.7113, Loss: 0.3368
Epoch  20 Batch  840/1077 - Train Accuracy: 0.7113, Validation Accuracy: 0.7099, Loss: 0.3264
Epoch  20 Batch  850/1077 - Train Accuracy: 0.6890, Validation Accuracy: 0.7102, Loss: 0.3547
Epoch  20 Batch  860/1077 - Train Accuracy: 0.6856, Validation Accuracy: 0.7166, Loss: 0.3267
Epoch  20 Batch  870/1077 - Train Accuracy: 0.6961, Validation Accuracy: 0.7081, Loss: 0.3452
Epoch  20 Batch  880/1077 - Train Accuracy: 0.7445, Validation Accuracy: 0.6989, Loss: 0.3321
Epoch  20 Batch  890/1077 - Train Accuracy: 0.7779, Validation Accuracy: 0.7021, Loss: 0.3058
Epoch  20 Batch  900/1077 - Train Accuracy: 0.7277, Validation Accuracy: 0.7131, Loss: 0.3367
Epoch  20 Batch  910/1077 - Train Accuracy: 0.6905, Validation Accuracy: 0.7067, Loss: 0.3336
Epoch  20 Batch  920/1077 - Train Accuracy: 0.7152, Validation Accuracy: 0.7049, Loss: 0.3366
Epoch  20 Batch  930/1077 - Train Accuracy: 0.7074, Validation Accuracy: 0.7106, Loss: 0.3215
Epoch  20 Batch  940/1077 - Train Accuracy: 0.7086, Validation Accuracy: 0.7060, Loss: 0.3251
Epoch  20 Batch  950/1077 - Train Accuracy: 0.7054, Validation Accuracy: 0.7067, Loss: 0.3153
Epoch  20 Batch  960/1077 - Train Accuracy: 0.7001, Validation Accuracy: 0.7045, Loss: 0.3234
Epoch  20 Batch  970/1077 - Train Accuracy: 0.7105, Validation Accuracy: 0.7212, Loss: 0.3239
Epoch  20 Batch  980/1077 - Train Accuracy: 0.7066, Validation Accuracy: 0.7138, Loss: 0.3405
Epoch  20 Batch  990/1077 - Train Accuracy: 0.7130, Validation Accuracy: 0.7184, Loss: 0.3511
Epoch  20 Batch 1000/1077 - Train Accuracy: 0.7541, Validation Accuracy: 0.7184, Loss: 0.2997
Epoch  20 Batch 1010/1077 - Train Accuracy: 0.7039, Validation Accuracy: 0.7148, Loss: 0.3413
Epoch  20 Batch 1020/1077 - Train Accuracy: 0.7125, Validation Accuracy: 0.7120, Loss: 0.3316
Epoch  20 Batch 1030/1077 - Train Accuracy: 0.6805, Validation Accuracy: 0.7166, Loss: 0.3444
Epoch  20 Batch 1040/1077 - Train Accuracy: 0.7278, Validation Accuracy: 0.7088, Loss: 0.3458
Epoch  20 Batch 1050/1077 - Train Accuracy: 0.6707, Validation Accuracy: 0.7205, Loss: 0.3317
Epoch  20 Batch 1060/1077 - Train Accuracy: 0.7254, Validation Accuracy: 0.7159, Loss: 0.3128
Epoch  20 Batch 1070/1077 - Train Accuracy: 0.6863, Validation Accuracy: 0.7219, Loss: 0.3385
Epoch  21 Batch   10/1077 - Train Accuracy: 0.7113, Validation Accuracy: 0.7148, Loss: 0.3444
Epoch  21 Batch   20/1077 - Train Accuracy: 0.7016, Validation Accuracy: 0.7195, Loss: 0.3282
Epoch  21 Batch   30/1077 - Train Accuracy: 0.6969, Validation Accuracy: 0.7248, Loss: 0.3331
Epoch  21 Batch   40/1077 - Train Accuracy: 0.7301, Validation Accuracy: 0.7106, Loss: 0.3244
Epoch  21 Batch   50/1077 - Train Accuracy: 0.6902, Validation Accuracy: 0.7188, Loss: 0.3297
Epoch  21 Batch   60/1077 - Train Accuracy: 0.7035, Validation Accuracy: 0.7141, Loss: 0.3239
Epoch  21 Batch   70/1077 - Train Accuracy: 0.7188, Validation Accuracy: 0.7099, Loss: 0.3408
Epoch  21 Batch   80/1077 - Train Accuracy: 0.7215, Validation Accuracy: 0.7124, Loss: 0.3444
Epoch  21 Batch   90/1077 - Train Accuracy: 0.7074, Validation Accuracy: 0.6992, Loss: 0.3423
Epoch  21 Batch  100/1077 - Train Accuracy: 0.7137, Validation Accuracy: 0.7092, Loss: 0.3313
Epoch  21 Batch  110/1077 - Train Accuracy: 0.7250, Validation Accuracy: 0.7116, Loss: 0.3129
Epoch  21 Batch  120/1077 - Train Accuracy: 0.7117, Validation Accuracy: 0.7283, Loss: 0.3389
Epoch  21 Batch  130/1077 - Train Accuracy: 0.7039, Validation Accuracy: 0.7081, Loss: 0.3116
Epoch  21 Batch  140/1077 - Train Accuracy: 0.7056, Validation Accuracy: 0.7067, Loss: 0.3404
Epoch  21 Batch  150/1077 - Train Accuracy: 0.7202, Validation Accuracy: 0.7152, Loss: 0.3237
Epoch  21 Batch  160/1077 - Train Accuracy: 0.7145, Validation Accuracy: 0.7113, Loss: 0.3284
Epoch  21 Batch  170/1077 - Train Accuracy: 0.6816, Validation Accuracy: 0.7141, Loss: 0.3369
Epoch  21 Batch  180/1077 - Train Accuracy: 0.7125, Validation Accuracy: 0.7070, Loss: 0.3412
Epoch  21 Batch  190/1077 - Train Accuracy: 0.7383, Validation Accuracy: 0.7074, Loss: 0.3182
Epoch  21 Batch  200/1077 - Train Accuracy: 0.7152, Validation Accuracy: 0.7184, Loss: 0.3310
Epoch  21 Batch  210/1077 - Train Accuracy: 0.7303, Validation Accuracy: 0.7095, Loss: 0.3206
Epoch  21 Batch  220/1077 - Train Accuracy: 0.7093, Validation Accuracy: 0.7191, Loss: 0.3410
Epoch  21 Batch  230/1077 - Train Accuracy: 0.7173, Validation Accuracy: 0.7202, Loss: 0.3037
Epoch  21 Batch  240/1077 - Train Accuracy: 0.7438, Validation Accuracy: 0.7166, Loss: 0.3146
Epoch  21 Batch  250/1077 - Train Accuracy: 0.6836, Validation Accuracy: 0.7109, Loss: 0.3022
Epoch  21 Batch  260/1077 - Train Accuracy: 0.7165, Validation Accuracy: 0.7116, Loss: 0.3035
Epoch  21 Batch  270/1077 - Train Accuracy: 0.6879, Validation Accuracy: 0.7166, Loss: 0.3360
Epoch  21 Batch  280/1077 - Train Accuracy: 0.7355, Validation Accuracy: 0.7148, Loss: 0.3281
Epoch  21 Batch  290/1077 - Train Accuracy: 0.6934, Validation Accuracy: 0.7177, Loss: 0.3359
Epoch  21 Batch  300/1077 - Train Accuracy: 0.7126, Validation Accuracy: 0.7188, Loss: 0.3222
Epoch  21 Batch  310/1077 - Train Accuracy: 0.6660, Validation Accuracy: 0.7145, Loss: 0.3520
Epoch  21 Batch  320/1077 - Train Accuracy: 0.7602, Validation Accuracy: 0.7141, Loss: 0.3513
Epoch  21 Batch  330/1077 - Train Accuracy: 0.7449, Validation Accuracy: 0.7120, Loss: 0.3263
Epoch  21 Batch  340/1077 - Train Accuracy: 0.7048, Validation Accuracy: 0.7063, Loss: 0.3353
Epoch  21 Batch  350/1077 - Train Accuracy: 0.6937, Validation Accuracy: 0.7095, Loss: 0.3242
Epoch  21 Batch  360/1077 - Train Accuracy: 0.6898, Validation Accuracy: 0.7251, Loss: 0.3284
Epoch  21 Batch  370/1077 - Train Accuracy: 0.7176, Validation Accuracy: 0.7074, Loss: 0.3204
Epoch  21 Batch  380/1077 - Train Accuracy: 0.6941, Validation Accuracy: 0.7053, Loss: 0.3158
Epoch  21 Batch  390/1077 - Train Accuracy: 0.6684, Validation Accuracy: 0.7124, Loss: 0.3366
Epoch  21 Batch  400/1077 - Train Accuracy: 0.7168, Validation Accuracy: 0.7077, Loss: 0.3345
Epoch  21 Batch  410/1077 - Train Accuracy: 0.7118, Validation Accuracy: 0.7113, Loss: 0.3461
Epoch  21 Batch  420/1077 - Train Accuracy: 0.7355, Validation Accuracy: 0.7095, Loss: 0.3141
Epoch  21 Batch  430/1077 - Train Accuracy: 0.6703, Validation Accuracy: 0.7230, Loss: 0.3187
Epoch  21 Batch  440/1077 - Train Accuracy: 0.6738, Validation Accuracy: 0.7241, Loss: 0.3322
Epoch  21 Batch  450/1077 - Train Accuracy: 0.7375, Validation Accuracy: 0.7177, Loss: 0.3149
Epoch  21 Batch  460/1077 - Train Accuracy: 0.7309, Validation Accuracy: 0.7195, Loss: 0.3390
Epoch  21 Batch  470/1077 - Train Accuracy: 0.6978, Validation Accuracy: 0.7156, Loss: 0.3464
Epoch  21 Batch  480/1077 - Train Accuracy: 0.7422, Validation Accuracy: 0.7156, Loss: 0.3320
Epoch  21 Batch  490/1077 - Train Accuracy: 0.7242, Validation Accuracy: 0.7188, Loss: 0.3313
Epoch  21 Batch  500/1077 - Train Accuracy: 0.7195, Validation Accuracy: 0.7227, Loss: 0.3118
Epoch  21 Batch  510/1077 - Train Accuracy: 0.7184, Validation Accuracy: 0.7251, Loss: 0.3159
Epoch  21 Batch  520/1077 - Train Accuracy: 0.7407, Validation Accuracy: 0.7244, Loss: 0.3066
Epoch  21 Batch  530/1077 - Train Accuracy: 0.6922, Validation Accuracy: 0.7262, Loss: 0.3374
Epoch  21 Batch  540/1077 - Train Accuracy: 0.7250, Validation Accuracy: 0.7294, Loss: 0.3101
Epoch  21 Batch  550/1077 - Train Accuracy: 0.7027, Validation Accuracy: 0.7251, Loss: 0.3479
Epoch  21 Batch  560/1077 - Train Accuracy: 0.7066, Validation Accuracy: 0.7180, Loss: 0.3284
Epoch  21 Batch  570/1077 - Train Accuracy: 0.7052, Validation Accuracy: 0.7205, Loss: 0.3505
Epoch  21 Batch  580/1077 - Train Accuracy: 0.7444, Validation Accuracy: 0.7156, Loss: 0.3052
Epoch  21 Batch  590/1077 - Train Accuracy: 0.6797, Validation Accuracy: 0.7259, Loss: 0.3487
Epoch  21 Batch  600/1077 - Train Accuracy: 0.7504, Validation Accuracy: 0.7241, Loss: 0.3075
Epoch  21 Batch  610/1077 - Train Accuracy: 0.6978, Validation Accuracy: 0.7152, Loss: 0.3323
Epoch  21 Batch  620/1077 - Train Accuracy: 0.7035, Validation Accuracy: 0.6996, Loss: 0.3133
Epoch  21 Batch  630/1077 - Train Accuracy: 0.7156, Validation Accuracy: 0.7038, Loss: 0.3237
Epoch  21 Batch  640/1077 - Train Accuracy: 0.7013, Validation Accuracy: 0.7063, Loss: 0.3084
Epoch  21 Batch  650/1077 - Train Accuracy: 0.6898, Validation Accuracy: 0.7262, Loss: 0.3332
Epoch  21 Batch  660/1077 - Train Accuracy: 0.6945, Validation Accuracy: 0.7127, Loss: 0.3367
Epoch  21 Batch  670/1077 - Train Accuracy: 0.7298, Validation Accuracy: 0.7145, Loss: 0.3025
Epoch  21 Batch  680/1077 - Train Accuracy: 0.7240, Validation Accuracy: 0.7056, Loss: 0.3170
Epoch  21 Batch  690/1077 - Train Accuracy: 0.7367, Validation Accuracy: 0.7102, Loss: 0.3282
Epoch  21 Batch  700/1077 - Train Accuracy: 0.6984, Validation Accuracy: 0.7095, Loss: 0.3132
Epoch  21 Batch  710/1077 - Train Accuracy: 0.6738, Validation Accuracy: 0.7216, Loss: 0.3174
Epoch  21 Batch  720/1077 - Train Accuracy: 0.7146, Validation Accuracy: 0.7045, Loss: 0.3386
Epoch  21 Batch  730/1077 - Train Accuracy: 0.6773, Validation Accuracy: 0.7038, Loss: 0.3301
Epoch  21 Batch  740/1077 - Train Accuracy: 0.7234, Validation Accuracy: 0.7141, Loss: 0.3080
Epoch  21 Batch  750/1077 - Train Accuracy: 0.7117, Validation Accuracy: 0.7060, Loss: 0.3148
Epoch  21 Batch  760/1077 - Train Accuracy: 0.7273, Validation Accuracy: 0.7170, Loss: 0.3265
Epoch  21 Batch  770/1077 - Train Accuracy: 0.7418, Validation Accuracy: 0.7163, Loss: 0.3032
Epoch  21 Batch  780/1077 - Train Accuracy: 0.7258, Validation Accuracy: 0.7148, Loss: 0.3465
Epoch  21 Batch  790/1077 - Train Accuracy: 0.6648, Validation Accuracy: 0.7031, Loss: 0.3386
Epoch  21 Batch  800/1077 - Train Accuracy: 0.6852, Validation Accuracy: 0.7141, Loss: 0.3349
Epoch  21 Batch  810/1077 - Train Accuracy: 0.7121, Validation Accuracy: 0.7081, Loss: 0.3035
Epoch  21 Batch  820/1077 - Train Accuracy: 0.6910, Validation Accuracy: 0.7063, Loss: 0.3472
Epoch  21 Batch  830/1077 - Train Accuracy: 0.6797, Validation Accuracy: 0.7045, Loss: 0.3285
Epoch  21 Batch  840/1077 - Train Accuracy: 0.7098, Validation Accuracy: 0.7013, Loss: 0.3150
Epoch  21 Batch  850/1077 - Train Accuracy: 0.6890, Validation Accuracy: 0.7109, Loss: 0.3470
Epoch  21 Batch  860/1077 - Train Accuracy: 0.6827, Validation Accuracy: 0.7045, Loss: 0.3183
Epoch  21 Batch  870/1077 - Train Accuracy: 0.7007, Validation Accuracy: 0.7056, Loss: 0.3347
Epoch  21 Batch  880/1077 - Train Accuracy: 0.7520, Validation Accuracy: 0.6974, Loss: 0.3138
Epoch  21 Batch  890/1077 - Train Accuracy: 0.7794, Validation Accuracy: 0.7031, Loss: 0.3016
Epoch  21 Batch  900/1077 - Train Accuracy: 0.7340, Validation Accuracy: 0.7056, Loss: 0.3345
Epoch  21 Batch  910/1077 - Train Accuracy: 0.6983, Validation Accuracy: 0.7152, Loss: 0.3218
Epoch  21 Batch  920/1077 - Train Accuracy: 0.7102, Validation Accuracy: 0.7184, Loss: 0.3343
Epoch  21 Batch  930/1077 - Train Accuracy: 0.7008, Validation Accuracy: 0.7056, Loss: 0.2992
Epoch  21 Batch  940/1077 - Train Accuracy: 0.7016, Validation Accuracy: 0.7038, Loss: 0.3099
Epoch  21 Batch  950/1077 - Train Accuracy: 0.6972, Validation Accuracy: 0.7102, Loss: 0.2966
Epoch  21 Batch  960/1077 - Train Accuracy: 0.7117, Validation Accuracy: 0.7053, Loss: 0.3128
Epoch  21 Batch  970/1077 - Train Accuracy: 0.7102, Validation Accuracy: 0.7134, Loss: 0.3310
Epoch  21 Batch  980/1077 - Train Accuracy: 0.6969, Validation Accuracy: 0.7031, Loss: 0.3217
Epoch  21 Batch  990/1077 - Train Accuracy: 0.7138, Validation Accuracy: 0.7283, Loss: 0.3463
Epoch  21 Batch 1000/1077 - Train Accuracy: 0.7597, Validation Accuracy: 0.7177, Loss: 0.3030
Epoch  21 Batch 1010/1077 - Train Accuracy: 0.7016, Validation Accuracy: 0.7053, Loss: 0.3338
Epoch  21 Batch 1020/1077 - Train Accuracy: 0.7020, Validation Accuracy: 0.7038, Loss: 0.3077
Epoch  21 Batch 1030/1077 - Train Accuracy: 0.6980, Validation Accuracy: 0.7106, Loss: 0.3324
Epoch  21 Batch 1040/1077 - Train Accuracy: 0.7208, Validation Accuracy: 0.7156, Loss: 0.3252
Epoch  21 Batch 1050/1077 - Train Accuracy: 0.6734, Validation Accuracy: 0.7141, Loss: 0.3178
Epoch  21 Batch 1060/1077 - Train Accuracy: 0.7355, Validation Accuracy: 0.7124, Loss: 0.2974
Epoch  21 Batch 1070/1077 - Train Accuracy: 0.6992, Validation Accuracy: 0.7138, Loss: 0.3242
Epoch  22 Batch   10/1077 - Train Accuracy: 0.7150, Validation Accuracy: 0.7237, Loss: 0.3480
Epoch  22 Batch   20/1077 - Train Accuracy: 0.7113, Validation Accuracy: 0.7184, Loss: 0.3075
Epoch  22 Batch   30/1077 - Train Accuracy: 0.7000, Validation Accuracy: 0.7120, Loss: 0.3221
Epoch  22 Batch   40/1077 - Train Accuracy: 0.7367, Validation Accuracy: 0.7205, Loss: 0.3240
Epoch  22 Batch   50/1077 - Train Accuracy: 0.6949, Validation Accuracy: 0.7184, Loss: 0.3063
Epoch  22 Batch   60/1077 - Train Accuracy: 0.6983, Validation Accuracy: 0.7120, Loss: 0.3105
Epoch  22 Batch   70/1077 - Train Accuracy: 0.7097, Validation Accuracy: 0.7099, Loss: 0.3352
Epoch  22 Batch   80/1077 - Train Accuracy: 0.7164, Validation Accuracy: 0.7109, Loss: 0.3301
Epoch  22 Batch   90/1077 - Train Accuracy: 0.6988, Validation Accuracy: 0.7116, Loss: 0.3451
Epoch  22 Batch  100/1077 - Train Accuracy: 0.7094, Validation Accuracy: 0.7230, Loss: 0.3282
Epoch  22 Batch  110/1077 - Train Accuracy: 0.7352, Validation Accuracy: 0.7188, Loss: 0.3041
Epoch  22 Batch  120/1077 - Train Accuracy: 0.7168, Validation Accuracy: 0.7216, Loss: 0.3351
Epoch  22 Batch  130/1077 - Train Accuracy: 0.7154, Validation Accuracy: 0.7209, Loss: 0.3090
Epoch  22 Batch  140/1077 - Train Accuracy: 0.7002, Validation Accuracy: 0.7177, Loss: 0.3231
Epoch  22 Batch  150/1077 - Train Accuracy: 0.7325, Validation Accuracy: 0.7085, Loss: 0.3161
Epoch  22 Batch  160/1077 - Train Accuracy: 0.7051, Validation Accuracy: 0.7251, Loss: 0.3212
Epoch  22 Batch  170/1077 - Train Accuracy: 0.6723, Validation Accuracy: 0.7152, Loss: 0.3438
Epoch  22 Batch  180/1077 - Train Accuracy: 0.7125, Validation Accuracy: 0.7085, Loss: 0.3182
Epoch  22 Batch  190/1077 - Train Accuracy: 0.7445, Validation Accuracy: 0.7138, Loss: 0.3077
Epoch  22 Batch  200/1077 - Train Accuracy: 0.7137, Validation Accuracy: 0.7156, Loss: 0.3320
Epoch  22 Batch  210/1077 - Train Accuracy: 0.7243, Validation Accuracy: 0.7212, Loss: 0.3222
Epoch  22 Batch  220/1077 - Train Accuracy: 0.7146, Validation Accuracy: 0.7116, Loss: 0.3274
Epoch  22 Batch  230/1077 - Train Accuracy: 0.7132, Validation Accuracy: 0.7177, Loss: 0.2969
Epoch  22 Batch  240/1077 - Train Accuracy: 0.7555, Validation Accuracy: 0.7124, Loss: 0.3010
Epoch  22 Batch  250/1077 - Train Accuracy: 0.6999, Validation Accuracy: 0.7141, Loss: 0.3090
Epoch  22 Batch  260/1077 - Train Accuracy: 0.7266, Validation Accuracy: 0.7148, Loss: 0.2980
Epoch  22 Batch  270/1077 - Train Accuracy: 0.7078, Validation Accuracy: 0.7113, Loss: 0.3359
Epoch  22 Batch  280/1077 - Train Accuracy: 0.7238, Validation Accuracy: 0.7177, Loss: 0.3302
Epoch  22 Batch  290/1077 - Train Accuracy: 0.6902, Validation Accuracy: 0.7010, Loss: 0.3345
Epoch  22 Batch  300/1077 - Train Accuracy: 0.7175, Validation Accuracy: 0.7045, Loss: 0.3134
Epoch  22 Batch  310/1077 - Train Accuracy: 0.6598, Validation Accuracy: 0.7063, Loss: 0.3414
Epoch  22 Batch  320/1077 - Train Accuracy: 0.7602, Validation Accuracy: 0.7056, Loss: 0.3521
Epoch  22 Batch  330/1077 - Train Accuracy: 0.7418, Validation Accuracy: 0.7141, Loss: 0.3073
Epoch  22 Batch  340/1077 - Train Accuracy: 0.7076, Validation Accuracy: 0.7074, Loss: 0.3240
Epoch  22 Batch  350/1077 - Train Accuracy: 0.6816, Validation Accuracy: 0.7056, Loss: 0.3148
Epoch  22 Batch  360/1077 - Train Accuracy: 0.6801, Validation Accuracy: 0.7195, Loss: 0.3142
Epoch  22 Batch  370/1077 - Train Accuracy: 0.7176, Validation Accuracy: 0.7056, Loss: 0.3148
Epoch  22 Batch  380/1077 - Train Accuracy: 0.6996, Validation Accuracy: 0.7095, Loss: 0.3102
Epoch  22 Batch  390/1077 - Train Accuracy: 0.6715, Validation Accuracy: 0.7056, Loss: 0.3366
Epoch  22 Batch  400/1077 - Train Accuracy: 0.7199, Validation Accuracy: 0.7120, Loss: 0.3286
Epoch  22 Batch  410/1077 - Train Accuracy: 0.7101, Validation Accuracy: 0.7106, Loss: 0.3316
Epoch  22 Batch  420/1077 - Train Accuracy: 0.7504, Validation Accuracy: 0.7095, Loss: 0.2956
Epoch  22 Batch  430/1077 - Train Accuracy: 0.6840, Validation Accuracy: 0.7191, Loss: 0.3168
Epoch  22 Batch  440/1077 - Train Accuracy: 0.6832, Validation Accuracy: 0.7134, Loss: 0.3445
Epoch  22 Batch  450/1077 - Train Accuracy: 0.7219, Validation Accuracy: 0.7141, Loss: 0.3096
Epoch  22 Batch  460/1077 - Train Accuracy: 0.7289, Validation Accuracy: 0.7109, Loss: 0.3279
Epoch  22 Batch  470/1077 - Train Accuracy: 0.7105, Validation Accuracy: 0.7081, Loss: 0.3268
Epoch  22 Batch  480/1077 - Train Accuracy: 0.7467, Validation Accuracy: 0.7085, Loss: 0.3238
Epoch  22 Batch  490/1077 - Train Accuracy: 0.7289, Validation Accuracy: 0.7031, Loss: 0.3227
Epoch  22 Batch  500/1077 - Train Accuracy: 0.7387, Validation Accuracy: 0.7017, Loss: 0.3098
Epoch  22 Batch  510/1077 - Train Accuracy: 0.7359, Validation Accuracy: 0.7145, Loss: 0.3039
Epoch  22 Batch  520/1077 - Train Accuracy: 0.7485, Validation Accuracy: 0.7060, Loss: 0.2887
Epoch  22 Batch  530/1077 - Train Accuracy: 0.6844, Validation Accuracy: 0.7191, Loss: 0.3227
Epoch  22 Batch  540/1077 - Train Accuracy: 0.7211, Validation Accuracy: 0.7227, Loss: 0.2970
Epoch  22 Batch  550/1077 - Train Accuracy: 0.7098, Validation Accuracy: 0.7166, Loss: 0.3318
Epoch  22 Batch  560/1077 - Train Accuracy: 0.7148, Validation Accuracy: 0.7177, Loss: 0.3143
Epoch  22 Batch  570/1077 - Train Accuracy: 0.7155, Validation Accuracy: 0.7124, Loss: 0.3503
Epoch  22 Batch  580/1077 - Train Accuracy: 0.7608, Validation Accuracy: 0.7159, Loss: 0.2898
Epoch  22 Batch  590/1077 - Train Accuracy: 0.6817, Validation Accuracy: 0.7106, Loss: 0.3530
Epoch  22 Batch  600/1077 - Train Accuracy: 0.7440, Validation Accuracy: 0.7134, Loss: 0.3000
Epoch  22 Batch  610/1077 - Train Accuracy: 0.7044, Validation Accuracy: 0.7127, Loss: 0.3370
Epoch  22 Batch  620/1077 - Train Accuracy: 0.7145, Validation Accuracy: 0.7127, Loss: 0.3119
Epoch  22 Batch  630/1077 - Train Accuracy: 0.7055, Validation Accuracy: 0.7092, Loss: 0.3172
Epoch  22 Batch  640/1077 - Train Accuracy: 0.7132, Validation Accuracy: 0.7145, Loss: 0.3001
Epoch  22 Batch  650/1077 - Train Accuracy: 0.6961, Validation Accuracy: 0.7219, Loss: 0.3226
Epoch  22 Batch  660/1077 - Train Accuracy: 0.7031, Validation Accuracy: 0.7237, Loss: 0.3328
Epoch  22 Batch  670/1077 - Train Accuracy: 0.7322, Validation Accuracy: 0.7230, Loss: 0.3001
Epoch  22 Batch  680/1077 - Train Accuracy: 0.7188, Validation Accuracy: 0.6992, Loss: 0.3264
Epoch  22 Batch  690/1077 - Train Accuracy: 0.7391, Validation Accuracy: 0.7081, Loss: 0.3184
Epoch  22 Batch  700/1077 - Train Accuracy: 0.7137, Validation Accuracy: 0.7035, Loss: 0.3077
Epoch  22 Batch  710/1077 - Train Accuracy: 0.6363, Validation Accuracy: 0.7109, Loss: 0.3224
Epoch  22 Batch  720/1077 - Train Accuracy: 0.7150, Validation Accuracy: 0.6992, Loss: 0.3426
Epoch  22 Batch  730/1077 - Train Accuracy: 0.6988, Validation Accuracy: 0.7056, Loss: 0.3289
Epoch  22 Batch  740/1077 - Train Accuracy: 0.7273, Validation Accuracy: 0.7223, Loss: 0.3106
Epoch  22 Batch  750/1077 - Train Accuracy: 0.7434, Validation Accuracy: 0.7195, Loss: 0.3132
Epoch  22 Batch  760/1077 - Train Accuracy: 0.7363, Validation Accuracy: 0.7141, Loss: 0.3134
Epoch  22 Batch  770/1077 - Train Accuracy: 0.7478, Validation Accuracy: 0.7131, Loss: 0.3057
Epoch  22 Batch  780/1077 - Train Accuracy: 0.7234, Validation Accuracy: 0.7212, Loss: 0.3343
Epoch  22 Batch  790/1077 - Train Accuracy: 0.6695, Validation Accuracy: 0.7109, Loss: 0.3486
Epoch  22 Batch  800/1077 - Train Accuracy: 0.6949, Validation Accuracy: 0.7106, Loss: 0.3203
Epoch  22 Batch  810/1077 - Train Accuracy: 0.7009, Validation Accuracy: 0.7099, Loss: 0.2932
Epoch  22 Batch  820/1077 - Train Accuracy: 0.7012, Validation Accuracy: 0.7177, Loss: 0.3337
Epoch  22 Batch  830/1077 - Train Accuracy: 0.6828, Validation Accuracy: 0.7085, Loss: 0.3198
Epoch  22 Batch  840/1077 - Train Accuracy: 0.7039, Validation Accuracy: 0.7038, Loss: 0.3166
Epoch  22 Batch  850/1077 - Train Accuracy: 0.6912, Validation Accuracy: 0.7134, Loss: 0.3403
Epoch  22 Batch  860/1077 - Train Accuracy: 0.6871, Validation Accuracy: 0.7102, Loss: 0.3154
Epoch  22 Batch  870/1077 - Train Accuracy: 0.7002, Validation Accuracy: 0.7010, Loss: 0.3283
Epoch  22 Batch  880/1077 - Train Accuracy: 0.7504, Validation Accuracy: 0.7031, Loss: 0.3231
Epoch  22 Batch  890/1077 - Train Accuracy: 0.7831, Validation Accuracy: 0.7045, Loss: 0.2999
Epoch  22 Batch  900/1077 - Train Accuracy: 0.7375, Validation Accuracy: 0.7138, Loss: 0.3227
Epoch  22 Batch  910/1077 - Train Accuracy: 0.7028, Validation Accuracy: 0.7127, Loss: 0.3147
Epoch  22 Batch  920/1077 - Train Accuracy: 0.7016, Validation Accuracy: 0.7262, Loss: 0.3232
Epoch  22 Batch  930/1077 - Train Accuracy: 0.7063, Validation Accuracy: 0.7209, Loss: 0.3020
Epoch  22 Batch  940/1077 - Train Accuracy: 0.7281, Validation Accuracy: 0.7088, Loss: 0.3153
Epoch  22 Batch  950/1077 - Train Accuracy: 0.6975, Validation Accuracy: 0.7127, Loss: 0.2976
Epoch  22 Batch  960/1077 - Train Accuracy: 0.7150, Validation Accuracy: 0.7106, Loss: 0.3078
Epoch  22 Batch  970/1077 - Train Accuracy: 0.7098, Validation Accuracy: 0.7259, Loss: 0.3240
Epoch  22 Batch  980/1077 - Train Accuracy: 0.7113, Validation Accuracy: 0.7280, Loss: 0.3164
Epoch  22 Batch  990/1077 - Train Accuracy: 0.7089, Validation Accuracy: 0.7212, Loss: 0.3364
Epoch  22 Batch 1000/1077 - Train Accuracy: 0.7626, Validation Accuracy: 0.7120, Loss: 0.2878
Epoch  22 Batch 1010/1077 - Train Accuracy: 0.7008, Validation Accuracy: 0.7159, Loss: 0.3230
Epoch  22 Batch 1020/1077 - Train Accuracy: 0.7094, Validation Accuracy: 0.7212, Loss: 0.3092
Epoch  22 Batch 1030/1077 - Train Accuracy: 0.7047, Validation Accuracy: 0.7219, Loss: 0.3247
Epoch  22 Batch 1040/1077 - Train Accuracy: 0.7229, Validation Accuracy: 0.7351, Loss: 0.3377
Epoch  22 Batch 1050/1077 - Train Accuracy: 0.6652, Validation Accuracy: 0.7244, Loss: 0.3130
Epoch  22 Batch 1060/1077 - Train Accuracy: 0.7320, Validation Accuracy: 0.7134, Loss: 0.2876
Epoch  22 Batch 1070/1077 - Train Accuracy: 0.6926, Validation Accuracy: 0.7212, Loss: 0.3236
Epoch  23 Batch   10/1077 - Train Accuracy: 0.7183, Validation Accuracy: 0.7188, Loss: 0.3224
Epoch  23 Batch   20/1077 - Train Accuracy: 0.7055, Validation Accuracy: 0.7223, Loss: 0.3149
Epoch  23 Batch   30/1077 - Train Accuracy: 0.7113, Validation Accuracy: 0.7234, Loss: 0.3063
Epoch  23 Batch   40/1077 - Train Accuracy: 0.7387, Validation Accuracy: 0.7166, Loss: 0.3092
Epoch  23 Batch   50/1077 - Train Accuracy: 0.6996, Validation Accuracy: 0.7290, Loss: 0.3061
Epoch  23 Batch   60/1077 - Train Accuracy: 0.7121, Validation Accuracy: 0.7152, Loss: 0.3031
Epoch  23 Batch   70/1077 - Train Accuracy: 0.7192, Validation Accuracy: 0.7152, Loss: 0.3352
Epoch  23 Batch   80/1077 - Train Accuracy: 0.7258, Validation Accuracy: 0.7180, Loss: 0.3137
Epoch  23 Batch   90/1077 - Train Accuracy: 0.6988, Validation Accuracy: 0.7241, Loss: 0.3384
Epoch  23 Batch  100/1077 - Train Accuracy: 0.7180, Validation Accuracy: 0.7340, Loss: 0.3089
Epoch  23 Batch  110/1077 - Train Accuracy: 0.7316, Validation Accuracy: 0.7262, Loss: 0.2926
Epoch  23 Batch  120/1077 - Train Accuracy: 0.7230, Validation Accuracy: 0.7369, Loss: 0.3304
Epoch  23 Batch  130/1077 - Train Accuracy: 0.7065, Validation Accuracy: 0.7223, Loss: 0.3045
Epoch  23 Batch  140/1077 - Train Accuracy: 0.7097, Validation Accuracy: 0.7237, Loss: 0.3212
Epoch  23 Batch  150/1077 - Train Accuracy: 0.7273, Validation Accuracy: 0.7156, Loss: 0.3196
Epoch  23 Batch  160/1077 - Train Accuracy: 0.7176, Validation Accuracy: 0.7262, Loss: 0.3223
Epoch  23 Batch  170/1077 - Train Accuracy: 0.6711, Validation Accuracy: 0.7092, Loss: 0.3374
Epoch  23 Batch  180/1077 - Train Accuracy: 0.7137, Validation Accuracy: 0.7074, Loss: 0.3129
Epoch  23 Batch  190/1077 - Train Accuracy: 0.7363, Validation Accuracy: 0.7156, Loss: 0.3218
Epoch  23 Batch  200/1077 - Train Accuracy: 0.7160, Validation Accuracy: 0.7386, Loss: 0.3202
Epoch  23 Batch  210/1077 - Train Accuracy: 0.7340, Validation Accuracy: 0.7319, Loss: 0.3196
Epoch  23 Batch  220/1077 - Train Accuracy: 0.7183, Validation Accuracy: 0.7227, Loss: 0.3312
Epoch  23 Batch  230/1077 - Train Accuracy: 0.7173, Validation Accuracy: 0.7163, Loss: 0.2968
Epoch  23 Batch  240/1077 - Train Accuracy: 0.7582, Validation Accuracy: 0.7134, Loss: 0.2941
Epoch  23 Batch  250/1077 - Train Accuracy: 0.7006, Validation Accuracy: 0.7035, Loss: 0.2921
Epoch  23 Batch  260/1077 - Train Accuracy: 0.7374, Validation Accuracy: 0.7358, Loss: 0.2950
Epoch  23 Batch  270/1077 - Train Accuracy: 0.7035, Validation Accuracy: 0.7223, Loss: 0.3338
Epoch  23 Batch  280/1077 - Train Accuracy: 0.7215, Validation Accuracy: 0.7099, Loss: 0.3154
Epoch  23 Batch  290/1077 - Train Accuracy: 0.7043, Validation Accuracy: 0.7205, Loss: 0.3232
Epoch  23 Batch  300/1077 - Train Accuracy: 0.7373, Validation Accuracy: 0.7127, Loss: 0.2999
Epoch  23 Batch  310/1077 - Train Accuracy: 0.6754, Validation Accuracy: 0.7113, Loss: 0.3303
Epoch  23 Batch  320/1077 - Train Accuracy: 0.7602, Validation Accuracy: 0.7077, Loss: 0.3433
Epoch  23 Batch  330/1077 - Train Accuracy: 0.7395, Validation Accuracy: 0.7017, Loss: 0.3114
Epoch  23 Batch  340/1077 - Train Accuracy: 0.7179, Validation Accuracy: 0.7045, Loss: 0.3158
Epoch  23 Batch  350/1077 - Train Accuracy: 0.6871, Validation Accuracy: 0.7120, Loss: 0.3050
Epoch  23 Batch  360/1077 - Train Accuracy: 0.6969, Validation Accuracy: 0.7333, Loss: 0.3154
Epoch  23 Batch  370/1077 - Train Accuracy: 0.7068, Validation Accuracy: 0.7290, Loss: 0.3126
Epoch  23 Batch  380/1077 - Train Accuracy: 0.6961, Validation Accuracy: 0.7212, Loss: 0.2910
Epoch  23 Batch  390/1077 - Train Accuracy: 0.6789, Validation Accuracy: 0.7134, Loss: 0.3336
Epoch  23 Batch  400/1077 - Train Accuracy: 0.7277, Validation Accuracy: 0.7223, Loss: 0.3205
Epoch  23 Batch  410/1077 - Train Accuracy: 0.7167, Validation Accuracy: 0.7188, Loss: 0.3229
Epoch  23 Batch  420/1077 - Train Accuracy: 0.7555, Validation Accuracy: 0.7099, Loss: 0.2927
Epoch  23 Batch  430/1077 - Train Accuracy: 0.6957, Validation Accuracy: 0.7177, Loss: 0.3138
Epoch  23 Batch  440/1077 - Train Accuracy: 0.6742, Validation Accuracy: 0.7237, Loss: 0.3218
Epoch  23 Batch  450/1077 - Train Accuracy: 0.7434, Validation Accuracy: 0.7109, Loss: 0.3069
Epoch  23 Batch  460/1077 - Train Accuracy: 0.7348, Validation Accuracy: 0.7159, Loss: 0.3202
Epoch  23 Batch  470/1077 - Train Accuracy: 0.7241, Validation Accuracy: 0.7131, Loss: 0.3356
Epoch  23 Batch  480/1077 - Train Accuracy: 0.7414, Validation Accuracy: 0.7109, Loss: 0.3192
Epoch  23 Batch  490/1077 - Train Accuracy: 0.7332, Validation Accuracy: 0.7099, Loss: 0.3132
Epoch  23 Batch  500/1077 - Train Accuracy: 0.7453, Validation Accuracy: 0.7159, Loss: 0.3013
Epoch  23 Batch  510/1077 - Train Accuracy: 0.7273, Validation Accuracy: 0.7237, Loss: 0.2981
Epoch  23 Batch  520/1077 - Train Accuracy: 0.7530, Validation Accuracy: 0.7276, Loss: 0.2876
Epoch  23 Batch  530/1077 - Train Accuracy: 0.6867, Validation Accuracy: 0.7290, Loss: 0.3221
Epoch  23 Batch  540/1077 - Train Accuracy: 0.7316, Validation Accuracy: 0.7244, Loss: 0.2971
Epoch  23 Batch  550/1077 - Train Accuracy: 0.7141, Validation Accuracy: 0.7298, Loss: 0.3278
Epoch  23 Batch  560/1077 - Train Accuracy: 0.7262, Validation Accuracy: 0.7287, Loss: 0.3117
Epoch  23 Batch  570/1077 - Train Accuracy: 0.7274, Validation Accuracy: 0.7198, Loss: 0.3410
Epoch  23 Batch  580/1077 - Train Accuracy: 0.7586, Validation Accuracy: 0.7280, Loss: 0.2867
Epoch  23 Batch  590/1077 - Train Accuracy: 0.6875, Validation Accuracy: 0.7319, Loss: 0.3406
Epoch  23 Batch  600/1077 - Train Accuracy: 0.7630, Validation Accuracy: 0.7223, Loss: 0.2965
Epoch  23 Batch  610/1077 - Train Accuracy: 0.7056, Validation Accuracy: 0.7198, Loss: 0.3258
Epoch  23 Batch  620/1077 - Train Accuracy: 0.7055, Validation Accuracy: 0.7227, Loss: 0.3250
Epoch  23 Batch  630/1077 - Train Accuracy: 0.7207, Validation Accuracy: 0.7195, Loss: 0.3050
Epoch  23 Batch  640/1077 - Train Accuracy: 0.7303, Validation Accuracy: 0.7227, Loss: 0.2979
Epoch  23 Batch  650/1077 - Train Accuracy: 0.6988, Validation Accuracy: 0.7180, Loss: 0.3242
Epoch  23 Batch  660/1077 - Train Accuracy: 0.7230, Validation Accuracy: 0.7152, Loss: 0.3232
Epoch  23 Batch  670/1077 - Train Accuracy: 0.7393, Validation Accuracy: 0.7280, Loss: 0.2908
Epoch  23 Batch  680/1077 - Train Accuracy: 0.7377, Validation Accuracy: 0.7120, Loss: 0.3104
Epoch  23 Batch  690/1077 - Train Accuracy: 0.7305, Validation Accuracy: 0.7230, Loss: 0.3127
Epoch  23 Batch  700/1077 - Train Accuracy: 0.6930, Validation Accuracy: 0.7145, Loss: 0.2929
Epoch  23 Batch  710/1077 - Train Accuracy: 0.6660, Validation Accuracy: 0.7287, Loss: 0.3265
Epoch  23 Batch  720/1077 - Train Accuracy: 0.7327, Validation Accuracy: 0.7095, Loss: 0.3338
Epoch  23 Batch  730/1077 - Train Accuracy: 0.6891, Validation Accuracy: 0.7230, Loss: 0.3102
Epoch  23 Batch  740/1077 - Train Accuracy: 0.7273, Validation Accuracy: 0.7127, Loss: 0.3111
Epoch  23 Batch  750/1077 - Train Accuracy: 0.7242, Validation Accuracy: 0.7230, Loss: 0.3095
Epoch  23 Batch  760/1077 - Train Accuracy: 0.7344, Validation Accuracy: 0.7280, Loss: 0.3152
Epoch  23 Batch  770/1077 - Train Accuracy: 0.7649, Validation Accuracy: 0.7209, Loss: 0.2919
Epoch  23 Batch  780/1077 - Train Accuracy: 0.7336, Validation Accuracy: 0.7180, Loss: 0.3293
Epoch  23 Batch  790/1077 - Train Accuracy: 0.6609, Validation Accuracy: 0.7152, Loss: 0.3318
Epoch  23 Batch  800/1077 - Train Accuracy: 0.6941, Validation Accuracy: 0.7227, Loss: 0.3097
Epoch  23 Batch  810/1077 - Train Accuracy: 0.7024, Validation Accuracy: 0.7106, Loss: 0.2965
Epoch  23 Batch  820/1077 - Train Accuracy: 0.6984, Validation Accuracy: 0.7166, Loss: 0.3273
Epoch  23 Batch  830/1077 - Train Accuracy: 0.6898, Validation Accuracy: 0.7219, Loss: 0.3285
Epoch  23 Batch  840/1077 - Train Accuracy: 0.7293, Validation Accuracy: 0.7152, Loss: 0.3061
Epoch  23 Batch  850/1077 - Train Accuracy: 0.6912, Validation Accuracy: 0.7113, Loss: 0.3397
Epoch  23 Batch  860/1077 - Train Accuracy: 0.6990, Validation Accuracy: 0.7216, Loss: 0.3123
Epoch  23 Batch  870/1077 - Train Accuracy: 0.6994, Validation Accuracy: 0.7202, Loss: 0.3203
Epoch  23 Batch  880/1077 - Train Accuracy: 0.7539, Validation Accuracy: 0.7184, Loss: 0.3047
Epoch  23 Batch  890/1077 - Train Accuracy: 0.7861, Validation Accuracy: 0.7202, Loss: 0.2966
Epoch  23 Batch  900/1077 - Train Accuracy: 0.7301, Validation Accuracy: 0.7159, Loss: 0.3096
Epoch  23 Batch  910/1077 - Train Accuracy: 0.7057, Validation Accuracy: 0.7276, Loss: 0.2994
Epoch  23 Batch  920/1077 - Train Accuracy: 0.7215, Validation Accuracy: 0.7308, Loss: 0.3253
Epoch  23 Batch  930/1077 - Train Accuracy: 0.7223, Validation Accuracy: 0.7166, Loss: 0.2988
Epoch  23 Batch  940/1077 - Train Accuracy: 0.7328, Validation Accuracy: 0.7113, Loss: 0.2995
Epoch  23 Batch  950/1077 - Train Accuracy: 0.6927, Validation Accuracy: 0.7092, Loss: 0.2885
Epoch  23 Batch  960/1077 - Train Accuracy: 0.7188, Validation Accuracy: 0.7173, Loss: 0.3021
Epoch  23 Batch  970/1077 - Train Accuracy: 0.7320, Validation Accuracy: 0.7248, Loss: 0.3215
Epoch  23 Batch  980/1077 - Train Accuracy: 0.7227, Validation Accuracy: 0.7337, Loss: 0.3152
Epoch  23 Batch  990/1077 - Train Accuracy: 0.7039, Validation Accuracy: 0.7269, Loss: 0.3328
Epoch  23 Batch 1000/1077 - Train Accuracy: 0.7749, Validation Accuracy: 0.7266, Loss: 0.2965
Epoch  23 Batch 1010/1077 - Train Accuracy: 0.7188, Validation Accuracy: 0.7198, Loss: 0.3084
Epoch  23 Batch 1020/1077 - Train Accuracy: 0.7230, Validation Accuracy: 0.7127, Loss: 0.3030
Epoch  23 Batch 1030/1077 - Train Accuracy: 0.7023, Validation Accuracy: 0.7173, Loss: 0.3266
Epoch  23 Batch 1040/1077 - Train Accuracy: 0.7393, Validation Accuracy: 0.7269, Loss: 0.3201
Epoch  23 Batch 1050/1077 - Train Accuracy: 0.6676, Validation Accuracy: 0.7244, Loss: 0.3076
Epoch  23 Batch 1060/1077 - Train Accuracy: 0.7410, Validation Accuracy: 0.7280, Loss: 0.2870
Epoch  23 Batch 1070/1077 - Train Accuracy: 0.7023, Validation Accuracy: 0.7305, Loss: 0.3175
Epoch  24 Batch   10/1077 - Train Accuracy: 0.7192, Validation Accuracy: 0.7276, Loss: 0.3221
Epoch  24 Batch   20/1077 - Train Accuracy: 0.7172, Validation Accuracy: 0.7266, Loss: 0.2976
Epoch  24 Batch   30/1077 - Train Accuracy: 0.7152, Validation Accuracy: 0.7209, Loss: 0.3089
Epoch  24 Batch   40/1077 - Train Accuracy: 0.7410, Validation Accuracy: 0.7290, Loss: 0.3093
Epoch  24 Batch   50/1077 - Train Accuracy: 0.7199, Validation Accuracy: 0.7326, Loss: 0.3145
Epoch  24 Batch   60/1077 - Train Accuracy: 0.7124, Validation Accuracy: 0.7173, Loss: 0.2993
Epoch  24 Batch   70/1077 - Train Accuracy: 0.7282, Validation Accuracy: 0.7163, Loss: 0.3275
Epoch  24 Batch   80/1077 - Train Accuracy: 0.7242, Validation Accuracy: 0.7259, Loss: 0.3151
Epoch  24 Batch   90/1077 - Train Accuracy: 0.7086, Validation Accuracy: 0.7276, Loss: 0.3199
Epoch  24 Batch  100/1077 - Train Accuracy: 0.7242, Validation Accuracy: 0.7301, Loss: 0.2981
Epoch  24 Batch  110/1077 - Train Accuracy: 0.7418, Validation Accuracy: 0.7333, Loss: 0.2998
Epoch  24 Batch  120/1077 - Train Accuracy: 0.7254, Validation Accuracy: 0.7379, Loss: 0.3309
Epoch  24 Batch  130/1077 - Train Accuracy: 0.7128, Validation Accuracy: 0.7362, Loss: 0.2954
Epoch  24 Batch  140/1077 - Train Accuracy: 0.7196, Validation Accuracy: 0.7173, Loss: 0.3231
Epoch  24 Batch  150/1077 - Train Accuracy: 0.7295, Validation Accuracy: 0.7266, Loss: 0.2969
Epoch  24 Batch  160/1077 - Train Accuracy: 0.7254, Validation Accuracy: 0.7273, Loss: 0.3113
Epoch  24 Batch  170/1077 - Train Accuracy: 0.6727, Validation Accuracy: 0.7241, Loss: 0.3134
Epoch  24 Batch  180/1077 - Train Accuracy: 0.7188, Validation Accuracy: 0.7266, Loss: 0.3064
Epoch  24 Batch  190/1077 - Train Accuracy: 0.7543, Validation Accuracy: 0.7301, Loss: 0.3130
Epoch  24 Batch  200/1077 - Train Accuracy: 0.7191, Validation Accuracy: 0.7298, Loss: 0.3159
Epoch  24 Batch  210/1077 - Train Accuracy: 0.7541, Validation Accuracy: 0.7365, Loss: 0.2952
Epoch  24 Batch  220/1077 - Train Accuracy: 0.7290, Validation Accuracy: 0.7262, Loss: 0.3180
Epoch  24 Batch  230/1077 - Train Accuracy: 0.7188, Validation Accuracy: 0.7180, Loss: 0.3014
Epoch  24 Batch  240/1077 - Train Accuracy: 0.7652, Validation Accuracy: 0.7294, Loss: 0.2954
Epoch  24 Batch  250/1077 - Train Accuracy: 0.7028, Validation Accuracy: 0.7191, Loss: 0.2961
Epoch  24 Batch  260/1077 - Train Accuracy: 0.7422, Validation Accuracy: 0.7234, Loss: 0.2903
Epoch  24 Batch  270/1077 - Train Accuracy: 0.7109, Validation Accuracy: 0.7326, Loss: 0.3153
Epoch  24 Batch  280/1077 - Train Accuracy: 0.7258, Validation Accuracy: 0.7202, Loss: 0.3154
Epoch  24 Batch  290/1077 - Train Accuracy: 0.6949, Validation Accuracy: 0.7166, Loss: 0.3162
Epoch  24 Batch  300/1077 - Train Accuracy: 0.7319, Validation Accuracy: 0.7141, Loss: 0.3074
Epoch  24 Batch  310/1077 - Train Accuracy: 0.6777, Validation Accuracy: 0.7163, Loss: 0.3369
Epoch  24 Batch  320/1077 - Train Accuracy: 0.7648, Validation Accuracy: 0.7188, Loss: 0.3279
Epoch  24 Batch  330/1077 - Train Accuracy: 0.7418, Validation Accuracy: 0.7077, Loss: 0.2968
Epoch  24 Batch  340/1077 - Train Accuracy: 0.7150, Validation Accuracy: 0.7163, Loss: 0.3014
Epoch  24 Batch  350/1077 - Train Accuracy: 0.6965, Validation Accuracy: 0.7301, Loss: 0.3020
Epoch  24 Batch  360/1077 - Train Accuracy: 0.7000, Validation Accuracy: 0.7255, Loss: 0.3105
Epoch  24 Batch  370/1077 - Train Accuracy: 0.7102, Validation Accuracy: 0.7219, Loss: 0.3104
Epoch  24 Batch  380/1077 - Train Accuracy: 0.7125, Validation Accuracy: 0.7173, Loss: 0.2981
Epoch  24 Batch  390/1077 - Train Accuracy: 0.6793, Validation Accuracy: 0.7262, Loss: 0.3308
Epoch  24 Batch  400/1077 - Train Accuracy: 0.7242, Validation Accuracy: 0.7230, Loss: 0.3169
Epoch  24 Batch  410/1077 - Train Accuracy: 0.7266, Validation Accuracy: 0.7305, Loss: 0.3218
Epoch  24 Batch  420/1077 - Train Accuracy: 0.7438, Validation Accuracy: 0.7173, Loss: 0.2851
Epoch  24 Batch  430/1077 - Train Accuracy: 0.6816, Validation Accuracy: 0.7287, Loss: 0.3057
Epoch  24 Batch  440/1077 - Train Accuracy: 0.6828, Validation Accuracy: 0.7209, Loss: 0.3253
Epoch  24 Batch  450/1077 - Train Accuracy: 0.7461, Validation Accuracy: 0.7120, Loss: 0.3001
Epoch  24 Batch  460/1077 - Train Accuracy: 0.7473, Validation Accuracy: 0.7156, Loss: 0.3260
Epoch  24 Batch  470/1077 - Train Accuracy: 0.7134, Validation Accuracy: 0.7219, Loss: 0.3256
Epoch  24 Batch  480/1077 - Train Accuracy: 0.7603, Validation Accuracy: 0.7180, Loss: 0.3165
Epoch  24 Batch  490/1077 - Train Accuracy: 0.7359, Validation Accuracy: 0.7227, Loss: 0.2979
Epoch  24 Batch  500/1077 - Train Accuracy: 0.7516, Validation Accuracy: 0.7401, Loss: 0.2994
Epoch  24 Batch  510/1077 - Train Accuracy: 0.7246, Validation Accuracy: 0.7276, Loss: 0.3153
Epoch  24 Batch  520/1077 - Train Accuracy: 0.7671, Validation Accuracy: 0.7173, Loss: 0.2897
Epoch  24 Batch  530/1077 - Train Accuracy: 0.6988, Validation Accuracy: 0.7173, Loss: 0.3256
Epoch  24 Batch  540/1077 - Train Accuracy: 0.7293, Validation Accuracy: 0.7337, Loss: 0.2996
Epoch  24 Batch  550/1077 - Train Accuracy: 0.7082, Validation Accuracy: 0.7241, Loss: 0.3255
Epoch  24 Batch  560/1077 - Train Accuracy: 0.7324, Validation Accuracy: 0.7177, Loss: 0.3067
Epoch  24 Batch  570/1077 - Train Accuracy: 0.7118, Validation Accuracy: 0.7219, Loss: 0.3355
Epoch  24 Batch  580/1077 - Train Accuracy: 0.7552, Validation Accuracy: 0.7365, Loss: 0.2886
Epoch  24 Batch  590/1077 - Train Accuracy: 0.6970, Validation Accuracy: 0.7212, Loss: 0.3473
Epoch  24 Batch  600/1077 - Train Accuracy: 0.7560, Validation Accuracy: 0.7369, Loss: 0.2860
Epoch  24 Batch  610/1077 - Train Accuracy: 0.7101, Validation Accuracy: 0.7244, Loss: 0.3135
Epoch  24 Batch  620/1077 - Train Accuracy: 0.7215, Validation Accuracy: 0.7269, Loss: 0.2886
Epoch  24 Batch  630/1077 - Train Accuracy: 0.7262, Validation Accuracy: 0.7298, Loss: 0.3040
Epoch  24 Batch  640/1077 - Train Accuracy: 0.7199, Validation Accuracy: 0.7209, Loss: 0.2897
Epoch  24 Batch  650/1077 - Train Accuracy: 0.7066, Validation Accuracy: 0.7290, Loss: 0.3040
Epoch  24 Batch  660/1077 - Train Accuracy: 0.7410, Validation Accuracy: 0.7269, Loss: 0.3079
Epoch  24 Batch  670/1077 - Train Accuracy: 0.7358, Validation Accuracy: 0.7372, Loss: 0.2689
Epoch  24 Batch  680/1077 - Train Accuracy: 0.7351, Validation Accuracy: 0.7248, Loss: 0.3237
Epoch  24 Batch  690/1077 - Train Accuracy: 0.7379, Validation Accuracy: 0.7273, Loss: 0.3044
Epoch  24 Batch  700/1077 - Train Accuracy: 0.7207, Validation Accuracy: 0.7244, Loss: 0.3043
Epoch  24 Batch  710/1077 - Train Accuracy: 0.6469, Validation Accuracy: 0.7212, Loss: 0.2999
Epoch  24 Batch  720/1077 - Train Accuracy: 0.7533, Validation Accuracy: 0.7283, Loss: 0.3405
Epoch  24 Batch  730/1077 - Train Accuracy: 0.7027, Validation Accuracy: 0.7156, Loss: 0.3148
Epoch  24 Batch  740/1077 - Train Accuracy: 0.7391, Validation Accuracy: 0.7230, Loss: 0.3006
Epoch  24 Batch  750/1077 - Train Accuracy: 0.7590, Validation Accuracy: 0.7166, Loss: 0.3117
Epoch  24 Batch  760/1077 - Train Accuracy: 0.7445, Validation Accuracy: 0.7237, Loss: 0.3047
Epoch  24 Batch  770/1077 - Train Accuracy: 0.7519, Validation Accuracy: 0.7134, Loss: 0.2817
Epoch  24 Batch  780/1077 - Train Accuracy: 0.7188, Validation Accuracy: 0.7116, Loss: 0.3175
Epoch  24 Batch  790/1077 - Train Accuracy: 0.6715, Validation Accuracy: 0.7205, Loss: 0.3234
Epoch  24 Batch  800/1077 - Train Accuracy: 0.6961, Validation Accuracy: 0.7319, Loss: 0.3033
Epoch  24 Batch  810/1077 - Train Accuracy: 0.7254, Validation Accuracy: 0.7177, Loss: 0.2934
Epoch  24 Batch  820/1077 - Train Accuracy: 0.6992, Validation Accuracy: 0.7269, Loss: 0.3317
Epoch  24 Batch  830/1077 - Train Accuracy: 0.6957, Validation Accuracy: 0.7219, Loss: 0.3084
Epoch  24 Batch  840/1077 - Train Accuracy: 0.7410, Validation Accuracy: 0.7127, Loss: 0.3017
Epoch  24 Batch  850/1077 - Train Accuracy: 0.6949, Validation Accuracy: 0.7280, Loss: 0.3445
Epoch  24 Batch  860/1077 - Train Accuracy: 0.6987, Validation Accuracy: 0.7301, Loss: 0.3060
Epoch  24 Batch  870/1077 - Train Accuracy: 0.7101, Validation Accuracy: 0.7237, Loss: 0.3267
Epoch  24 Batch  880/1077 - Train Accuracy: 0.7645, Validation Accuracy: 0.7116, Loss: 0.3043
Epoch  24 Batch  890/1077 - Train Accuracy: 0.7801, Validation Accuracy: 0.7131, Loss: 0.2869
Epoch  24 Batch  900/1077 - Train Accuracy: 0.7344, Validation Accuracy: 0.7177, Loss: 0.3155
Epoch  24 Batch  910/1077 - Train Accuracy: 0.7150, Validation Accuracy: 0.7230, Loss: 0.3060
Epoch  24 Batch  920/1077 - Train Accuracy: 0.7152, Validation Accuracy: 0.7379, Loss: 0.3100
Epoch  24 Batch  930/1077 - Train Accuracy: 0.7121, Validation Accuracy: 0.7191, Loss: 0.2887
Epoch  24 Batch  940/1077 - Train Accuracy: 0.7277, Validation Accuracy: 0.7088, Loss: 0.3042
Epoch  24 Batch  950/1077 - Train Accuracy: 0.7020, Validation Accuracy: 0.7290, Loss: 0.2889
Epoch  24 Batch  960/1077 - Train Accuracy: 0.7180, Validation Accuracy: 0.7205, Loss: 0.2988
Epoch  24 Batch  970/1077 - Train Accuracy: 0.7363, Validation Accuracy: 0.7354, Loss: 0.3074
Epoch  24 Batch  980/1077 - Train Accuracy: 0.7137, Validation Accuracy: 0.7362, Loss: 0.3162
Epoch  24 Batch  990/1077 - Train Accuracy: 0.7253, Validation Accuracy: 0.7362, Loss: 0.3170
Epoch  24 Batch 1000/1077 - Train Accuracy: 0.7857, Validation Accuracy: 0.7322, Loss: 0.2847
Epoch  24 Batch 1010/1077 - Train Accuracy: 0.7215, Validation Accuracy: 0.7301, Loss: 0.3100
Epoch  24 Batch 1020/1077 - Train Accuracy: 0.7078, Validation Accuracy: 0.7251, Loss: 0.2998
Epoch  24 Batch 1030/1077 - Train Accuracy: 0.7027, Validation Accuracy: 0.7276, Loss: 0.3177
Epoch  24 Batch 1040/1077 - Train Accuracy: 0.7290, Validation Accuracy: 0.7330, Loss: 0.3153
Epoch  24 Batch 1050/1077 - Train Accuracy: 0.6758, Validation Accuracy: 0.7290, Loss: 0.3022
Epoch  24 Batch 1060/1077 - Train Accuracy: 0.7504, Validation Accuracy: 0.7298, Loss: 0.2926
Epoch  24 Batch 1070/1077 - Train Accuracy: 0.7012, Validation Accuracy: 0.7266, Loss: 0.3101
Epoch  25 Batch   10/1077 - Train Accuracy: 0.7299, Validation Accuracy: 0.7333, Loss: 0.3149
Epoch  25 Batch   20/1077 - Train Accuracy: 0.7129, Validation Accuracy: 0.7351, Loss: 0.2995
Epoch  25 Batch   30/1077 - Train Accuracy: 0.7230, Validation Accuracy: 0.7262, Loss: 0.2991
Epoch  25 Batch   40/1077 - Train Accuracy: 0.7477, Validation Accuracy: 0.7351, Loss: 0.3197
Epoch  25 Batch   50/1077 - Train Accuracy: 0.7176, Validation Accuracy: 0.7266, Loss: 0.3085
Epoch  25 Batch   60/1077 - Train Accuracy: 0.7385, Validation Accuracy: 0.7411, Loss: 0.2927
Epoch  25 Batch   70/1077 - Train Accuracy: 0.7463, Validation Accuracy: 0.7195, Loss: 0.3234
Epoch  25 Batch   80/1077 - Train Accuracy: 0.7254, Validation Accuracy: 0.7188, Loss: 0.3072
Epoch  25 Batch   90/1077 - Train Accuracy: 0.7172, Validation Accuracy: 0.7184, Loss: 0.3167
Epoch  25 Batch  100/1077 - Train Accuracy: 0.7223, Validation Accuracy: 0.7283, Loss: 0.3045
Epoch  25 Batch  110/1077 - Train Accuracy: 0.7336, Validation Accuracy: 0.7259, Loss: 0.2816
Epoch  25 Batch  120/1077 - Train Accuracy: 0.7363, Validation Accuracy: 0.7319, Loss: 0.3142
Epoch  25 Batch  130/1077 - Train Accuracy: 0.7281, Validation Accuracy: 0.7489, Loss: 0.2958
Epoch  25 Batch  140/1077 - Train Accuracy: 0.7274, Validation Accuracy: 0.7489, Loss: 0.3201
Epoch  25 Batch  150/1077 - Train Accuracy: 0.7530, Validation Accuracy: 0.7234, Loss: 0.3024
Epoch  25 Batch  160/1077 - Train Accuracy: 0.7340, Validation Accuracy: 0.7262, Loss: 0.3052
Epoch  25 Batch  170/1077 - Train Accuracy: 0.6762, Validation Accuracy: 0.7241, Loss: 0.3136
Epoch  25 Batch  180/1077 - Train Accuracy: 0.7508, Validation Accuracy: 0.7259, Loss: 0.2924
Epoch  25 Batch  190/1077 - Train Accuracy: 0.7480, Validation Accuracy: 0.7354, Loss: 0.3073
Epoch  25 Batch  200/1077 - Train Accuracy: 0.7289, Validation Accuracy: 0.7372, Loss: 0.3225
Epoch  25 Batch  210/1077 - Train Accuracy: 0.7400, Validation Accuracy: 0.7294, Loss: 0.2992
Epoch  25 Batch  220/1077 - Train Accuracy: 0.7373, Validation Accuracy: 0.7301, Loss: 0.3249
Epoch  25 Batch  230/1077 - Train Accuracy: 0.7329, Validation Accuracy: 0.7340, Loss: 0.2762
Epoch  25 Batch  240/1077 - Train Accuracy: 0.7680, Validation Accuracy: 0.7362, Loss: 0.2946
Epoch  25 Batch  250/1077 - Train Accuracy: 0.7180, Validation Accuracy: 0.7262, Loss: 0.2771
Epoch  25 Batch  260/1077 - Train Accuracy: 0.7429, Validation Accuracy: 0.7241, Loss: 0.2804
Epoch  25 Batch  270/1077 - Train Accuracy: 0.7168, Validation Accuracy: 0.7223, Loss: 0.3108
Epoch  25 Batch  280/1077 - Train Accuracy: 0.7102, Validation Accuracy: 0.7120, Loss: 0.3113
Epoch  25 Batch  290/1077 - Train Accuracy: 0.7043, Validation Accuracy: 0.7287, Loss: 0.3104
Epoch  25 Batch  300/1077 - Train Accuracy: 0.7541, Validation Accuracy: 0.7411, Loss: 0.2984
Epoch  25 Batch  310/1077 - Train Accuracy: 0.6984, Validation Accuracy: 0.7109, Loss: 0.3364
Epoch  25 Batch  320/1077 - Train Accuracy: 0.7457, Validation Accuracy: 0.7212, Loss: 0.3241
Epoch  25 Batch  330/1077 - Train Accuracy: 0.7613, Validation Accuracy: 0.7290, Loss: 0.2922
Epoch  25 Batch  340/1077 - Train Accuracy: 0.7130, Validation Accuracy: 0.7237, Loss: 0.2986
Epoch  25 Batch  350/1077 - Train Accuracy: 0.7121, Validation Accuracy: 0.7223, Loss: 0.2988
Epoch  25 Batch  360/1077 - Train Accuracy: 0.7176, Validation Accuracy: 0.7042, Loss: 0.2939
Epoch  25 Batch  370/1077 - Train Accuracy: 0.7217, Validation Accuracy: 0.7383, Loss: 0.2927
Epoch  25 Batch  380/1077 - Train Accuracy: 0.7172, Validation Accuracy: 0.7223, Loss: 0.2882
Epoch  25 Batch  390/1077 - Train Accuracy: 0.6984, Validation Accuracy: 0.7166, Loss: 0.3266
Epoch  25 Batch  400/1077 - Train Accuracy: 0.7398, Validation Accuracy: 0.7273, Loss: 0.3077
Epoch  25 Batch  410/1077 - Train Accuracy: 0.7266, Validation Accuracy: 0.7354, Loss: 0.3241
Epoch  25 Batch  420/1077 - Train Accuracy: 0.7621, Validation Accuracy: 0.7148, Loss: 0.2821
Epoch  25 Batch  430/1077 - Train Accuracy: 0.7074, Validation Accuracy: 0.7067, Loss: 0.2932
Epoch  25 Batch  440/1077 - Train Accuracy: 0.7020, Validation Accuracy: 0.7070, Loss: 0.3121
Epoch  25 Batch  450/1077 - Train Accuracy: 0.7734, Validation Accuracy: 0.7056, Loss: 0.2969
Epoch  25 Batch  460/1077 - Train Accuracy: 0.7438, Validation Accuracy: 0.7070, Loss: 0.3121
Epoch  25 Batch  470/1077 - Train Accuracy: 0.7072, Validation Accuracy: 0.7198, Loss: 0.3121
Epoch  25 Batch  480/1077 - Train Accuracy: 0.7368, Validation Accuracy: 0.7209, Loss: 0.3250
Epoch  25 Batch  490/1077 - Train Accuracy: 0.7230, Validation Accuracy: 0.7106, Loss: 0.2990
Epoch  25 Batch  500/1077 - Train Accuracy: 0.7625, Validation Accuracy: 0.7085, Loss: 0.2986
Epoch  25 Batch  510/1077 - Train Accuracy: 0.7504, Validation Accuracy: 0.7163, Loss: 0.2953
Epoch  25 Batch  520/1077 - Train Accuracy: 0.7861, Validation Accuracy: 0.7209, Loss: 0.2837
Epoch  25 Batch  530/1077 - Train Accuracy: 0.6961, Validation Accuracy: 0.7188, Loss: 0.3167
Epoch  25 Batch  540/1077 - Train Accuracy: 0.7578, Validation Accuracy: 0.7259, Loss: 0.2786
Epoch  25 Batch  550/1077 - Train Accuracy: 0.7063, Validation Accuracy: 0.7227, Loss: 0.3142
Epoch  25 Batch  560/1077 - Train Accuracy: 0.7312, Validation Accuracy: 0.7273, Loss: 0.2958
Epoch  25 Batch  570/1077 - Train Accuracy: 0.7167, Validation Accuracy: 0.7212, Loss: 0.3278
Epoch  25 Batch  580/1077 - Train Accuracy: 0.7422, Validation Accuracy: 0.7195, Loss: 0.2771
Epoch  25 Batch  590/1077 - Train Accuracy: 0.7113, Validation Accuracy: 0.7219, Loss: 0.3163
Epoch  25 Batch  600/1077 - Train Accuracy: 0.7589, Validation Accuracy: 0.7230, Loss: 0.2724
Epoch  25 Batch  610/1077 - Train Accuracy: 0.7027, Validation Accuracy: 0.7184, Loss: 0.3129
Epoch  25 Batch  620/1077 - Train Accuracy: 0.7367, Validation Accuracy: 0.7177, Loss: 0.2883
Epoch  25 Batch  630/1077 - Train Accuracy: 0.7297, Validation Accuracy: 0.7269, Loss: 0.2974
Epoch  25 Batch  640/1077 - Train Accuracy: 0.7433, Validation Accuracy: 0.7308, Loss: 0.2725
Epoch  25 Batch  650/1077 - Train Accuracy: 0.7246, Validation Accuracy: 0.7230, Loss: 0.3040
Epoch  25 Batch  660/1077 - Train Accuracy: 0.7410, Validation Accuracy: 0.7234, Loss: 0.3153
Epoch  25 Batch  670/1077 - Train Accuracy: 0.7521, Validation Accuracy: 0.7259, Loss: 0.2815
Epoch  25 Batch  680/1077 - Train Accuracy: 0.7507, Validation Accuracy: 0.7216, Loss: 0.3099
Epoch  25 Batch  690/1077 - Train Accuracy: 0.7367, Validation Accuracy: 0.7287, Loss: 0.2950
Epoch  25 Batch  700/1077 - Train Accuracy: 0.7457, Validation Accuracy: 0.7088, Loss: 0.2767
Epoch  25 Batch  710/1077 - Train Accuracy: 0.6898, Validation Accuracy: 0.7251, Loss: 0.2916
Epoch  25 Batch  720/1077 - Train Accuracy: 0.7229, Validation Accuracy: 0.7120, Loss: 0.3163
Epoch  25 Batch  730/1077 - Train Accuracy: 0.7168, Validation Accuracy: 0.7212, Loss: 0.3116
Epoch  25 Batch  740/1077 - Train Accuracy: 0.7336, Validation Accuracy: 0.7159, Loss: 0.2847
Epoch  25 Batch  750/1077 - Train Accuracy: 0.7359, Validation Accuracy: 0.7180, Loss: 0.2950
Epoch  25 Batch  760/1077 - Train Accuracy: 0.7305, Validation Accuracy: 0.7237, Loss: 0.2957
Epoch  25 Batch  770/1077 - Train Accuracy: 0.7310, Validation Accuracy: 0.7141, Loss: 0.2918
Epoch  25 Batch  780/1077 - Train Accuracy: 0.7184, Validation Accuracy: 0.7159, Loss: 0.3182
Epoch  25 Batch  790/1077 - Train Accuracy: 0.6738, Validation Accuracy: 0.7170, Loss: 0.3217
Epoch  25 Batch  800/1077 - Train Accuracy: 0.7305, Validation Accuracy: 0.7227, Loss: 0.2982
Epoch  25 Batch  810/1077 - Train Accuracy: 0.7385, Validation Accuracy: 0.7216, Loss: 0.2786
Epoch  25 Batch  820/1077 - Train Accuracy: 0.7023, Validation Accuracy: 0.7163, Loss: 0.3189
Epoch  25 Batch  830/1077 - Train Accuracy: 0.6773, Validation Accuracy: 0.7259, Loss: 0.2984
Epoch  25 Batch  840/1077 - Train Accuracy: 0.7578, Validation Accuracy: 0.7180, Loss: 0.2818
Epoch  25 Batch  850/1077 - Train Accuracy: 0.7240, Validation Accuracy: 0.7244, Loss: 0.3144
Epoch  25 Batch  860/1077 - Train Accuracy: 0.7091, Validation Accuracy: 0.7244, Loss: 0.2997
Epoch  25 Batch  870/1077 - Train Accuracy: 0.7089, Validation Accuracy: 0.7138, Loss: 0.3191
Epoch  25 Batch  880/1077 - Train Accuracy: 0.7652, Validation Accuracy: 0.7081, Loss: 0.3003
Epoch  25 Batch  890/1077 - Train Accuracy: 0.7772, Validation Accuracy: 0.7152, Loss: 0.2699
Epoch  25 Batch  900/1077 - Train Accuracy: 0.7621, Validation Accuracy: 0.7156, Loss: 0.3014
Epoch  25 Batch  910/1077 - Train Accuracy: 0.7392, Validation Accuracy: 0.7294, Loss: 0.2886
Epoch  25 Batch  920/1077 - Train Accuracy: 0.7500, Validation Accuracy: 0.7280, Loss: 0.3162
Epoch  25 Batch  930/1077 - Train Accuracy: 0.7422, Validation Accuracy: 0.7312, Loss: 0.2849
Epoch  25 Batch  940/1077 - Train Accuracy: 0.7426, Validation Accuracy: 0.7205, Loss: 0.3004
Epoch  25 Batch  950/1077 - Train Accuracy: 0.7355, Validation Accuracy: 0.7290, Loss: 0.2784
Epoch  25 Batch  960/1077 - Train Accuracy: 0.7321, Validation Accuracy: 0.7159, Loss: 0.2868
Epoch  25 Batch  970/1077 - Train Accuracy: 0.7324, Validation Accuracy: 0.6985, Loss: 0.3075
Epoch  25 Batch  980/1077 - Train Accuracy: 0.7070, Validation Accuracy: 0.7195, Loss: 0.2986
Epoch  25 Batch  990/1077 - Train Accuracy: 0.7278, Validation Accuracy: 0.7205, Loss: 0.3073
Epoch  25 Batch 1000/1077 - Train Accuracy: 0.7913, Validation Accuracy: 0.7273, Loss: 0.2756
Epoch  25 Batch 1010/1077 - Train Accuracy: 0.7242, Validation Accuracy: 0.7205, Loss: 0.3031
Epoch  25 Batch 1020/1077 - Train Accuracy: 0.7320, Validation Accuracy: 0.7173, Loss: 0.2911
Epoch  25 Batch 1030/1077 - Train Accuracy: 0.7344, Validation Accuracy: 0.7205, Loss: 0.3013
Epoch  25 Batch 1040/1077 - Train Accuracy: 0.7434, Validation Accuracy: 0.7177, Loss: 0.3084
Epoch  25 Batch 1050/1077 - Train Accuracy: 0.6867, Validation Accuracy: 0.7188, Loss: 0.2957
Epoch  25 Batch 1060/1077 - Train Accuracy: 0.7883, Validation Accuracy: 0.7266, Loss: 0.2693
Epoch  25 Batch 1070/1077 - Train Accuracy: 0.7316, Validation Accuracy: 0.7337, Loss: 0.2970
Epoch  26 Batch   10/1077 - Train Accuracy: 0.7459, Validation Accuracy: 0.7212, Loss: 0.3126
Epoch  26 Batch   20/1077 - Train Accuracy: 0.7207, Validation Accuracy: 0.7063, Loss: 0.3005
Epoch  26 Batch   30/1077 - Train Accuracy: 0.7574, Validation Accuracy: 0.7092, Loss: 0.2873
Epoch  26 Batch   40/1077 - Train Accuracy: 0.7441, Validation Accuracy: 0.7095, Loss: 0.3018
Epoch  26 Batch   50/1077 - Train Accuracy: 0.7039, Validation Accuracy: 0.7255, Loss: 0.2901
Epoch  26 Batch   60/1077 - Train Accuracy: 0.7310, Validation Accuracy: 0.7287, Loss: 0.2794
Epoch  26 Batch   70/1077 - Train Accuracy: 0.7447, Validation Accuracy: 0.7248, Loss: 0.3061
Epoch  26 Batch   80/1077 - Train Accuracy: 0.7145, Validation Accuracy: 0.7124, Loss: 0.2952
Epoch  26 Batch   90/1077 - Train Accuracy: 0.7141, Validation Accuracy: 0.7077, Loss: 0.3160
Epoch  26 Batch  100/1077 - Train Accuracy: 0.7199, Validation Accuracy: 0.7237, Loss: 0.2844
Epoch  26 Batch  110/1077 - Train Accuracy: 0.7352, Validation Accuracy: 0.7195, Loss: 0.2765
Epoch  26 Batch  120/1077 - Train Accuracy: 0.7195, Validation Accuracy: 0.7056, Loss: 0.3144
Epoch  26 Batch  130/1077 - Train Accuracy: 0.7214, Validation Accuracy: 0.7077, Loss: 0.2776
Epoch  26 Batch  140/1077 - Train Accuracy: 0.7311, Validation Accuracy: 0.7237, Loss: 0.2958
Epoch  26 Batch  150/1077 - Train Accuracy: 0.7593, Validation Accuracy: 0.7063, Loss: 0.2829
Epoch  26 Batch  160/1077 - Train Accuracy: 0.7258, Validation Accuracy: 0.7077, Loss: 0.3012
Epoch  26 Batch  170/1077 - Train Accuracy: 0.6961, Validation Accuracy: 0.7294, Loss: 0.2936
Epoch  26 Batch  180/1077 - Train Accuracy: 0.7391, Validation Accuracy: 0.7159, Loss: 0.2794
Epoch  26 Batch  190/1077 - Train Accuracy: 0.7578, Validation Accuracy: 0.7074, Loss: 0.2846
Epoch  26 Batch  200/1077 - Train Accuracy: 0.7555, Validation Accuracy: 0.7074, Loss: 0.2953
Epoch  26 Batch  210/1077 - Train Accuracy: 0.7214, Validation Accuracy: 0.6989, Loss: 0.2866
Epoch  26 Batch  220/1077 - Train Accuracy: 0.7204, Validation Accuracy: 0.7031, Loss: 0.3070
Epoch  26 Batch  230/1077 - Train Accuracy: 0.7511, Validation Accuracy: 0.7095, Loss: 0.2736
Epoch  26 Batch  240/1077 - Train Accuracy: 0.7773, Validation Accuracy: 0.7195, Loss: 0.2747
Epoch  26 Batch  250/1077 - Train Accuracy: 0.7344, Validation Accuracy: 0.7099, Loss: 0.2839
Epoch  26 Batch  260/1077 - Train Accuracy: 0.7608, Validation Accuracy: 0.7141, Loss: 0.2715
Epoch  26 Batch  270/1077 - Train Accuracy: 0.7348, Validation Accuracy: 0.7067, Loss: 0.3017
Epoch  26 Batch  280/1077 - Train Accuracy: 0.7234, Validation Accuracy: 0.7113, Loss: 0.2970
Epoch  26 Batch  290/1077 - Train Accuracy: 0.7066, Validation Accuracy: 0.7045, Loss: 0.3103
Epoch  26 Batch  300/1077 - Train Accuracy: 0.7373, Validation Accuracy: 0.7188, Loss: 0.2893
Epoch  26 Batch  310/1077 - Train Accuracy: 0.6902, Validation Accuracy: 0.7180, Loss: 0.3085
Epoch  26 Batch  320/1077 - Train Accuracy: 0.7691, Validation Accuracy: 0.7109, Loss: 0.3221
Epoch  26 Batch  330/1077 - Train Accuracy: 0.7598, Validation Accuracy: 0.7156, Loss: 0.2945
Epoch  26 Batch  340/1077 - Train Accuracy: 0.7155, Validation Accuracy: 0.7191, Loss: 0.3027
Epoch  26 Batch  350/1077 - Train Accuracy: 0.7371, Validation Accuracy: 0.7202, Loss: 0.2877
Epoch  26 Batch  360/1077 - Train Accuracy: 0.7184, Validation Accuracy: 0.7138, Loss: 0.2935
Epoch  26 Batch  370/1077 - Train Accuracy: 0.7582, Validation Accuracy: 0.7262, Loss: 0.2952
Epoch  26 Batch  380/1077 - Train Accuracy: 0.7254, Validation Accuracy: 0.7131, Loss: 0.2785
Epoch  26 Batch  390/1077 - Train Accuracy: 0.6793, Validation Accuracy: 0.7188, Loss: 0.3099
Epoch  26 Batch  400/1077 - Train Accuracy: 0.7508, Validation Accuracy: 0.7099, Loss: 0.3044
Epoch  26 Batch  410/1077 - Train Accuracy: 0.7521, Validation Accuracy: 0.7195, Loss: 0.3007
Epoch  26 Batch  420/1077 - Train Accuracy: 0.7676, Validation Accuracy: 0.7024, Loss: 0.2778
Epoch  26 Batch  430/1077 - Train Accuracy: 0.6957, Validation Accuracy: 0.7077, Loss: 0.2916
Epoch  26 Batch  440/1077 - Train Accuracy: 0.7102, Validation Accuracy: 0.7145, Loss: 0.2914
Epoch  26 Batch  450/1077 - Train Accuracy: 0.7625, Validation Accuracy: 0.7070, Loss: 0.2820
Epoch  26 Batch  460/1077 - Train Accuracy: 0.7137, Validation Accuracy: 0.7184, Loss: 0.2952
Epoch  26 Batch  470/1077 - Train Accuracy: 0.7336, Validation Accuracy: 0.7081, Loss: 0.3080
Epoch  26 Batch  480/1077 - Train Accuracy: 0.7249, Validation Accuracy: 0.7173, Loss: 0.2997
Epoch  26 Batch  490/1077 - Train Accuracy: 0.7227, Validation Accuracy: 0.7166, Loss: 0.2959
Epoch  26 Batch  500/1077 - Train Accuracy: 0.7707, Validation Accuracy: 0.7163, Loss: 0.2920
Epoch  26 Batch  510/1077 - Train Accuracy: 0.7773, Validation Accuracy: 0.7060, Loss: 0.3047
Epoch  26 Batch  520/1077 - Train Accuracy: 0.7757, Validation Accuracy: 0.7184, Loss: 0.2687
Epoch  26 Batch  530/1077 - Train Accuracy: 0.6801, Validation Accuracy: 0.7127, Loss: 0.3017
Epoch  26 Batch  540/1077 - Train Accuracy: 0.7617, Validation Accuracy: 0.7280, Loss: 0.2725
Epoch  26 Batch  550/1077 - Train Accuracy: 0.7098, Validation Accuracy: 0.7188, Loss: 0.2959
Epoch  26 Batch  560/1077 - Train Accuracy: 0.7355, Validation Accuracy: 0.7219, Loss: 0.2787
Epoch  26 Batch  570/1077 - Train Accuracy: 0.7249, Validation Accuracy: 0.7248, Loss: 0.3139
Epoch  26 Batch  580/1077 - Train Accuracy: 0.7374, Validation Accuracy: 0.7333, Loss: 0.2639
Epoch  26 Batch  590/1077 - Train Accuracy: 0.7072, Validation Accuracy: 0.7131, Loss: 0.3079
Epoch  26 Batch  600/1077 - Train Accuracy: 0.7522, Validation Accuracy: 0.7141, Loss: 0.2731
Epoch  26 Batch  610/1077 - Train Accuracy: 0.7274, Validation Accuracy: 0.7131, Loss: 0.2971
Epoch  26 Batch  620/1077 - Train Accuracy: 0.7328, Validation Accuracy: 0.7287, Loss: 0.2701
Epoch  26 Batch  630/1077 - Train Accuracy: 0.7379, Validation Accuracy: 0.7259, Loss: 0.2787
Epoch  26 Batch  640/1077 - Train Accuracy: 0.7582, Validation Accuracy: 0.7234, Loss: 0.2619
Epoch  26 Batch  650/1077 - Train Accuracy: 0.7258, Validation Accuracy: 0.7280, Loss: 0.2831
Epoch  26 Batch  660/1077 - Train Accuracy: 0.7484, Validation Accuracy: 0.7173, Loss: 0.2973
Epoch  26 Batch  670/1077 - Train Accuracy: 0.7734, Validation Accuracy: 0.7081, Loss: 0.2697
Epoch  26 Batch  680/1077 - Train Accuracy: 0.7318, Validation Accuracy: 0.7219, Loss: 0.2990
Epoch  26 Batch  690/1077 - Train Accuracy: 0.7426, Validation Accuracy: 0.7131, Loss: 0.2892
Epoch  26 Batch  700/1077 - Train Accuracy: 0.7352, Validation Accuracy: 0.7131, Loss: 0.2726
Epoch  26 Batch  710/1077 - Train Accuracy: 0.6961, Validation Accuracy: 0.7166, Loss: 0.2802
Epoch  26 Batch  720/1077 - Train Accuracy: 0.7442, Validation Accuracy: 0.7077, Loss: 0.3081
Epoch  26 Batch  730/1077 - Train Accuracy: 0.7406, Validation Accuracy: 0.7088, Loss: 0.2862
Epoch  26 Batch  740/1077 - Train Accuracy: 0.7375, Validation Accuracy: 0.7124, Loss: 0.2837
Epoch  26 Batch  750/1077 - Train Accuracy: 0.7617, Validation Accuracy: 0.7152, Loss: 0.2920
Epoch  26 Batch  760/1077 - Train Accuracy: 0.7254, Validation Accuracy: 0.7223, Loss: 0.2937
Epoch  26 Batch  770/1077 - Train Accuracy: 0.7411, Validation Accuracy: 0.7113, Loss: 0.2816
Epoch  26 Batch  780/1077 - Train Accuracy: 0.7109, Validation Accuracy: 0.7081, Loss: 0.3060
Epoch  26 Batch  790/1077 - Train Accuracy: 0.6781, Validation Accuracy: 0.7191, Loss: 0.3087
Epoch  26 Batch  800/1077 - Train Accuracy: 0.7188, Validation Accuracy: 0.7156, Loss: 0.2876
Epoch  26 Batch  810/1077 - Train Accuracy: 0.7474, Validation Accuracy: 0.7163, Loss: 0.2813
Epoch  26 Batch  820/1077 - Train Accuracy: 0.6992, Validation Accuracy: 0.7134, Loss: 0.3077
Epoch  26 Batch  830/1077 - Train Accuracy: 0.7082, Validation Accuracy: 0.7148, Loss: 0.2948
Epoch  26 Batch  840/1077 - Train Accuracy: 0.7523, Validation Accuracy: 0.7198, Loss: 0.2796
Epoch  26 Batch  850/1077 - Train Accuracy: 0.7210, Validation Accuracy: 0.7244, Loss: 0.3108
Epoch  26 Batch  860/1077 - Train Accuracy: 0.7046, Validation Accuracy: 0.7202, Loss: 0.3003
Epoch  26 Batch  870/1077 - Train Accuracy: 0.7146, Validation Accuracy: 0.7163, Loss: 0.2963
Epoch  26 Batch  880/1077 - Train Accuracy: 0.7707, Validation Accuracy: 0.7209, Loss: 0.2982
Epoch  26 Batch  890/1077 - Train Accuracy: 0.8032, Validation Accuracy: 0.7053, Loss: 0.2780
Epoch  26 Batch  900/1077 - Train Accuracy: 0.7496, Validation Accuracy: 0.7010, Loss: 0.2876
Epoch  26 Batch  910/1077 - Train Accuracy: 0.7407, Validation Accuracy: 0.7202, Loss: 0.3046
Epoch  26 Batch  920/1077 - Train Accuracy: 0.7336, Validation Accuracy: 0.7177, Loss: 0.2960
Epoch  26 Batch  930/1077 - Train Accuracy: 0.7371, Validation Accuracy: 0.7145, Loss: 0.2728
Epoch  26 Batch  940/1077 - Train Accuracy: 0.7578, Validation Accuracy: 0.7173, Loss: 0.2741
Epoch  26 Batch  950/1077 - Train Accuracy: 0.7344, Validation Accuracy: 0.7191, Loss: 0.2613
Epoch  26 Batch  960/1077 - Train Accuracy: 0.7392, Validation Accuracy: 0.7156, Loss: 0.2794
Epoch  26 Batch  970/1077 - Train Accuracy: 0.7348, Validation Accuracy: 0.7166, Loss: 0.3094
Epoch  26 Batch  980/1077 - Train Accuracy: 0.7266, Validation Accuracy: 0.7177, Loss: 0.2923
Epoch  26 Batch  990/1077 - Train Accuracy: 0.7311, Validation Accuracy: 0.7436, Loss: 0.2917
Epoch  26 Batch 1000/1077 - Train Accuracy: 0.7865, Validation Accuracy: 0.7305, Loss: 0.2608
Epoch  26 Batch 1010/1077 - Train Accuracy: 0.7219, Validation Accuracy: 0.7212, Loss: 0.2887
Epoch  26 Batch 1020/1077 - Train Accuracy: 0.7391, Validation Accuracy: 0.7308, Loss: 0.2690
Epoch  26 Batch 1030/1077 - Train Accuracy: 0.7227, Validation Accuracy: 0.7195, Loss: 0.2867
Epoch  26 Batch 1040/1077 - Train Accuracy: 0.7484, Validation Accuracy: 0.7134, Loss: 0.2968
Epoch  26 Batch 1050/1077 - Train Accuracy: 0.6836, Validation Accuracy: 0.7106, Loss: 0.2834
Epoch  26 Batch 1060/1077 - Train Accuracy: 0.7859, Validation Accuracy: 0.7081, Loss: 0.2710
Epoch  26 Batch 1070/1077 - Train Accuracy: 0.7223, Validation Accuracy: 0.7351, Loss: 0.2875
Epoch  27 Batch   10/1077 - Train Accuracy: 0.7410, Validation Accuracy: 0.7244, Loss: 0.3039
Epoch  27 Batch   20/1077 - Train Accuracy: 0.7184, Validation Accuracy: 0.7088, Loss: 0.2794
Epoch  27 Batch   30/1077 - Train Accuracy: 0.7488, Validation Accuracy: 0.7152, Loss: 0.2842
Epoch  27 Batch   40/1077 - Train Accuracy: 0.7566, Validation Accuracy: 0.7198, Loss: 0.2809
Epoch  27 Batch   50/1077 - Train Accuracy: 0.7359, Validation Accuracy: 0.7351, Loss: 0.2913
Epoch  27 Batch   60/1077 - Train Accuracy: 0.7247, Validation Accuracy: 0.7340, Loss: 0.2725
Epoch  27 Batch   70/1077 - Train Accuracy: 0.7500, Validation Accuracy: 0.7223, Loss: 0.2951
Epoch  27 Batch   80/1077 - Train Accuracy: 0.7094, Validation Accuracy: 0.7205, Loss: 0.2904
Epoch  27 Batch   90/1077 - Train Accuracy: 0.7137, Validation Accuracy: 0.7060, Loss: 0.2992
Epoch  27 Batch  100/1077 - Train Accuracy: 0.7262, Validation Accuracy: 0.7347, Loss: 0.2738
Epoch  27 Batch  110/1077 - Train Accuracy: 0.7320, Validation Accuracy: 0.7230, Loss: 0.2767
Epoch  27 Batch  120/1077 - Train Accuracy: 0.7039, Validation Accuracy: 0.7173, Loss: 0.3086
Epoch  27 Batch  130/1077 - Train Accuracy: 0.7310, Validation Accuracy: 0.7269, Loss: 0.2667
Epoch  27 Batch  140/1077 - Train Accuracy: 0.7241, Validation Accuracy: 0.7092, Loss: 0.2909
Epoch  27 Batch  150/1077 - Train Accuracy: 0.7842, Validation Accuracy: 0.7269, Loss: 0.2745
Epoch  27 Batch  160/1077 - Train Accuracy: 0.7340, Validation Accuracy: 0.7166, Loss: 0.2850
Epoch  27 Batch  170/1077 - Train Accuracy: 0.6996, Validation Accuracy: 0.7170, Loss: 0.2957
Epoch  27 Batch  180/1077 - Train Accuracy: 0.7383, Validation Accuracy: 0.7095, Loss: 0.2875
Epoch  27 Batch  190/1077 - Train Accuracy: 0.7777, Validation Accuracy: 0.7085, Loss: 0.2805
Epoch  27 Batch  200/1077 - Train Accuracy: 0.7402, Validation Accuracy: 0.7074, Loss: 0.3016
Epoch  27 Batch  210/1077 - Train Accuracy: 0.7481, Validation Accuracy: 0.7170, Loss: 0.2856
Epoch  27 Batch  220/1077 - Train Accuracy: 0.7319, Validation Accuracy: 0.7212, Loss: 0.2918
Epoch  27 Batch  230/1077 - Train Accuracy: 0.7433, Validation Accuracy: 0.7166, Loss: 0.2713
Epoch  27 Batch  240/1077 - Train Accuracy: 0.7934, Validation Accuracy: 0.7141, Loss: 0.2744
Epoch  27 Batch  250/1077 - Train Accuracy: 0.7344, Validation Accuracy: 0.7166, Loss: 0.2649
Epoch  27 Batch  260/1077 - Train Accuracy: 0.7675, Validation Accuracy: 0.7234, Loss: 0.2602
Epoch  27 Batch  270/1077 - Train Accuracy: 0.7309, Validation Accuracy: 0.7205, Loss: 0.3001
Epoch  27 Batch  280/1077 - Train Accuracy: 0.7211, Validation Accuracy: 0.7124, Loss: 0.2925
Epoch  27 Batch  290/1077 - Train Accuracy: 0.7145, Validation Accuracy: 0.7244, Loss: 0.3102
Epoch  27 Batch  300/1077 - Train Accuracy: 0.7607, Validation Accuracy: 0.7010, Loss: 0.2690
Epoch  27 Batch  310/1077 - Train Accuracy: 0.7105, Validation Accuracy: 0.7191, Loss: 0.3015
Epoch  27 Batch  320/1077 - Train Accuracy: 0.7656, Validation Accuracy: 0.7191, Loss: 0.3107
Epoch  27 Batch  330/1077 - Train Accuracy: 0.7668, Validation Accuracy: 0.7266, Loss: 0.2835
Epoch  27 Batch  340/1077 - Train Accuracy: 0.7348, Validation Accuracy: 0.7212, Loss: 0.2979
Epoch  27 Batch  350/1077 - Train Accuracy: 0.7363, Validation Accuracy: 0.7273, Loss: 0.2752
Epoch  27 Batch  360/1077 - Train Accuracy: 0.7098, Validation Accuracy: 0.7216, Loss: 0.2841
Epoch  27 Batch  370/1077 - Train Accuracy: 0.7772, Validation Accuracy: 0.7223, Loss: 0.2787
Epoch  27 Batch  380/1077 - Train Accuracy: 0.7379, Validation Accuracy: 0.7166, Loss: 0.2797
Epoch  27 Batch  390/1077 - Train Accuracy: 0.6898, Validation Accuracy: 0.7173, Loss: 0.3071
Epoch  27 Batch  400/1077 - Train Accuracy: 0.7590, Validation Accuracy: 0.7120, Loss: 0.3026
Epoch  27 Batch  410/1077 - Train Accuracy: 0.7410, Validation Accuracy: 0.7351, Loss: 0.3048
Epoch  27 Batch  420/1077 - Train Accuracy: 0.7703, Validation Accuracy: 0.7195, Loss: 0.2656
Epoch  27 Batch  430/1077 - Train Accuracy: 0.7152, Validation Accuracy: 0.7159, Loss: 0.3026
Epoch  27 Batch  440/1077 - Train Accuracy: 0.7098, Validation Accuracy: 0.7212, Loss: 0.2844
Epoch  27 Batch  450/1077 - Train Accuracy: 0.7641, Validation Accuracy: 0.7212, Loss: 0.2734
Epoch  27 Batch  460/1077 - Train Accuracy: 0.7223, Validation Accuracy: 0.7195, Loss: 0.2893
Epoch  27 Batch  470/1077 - Train Accuracy: 0.7142, Validation Accuracy: 0.7184, Loss: 0.3006
Epoch  27 Batch  480/1077 - Train Accuracy: 0.7397, Validation Accuracy: 0.7205, Loss: 0.2929
Epoch  27 Batch  490/1077 - Train Accuracy: 0.7207, Validation Accuracy: 0.7287, Loss: 0.2802
Epoch  27 Batch  500/1077 - Train Accuracy: 0.7762, Validation Accuracy: 0.7188, Loss: 0.2704
Epoch  27 Batch  510/1077 - Train Accuracy: 0.7609, Validation Accuracy: 0.7255, Loss: 0.2785
Epoch  27 Batch  520/1077 - Train Accuracy: 0.7805, Validation Accuracy: 0.7266, Loss: 0.2648
Epoch  27 Batch  530/1077 - Train Accuracy: 0.7000, Validation Accuracy: 0.7131, Loss: 0.2934
Epoch  27 Batch  540/1077 - Train Accuracy: 0.7609, Validation Accuracy: 0.7198, Loss: 0.2534
Epoch  27 Batch  550/1077 - Train Accuracy: 0.7164, Validation Accuracy: 0.7188, Loss: 0.2920
Epoch  27 Batch  560/1077 - Train Accuracy: 0.7328, Validation Accuracy: 0.7475, Loss: 0.2699
Epoch  27 Batch  570/1077 - Train Accuracy: 0.7315, Validation Accuracy: 0.7440, Loss: 0.3034
Epoch  27 Batch  580/1077 - Train Accuracy: 0.7537, Validation Accuracy: 0.7425, Loss: 0.2501
Epoch  27 Batch  590/1077 - Train Accuracy: 0.7237, Validation Accuracy: 0.7369, Loss: 0.3103
Epoch  27 Batch  600/1077 - Train Accuracy: 0.7705, Validation Accuracy: 0.7241, Loss: 0.2629
Epoch  27 Batch  610/1077 - Train Accuracy: 0.7076, Validation Accuracy: 0.7244, Loss: 0.2959
Epoch  27 Batch  620/1077 - Train Accuracy: 0.7449, Validation Accuracy: 0.7237, Loss: 0.2715
Epoch  27 Batch  630/1077 - Train Accuracy: 0.7461, Validation Accuracy: 0.7287, Loss: 0.2696
Epoch  27 Batch  640/1077 - Train Accuracy: 0.7746, Validation Accuracy: 0.7362, Loss: 0.2672
Epoch  27 Batch  650/1077 - Train Accuracy: 0.7363, Validation Accuracy: 0.7330, Loss: 0.2787
Epoch  27 Batch  660/1077 - Train Accuracy: 0.7539, Validation Accuracy: 0.7269, Loss: 0.2927
Epoch  27 Batch  670/1077 - Train Accuracy: 0.7603, Validation Accuracy: 0.7134, Loss: 0.2640
Epoch  27 Batch  680/1077 - Train Accuracy: 0.7336, Validation Accuracy: 0.7202, Loss: 0.2800
Epoch  27 Batch  690/1077 - Train Accuracy: 0.7555, Validation Accuracy: 0.7251, Loss: 0.2857
Epoch  27 Batch  700/1077 - Train Accuracy: 0.7629, Validation Accuracy: 0.7163, Loss: 0.2610
Epoch  27 Batch  710/1077 - Train Accuracy: 0.7043, Validation Accuracy: 0.7333, Loss: 0.2802
Epoch  27 Batch  720/1077 - Train Accuracy: 0.7475, Validation Accuracy: 0.7156, Loss: 0.3040
Epoch  27 Batch  730/1077 - Train Accuracy: 0.7371, Validation Accuracy: 0.7230, Loss: 0.2817
Epoch  27 Batch  740/1077 - Train Accuracy: 0.7250, Validation Accuracy: 0.7177, Loss: 0.2790
Epoch  27 Batch  750/1077 - Train Accuracy: 0.7570, Validation Accuracy: 0.7251, Loss: 0.2951
Epoch  27 Batch  760/1077 - Train Accuracy: 0.7301, Validation Accuracy: 0.7330, Loss: 0.2791
Epoch  27 Batch  770/1077 - Train Accuracy: 0.7496, Validation Accuracy: 0.7074, Loss: 0.2762
Epoch  27 Batch  780/1077 - Train Accuracy: 0.7297, Validation Accuracy: 0.7184, Loss: 0.2882
Epoch  27 Batch  790/1077 - Train Accuracy: 0.6789, Validation Accuracy: 0.7195, Loss: 0.3011
Epoch  27 Batch  800/1077 - Train Accuracy: 0.7195, Validation Accuracy: 0.7294, Loss: 0.2937
Epoch  27 Batch  810/1077 - Train Accuracy: 0.7493, Validation Accuracy: 0.7337, Loss: 0.2621
Epoch  27 Batch  820/1077 - Train Accuracy: 0.6883, Validation Accuracy: 0.7191, Loss: 0.2997
Epoch  27 Batch  830/1077 - Train Accuracy: 0.7000, Validation Accuracy: 0.7312, Loss: 0.2807
Epoch  27 Batch  840/1077 - Train Accuracy: 0.7422, Validation Accuracy: 0.7393, Loss: 0.2784
Epoch  27 Batch  850/1077 - Train Accuracy: 0.7243, Validation Accuracy: 0.7212, Loss: 0.3042
Epoch  27 Batch  860/1077 - Train Accuracy: 0.7199, Validation Accuracy: 0.7248, Loss: 0.2681
Epoch  27 Batch  870/1077 - Train Accuracy: 0.7109, Validation Accuracy: 0.7152, Loss: 0.2976
Epoch  27 Batch  880/1077 - Train Accuracy: 0.7664, Validation Accuracy: 0.7237, Loss: 0.2751
Epoch  27 Batch  890/1077 - Train Accuracy: 0.7872, Validation Accuracy: 0.7305, Loss: 0.2706
Epoch  27 Batch  900/1077 - Train Accuracy: 0.7758, Validation Accuracy: 0.7234, Loss: 0.2772
Epoch  27 Batch  910/1077 - Train Accuracy: 0.7522, Validation Accuracy: 0.7237, Loss: 0.2861
Epoch  27 Batch  920/1077 - Train Accuracy: 0.7484, Validation Accuracy: 0.7166, Loss: 0.2839
Epoch  27 Batch  930/1077 - Train Accuracy: 0.7367, Validation Accuracy: 0.7411, Loss: 0.2739
Epoch  27 Batch  940/1077 - Train Accuracy: 0.7406, Validation Accuracy: 0.7184, Loss: 0.2735
Epoch  27 Batch  950/1077 - Train Accuracy: 0.7269, Validation Accuracy: 0.7269, Loss: 0.2642
Epoch  27 Batch  960/1077 - Train Accuracy: 0.7370, Validation Accuracy: 0.7223, Loss: 0.2751
Epoch  27 Batch  970/1077 - Train Accuracy: 0.7285, Validation Accuracy: 0.7166, Loss: 0.2822
Epoch  27 Batch  980/1077 - Train Accuracy: 0.7207, Validation Accuracy: 0.7180, Loss: 0.2913
Epoch  27 Batch  990/1077 - Train Accuracy: 0.7463, Validation Accuracy: 0.7401, Loss: 0.2945
Epoch  27 Batch 1000/1077 - Train Accuracy: 0.7846, Validation Accuracy: 0.7408, Loss: 0.2551
Epoch  27 Batch 1010/1077 - Train Accuracy: 0.7234, Validation Accuracy: 0.7340, Loss: 0.2897
Epoch  27 Batch 1020/1077 - Train Accuracy: 0.7559, Validation Accuracy: 0.7276, Loss: 0.2666
Epoch  27 Batch 1030/1077 - Train Accuracy: 0.7391, Validation Accuracy: 0.7251, Loss: 0.3067
Epoch  27 Batch 1040/1077 - Train Accuracy: 0.7660, Validation Accuracy: 0.7177, Loss: 0.2841
Epoch  27 Batch 1050/1077 - Train Accuracy: 0.7027, Validation Accuracy: 0.7244, Loss: 0.2803
Epoch  27 Batch 1060/1077 - Train Accuracy: 0.7887, Validation Accuracy: 0.7166, Loss: 0.2548
Epoch  27 Batch 1070/1077 - Train Accuracy: 0.7281, Validation Accuracy: 0.7383, Loss: 0.2777
Epoch  28 Batch   10/1077 - Train Accuracy: 0.7689, Validation Accuracy: 0.7159, Loss: 0.2892
Epoch  28 Batch   20/1077 - Train Accuracy: 0.7273, Validation Accuracy: 0.7113, Loss: 0.2627
Epoch  28 Batch   30/1077 - Train Accuracy: 0.7586, Validation Accuracy: 0.7063, Loss: 0.2767
Epoch  28 Batch   40/1077 - Train Accuracy: 0.7492, Validation Accuracy: 0.7166, Loss: 0.2754
Epoch  28 Batch   50/1077 - Train Accuracy: 0.7289, Validation Accuracy: 0.7344, Loss: 0.2781
Epoch  28 Batch   60/1077 - Train Accuracy: 0.7321, Validation Accuracy: 0.7333, Loss: 0.2690
Epoch  28 Batch   70/1077 - Train Accuracy: 0.7471, Validation Accuracy: 0.7280, Loss: 0.3052
Epoch  28 Batch   80/1077 - Train Accuracy: 0.7203, Validation Accuracy: 0.7227, Loss: 0.2791
Epoch  28 Batch   90/1077 - Train Accuracy: 0.7137, Validation Accuracy: 0.7159, Loss: 0.2906
Epoch  28 Batch  100/1077 - Train Accuracy: 0.7188, Validation Accuracy: 0.7472, Loss: 0.2684
Epoch  28 Batch  110/1077 - Train Accuracy: 0.7273, Validation Accuracy: 0.7401, Loss: 0.2669
Epoch  28 Batch  120/1077 - Train Accuracy: 0.7387, Validation Accuracy: 0.7177, Loss: 0.2860
Epoch  28 Batch  130/1077 - Train Accuracy: 0.7448, Validation Accuracy: 0.7248, Loss: 0.2713
Epoch  28 Batch  140/1077 - Train Accuracy: 0.7348, Validation Accuracy: 0.7045, Loss: 0.2866
Epoch  28 Batch  150/1077 - Train Accuracy: 0.7638, Validation Accuracy: 0.7259, Loss: 0.2649
Epoch  28 Batch  160/1077 - Train Accuracy: 0.7375, Validation Accuracy: 0.7294, Loss: 0.2779
Epoch  28 Batch  170/1077 - Train Accuracy: 0.7078, Validation Accuracy: 0.7283, Loss: 0.2876
Epoch  28 Batch  180/1077 - Train Accuracy: 0.7520, Validation Accuracy: 0.7205, Loss: 0.2656
Epoch  28 Batch  190/1077 - Train Accuracy: 0.7711, Validation Accuracy: 0.7212, Loss: 0.2796
Epoch  28 Batch  200/1077 - Train Accuracy: 0.7266, Validation Accuracy: 0.7188, Loss: 0.2896
Epoch  28 Batch  210/1077 - Train Accuracy: 0.7385, Validation Accuracy: 0.7184, Loss: 0.2777
Epoch  28 Batch  220/1077 - Train Accuracy: 0.7381, Validation Accuracy: 0.7227, Loss: 0.2807
Epoch  28 Batch  230/1077 - Train Accuracy: 0.7481, Validation Accuracy: 0.7145, Loss: 0.2598
Epoch  28 Batch  240/1077 - Train Accuracy: 0.7855, Validation Accuracy: 0.7109, Loss: 0.2699
Epoch  28 Batch  250/1077 - Train Accuracy: 0.7393, Validation Accuracy: 0.7134, Loss: 0.2704
Epoch  28 Batch  260/1077 - Train Accuracy: 0.7455, Validation Accuracy: 0.7152, Loss: 0.2548
Epoch  28 Batch  270/1077 - Train Accuracy: 0.7480, Validation Accuracy: 0.7219, Loss: 0.2859
Epoch  28 Batch  280/1077 - Train Accuracy: 0.7195, Validation Accuracy: 0.7102, Loss: 0.2939
Epoch  28 Batch  290/1077 - Train Accuracy: 0.7156, Validation Accuracy: 0.7237, Loss: 0.2956
Epoch  28 Batch  300/1077 - Train Accuracy: 0.7451, Validation Accuracy: 0.7180, Loss: 0.2727
Epoch  28 Batch  310/1077 - Train Accuracy: 0.7063, Validation Accuracy: 0.7227, Loss: 0.2875
Epoch  28 Batch  320/1077 - Train Accuracy: 0.7648, Validation Accuracy: 0.7145, Loss: 0.2981
Epoch  28 Batch  330/1077 - Train Accuracy: 0.7629, Validation Accuracy: 0.7234, Loss: 0.2761
Epoch  28 Batch  340/1077 - Train Accuracy: 0.7393, Validation Accuracy: 0.7266, Loss: 0.2735
Epoch  28 Batch  350/1077 - Train Accuracy: 0.7391, Validation Accuracy: 0.7166, Loss: 0.2724
Epoch  28 Batch  360/1077 - Train Accuracy: 0.7063, Validation Accuracy: 0.7156, Loss: 0.2760
Epoch  28 Batch  370/1077 - Train Accuracy: 0.7693, Validation Accuracy: 0.7251, Loss: 0.2706
Epoch  28 Batch  380/1077 - Train Accuracy: 0.7438, Validation Accuracy: 0.7191, Loss: 0.2630
Epoch  28 Batch  390/1077 - Train Accuracy: 0.7023, Validation Accuracy: 0.7205, Loss: 0.3014
Epoch  28 Batch  400/1077 - Train Accuracy: 0.7484, Validation Accuracy: 0.7248, Loss: 0.2852
Epoch  28 Batch  410/1077 - Train Accuracy: 0.7496, Validation Accuracy: 0.7362, Loss: 0.2888
Epoch  28 Batch  420/1077 - Train Accuracy: 0.7660, Validation Accuracy: 0.7170, Loss: 0.2540
Epoch  28 Batch  430/1077 - Train Accuracy: 0.6965, Validation Accuracy: 0.7127, Loss: 0.2805
Epoch  28 Batch  440/1077 - Train Accuracy: 0.7152, Validation Accuracy: 0.7099, Loss: 0.2754
Epoch  28 Batch  450/1077 - Train Accuracy: 0.7668, Validation Accuracy: 0.7095, Loss: 0.2674
Epoch  28 Batch  460/1077 - Train Accuracy: 0.7277, Validation Accuracy: 0.7070, Loss: 0.2857
Epoch  28 Batch  470/1077 - Train Accuracy: 0.7081, Validation Accuracy: 0.7241, Loss: 0.2889
Epoch  28 Batch  480/1077 - Train Accuracy: 0.7512, Validation Accuracy: 0.7230, Loss: 0.2796
Epoch  28 Batch  490/1077 - Train Accuracy: 0.7367, Validation Accuracy: 0.7251, Loss: 0.2827
Epoch  28 Batch  500/1077 - Train Accuracy: 0.7832, Validation Accuracy: 0.7269, Loss: 0.2651
Epoch  28 Batch  510/1077 - Train Accuracy: 0.7551, Validation Accuracy: 0.7180, Loss: 0.2736
Epoch  28 Batch  520/1077 - Train Accuracy: 0.7812, Validation Accuracy: 0.7227, Loss: 0.2514
Epoch  28 Batch  530/1077 - Train Accuracy: 0.6996, Validation Accuracy: 0.7145, Loss: 0.2824
Epoch  28 Batch  540/1077 - Train Accuracy: 0.7598, Validation Accuracy: 0.7124, Loss: 0.2553
Epoch  28 Batch  550/1077 - Train Accuracy: 0.7188, Validation Accuracy: 0.7230, Loss: 0.2702
Epoch  28 Batch  560/1077 - Train Accuracy: 0.7230, Validation Accuracy: 0.7415, Loss: 0.2537
Epoch  28 Batch  570/1077 - Train Accuracy: 0.7397, Validation Accuracy: 0.7443, Loss: 0.2991
Epoch  28 Batch  580/1077 - Train Accuracy: 0.7429, Validation Accuracy: 0.7411, Loss: 0.2491
Epoch  28 Batch  590/1077 - Train Accuracy: 0.7146, Validation Accuracy: 0.7287, Loss: 0.2950
Epoch  28 Batch  600/1077 - Train Accuracy: 0.7608, Validation Accuracy: 0.7088, Loss: 0.2648
Epoch  28 Batch  610/1077 - Train Accuracy: 0.7060, Validation Accuracy: 0.7095, Loss: 0.2812
Epoch  28 Batch  620/1077 - Train Accuracy: 0.7324, Validation Accuracy: 0.7195, Loss: 0.2533
Epoch  28 Batch  630/1077 - Train Accuracy: 0.7445, Validation Accuracy: 0.7369, Loss: 0.2808
Epoch  28 Batch  640/1077 - Train Accuracy: 0.7630, Validation Accuracy: 0.7518, Loss: 0.2571
Epoch  28 Batch  650/1077 - Train Accuracy: 0.7199, Validation Accuracy: 0.7305, Loss: 0.2778
Epoch  28 Batch  660/1077 - Train Accuracy: 0.7586, Validation Accuracy: 0.7315, Loss: 0.2798
Epoch  28 Batch  670/1077 - Train Accuracy: 0.7706, Validation Accuracy: 0.7198, Loss: 0.2523
Epoch  28 Batch  680/1077 - Train Accuracy: 0.7266, Validation Accuracy: 0.7319, Loss: 0.2798
Epoch  28 Batch  690/1077 - Train Accuracy: 0.7473, Validation Accuracy: 0.7177, Loss: 0.2769
Epoch  28 Batch  700/1077 - Train Accuracy: 0.7734, Validation Accuracy: 0.7298, Loss: 0.2776
Epoch  28 Batch  710/1077 - Train Accuracy: 0.6941, Validation Accuracy: 0.7315, Loss: 0.2808
Epoch  28 Batch  720/1077 - Train Accuracy: 0.7401, Validation Accuracy: 0.7163, Loss: 0.2915
Epoch  28 Batch  730/1077 - Train Accuracy: 0.7305, Validation Accuracy: 0.7198, Loss: 0.2829
Epoch  28 Batch  740/1077 - Train Accuracy: 0.7418, Validation Accuracy: 0.7251, Loss: 0.2717
Epoch  28 Batch  750/1077 - Train Accuracy: 0.7672, Validation Accuracy: 0.7248, Loss: 0.2747
Epoch  28 Batch  760/1077 - Train Accuracy: 0.7395, Validation Accuracy: 0.7273, Loss: 0.2771
Epoch  28 Batch  770/1077 - Train Accuracy: 0.7452, Validation Accuracy: 0.7234, Loss: 0.2571
Epoch  28 Batch  780/1077 - Train Accuracy: 0.7281, Validation Accuracy: 0.7248, Loss: 0.2896
Epoch  28 Batch  790/1077 - Train Accuracy: 0.6762, Validation Accuracy: 0.7198, Loss: 0.2940
Epoch  28 Batch  800/1077 - Train Accuracy: 0.7191, Validation Accuracy: 0.7259, Loss: 0.2765
Epoch  28 Batch  810/1077 - Train Accuracy: 0.7600, Validation Accuracy: 0.7365, Loss: 0.2525
Epoch  28 Batch  820/1077 - Train Accuracy: 0.6949, Validation Accuracy: 0.7259, Loss: 0.2847
Epoch  28 Batch  830/1077 - Train Accuracy: 0.7012, Validation Accuracy: 0.7372, Loss: 0.2798
Epoch  28 Batch  840/1077 - Train Accuracy: 0.7512, Validation Accuracy: 0.7326, Loss: 0.2696
Epoch  28 Batch  850/1077 - Train Accuracy: 0.7414, Validation Accuracy: 0.7269, Loss: 0.2966
Epoch  28 Batch  860/1077 - Train Accuracy: 0.7199, Validation Accuracy: 0.7315, Loss: 0.2808
Epoch  28 Batch  870/1077 - Train Accuracy: 0.7105, Validation Accuracy: 0.7234, Loss: 0.3068
Epoch  28 Batch  880/1077 - Train Accuracy: 0.7723, Validation Accuracy: 0.7234, Loss: 0.2729
Epoch  28 Batch  890/1077 - Train Accuracy: 0.7850, Validation Accuracy: 0.7301, Loss: 0.2504
Epoch  28 Batch  900/1077 - Train Accuracy: 0.7684, Validation Accuracy: 0.7379, Loss: 0.2718
Epoch  28 Batch  910/1077 - Train Accuracy: 0.7597, Validation Accuracy: 0.7294, Loss: 0.2786
Epoch  28 Batch  920/1077 - Train Accuracy: 0.7473, Validation Accuracy: 0.7276, Loss: 0.2772
Epoch  28 Batch  930/1077 - Train Accuracy: 0.7461, Validation Accuracy: 0.7340, Loss: 0.2602
Epoch  28 Batch  940/1077 - Train Accuracy: 0.7598, Validation Accuracy: 0.7397, Loss: 0.2715
Epoch  28 Batch  950/1077 - Train Accuracy: 0.7574, Validation Accuracy: 0.7393, Loss: 0.2615
Epoch  28 Batch  960/1077 - Train Accuracy: 0.7444, Validation Accuracy: 0.7315, Loss: 0.2687
Epoch  28 Batch  970/1077 - Train Accuracy: 0.7363, Validation Accuracy: 0.7216, Loss: 0.2738
Epoch  28 Batch  980/1077 - Train Accuracy: 0.7277, Validation Accuracy: 0.7198, Loss: 0.2818
Epoch  28 Batch  990/1077 - Train Accuracy: 0.7397, Validation Accuracy: 0.7539, Loss: 0.2837
Epoch  28 Batch 1000/1077 - Train Accuracy: 0.8017, Validation Accuracy: 0.7390, Loss: 0.2550
Epoch  28 Batch 1010/1077 - Train Accuracy: 0.7316, Validation Accuracy: 0.7223, Loss: 0.2652
Epoch  28 Batch 1020/1077 - Train Accuracy: 0.7469, Validation Accuracy: 0.7180, Loss: 0.2563
Epoch  28 Batch 1030/1077 - Train Accuracy: 0.7363, Validation Accuracy: 0.7340, Loss: 0.2952
Epoch  28 Batch 1040/1077 - Train Accuracy: 0.7632, Validation Accuracy: 0.7152, Loss: 0.2909
Epoch  28 Batch 1050/1077 - Train Accuracy: 0.7000, Validation Accuracy: 0.7198, Loss: 0.2608
Epoch  28 Batch 1060/1077 - Train Accuracy: 0.7984, Validation Accuracy: 0.7230, Loss: 0.2627
Epoch  28 Batch 1070/1077 - Train Accuracy: 0.7238, Validation Accuracy: 0.7216, Loss: 0.2798
Epoch  29 Batch   10/1077 - Train Accuracy: 0.7558, Validation Accuracy: 0.7195, Loss: 0.2945
Epoch  29 Batch   20/1077 - Train Accuracy: 0.7273, Validation Accuracy: 0.7148, Loss: 0.2681
Epoch  29 Batch   30/1077 - Train Accuracy: 0.7703, Validation Accuracy: 0.7124, Loss: 0.2658
Epoch  29 Batch   40/1077 - Train Accuracy: 0.7469, Validation Accuracy: 0.7163, Loss: 0.2763
Epoch  29 Batch   50/1077 - Train Accuracy: 0.7234, Validation Accuracy: 0.7425, Loss: 0.2759
Epoch  29 Batch   60/1077 - Train Accuracy: 0.7414, Validation Accuracy: 0.7443, Loss: 0.2598
Epoch  29 Batch   70/1077 - Train Accuracy: 0.7574, Validation Accuracy: 0.7351, Loss: 0.2854
Epoch  29 Batch   80/1077 - Train Accuracy: 0.7188, Validation Accuracy: 0.7259, Loss: 0.2661
Epoch  29 Batch   90/1077 - Train Accuracy: 0.7215, Validation Accuracy: 0.7159, Loss: 0.2817
Epoch  29 Batch  100/1077 - Train Accuracy: 0.7297, Validation Accuracy: 0.7447, Loss: 0.2609
Epoch  29 Batch  110/1077 - Train Accuracy: 0.7410, Validation Accuracy: 0.7379, Loss: 0.2509
Epoch  29 Batch  120/1077 - Train Accuracy: 0.7230, Validation Accuracy: 0.7266, Loss: 0.2878
Epoch  29 Batch  130/1077 - Train Accuracy: 0.7437, Validation Accuracy: 0.7294, Loss: 0.2611
Epoch  29 Batch  140/1077 - Train Accuracy: 0.7533, Validation Accuracy: 0.7184, Loss: 0.2717
Epoch  29 Batch  150/1077 - Train Accuracy: 0.7574, Validation Accuracy: 0.7177, Loss: 0.2514
Epoch  29 Batch  160/1077 - Train Accuracy: 0.7395, Validation Accuracy: 0.7262, Loss: 0.2696
Epoch  29 Batch  170/1077 - Train Accuracy: 0.7039, Validation Accuracy: 0.7227, Loss: 0.2809
Epoch  29 Batch  180/1077 - Train Accuracy: 0.7547, Validation Accuracy: 0.7188, Loss: 0.2664
Epoch  29 Batch  190/1077 - Train Accuracy: 0.7711, Validation Accuracy: 0.7063, Loss: 0.2622
Epoch  29 Batch  200/1077 - Train Accuracy: 0.7406, Validation Accuracy: 0.7124, Loss: 0.2693
Epoch  29 Batch  210/1077 - Train Accuracy: 0.7582, Validation Accuracy: 0.7131, Loss: 0.2775
Epoch  29 Batch  220/1077 - Train Accuracy: 0.7385, Validation Accuracy: 0.7287, Loss: 0.2791
Epoch  29 Batch  230/1077 - Train Accuracy: 0.7500, Validation Accuracy: 0.7273, Loss: 0.2565
Epoch  29 Batch  240/1077 - Train Accuracy: 0.8027, Validation Accuracy: 0.7244, Loss: 0.2637
Epoch  29 Batch  250/1077 - Train Accuracy: 0.7372, Validation Accuracy: 0.7216, Loss: 0.2537
Epoch  29 Batch  260/1077 - Train Accuracy: 0.7526, Validation Accuracy: 0.7308, Loss: 0.2485
Epoch  29 Batch  270/1077 - Train Accuracy: 0.7441, Validation Accuracy: 0.7298, Loss: 0.2804
Epoch  29 Batch  280/1077 - Train Accuracy: 0.7293, Validation Accuracy: 0.7195, Loss: 0.2637
Epoch  29 Batch  290/1077 - Train Accuracy: 0.7258, Validation Accuracy: 0.7266, Loss: 0.2884
Epoch  29 Batch  300/1077 - Train Accuracy: 0.7442, Validation Accuracy: 0.7301, Loss: 0.2614
Epoch  29 Batch  310/1077 - Train Accuracy: 0.7199, Validation Accuracy: 0.7251, Loss: 0.2886
Epoch  29 Batch  320/1077 - Train Accuracy: 0.7766, Validation Accuracy: 0.7337, Loss: 0.3029
Epoch  29 Batch  330/1077 - Train Accuracy: 0.7699, Validation Accuracy: 0.7294, Loss: 0.2716
Epoch  29 Batch  340/1077 - Train Accuracy: 0.7447, Validation Accuracy: 0.7280, Loss: 0.2694
Epoch  29 Batch  350/1077 - Train Accuracy: 0.7539, Validation Accuracy: 0.7227, Loss: 0.2569
Epoch  29 Batch  360/1077 - Train Accuracy: 0.7281, Validation Accuracy: 0.7195, Loss: 0.2839
Epoch  29 Batch  370/1077 - Train Accuracy: 0.7649, Validation Accuracy: 0.7273, Loss: 0.2675
Epoch  29 Batch  380/1077 - Train Accuracy: 0.7375, Validation Accuracy: 0.7283, Loss: 0.2507
Epoch  29 Batch  390/1077 - Train Accuracy: 0.6723, Validation Accuracy: 0.7131, Loss: 0.2871
Epoch  29 Batch  400/1077 - Train Accuracy: 0.7637, Validation Accuracy: 0.7326, Loss: 0.2701
Epoch  29 Batch  410/1077 - Train Accuracy: 0.7368, Validation Accuracy: 0.7312, Loss: 0.2825
Epoch  29 Batch  420/1077 - Train Accuracy: 0.7742, Validation Accuracy: 0.7237, Loss: 0.2557
Epoch  29 Batch  430/1077 - Train Accuracy: 0.7148, Validation Accuracy: 0.7290, Loss: 0.2660
Epoch  29 Batch  440/1077 - Train Accuracy: 0.7121, Validation Accuracy: 0.7230, Loss: 0.2780
Epoch  29 Batch  450/1077 - Train Accuracy: 0.7738, Validation Accuracy: 0.7223, Loss: 0.2649
Epoch  29 Batch  460/1077 - Train Accuracy: 0.7195, Validation Accuracy: 0.7173, Loss: 0.2756
Epoch  29 Batch  470/1077 - Train Accuracy: 0.7241, Validation Accuracy: 0.7180, Loss: 0.2818
Epoch  29 Batch  480/1077 - Train Accuracy: 0.7496, Validation Accuracy: 0.7330, Loss: 0.2805
Epoch  29 Batch  490/1077 - Train Accuracy: 0.7141, Validation Accuracy: 0.7269, Loss: 0.2780
Epoch  29 Batch  500/1077 - Train Accuracy: 0.7875, Validation Accuracy: 0.7223, Loss: 0.2568
Epoch  29 Batch  510/1077 - Train Accuracy: 0.7629, Validation Accuracy: 0.7223, Loss: 0.2654
Epoch  29 Batch  520/1077 - Train Accuracy: 0.8095, Validation Accuracy: 0.7369, Loss: 0.2392
Epoch  29 Batch  530/1077 - Train Accuracy: 0.7027, Validation Accuracy: 0.7244, Loss: 0.2907
Epoch  29 Batch  540/1077 - Train Accuracy: 0.7684, Validation Accuracy: 0.7237, Loss: 0.2766
Epoch  29 Batch  550/1077 - Train Accuracy: 0.7051, Validation Accuracy: 0.7269, Loss: 0.2784
Epoch  29 Batch  560/1077 - Train Accuracy: 0.7359, Validation Accuracy: 0.7429, Loss: 0.2657
Epoch  29 Batch  570/1077 - Train Accuracy: 0.7385, Validation Accuracy: 0.7482, Loss: 0.2932
Epoch  29 Batch  580/1077 - Train Accuracy: 0.7533, Validation Accuracy: 0.7433, Loss: 0.2466
Epoch  29 Batch  590/1077 - Train Accuracy: 0.7109, Validation Accuracy: 0.7390, Loss: 0.2913
Epoch  29 Batch  600/1077 - Train Accuracy: 0.7723, Validation Accuracy: 0.7290, Loss: 0.2563
Epoch  29 Batch  610/1077 - Train Accuracy: 0.7052, Validation Accuracy: 0.7177, Loss: 0.2771
Epoch  29 Batch  620/1077 - Train Accuracy: 0.7379, Validation Accuracy: 0.7305, Loss: 0.2534
Epoch  29 Batch  630/1077 - Train Accuracy: 0.7473, Validation Accuracy: 0.7369, Loss: 0.2558
Epoch  29 Batch  640/1077 - Train Accuracy: 0.7582, Validation Accuracy: 0.7475, Loss: 0.2535
Epoch  29 Batch  650/1077 - Train Accuracy: 0.7082, Validation Accuracy: 0.7354, Loss: 0.2811
Epoch  29 Batch  660/1077 - Train Accuracy: 0.7668, Validation Accuracy: 0.7251, Loss: 0.2722
Epoch  29 Batch  670/1077 - Train Accuracy: 0.7692, Validation Accuracy: 0.7294, Loss: 0.2530
Epoch  29 Batch  680/1077 - Train Accuracy: 0.7292, Validation Accuracy: 0.7401, Loss: 0.2698
Epoch  29 Batch  690/1077 - Train Accuracy: 0.7469, Validation Accuracy: 0.7163, Loss: 0.2705
Epoch  29 Batch  700/1077 - Train Accuracy: 0.7660, Validation Accuracy: 0.7330, Loss: 0.2524
Epoch  29 Batch  710/1077 - Train Accuracy: 0.7086, Validation Accuracy: 0.7337, Loss: 0.2665
Epoch  29 Batch  720/1077 - Train Accuracy: 0.7525, Validation Accuracy: 0.7283, Loss: 0.2827
Epoch  29 Batch  730/1077 - Train Accuracy: 0.7430, Validation Accuracy: 0.7262, Loss: 0.2722
Epoch  29 Batch  740/1077 - Train Accuracy: 0.7367, Validation Accuracy: 0.7163, Loss: 0.2598
Epoch  29 Batch  750/1077 - Train Accuracy: 0.7754, Validation Accuracy: 0.7376, Loss: 0.2606
Epoch  29 Batch  760/1077 - Train Accuracy: 0.7434, Validation Accuracy: 0.7358, Loss: 0.2738
Epoch  29 Batch  770/1077 - Train Accuracy: 0.7440, Validation Accuracy: 0.7230, Loss: 0.2536
Epoch  29 Batch  780/1077 - Train Accuracy: 0.7148, Validation Accuracy: 0.7308, Loss: 0.2819
Epoch  29 Batch  790/1077 - Train Accuracy: 0.6703, Validation Accuracy: 0.7287, Loss: 0.2861
Epoch  29 Batch  800/1077 - Train Accuracy: 0.7305, Validation Accuracy: 0.7383, Loss: 0.2805
Epoch  29 Batch  810/1077 - Train Accuracy: 0.7522, Validation Accuracy: 0.7436, Loss: 0.2559
Epoch  29 Batch  820/1077 - Train Accuracy: 0.6906, Validation Accuracy: 0.7333, Loss: 0.2861
Epoch  29 Batch  830/1077 - Train Accuracy: 0.7020, Validation Accuracy: 0.7393, Loss: 0.2675
Epoch  29 Batch  840/1077 - Train Accuracy: 0.7469, Validation Accuracy: 0.7333, Loss: 0.2691
Epoch  29 Batch  850/1077 - Train Accuracy: 0.7333, Validation Accuracy: 0.7283, Loss: 0.2875
Epoch  29 Batch  860/1077 - Train Accuracy: 0.7303, Validation Accuracy: 0.7305, Loss: 0.2622
Epoch  29 Batch  870/1077 - Train Accuracy: 0.7155, Validation Accuracy: 0.7294, Loss: 0.2823
Epoch  29 Batch  880/1077 - Train Accuracy: 0.7785, Validation Accuracy: 0.7227, Loss: 0.2670
Epoch  29 Batch  890/1077 - Train Accuracy: 0.7876, Validation Accuracy: 0.7305, Loss: 0.2569
Epoch  29 Batch  900/1077 - Train Accuracy: 0.7664, Validation Accuracy: 0.7401, Loss: 0.2671
Epoch  29 Batch  910/1077 - Train Accuracy: 0.7615, Validation Accuracy: 0.7276, Loss: 0.2781
Epoch  29 Batch  920/1077 - Train Accuracy: 0.7508, Validation Accuracy: 0.7219, Loss: 0.2742
Epoch  29 Batch  930/1077 - Train Accuracy: 0.7676, Validation Accuracy: 0.7259, Loss: 0.2609
Epoch  29 Batch  940/1077 - Train Accuracy: 0.7801, Validation Accuracy: 0.7415, Loss: 0.2539
Epoch  29 Batch  950/1077 - Train Accuracy: 0.7626, Validation Accuracy: 0.7358, Loss: 0.2491
Epoch  29 Batch  960/1077 - Train Accuracy: 0.7452, Validation Accuracy: 0.7276, Loss: 0.2588
Epoch  29 Batch  970/1077 - Train Accuracy: 0.7449, Validation Accuracy: 0.7124, Loss: 0.2768
Epoch  29 Batch  980/1077 - Train Accuracy: 0.7227, Validation Accuracy: 0.7244, Loss: 0.2695
Epoch  29 Batch  990/1077 - Train Accuracy: 0.7512, Validation Accuracy: 0.7496, Loss: 0.2914
Epoch  29 Batch 1000/1077 - Train Accuracy: 0.7794, Validation Accuracy: 0.7450, Loss: 0.2470
Epoch  29 Batch 1010/1077 - Train Accuracy: 0.7375, Validation Accuracy: 0.7362, Loss: 0.2747
Epoch  29 Batch 1020/1077 - Train Accuracy: 0.7578, Validation Accuracy: 0.7340, Loss: 0.2673
Epoch  29 Batch 1030/1077 - Train Accuracy: 0.7238, Validation Accuracy: 0.7294, Loss: 0.2858
Epoch  29 Batch 1040/1077 - Train Accuracy: 0.7808, Validation Accuracy: 0.7262, Loss: 0.2698
Epoch  29 Batch 1050/1077 - Train Accuracy: 0.6957, Validation Accuracy: 0.7259, Loss: 0.2660
Epoch  29 Batch 1060/1077 - Train Accuracy: 0.7910, Validation Accuracy: 0.7156, Loss: 0.2456
Epoch  29 Batch 1070/1077 - Train Accuracy: 0.7531, Validation Accuracy: 0.7283, Loss: 0.2887
Epoch  30 Batch   10/1077 - Train Accuracy: 0.7492, Validation Accuracy: 0.7390, Loss: 0.2840
Epoch  30 Batch   20/1077 - Train Accuracy: 0.7215, Validation Accuracy: 0.7227, Loss: 0.2612
Epoch  30 Batch   30/1077 - Train Accuracy: 0.7641, Validation Accuracy: 0.7145, Loss: 0.2582
Epoch  30 Batch   40/1077 - Train Accuracy: 0.7566, Validation Accuracy: 0.7202, Loss: 0.2762
Epoch  30 Batch   50/1077 - Train Accuracy: 0.7363, Validation Accuracy: 0.7461, Loss: 0.2675
Epoch  30 Batch   60/1077 - Train Accuracy: 0.7422, Validation Accuracy: 0.7411, Loss: 0.2471
Epoch  30 Batch   70/1077 - Train Accuracy: 0.7780, Validation Accuracy: 0.7234, Loss: 0.2710
Epoch  30 Batch   80/1077 - Train Accuracy: 0.7250, Validation Accuracy: 0.7195, Loss: 0.2659
Epoch  30 Batch   90/1077 - Train Accuracy: 0.7219, Validation Accuracy: 0.7269, Loss: 0.2767
Epoch  30 Batch  100/1077 - Train Accuracy: 0.7281, Validation Accuracy: 0.7479, Loss: 0.2556
Epoch  30 Batch  110/1077 - Train Accuracy: 0.7430, Validation Accuracy: 0.7337, Loss: 0.2428
Epoch  30 Batch  120/1077 - Train Accuracy: 0.7309, Validation Accuracy: 0.7333, Loss: 0.2755
Epoch  30 Batch  130/1077 - Train Accuracy: 0.7411, Validation Accuracy: 0.7365, Loss: 0.2536
Epoch  30 Batch  140/1077 - Train Accuracy: 0.7455, Validation Accuracy: 0.7358, Loss: 0.2696
Epoch  30 Batch  150/1077 - Train Accuracy: 0.7716, Validation Accuracy: 0.7372, Loss: 0.2504
Epoch  30 Batch  160/1077 - Train Accuracy: 0.7434, Validation Accuracy: 0.7365, Loss: 0.2678
Epoch  30 Batch  170/1077 - Train Accuracy: 0.6898, Validation Accuracy: 0.7205, Loss: 0.2829
Epoch  30 Batch  180/1077 - Train Accuracy: 0.7562, Validation Accuracy: 0.7230, Loss: 0.2500
Epoch  30 Batch  190/1077 - Train Accuracy: 0.7852, Validation Accuracy: 0.7269, Loss: 0.2556
Epoch  30 Batch  200/1077 - Train Accuracy: 0.7480, Validation Accuracy: 0.7212, Loss: 0.2650
Epoch  30 Batch  210/1077 - Train Accuracy: 0.7626, Validation Accuracy: 0.7223, Loss: 0.2642
Epoch  30 Batch  220/1077 - Train Accuracy: 0.7434, Validation Accuracy: 0.7212, Loss: 0.2675
Epoch  30 Batch  230/1077 - Train Accuracy: 0.7541, Validation Accuracy: 0.7337, Loss: 0.2587
Epoch  30 Batch  240/1077 - Train Accuracy: 0.7879, Validation Accuracy: 0.7365, Loss: 0.2595
Epoch  30 Batch  250/1077 - Train Accuracy: 0.7564, Validation Accuracy: 0.7351, Loss: 0.2531
Epoch  30 Batch  260/1077 - Train Accuracy: 0.7608, Validation Accuracy: 0.7290, Loss: 0.2403
Epoch  30 Batch  270/1077 - Train Accuracy: 0.7629, Validation Accuracy: 0.7237, Loss: 0.2672
Epoch  30 Batch  280/1077 - Train Accuracy: 0.7211, Validation Accuracy: 0.7351, Loss: 0.2610
Epoch  30 Batch  290/1077 - Train Accuracy: 0.7422, Validation Accuracy: 0.7344, Loss: 0.2801
Epoch  30 Batch  300/1077 - Train Accuracy: 0.7701, Validation Accuracy: 0.7283, Loss: 0.2552
Epoch  30 Batch  310/1077 - Train Accuracy: 0.7262, Validation Accuracy: 0.7184, Loss: 0.2855
Epoch  30 Batch  320/1077 - Train Accuracy: 0.7820, Validation Accuracy: 0.7290, Loss: 0.2921
Epoch  30 Batch  330/1077 - Train Accuracy: 0.7602, Validation Accuracy: 0.7383, Loss: 0.2617
Epoch  30 Batch  340/1077 - Train Accuracy: 0.7484, Validation Accuracy: 0.7312, Loss: 0.2678
Epoch  30 Batch  350/1077 - Train Accuracy: 0.7516, Validation Accuracy: 0.7259, Loss: 0.2474
Epoch  30 Batch  360/1077 - Train Accuracy: 0.7145, Validation Accuracy: 0.7219, Loss: 0.2572
Epoch  30 Batch  370/1077 - Train Accuracy: 0.7560, Validation Accuracy: 0.7312, Loss: 0.2686
Epoch  30 Batch  380/1077 - Train Accuracy: 0.7613, Validation Accuracy: 0.7276, Loss: 0.2558
Epoch  30 Batch  390/1077 - Train Accuracy: 0.6980, Validation Accuracy: 0.7131, Loss: 0.2826
Epoch  30 Batch  400/1077 - Train Accuracy: 0.7773, Validation Accuracy: 0.7347, Loss: 0.2667
Epoch  30 Batch  410/1077 - Train Accuracy: 0.7512, Validation Accuracy: 0.7308, Loss: 0.2824
Epoch  30 Batch  420/1077 - Train Accuracy: 0.7742, Validation Accuracy: 0.7188, Loss: 0.2408
Epoch  30 Batch  430/1077 - Train Accuracy: 0.7188, Validation Accuracy: 0.7120, Loss: 0.2608
Epoch  30 Batch  440/1077 - Train Accuracy: 0.7074, Validation Accuracy: 0.7141, Loss: 0.2814
Epoch  30 Batch  450/1077 - Train Accuracy: 0.7809, Validation Accuracy: 0.7191, Loss: 0.2595
Epoch  30 Batch  460/1077 - Train Accuracy: 0.7199, Validation Accuracy: 0.7234, Loss: 0.2863
Epoch  30 Batch  470/1077 - Train Accuracy: 0.7541, Validation Accuracy: 0.7298, Loss: 0.2800
Epoch  30 Batch  480/1077 - Train Accuracy: 0.7648, Validation Accuracy: 0.7362, Loss: 0.2850
Epoch  30 Batch  490/1077 - Train Accuracy: 0.7039, Validation Accuracy: 0.7273, Loss: 0.2750
Epoch  30 Batch  500/1077 - Train Accuracy: 0.7805, Validation Accuracy: 0.7333, Loss: 0.2545
Epoch  30 Batch  510/1077 - Train Accuracy: 0.7844, Validation Accuracy: 0.7237, Loss: 0.2605
Epoch  30 Batch  520/1077 - Train Accuracy: 0.7969, Validation Accuracy: 0.7347, Loss: 0.2396
Epoch  30 Batch  530/1077 - Train Accuracy: 0.6941, Validation Accuracy: 0.7234, Loss: 0.2884
Epoch  30 Batch  540/1077 - Train Accuracy: 0.7680, Validation Accuracy: 0.7347, Loss: 0.2463
Epoch  30 Batch  550/1077 - Train Accuracy: 0.7148, Validation Accuracy: 0.7287, Loss: 0.2829
Epoch  30 Batch  560/1077 - Train Accuracy: 0.7465, Validation Accuracy: 0.7425, Loss: 0.2532
Epoch  30 Batch  570/1077 - Train Accuracy: 0.7389, Validation Accuracy: 0.7422, Loss: 0.2832
Epoch  30 Batch  580/1077 - Train Accuracy: 0.7623, Validation Accuracy: 0.7408, Loss: 0.2400
Epoch  30 Batch  590/1077 - Train Accuracy: 0.7150, Validation Accuracy: 0.7376, Loss: 0.2765
Epoch  30 Batch  600/1077 - Train Accuracy: 0.7719, Validation Accuracy: 0.7177, Loss: 0.2516
Epoch  30 Batch  610/1077 - Train Accuracy: 0.7249, Validation Accuracy: 0.7202, Loss: 0.2750
Epoch  30 Batch  620/1077 - Train Accuracy: 0.7531, Validation Accuracy: 0.7145, Loss: 0.2384
Epoch  30 Batch  630/1077 - Train Accuracy: 0.7480, Validation Accuracy: 0.7255, Loss: 0.2581
Epoch  30 Batch  640/1077 - Train Accuracy: 0.7738, Validation Accuracy: 0.7425, Loss: 0.2509
Epoch  30 Batch  650/1077 - Train Accuracy: 0.7410, Validation Accuracy: 0.7457, Loss: 0.2672
Epoch  30 Batch  660/1077 - Train Accuracy: 0.7578, Validation Accuracy: 0.7358, Loss: 0.2680
Epoch  30 Batch  670/1077 - Train Accuracy: 0.7653, Validation Accuracy: 0.7198, Loss: 0.2397
Epoch  30 Batch  680/1077 - Train Accuracy: 0.7347, Validation Accuracy: 0.7372, Loss: 0.2861
Epoch  30 Batch  690/1077 - Train Accuracy: 0.7426, Validation Accuracy: 0.7198, Loss: 0.2563
Epoch  30 Batch  700/1077 - Train Accuracy: 0.7609, Validation Accuracy: 0.7308, Loss: 0.2494
Epoch  30 Batch  710/1077 - Train Accuracy: 0.7113, Validation Accuracy: 0.7358, Loss: 0.2636
Epoch  30 Batch  720/1077 - Train Accuracy: 0.7553, Validation Accuracy: 0.7191, Loss: 0.2799
Epoch  30 Batch  730/1077 - Train Accuracy: 0.7406, Validation Accuracy: 0.7330, Loss: 0.2653
Epoch  30 Batch  740/1077 - Train Accuracy: 0.7461, Validation Accuracy: 0.7234, Loss: 0.2607
Epoch  30 Batch  750/1077 - Train Accuracy: 0.7703, Validation Accuracy: 0.7351, Loss: 0.2701
Epoch  30 Batch  760/1077 - Train Accuracy: 0.7441, Validation Accuracy: 0.7379, Loss: 0.2584
Epoch  30 Batch  770/1077 - Train Accuracy: 0.7273, Validation Accuracy: 0.7290, Loss: 0.2477
Epoch  30 Batch  780/1077 - Train Accuracy: 0.7277, Validation Accuracy: 0.7280, Loss: 0.2812
Epoch  30 Batch  790/1077 - Train Accuracy: 0.6687, Validation Accuracy: 0.7305, Loss: 0.2752
Epoch  30 Batch  800/1077 - Train Accuracy: 0.7309, Validation Accuracy: 0.7386, Loss: 0.2523
Epoch  30 Batch  810/1077 - Train Accuracy: 0.7563, Validation Accuracy: 0.7425, Loss: 0.2435
Epoch  30 Batch  820/1077 - Train Accuracy: 0.6867, Validation Accuracy: 0.7358, Loss: 0.2745
Epoch  30 Batch  830/1077 - Train Accuracy: 0.7004, Validation Accuracy: 0.7408, Loss: 0.2660
Epoch  30 Batch  840/1077 - Train Accuracy: 0.7633, Validation Accuracy: 0.7369, Loss: 0.2579
Epoch  30 Batch  850/1077 - Train Accuracy: 0.7433, Validation Accuracy: 0.7365, Loss: 0.2811
Epoch  30 Batch  860/1077 - Train Accuracy: 0.7266, Validation Accuracy: 0.7266, Loss: 0.2666
Epoch  30 Batch  870/1077 - Train Accuracy: 0.7179, Validation Accuracy: 0.7315, Loss: 0.2807
Epoch  30 Batch  880/1077 - Train Accuracy: 0.7926, Validation Accuracy: 0.7312, Loss: 0.2603
Epoch  30 Batch  890/1077 - Train Accuracy: 0.7928, Validation Accuracy: 0.7290, Loss: 0.2551
Epoch  30 Batch  900/1077 - Train Accuracy: 0.7793, Validation Accuracy: 0.7322, Loss: 0.2655
Epoch  30 Batch  910/1077 - Train Accuracy: 0.7775, Validation Accuracy: 0.7330, Loss: 0.2621
Epoch  30 Batch  920/1077 - Train Accuracy: 0.7461, Validation Accuracy: 0.7287, Loss: 0.2616
Epoch  30 Batch  930/1077 - Train Accuracy: 0.7543, Validation Accuracy: 0.7450, Loss: 0.2515
Epoch  30 Batch  940/1077 - Train Accuracy: 0.7793, Validation Accuracy: 0.7383, Loss: 0.2536
Epoch  30 Batch  950/1077 - Train Accuracy: 0.7571, Validation Accuracy: 0.7340, Loss: 0.2363
Epoch  30 Batch  960/1077 - Train Accuracy: 0.7314, Validation Accuracy: 0.7358, Loss: 0.2552
Epoch  30 Batch  970/1077 - Train Accuracy: 0.7551, Validation Accuracy: 0.7184, Loss: 0.2743
Epoch  30 Batch  980/1077 - Train Accuracy: 0.7215, Validation Accuracy: 0.7269, Loss: 0.2777
Epoch  30 Batch  990/1077 - Train Accuracy: 0.7496, Validation Accuracy: 0.7486, Loss: 0.2850
Epoch  30 Batch 1000/1077 - Train Accuracy: 0.7932, Validation Accuracy: 0.7408, Loss: 0.2464
Epoch  30 Batch 1010/1077 - Train Accuracy: 0.7320, Validation Accuracy: 0.7433, Loss: 0.2630
Epoch  30 Batch 1020/1077 - Train Accuracy: 0.7469, Validation Accuracy: 0.7369, Loss: 0.2582
Epoch  30 Batch 1030/1077 - Train Accuracy: 0.7496, Validation Accuracy: 0.7429, Loss: 0.2755
Epoch  30 Batch 1040/1077 - Train Accuracy: 0.7718, Validation Accuracy: 0.7276, Loss: 0.2766
Epoch  30 Batch 1050/1077 - Train Accuracy: 0.6977, Validation Accuracy: 0.7259, Loss: 0.2526
Epoch  30 Batch 1060/1077 - Train Accuracy: 0.8117, Validation Accuracy: 0.7251, Loss: 0.2395
Epoch  30 Batch 1070/1077 - Train Accuracy: 0.7285, Validation Accuracy: 0.7386, Loss: 0.2581
Epoch  31 Batch   10/1077 - Train Accuracy: 0.7767, Validation Accuracy: 0.7390, Loss: 0.2771
Epoch  31 Batch   20/1077 - Train Accuracy: 0.7449, Validation Accuracy: 0.7287, Loss: 0.2519
Epoch  31 Batch   30/1077 - Train Accuracy: 0.7777, Validation Accuracy: 0.7244, Loss: 0.2597
Epoch  31 Batch   40/1077 - Train Accuracy: 0.7738, Validation Accuracy: 0.7280, Loss: 0.2625
Epoch  31 Batch   50/1077 - Train Accuracy: 0.7375, Validation Accuracy: 0.7518, Loss: 0.2604
Epoch  31 Batch   60/1077 - Train Accuracy: 0.7504, Validation Accuracy: 0.7486, Loss: 0.2483
Epoch  31 Batch   70/1077 - Train Accuracy: 0.7829, Validation Accuracy: 0.7376, Loss: 0.2799
Epoch  31 Batch   80/1077 - Train Accuracy: 0.7434, Validation Accuracy: 0.7347, Loss: 0.2687
Epoch  31 Batch   90/1077 - Train Accuracy: 0.7281, Validation Accuracy: 0.7308, Loss: 0.2746
Epoch  31 Batch  100/1077 - Train Accuracy: 0.7234, Validation Accuracy: 0.7493, Loss: 0.2565
Epoch  31 Batch  110/1077 - Train Accuracy: 0.7496, Validation Accuracy: 0.7422, Loss: 0.2368
Epoch  31 Batch  120/1077 - Train Accuracy: 0.7449, Validation Accuracy: 0.7457, Loss: 0.2763
Epoch  31 Batch  130/1077 - Train Accuracy: 0.7489, Validation Accuracy: 0.7404, Loss: 0.2495
Epoch  31 Batch  140/1077 - Train Accuracy: 0.7595, Validation Accuracy: 0.7372, Loss: 0.2629
Epoch  31 Batch  150/1077 - Train Accuracy: 0.7649, Validation Accuracy: 0.7362, Loss: 0.2488
Epoch  31 Batch  160/1077 - Train Accuracy: 0.7555, Validation Accuracy: 0.7305, Loss: 0.2577
Epoch  31 Batch  170/1077 - Train Accuracy: 0.7105, Validation Accuracy: 0.7298, Loss: 0.2936
Epoch  31 Batch  180/1077 - Train Accuracy: 0.7652, Validation Accuracy: 0.7237, Loss: 0.2538
Epoch  31 Batch  190/1077 - Train Accuracy: 0.7723, Validation Accuracy: 0.7312, Loss: 0.2545
Epoch  31 Batch  200/1077 - Train Accuracy: 0.7578, Validation Accuracy: 0.7255, Loss: 0.2712
Epoch  31 Batch  210/1077 - Train Accuracy: 0.7653, Validation Accuracy: 0.7294, Loss: 0.2598
Epoch  31 Batch  220/1077 - Train Accuracy: 0.7496, Validation Accuracy: 0.7180, Loss: 0.2771
Epoch  31 Batch  230/1077 - Train Accuracy: 0.7388, Validation Accuracy: 0.7287, Loss: 0.2492
Epoch  31 Batch  240/1077 - Train Accuracy: 0.8145, Validation Accuracy: 0.7283, Loss: 0.2539
Epoch  31 Batch  250/1077 - Train Accuracy: 0.7408, Validation Accuracy: 0.7351, Loss: 0.2484
Epoch  31 Batch  260/1077 - Train Accuracy: 0.7653, Validation Accuracy: 0.7251, Loss: 0.2419
Epoch  31 Batch  270/1077 - Train Accuracy: 0.7582, Validation Accuracy: 0.7362, Loss: 0.2690
Epoch  31 Batch  280/1077 - Train Accuracy: 0.7336, Validation Accuracy: 0.7276, Loss: 0.2616
Epoch  31 Batch  290/1077 - Train Accuracy: 0.7395, Validation Accuracy: 0.7266, Loss: 0.2658
Epoch  31 Batch  300/1077 - Train Accuracy: 0.7562, Validation Accuracy: 0.7266, Loss: 0.2582
Epoch  31 Batch  310/1077 - Train Accuracy: 0.7246, Validation Accuracy: 0.7262, Loss: 0.2694
Epoch  31 Batch  320/1077 - Train Accuracy: 0.7863, Validation Accuracy: 0.7358, Loss: 0.2852
Epoch  31 Batch  330/1077 - Train Accuracy: 0.7480, Validation Accuracy: 0.7369, Loss: 0.2566
Epoch  31 Batch  340/1077 - Train Accuracy: 0.7566, Validation Accuracy: 0.7283, Loss: 0.2660
Epoch  31 Batch  350/1077 - Train Accuracy: 0.7551, Validation Accuracy: 0.7312, Loss: 0.2577
Epoch  31 Batch  360/1077 - Train Accuracy: 0.7266, Validation Accuracy: 0.7290, Loss: 0.2625
Epoch  31 Batch  370/1077 - Train Accuracy: 0.7742, Validation Accuracy: 0.7290, Loss: 0.2720
Epoch  31 Batch  380/1077 - Train Accuracy: 0.7617, Validation Accuracy: 0.7290, Loss: 0.2594
Epoch  31 Batch  390/1077 - Train Accuracy: 0.7063, Validation Accuracy: 0.7390, Loss: 0.2756
Epoch  31 Batch  400/1077 - Train Accuracy: 0.7750, Validation Accuracy: 0.7319, Loss: 0.2773
Epoch  31 Batch  410/1077 - Train Accuracy: 0.7471, Validation Accuracy: 0.7450, Loss: 0.2710
Epoch  31 Batch  420/1077 - Train Accuracy: 0.7664, Validation Accuracy: 0.7266, Loss: 0.2577
Epoch  31 Batch  430/1077 - Train Accuracy: 0.7391, Validation Accuracy: 0.7333, Loss: 0.2565
Epoch  31 Batch  440/1077 - Train Accuracy: 0.7137, Validation Accuracy: 0.7202, Loss: 0.2692
Epoch  31 Batch  450/1077 - Train Accuracy: 0.7793, Validation Accuracy: 0.7202, Loss: 0.2541
Epoch  31 Batch  460/1077 - Train Accuracy: 0.7250, Validation Accuracy: 0.7259, Loss: 0.2633
Epoch  31 Batch  470/1077 - Train Accuracy: 0.7615, Validation Accuracy: 0.7354, Loss: 0.2610
Epoch  31 Batch  480/1077 - Train Accuracy: 0.7722, Validation Accuracy: 0.7362, Loss: 0.2526
Epoch  31 Batch  490/1077 - Train Accuracy: 0.7164, Validation Accuracy: 0.7312, Loss: 0.2703
Epoch  31 Batch  500/1077 - Train Accuracy: 0.7820, Validation Accuracy: 0.7365, Loss: 0.2441
Epoch  31 Batch  510/1077 - Train Accuracy: 0.7848, Validation Accuracy: 0.7298, Loss: 0.2567
Epoch  31 Batch  520/1077 - Train Accuracy: 0.8025, Validation Accuracy: 0.7290, Loss: 0.2293
Epoch  31 Batch  530/1077 - Train Accuracy: 0.7137, Validation Accuracy: 0.7351, Loss: 0.2629
Epoch  31 Batch  540/1077 - Train Accuracy: 0.7719, Validation Accuracy: 0.7290, Loss: 0.2373
Epoch  31 Batch  550/1077 - Train Accuracy: 0.7180, Validation Accuracy: 0.7372, Loss: 0.2749
Epoch  31 Batch  560/1077 - Train Accuracy: 0.7465, Validation Accuracy: 0.7457, Loss: 0.2420
Epoch  31 Batch  570/1077 - Train Accuracy: 0.7368, Validation Accuracy: 0.7415, Loss: 0.2862
Epoch  31 Batch  580/1077 - Train Accuracy: 0.7548, Validation Accuracy: 0.7372, Loss: 0.2333
Epoch  31 Batch  590/1077 - Train Accuracy: 0.7179, Validation Accuracy: 0.7454, Loss: 0.2788
Epoch  31 Batch  600/1077 - Train Accuracy: 0.7638, Validation Accuracy: 0.7337, Loss: 0.2408
Epoch  31 Batch  610/1077 - Train Accuracy: 0.7249, Validation Accuracy: 0.7322, Loss: 0.2743
Epoch  31 Batch  620/1077 - Train Accuracy: 0.7547, Validation Accuracy: 0.7401, Loss: 0.2503
Epoch  31 Batch  630/1077 - Train Accuracy: 0.7590, Validation Accuracy: 0.7383, Loss: 0.2499
Epoch  31 Batch  640/1077 - Train Accuracy: 0.7686, Validation Accuracy: 0.7475, Loss: 0.2410
Epoch  31 Batch  650/1077 - Train Accuracy: 0.7465, Validation Accuracy: 0.7372, Loss: 0.2605
Epoch  31 Batch  660/1077 - Train Accuracy: 0.7684, Validation Accuracy: 0.7330, Loss: 0.2656
Epoch  31 Batch  670/1077 - Train Accuracy: 0.7752, Validation Accuracy: 0.7393, Loss: 0.2443
Epoch  31 Batch  680/1077 - Train Accuracy: 0.7400, Validation Accuracy: 0.7401, Loss: 0.2742
Epoch  31 Batch  690/1077 - Train Accuracy: 0.7605, Validation Accuracy: 0.7301, Loss: 0.2739
Epoch  31 Batch  700/1077 - Train Accuracy: 0.7613, Validation Accuracy: 0.7457, Loss: 0.2368
Epoch  31 Batch  710/1077 - Train Accuracy: 0.7129, Validation Accuracy: 0.7425, Loss: 0.2497
Epoch  31 Batch  720/1077 - Train Accuracy: 0.7434, Validation Accuracy: 0.7234, Loss: 0.2800
Epoch  31 Batch  730/1077 - Train Accuracy: 0.7527, Validation Accuracy: 0.7269, Loss: 0.2667
Epoch  31 Batch  740/1077 - Train Accuracy: 0.7504, Validation Accuracy: 0.7287, Loss: 0.2536
Epoch  31 Batch  750/1077 - Train Accuracy: 0.7590, Validation Accuracy: 0.7337, Loss: 0.2546
Epoch  31 Batch  760/1077 - Train Accuracy: 0.7480, Validation Accuracy: 0.7429, Loss: 0.2587
Epoch  31 Batch  770/1077 - Train Accuracy: 0.7526, Validation Accuracy: 0.7386, Loss: 0.2361
Epoch  31 Batch  780/1077 - Train Accuracy: 0.7258, Validation Accuracy: 0.7259, Loss: 0.2770
Epoch  31 Batch  790/1077 - Train Accuracy: 0.6914, Validation Accuracy: 0.7290, Loss: 0.2819
Epoch  31 Batch  800/1077 - Train Accuracy: 0.7395, Validation Accuracy: 0.7365, Loss: 0.2523
Epoch  31 Batch  810/1077 - Train Accuracy: 0.7526, Validation Accuracy: 0.7479, Loss: 0.2323
Epoch  31 Batch  820/1077 - Train Accuracy: 0.6891, Validation Accuracy: 0.7411, Loss: 0.2699
Epoch  31 Batch  830/1077 - Train Accuracy: 0.7160, Validation Accuracy: 0.7322, Loss: 0.2589
Epoch  31 Batch  840/1077 - Train Accuracy: 0.7574, Validation Accuracy: 0.7472, Loss: 0.2609
Epoch  31 Batch  850/1077 - Train Accuracy: 0.7519, Validation Accuracy: 0.7354, Loss: 0.2848
Epoch  31 Batch  860/1077 - Train Accuracy: 0.7314, Validation Accuracy: 0.7461, Loss: 0.2645
Epoch  31 Batch  870/1077 - Train Accuracy: 0.7179, Validation Accuracy: 0.7362, Loss: 0.2687
Epoch  31 Batch  880/1077 - Train Accuracy: 0.7848, Validation Accuracy: 0.7376, Loss: 0.2583
Epoch  31 Batch  890/1077 - Train Accuracy: 0.8006, Validation Accuracy: 0.7447, Loss: 0.2305
Epoch  31 Batch  900/1077 - Train Accuracy: 0.7766, Validation Accuracy: 0.7401, Loss: 0.2671
Epoch  31 Batch  910/1077 - Train Accuracy: 0.7790, Validation Accuracy: 0.7411, Loss: 0.2510
Epoch  31 Batch  920/1077 - Train Accuracy: 0.7535, Validation Accuracy: 0.7305, Loss: 0.2659
Epoch  31 Batch  930/1077 - Train Accuracy: 0.7598, Validation Accuracy: 0.7457, Loss: 0.2469
Epoch  31 Batch  940/1077 - Train Accuracy: 0.7629, Validation Accuracy: 0.7376, Loss: 0.2410
Epoch  31 Batch  950/1077 - Train Accuracy: 0.7675, Validation Accuracy: 0.7372, Loss: 0.2557
Epoch  31 Batch  960/1077 - Train Accuracy: 0.7347, Validation Accuracy: 0.7358, Loss: 0.2538
Epoch  31 Batch  970/1077 - Train Accuracy: 0.7480, Validation Accuracy: 0.7156, Loss: 0.2615
Epoch  31 Batch  980/1077 - Train Accuracy: 0.7285, Validation Accuracy: 0.7273, Loss: 0.2706
Epoch  31 Batch  990/1077 - Train Accuracy: 0.7492, Validation Accuracy: 0.7521, Loss: 0.2707
Epoch  31 Batch 1000/1077 - Train Accuracy: 0.7876, Validation Accuracy: 0.7514, Loss: 0.2413
Epoch  31 Batch 1010/1077 - Train Accuracy: 0.7512, Validation Accuracy: 0.7386, Loss: 0.2510
Epoch  31 Batch 1020/1077 - Train Accuracy: 0.7551, Validation Accuracy: 0.7422, Loss: 0.2485
Epoch  31 Batch 1030/1077 - Train Accuracy: 0.7355, Validation Accuracy: 0.7411, Loss: 0.2980
Epoch  31 Batch 1040/1077 - Train Accuracy: 0.7866, Validation Accuracy: 0.7280, Loss: 0.2553
Epoch  31 Batch 1050/1077 - Train Accuracy: 0.6941, Validation Accuracy: 0.7209, Loss: 0.2518
Epoch  31 Batch 1060/1077 - Train Accuracy: 0.7930, Validation Accuracy: 0.7330, Loss: 0.2404
Epoch  31 Batch 1070/1077 - Train Accuracy: 0.7406, Validation Accuracy: 0.7337, Loss: 0.2595
Epoch  32 Batch   10/1077 - Train Accuracy: 0.7632, Validation Accuracy: 0.7212, Loss: 0.2755
Epoch  32 Batch   20/1077 - Train Accuracy: 0.7555, Validation Accuracy: 0.7209, Loss: 0.2550
Epoch  32 Batch   30/1077 - Train Accuracy: 0.7879, Validation Accuracy: 0.7266, Loss: 0.2566
Epoch  32 Batch   40/1077 - Train Accuracy: 0.7754, Validation Accuracy: 0.7266, Loss: 0.2482
Epoch  32 Batch   50/1077 - Train Accuracy: 0.7469, Validation Accuracy: 0.7479, Loss: 0.2650
Epoch  32 Batch   60/1077 - Train Accuracy: 0.7578, Validation Accuracy: 0.7493, Loss: 0.2380
Epoch  32 Batch   70/1077 - Train Accuracy: 0.7788, Validation Accuracy: 0.7393, Loss: 0.2548
Epoch  32 Batch   80/1077 - Train Accuracy: 0.7469, Validation Accuracy: 0.7212, Loss: 0.2593
Epoch  32 Batch   90/1077 - Train Accuracy: 0.7387, Validation Accuracy: 0.7290, Loss: 0.2573
Epoch  32 Batch  100/1077 - Train Accuracy: 0.7328, Validation Accuracy: 0.7514, Loss: 0.2561
Epoch  32 Batch  110/1077 - Train Accuracy: 0.7535, Validation Accuracy: 0.7404, Loss: 0.2379
Epoch  32 Batch  120/1077 - Train Accuracy: 0.7543, Validation Accuracy: 0.7255, Loss: 0.2633
Epoch  32 Batch  130/1077 - Train Accuracy: 0.7519, Validation Accuracy: 0.7408, Loss: 0.2472
Epoch  32 Batch  140/1077 - Train Accuracy: 0.7652, Validation Accuracy: 0.7319, Loss: 0.2614
Epoch  32 Batch  150/1077 - Train Accuracy: 0.7645, Validation Accuracy: 0.7404, Loss: 0.2384
Epoch  32 Batch  160/1077 - Train Accuracy: 0.7492, Validation Accuracy: 0.7376, Loss: 0.2544
Epoch  32 Batch  170/1077 - Train Accuracy: 0.7016, Validation Accuracy: 0.7379, Loss: 0.2651
Epoch  32 Batch  180/1077 - Train Accuracy: 0.7676, Validation Accuracy: 0.7241, Loss: 0.2416
Epoch  32 Batch  190/1077 - Train Accuracy: 0.7812, Validation Accuracy: 0.7383, Loss: 0.2501
Epoch  32 Batch  200/1077 - Train Accuracy: 0.7484, Validation Accuracy: 0.7393, Loss: 0.2620
Epoch  32 Batch  210/1077 - Train Accuracy: 0.7656, Validation Accuracy: 0.7298, Loss: 0.2512
Epoch  32 Batch  220/1077 - Train Accuracy: 0.7669, Validation Accuracy: 0.7230, Loss: 0.2597
Epoch  32 Batch  230/1077 - Train Accuracy: 0.7377, Validation Accuracy: 0.7298, Loss: 0.2383
Epoch  32 Batch  240/1077 - Train Accuracy: 0.8082, Validation Accuracy: 0.7273, Loss: 0.2298
Epoch  32 Batch  250/1077 - Train Accuracy: 0.7436, Validation Accuracy: 0.7298, Loss: 0.2394
Epoch  32 Batch  260/1077 - Train Accuracy: 0.7708, Validation Accuracy: 0.7415, Loss: 0.2424
Epoch  32 Batch  270/1077 - Train Accuracy: 0.7484, Validation Accuracy: 0.7415, Loss: 0.2696
Epoch  32 Batch  280/1077 - Train Accuracy: 0.7312, Validation Accuracy: 0.7454, Loss: 0.2719
Epoch  32 Batch  290/1077 - Train Accuracy: 0.7273, Validation Accuracy: 0.7376, Loss: 0.2539
Epoch  32 Batch  300/1077 - Train Accuracy: 0.7738, Validation Accuracy: 0.7390, Loss: 0.2532
Epoch  32 Batch  310/1077 - Train Accuracy: 0.7355, Validation Accuracy: 0.7333, Loss: 0.2828
Epoch  32 Batch  320/1077 - Train Accuracy: 0.7742, Validation Accuracy: 0.7411, Loss: 0.2930
Epoch  32 Batch  330/1077 - Train Accuracy: 0.7574, Validation Accuracy: 0.7504, Loss: 0.2607
Epoch  32 Batch  340/1077 - Train Accuracy: 0.7512, Validation Accuracy: 0.7415, Loss: 0.2507
Epoch  32 Batch  350/1077 - Train Accuracy: 0.7574, Validation Accuracy: 0.7280, Loss: 0.2496
Epoch  32 Batch  360/1077 - Train Accuracy: 0.7355, Validation Accuracy: 0.7212, Loss: 0.2537
Epoch  32 Batch  370/1077 - Train Accuracy: 0.7768, Validation Accuracy: 0.7369, Loss: 0.2435
Epoch  32 Batch  380/1077 - Train Accuracy: 0.7660, Validation Accuracy: 0.7344, Loss: 0.2367
Epoch  32 Batch  390/1077 - Train Accuracy: 0.7113, Validation Accuracy: 0.7344, Loss: 0.2724
Epoch  32 Batch  400/1077 - Train Accuracy: 0.7777, Validation Accuracy: 0.7337, Loss: 0.2623
Epoch  32 Batch  410/1077 - Train Accuracy: 0.7570, Validation Accuracy: 0.7386, Loss: 0.2558
Epoch  32 Batch  420/1077 - Train Accuracy: 0.7676, Validation Accuracy: 0.7401, Loss: 0.2344
Epoch  32 Batch  430/1077 - Train Accuracy: 0.7176, Validation Accuracy: 0.7376, Loss: 0.2553
Epoch  32 Batch  440/1077 - Train Accuracy: 0.7047, Validation Accuracy: 0.7298, Loss: 0.2686
Epoch  32 Batch  450/1077 - Train Accuracy: 0.7918, Validation Accuracy: 0.7266, Loss: 0.2582
Epoch  32 Batch  460/1077 - Train Accuracy: 0.7449, Validation Accuracy: 0.7266, Loss: 0.2665
Epoch  32 Batch  470/1077 - Train Accuracy: 0.7697, Validation Accuracy: 0.7280, Loss: 0.2664
Epoch  32 Batch  480/1077 - Train Accuracy: 0.7578, Validation Accuracy: 0.7365, Loss: 0.2524
Epoch  32 Batch  490/1077 - Train Accuracy: 0.7219, Validation Accuracy: 0.7397, Loss: 0.2620
Epoch  32 Batch  500/1077 - Train Accuracy: 0.7957, Validation Accuracy: 0.7386, Loss: 0.2369
Epoch  32 Batch  510/1077 - Train Accuracy: 0.7738, Validation Accuracy: 0.7440, Loss: 0.2351
Epoch  32 Batch  520/1077 - Train Accuracy: 0.8192, Validation Accuracy: 0.7422, Loss: 0.2299
Epoch  32 Batch  530/1077 - Train Accuracy: 0.7211, Validation Accuracy: 0.7273, Loss: 0.2700
Epoch  32 Batch  540/1077 - Train Accuracy: 0.7605, Validation Accuracy: 0.7241, Loss: 0.2340
Epoch  32 Batch  550/1077 - Train Accuracy: 0.7145, Validation Accuracy: 0.7401, Loss: 0.2639
Epoch  32 Batch  560/1077 - Train Accuracy: 0.7598, Validation Accuracy: 0.7528, Loss: 0.2461
Epoch  32 Batch  570/1077 - Train Accuracy: 0.7558, Validation Accuracy: 0.7511, Loss: 0.2836
Epoch  32 Batch  580/1077 - Train Accuracy: 0.7764, Validation Accuracy: 0.7472, Loss: 0.2330
Epoch  32 Batch  590/1077 - Train Accuracy: 0.7241, Validation Accuracy: 0.7369, Loss: 0.2720
Epoch  32 Batch  600/1077 - Train Accuracy: 0.7619, Validation Accuracy: 0.7390, Loss: 0.2481
Epoch  32 Batch  610/1077 - Train Accuracy: 0.7262, Validation Accuracy: 0.7408, Loss: 0.2478
Epoch  32 Batch  620/1077 - Train Accuracy: 0.7344, Validation Accuracy: 0.7390, Loss: 0.2487
Epoch  32 Batch  630/1077 - Train Accuracy: 0.7496, Validation Accuracy: 0.7276, Loss: 0.2506
Epoch  32 Batch  640/1077 - Train Accuracy: 0.7775, Validation Accuracy: 0.7532, Loss: 0.2361
Epoch  32 Batch  650/1077 - Train Accuracy: 0.7535, Validation Accuracy: 0.7461, Loss: 0.2458
Epoch  32 Batch  660/1077 - Train Accuracy: 0.7676, Validation Accuracy: 0.7482, Loss: 0.2680
Epoch  32 Batch  670/1077 - Train Accuracy: 0.7837, Validation Accuracy: 0.7436, Loss: 0.2364
Epoch  32 Batch  680/1077 - Train Accuracy: 0.7281, Validation Accuracy: 0.7347, Loss: 0.2766
Epoch  32 Batch  690/1077 - Train Accuracy: 0.7656, Validation Accuracy: 0.7337, Loss: 0.2525
Epoch  32 Batch  700/1077 - Train Accuracy: 0.7684, Validation Accuracy: 0.7308, Loss: 0.2408
Epoch  32 Batch  710/1077 - Train Accuracy: 0.7180, Validation Accuracy: 0.7401, Loss: 0.2530
Epoch  32 Batch  720/1077 - Train Accuracy: 0.7307, Validation Accuracy: 0.7237, Loss: 0.2727
Epoch  32 Batch  730/1077 - Train Accuracy: 0.7559, Validation Accuracy: 0.7312, Loss: 0.2575
Epoch  32 Batch  740/1077 - Train Accuracy: 0.7602, Validation Accuracy: 0.7202, Loss: 0.2479
Epoch  32 Batch  750/1077 - Train Accuracy: 0.7680, Validation Accuracy: 0.7454, Loss: 0.2564
Epoch  32 Batch  760/1077 - Train Accuracy: 0.7453, Validation Accuracy: 0.7415, Loss: 0.2535
Epoch  32 Batch  770/1077 - Train Accuracy: 0.7764, Validation Accuracy: 0.7266, Loss: 0.2435
Epoch  32 Batch  780/1077 - Train Accuracy: 0.7250, Validation Accuracy: 0.7344, Loss: 0.2597
Epoch  32 Batch  790/1077 - Train Accuracy: 0.6848, Validation Accuracy: 0.7315, Loss: 0.2574
Epoch  32 Batch  800/1077 - Train Accuracy: 0.7535, Validation Accuracy: 0.7322, Loss: 0.2624
Epoch  32 Batch  810/1077 - Train Accuracy: 0.7686, Validation Accuracy: 0.7546, Loss: 0.2317
Epoch  32 Batch  820/1077 - Train Accuracy: 0.7016, Validation Accuracy: 0.7521, Loss: 0.2685
Epoch  32 Batch  830/1077 - Train Accuracy: 0.7168, Validation Accuracy: 0.7539, Loss: 0.2594
Epoch  32 Batch  840/1077 - Train Accuracy: 0.7574, Validation Accuracy: 0.7390, Loss: 0.2549
Epoch  32 Batch  850/1077 - Train Accuracy: 0.7414, Validation Accuracy: 0.7408, Loss: 0.2836
Epoch  32 Batch  860/1077 - Train Accuracy: 0.7336, Validation Accuracy: 0.7315, Loss: 0.2630
Epoch  32 Batch  870/1077 - Train Accuracy: 0.7389, Validation Accuracy: 0.7365, Loss: 0.2681
Epoch  32 Batch  880/1077 - Train Accuracy: 0.7941, Validation Accuracy: 0.7308, Loss: 0.2511
Epoch  32 Batch  890/1077 - Train Accuracy: 0.8062, Validation Accuracy: 0.7440, Loss: 0.2342
Epoch  32 Batch  900/1077 - Train Accuracy: 0.7730, Validation Accuracy: 0.7386, Loss: 0.2529
Epoch  32 Batch  910/1077 - Train Accuracy: 0.7749, Validation Accuracy: 0.7269, Loss: 0.2482
Epoch  32 Batch  920/1077 - Train Accuracy: 0.7625, Validation Accuracy: 0.7305, Loss: 0.2625
Epoch  32 Batch  930/1077 - Train Accuracy: 0.7707, Validation Accuracy: 0.7283, Loss: 0.2328
Epoch  32 Batch  940/1077 - Train Accuracy: 0.7660, Validation Accuracy: 0.7326, Loss: 0.2414
Epoch  32 Batch  950/1077 - Train Accuracy: 0.7645, Validation Accuracy: 0.7489, Loss: 0.2330
Epoch  32 Batch  960/1077 - Train Accuracy: 0.7493, Validation Accuracy: 0.7457, Loss: 0.2295
Epoch  32 Batch  970/1077 - Train Accuracy: 0.7461, Validation Accuracy: 0.7290, Loss: 0.2569
Epoch  32 Batch  980/1077 - Train Accuracy: 0.7160, Validation Accuracy: 0.7301, Loss: 0.2541
Epoch  32 Batch  990/1077 - Train Accuracy: 0.7377, Validation Accuracy: 0.7507, Loss: 0.2701
Epoch  32 Batch 1000/1077 - Train Accuracy: 0.7891, Validation Accuracy: 0.7472, Loss: 0.2322
Epoch  32 Batch 1010/1077 - Train Accuracy: 0.7445, Validation Accuracy: 0.7429, Loss: 0.2472
Epoch  32 Batch 1020/1077 - Train Accuracy: 0.7512, Validation Accuracy: 0.7433, Loss: 0.2382
Epoch  32 Batch 1030/1077 - Train Accuracy: 0.7367, Validation Accuracy: 0.7386, Loss: 0.2525
Epoch  32 Batch 1040/1077 - Train Accuracy: 0.7747, Validation Accuracy: 0.7340, Loss: 0.2633
Epoch  32 Batch 1050/1077 - Train Accuracy: 0.6937, Validation Accuracy: 0.7326, Loss: 0.2420
Epoch  32 Batch 1060/1077 - Train Accuracy: 0.7937, Validation Accuracy: 0.7425, Loss: 0.2250
Epoch  32 Batch 1070/1077 - Train Accuracy: 0.7512, Validation Accuracy: 0.7401, Loss: 0.2494
Epoch  33 Batch   10/1077 - Train Accuracy: 0.7858, Validation Accuracy: 0.7315, Loss: 0.2658
Epoch  33 Batch   20/1077 - Train Accuracy: 0.7484, Validation Accuracy: 0.7326, Loss: 0.2318
Epoch  33 Batch   30/1077 - Train Accuracy: 0.7750, Validation Accuracy: 0.7337, Loss: 0.2489
Epoch  33 Batch   40/1077 - Train Accuracy: 0.7805, Validation Accuracy: 0.7365, Loss: 0.2509
Epoch  33 Batch   50/1077 - Train Accuracy: 0.7543, Validation Accuracy: 0.7603, Loss: 0.2578
Epoch  33 Batch   60/1077 - Train Accuracy: 0.7560, Validation Accuracy: 0.7454, Loss: 0.2384
Epoch  33 Batch   70/1077 - Train Accuracy: 0.7812, Validation Accuracy: 0.7482, Loss: 0.2507
Epoch  33 Batch   80/1077 - Train Accuracy: 0.7402, Validation Accuracy: 0.7326, Loss: 0.2481
Epoch  33 Batch   90/1077 - Train Accuracy: 0.7293, Validation Accuracy: 0.7404, Loss: 0.2638
Epoch  33 Batch  100/1077 - Train Accuracy: 0.7434, Validation Accuracy: 0.7521, Loss: 0.2308
Epoch  33 Batch  110/1077 - Train Accuracy: 0.7676, Validation Accuracy: 0.7457, Loss: 0.2271
Epoch  33 Batch  120/1077 - Train Accuracy: 0.7598, Validation Accuracy: 0.7251, Loss: 0.2494
Epoch  33 Batch  130/1077 - Train Accuracy: 0.7370, Validation Accuracy: 0.7433, Loss: 0.2431
Epoch  33 Batch  140/1077 - Train Accuracy: 0.7656, Validation Accuracy: 0.7358, Loss: 0.2603
Epoch  33 Batch  150/1077 - Train Accuracy: 0.7783, Validation Accuracy: 0.7301, Loss: 0.2278
Epoch  33 Batch  160/1077 - Train Accuracy: 0.7434, Validation Accuracy: 0.7390, Loss: 0.2492
Epoch  33 Batch  170/1077 - Train Accuracy: 0.7219, Validation Accuracy: 0.7408, Loss: 0.2670
Epoch  33 Batch  180/1077 - Train Accuracy: 0.7746, Validation Accuracy: 0.7191, Loss: 0.2324
Epoch  33 Batch  190/1077 - Train Accuracy: 0.7957, Validation Accuracy: 0.7308, Loss: 0.2570
Epoch  33 Batch  200/1077 - Train Accuracy: 0.7449, Validation Accuracy: 0.7500, Loss: 0.2571
Epoch  33 Batch  210/1077 - Train Accuracy: 0.7626, Validation Accuracy: 0.7177, Loss: 0.2427
Epoch  33 Batch  220/1077 - Train Accuracy: 0.7640, Validation Accuracy: 0.7251, Loss: 0.2479
Epoch  33 Batch  230/1077 - Train Accuracy: 0.7403, Validation Accuracy: 0.7372, Loss: 0.2332
Epoch  33 Batch  240/1077 - Train Accuracy: 0.8187, Validation Accuracy: 0.7376, Loss: 0.2261
Epoch  33 Batch  250/1077 - Train Accuracy: 0.7532, Validation Accuracy: 0.7290, Loss: 0.2411
Epoch  33 Batch  260/1077 - Train Accuracy: 0.7727, Validation Accuracy: 0.7255, Loss: 0.2311
Epoch  33 Batch  270/1077 - Train Accuracy: 0.7676, Validation Accuracy: 0.7308, Loss: 0.2600
Epoch  33 Batch  280/1077 - Train Accuracy: 0.7340, Validation Accuracy: 0.7397, Loss: 0.2522
Epoch  33 Batch  290/1077 - Train Accuracy: 0.7402, Validation Accuracy: 0.7457, Loss: 0.2661
Epoch  33 Batch  300/1077 - Train Accuracy: 0.7685, Validation Accuracy: 0.7340, Loss: 0.2415
Epoch  33 Batch  310/1077 - Train Accuracy: 0.7344, Validation Accuracy: 0.7379, Loss: 0.2690
Epoch  33 Batch  320/1077 - Train Accuracy: 0.7875, Validation Accuracy: 0.7418, Loss: 0.2759
Epoch  33 Batch  330/1077 - Train Accuracy: 0.7609, Validation Accuracy: 0.7589, Loss: 0.2475
Epoch  33 Batch  340/1077 - Train Accuracy: 0.7590, Validation Accuracy: 0.7521, Loss: 0.2492
Epoch  33 Batch  350/1077 - Train Accuracy: 0.7629, Validation Accuracy: 0.7369, Loss: 0.2534
Epoch  33 Batch  360/1077 - Train Accuracy: 0.7250, Validation Accuracy: 0.7383, Loss: 0.2429
Epoch  33 Batch  370/1077 - Train Accuracy: 0.7757, Validation Accuracy: 0.7358, Loss: 0.2393
Epoch  33 Batch  380/1077 - Train Accuracy: 0.7664, Validation Accuracy: 0.7308, Loss: 0.2401
Epoch  33 Batch  390/1077 - Train Accuracy: 0.7086, Validation Accuracy: 0.7333, Loss: 0.2690
Epoch  33 Batch  400/1077 - Train Accuracy: 0.7824, Validation Accuracy: 0.7404, Loss: 0.2558
Epoch  33 Batch  410/1077 - Train Accuracy: 0.7475, Validation Accuracy: 0.7443, Loss: 0.2626
Epoch  33 Batch  420/1077 - Train Accuracy: 0.7746, Validation Accuracy: 0.7305, Loss: 0.2356
Epoch  33 Batch  430/1077 - Train Accuracy: 0.7395, Validation Accuracy: 0.7276, Loss: 0.2412
Epoch  33 Batch  440/1077 - Train Accuracy: 0.7207, Validation Accuracy: 0.7369, Loss: 0.2547
Epoch  33 Batch  450/1077 - Train Accuracy: 0.8039, Validation Accuracy: 0.7337, Loss: 0.2379
Epoch  33 Batch  460/1077 - Train Accuracy: 0.7492, Validation Accuracy: 0.7411, Loss: 0.2553
Epoch  33 Batch  470/1077 - Train Accuracy: 0.7632, Validation Accuracy: 0.7315, Loss: 0.2596
Epoch  33 Batch  480/1077 - Train Accuracy: 0.7578, Validation Accuracy: 0.7372, Loss: 0.2430
Epoch  33 Batch  490/1077 - Train Accuracy: 0.7234, Validation Accuracy: 0.7404, Loss: 0.2473
Epoch  33 Batch  500/1077 - Train Accuracy: 0.7973, Validation Accuracy: 0.7340, Loss: 0.2287
Epoch  33 Batch  510/1077 - Train Accuracy: 0.7723, Validation Accuracy: 0.7298, Loss: 0.2368
Epoch  33 Batch  520/1077 - Train Accuracy: 0.8118, Validation Accuracy: 0.7347, Loss: 0.2282
Epoch  33 Batch  530/1077 - Train Accuracy: 0.7004, Validation Accuracy: 0.7351, Loss: 0.2711
Epoch  33 Batch  540/1077 - Train Accuracy: 0.7758, Validation Accuracy: 0.7379, Loss: 0.2404
Epoch  33 Batch  550/1077 - Train Accuracy: 0.7277, Validation Accuracy: 0.7351, Loss: 0.2562
Epoch  33 Batch  560/1077 - Train Accuracy: 0.7523, Validation Accuracy: 0.7486, Loss: 0.2354
Epoch  33 Batch  570/1077 - Train Accuracy: 0.7619, Validation Accuracy: 0.7475, Loss: 0.2597
Epoch  33 Batch  580/1077 - Train Accuracy: 0.7809, Validation Accuracy: 0.7514, Loss: 0.2122
Epoch  33 Batch  590/1077 - Train Accuracy: 0.7245, Validation Accuracy: 0.7429, Loss: 0.2604
Epoch  33 Batch  600/1077 - Train Accuracy: 0.7719, Validation Accuracy: 0.7425, Loss: 0.2547
Epoch  33 Batch  610/1077 - Train Accuracy: 0.7360, Validation Accuracy: 0.7322, Loss: 0.2604
Epoch  33 Batch  620/1077 - Train Accuracy: 0.7441, Validation Accuracy: 0.7354, Loss: 0.2267
Epoch  33 Batch  630/1077 - Train Accuracy: 0.7559, Validation Accuracy: 0.7433, Loss: 0.2458
Epoch  33 Batch  640/1077 - Train Accuracy: 0.7760, Validation Accuracy: 0.7546, Loss: 0.2339
Epoch  33 Batch  650/1077 - Train Accuracy: 0.7531, Validation Accuracy: 0.7532, Loss: 0.2429
Epoch  33 Batch  660/1077 - Train Accuracy: 0.7547, Validation Accuracy: 0.7369, Loss: 0.2493
Epoch  33 Batch  670/1077 - Train Accuracy: 0.7820, Validation Accuracy: 0.7337, Loss: 0.2253
Epoch  33 Batch  680/1077 - Train Accuracy: 0.7493, Validation Accuracy: 0.7411, Loss: 0.2415
Epoch  33 Batch  690/1077 - Train Accuracy: 0.7637, Validation Accuracy: 0.7418, Loss: 0.2433
Epoch  33 Batch  700/1077 - Train Accuracy: 0.7637, Validation Accuracy: 0.7457, Loss: 0.2304
Epoch  33 Batch  710/1077 - Train Accuracy: 0.7273, Validation Accuracy: 0.7425, Loss: 0.2377
Epoch  33 Batch  720/1077 - Train Accuracy: 0.7508, Validation Accuracy: 0.7379, Loss: 0.2574
Epoch  33 Batch  730/1077 - Train Accuracy: 0.7637, Validation Accuracy: 0.7276, Loss: 0.2535
Epoch  33 Batch  740/1077 - Train Accuracy: 0.7570, Validation Accuracy: 0.7397, Loss: 0.2405
Epoch  33 Batch  750/1077 - Train Accuracy: 0.7824, Validation Accuracy: 0.7425, Loss: 0.2462
Epoch  33 Batch  760/1077 - Train Accuracy: 0.7512, Validation Accuracy: 0.7482, Loss: 0.2524
Epoch  33 Batch  770/1077 - Train Accuracy: 0.7690, Validation Accuracy: 0.7390, Loss: 0.2389
Epoch  33 Batch  780/1077 - Train Accuracy: 0.7422, Validation Accuracy: 0.7415, Loss: 0.2618
Epoch  33 Batch  790/1077 - Train Accuracy: 0.6902, Validation Accuracy: 0.7337, Loss: 0.2572
Epoch  33 Batch  800/1077 - Train Accuracy: 0.7387, Validation Accuracy: 0.7390, Loss: 0.2783
Epoch  33 Batch  810/1077 - Train Accuracy: 0.7615, Validation Accuracy: 0.7536, Loss: 0.2295
Epoch  33 Batch  820/1077 - Train Accuracy: 0.7105, Validation Accuracy: 0.7525, Loss: 0.2564
Epoch  33 Batch  830/1077 - Train Accuracy: 0.7195, Validation Accuracy: 0.7578, Loss: 0.2659
Epoch  33 Batch  840/1077 - Train Accuracy: 0.7570, Validation Accuracy: 0.7521, Loss: 0.2417
Epoch  33 Batch  850/1077 - Train Accuracy: 0.7385, Validation Accuracy: 0.7433, Loss: 0.2610
Epoch  33 Batch  860/1077 - Train Accuracy: 0.7396, Validation Accuracy: 0.7383, Loss: 0.2471
Epoch  33 Batch  870/1077 - Train Accuracy: 0.7504, Validation Accuracy: 0.7383, Loss: 0.2582
Epoch  33 Batch  880/1077 - Train Accuracy: 0.8102, Validation Accuracy: 0.7340, Loss: 0.2502
Epoch  33 Batch  890/1077 - Train Accuracy: 0.7943, Validation Accuracy: 0.7415, Loss: 0.2193
Epoch  33 Batch  900/1077 - Train Accuracy: 0.7828, Validation Accuracy: 0.7422, Loss: 0.2394
Epoch  33 Batch  910/1077 - Train Accuracy: 0.7738, Validation Accuracy: 0.7440, Loss: 0.2411
Epoch  33 Batch  920/1077 - Train Accuracy: 0.7621, Validation Accuracy: 0.7436, Loss: 0.2421
Epoch  33 Batch  930/1077 - Train Accuracy: 0.7781, Validation Accuracy: 0.7351, Loss: 0.2275
Epoch  33 Batch  940/1077 - Train Accuracy: 0.7652, Validation Accuracy: 0.7454, Loss: 0.2349
Epoch  33 Batch  950/1077 - Train Accuracy: 0.7690, Validation Accuracy: 0.7674, Loss: 0.2194
Epoch  33 Batch  960/1077 - Train Accuracy: 0.7459, Validation Accuracy: 0.7386, Loss: 0.2324
Epoch  33 Batch  970/1077 - Train Accuracy: 0.7465, Validation Accuracy: 0.7227, Loss: 0.2572
Epoch  33 Batch  980/1077 - Train Accuracy: 0.7344, Validation Accuracy: 0.7330, Loss: 0.2459
Epoch  33 Batch  990/1077 - Train Accuracy: 0.7274, Validation Accuracy: 0.7543, Loss: 0.2682
Epoch  33 Batch 1000/1077 - Train Accuracy: 0.7898, Validation Accuracy: 0.7475, Loss: 0.2231
Epoch  33 Batch 1010/1077 - Train Accuracy: 0.7414, Validation Accuracy: 0.7433, Loss: 0.2409
Epoch  33 Batch 1020/1077 - Train Accuracy: 0.7516, Validation Accuracy: 0.7404, Loss: 0.2344
Epoch  33 Batch 1030/1077 - Train Accuracy: 0.7449, Validation Accuracy: 0.7315, Loss: 0.2520
Epoch  33 Batch 1040/1077 - Train Accuracy: 0.7796, Validation Accuracy: 0.7322, Loss: 0.2377
Epoch  33 Batch 1050/1077 - Train Accuracy: 0.6941, Validation Accuracy: 0.7369, Loss: 0.2344
Epoch  33 Batch 1060/1077 - Train Accuracy: 0.8039, Validation Accuracy: 0.7376, Loss: 0.2211
Epoch  33 Batch 1070/1077 - Train Accuracy: 0.7422, Validation Accuracy: 0.7433, Loss: 0.2445
Epoch  34 Batch   10/1077 - Train Accuracy: 0.7841, Validation Accuracy: 0.7262, Loss: 0.2451
Epoch  34 Batch   20/1077 - Train Accuracy: 0.7504, Validation Accuracy: 0.7290, Loss: 0.2284
Epoch  34 Batch   30/1077 - Train Accuracy: 0.7879, Validation Accuracy: 0.7301, Loss: 0.2404
Epoch  34 Batch   40/1077 - Train Accuracy: 0.7840, Validation Accuracy: 0.7276, Loss: 0.2433
Epoch  34 Batch   50/1077 - Train Accuracy: 0.7445, Validation Accuracy: 0.7653, Loss: 0.2504
Epoch  34 Batch   60/1077 - Train Accuracy: 0.7671, Validation Accuracy: 0.7518, Loss: 0.2244
Epoch  34 Batch   70/1077 - Train Accuracy: 0.7915, Validation Accuracy: 0.7425, Loss: 0.2611
Epoch  34 Batch   80/1077 - Train Accuracy: 0.7488, Validation Accuracy: 0.7333, Loss: 0.2448
Epoch  34 Batch   90/1077 - Train Accuracy: 0.7375, Validation Accuracy: 0.7362, Loss: 0.2640
Epoch  34 Batch  100/1077 - Train Accuracy: 0.7395, Validation Accuracy: 0.7564, Loss: 0.2343
Epoch  34 Batch  110/1077 - Train Accuracy: 0.7672, Validation Accuracy: 0.7493, Loss: 0.2237
Epoch  34 Batch  120/1077 - Train Accuracy: 0.7598, Validation Accuracy: 0.7347, Loss: 0.2558
Epoch  34 Batch  130/1077 - Train Accuracy: 0.7440, Validation Accuracy: 0.7340, Loss: 0.2491
Epoch  34 Batch  140/1077 - Train Accuracy: 0.7640, Validation Accuracy: 0.7298, Loss: 0.2461
Epoch  34 Batch  150/1077 - Train Accuracy: 0.7693, Validation Accuracy: 0.7358, Loss: 0.2283
Epoch  34 Batch  160/1077 - Train Accuracy: 0.7508, Validation Accuracy: 0.7411, Loss: 0.2489
Epoch  34 Batch  170/1077 - Train Accuracy: 0.7219, Validation Accuracy: 0.7425, Loss: 0.2592
Epoch  34 Batch  180/1077 - Train Accuracy: 0.7711, Validation Accuracy: 0.7280, Loss: 0.2395
Epoch  34 Batch  190/1077 - Train Accuracy: 0.7910, Validation Accuracy: 0.7386, Loss: 0.2343
Epoch  34 Batch  200/1077 - Train Accuracy: 0.7629, Validation Accuracy: 0.7280, Loss: 0.2441
Epoch  34 Batch  210/1077 - Train Accuracy: 0.7701, Validation Accuracy: 0.7287, Loss: 0.2455
Epoch  34 Batch  220/1077 - Train Accuracy: 0.7780, Validation Accuracy: 0.7340, Loss: 0.2495
Epoch  34 Batch  230/1077 - Train Accuracy: 0.7411, Validation Accuracy: 0.7436, Loss: 0.2359
Epoch  34 Batch  240/1077 - Train Accuracy: 0.8184, Validation Accuracy: 0.7433, Loss: 0.2372
Epoch  34 Batch  250/1077 - Train Accuracy: 0.7486, Validation Accuracy: 0.7330, Loss: 0.2359
Epoch  34 Batch  260/1077 - Train Accuracy: 0.7705, Validation Accuracy: 0.7468, Loss: 0.2244
Epoch  34 Batch  270/1077 - Train Accuracy: 0.7578, Validation Accuracy: 0.7422, Loss: 0.2531
Epoch  34 Batch  280/1077 - Train Accuracy: 0.7582, Validation Accuracy: 0.7344, Loss: 0.2380
Epoch  34 Batch  290/1077 - Train Accuracy: 0.7363, Validation Accuracy: 0.7330, Loss: 0.2629
Epoch  34 Batch  300/1077 - Train Accuracy: 0.7722, Validation Accuracy: 0.7379, Loss: 0.2416
Epoch  34 Batch  310/1077 - Train Accuracy: 0.7102, Validation Accuracy: 0.7344, Loss: 0.2479
Epoch  34 Batch  320/1077 - Train Accuracy: 0.7891, Validation Accuracy: 0.7511, Loss: 0.2680
Epoch  34 Batch  330/1077 - Train Accuracy: 0.7715, Validation Accuracy: 0.7493, Loss: 0.2409
Epoch  34 Batch  340/1077 - Train Accuracy: 0.7652, Validation Accuracy: 0.7354, Loss: 0.2360
Epoch  34 Batch  350/1077 - Train Accuracy: 0.7668, Validation Accuracy: 0.7408, Loss: 0.2354
Epoch  34 Batch  360/1077 - Train Accuracy: 0.7230, Validation Accuracy: 0.7230, Loss: 0.2316
Epoch  34 Batch  370/1077 - Train Accuracy: 0.7664, Validation Accuracy: 0.7390, Loss: 0.2506
Epoch  34 Batch  380/1077 - Train Accuracy: 0.7719, Validation Accuracy: 0.7241, Loss: 0.2349
Epoch  34 Batch  390/1077 - Train Accuracy: 0.6988, Validation Accuracy: 0.7148, Loss: 0.2645
Epoch  34 Batch  400/1077 - Train Accuracy: 0.7895, Validation Accuracy: 0.7479, Loss: 0.2580
Epoch  34 Batch  410/1077 - Train Accuracy: 0.7500, Validation Accuracy: 0.7475, Loss: 0.2543
Epoch  34 Batch  420/1077 - Train Accuracy: 0.7715, Validation Accuracy: 0.7266, Loss: 0.2253
Epoch  34 Batch  430/1077 - Train Accuracy: 0.7195, Validation Accuracy: 0.7290, Loss: 0.2299
Epoch  34 Batch  440/1077 - Train Accuracy: 0.7262, Validation Accuracy: 0.7298, Loss: 0.2424
Epoch  34 Batch  450/1077 - Train Accuracy: 0.7828, Validation Accuracy: 0.7351, Loss: 0.2377
Epoch  34 Batch  460/1077 - Train Accuracy: 0.7500, Validation Accuracy: 0.7259, Loss: 0.2526
Epoch  34 Batch  470/1077 - Train Accuracy: 0.7521, Validation Accuracy: 0.7255, Loss: 0.2621
Epoch  34 Batch  480/1077 - Train Accuracy: 0.7734, Validation Accuracy: 0.7383, Loss: 0.2438
Epoch  34 Batch  490/1077 - Train Accuracy: 0.7191, Validation Accuracy: 0.7383, Loss: 0.2492
Epoch  34 Batch  500/1077 - Train Accuracy: 0.7937, Validation Accuracy: 0.7390, Loss: 0.2242
Epoch  34 Batch  510/1077 - Train Accuracy: 0.7801, Validation Accuracy: 0.7401, Loss: 0.2373
Epoch  34 Batch  520/1077 - Train Accuracy: 0.8188, Validation Accuracy: 0.7472, Loss: 0.2126
Epoch  34 Batch  530/1077 - Train Accuracy: 0.7086, Validation Accuracy: 0.7308, Loss: 0.2421
Epoch  34 Batch  540/1077 - Train Accuracy: 0.7871, Validation Accuracy: 0.7362, Loss: 0.2368
Epoch  34 Batch  550/1077 - Train Accuracy: 0.7258, Validation Accuracy: 0.7386, Loss: 0.2493
Epoch  34 Batch  560/1077 - Train Accuracy: 0.7547, Validation Accuracy: 0.7560, Loss: 0.2346
Epoch  34 Batch  570/1077 - Train Accuracy: 0.7570, Validation Accuracy: 0.7397, Loss: 0.2649
Epoch  34 Batch  580/1077 - Train Accuracy: 0.7738, Validation Accuracy: 0.7553, Loss: 0.2140
Epoch  34 Batch  590/1077 - Train Accuracy: 0.7475, Validation Accuracy: 0.7475, Loss: 0.2698
Epoch  34 Batch  600/1077 - Train Accuracy: 0.7604, Validation Accuracy: 0.7290, Loss: 0.2267
Epoch  34 Batch  610/1077 - Train Accuracy: 0.7381, Validation Accuracy: 0.7351, Loss: 0.2389
Epoch  34 Batch  620/1077 - Train Accuracy: 0.7473, Validation Accuracy: 0.7393, Loss: 0.2213
Epoch  34 Batch  630/1077 - Train Accuracy: 0.7461, Validation Accuracy: 0.7472, Loss: 0.2391
Epoch  34 Batch  640/1077 - Train Accuracy: 0.7701, Validation Accuracy: 0.7518, Loss: 0.2292
Epoch  34 Batch  650/1077 - Train Accuracy: 0.7500, Validation Accuracy: 0.7472, Loss: 0.2253
Epoch  34 Batch  660/1077 - Train Accuracy: 0.7793, Validation Accuracy: 0.7422, Loss: 0.2519
Epoch  34 Batch  670/1077 - Train Accuracy: 0.7859, Validation Accuracy: 0.7326, Loss: 0.2266
Epoch  34 Batch  680/1077 - Train Accuracy: 0.7429, Validation Accuracy: 0.7393, Loss: 0.2404
Epoch  34 Batch  690/1077 - Train Accuracy: 0.7762, Validation Accuracy: 0.7401, Loss: 0.2481
Epoch  34 Batch  700/1077 - Train Accuracy: 0.7617, Validation Accuracy: 0.7369, Loss: 0.2314
Epoch  34 Batch  710/1077 - Train Accuracy: 0.7316, Validation Accuracy: 0.7415, Loss: 0.2447
Epoch  34 Batch  720/1077 - Train Accuracy: 0.7418, Validation Accuracy: 0.7290, Loss: 0.2554
Epoch  34 Batch  730/1077 - Train Accuracy: 0.7488, Validation Accuracy: 0.7354, Loss: 0.2389
Epoch  34 Batch  740/1077 - Train Accuracy: 0.7516, Validation Accuracy: 0.7411, Loss: 0.2306
Epoch  34 Batch  750/1077 - Train Accuracy: 0.7688, Validation Accuracy: 0.7493, Loss: 0.2425
Epoch  34 Batch  760/1077 - Train Accuracy: 0.7602, Validation Accuracy: 0.7599, Loss: 0.2498
Epoch  34 Batch  770/1077 - Train Accuracy: 0.7693, Validation Accuracy: 0.7333, Loss: 0.2163
Epoch  34 Batch  780/1077 - Train Accuracy: 0.7305, Validation Accuracy: 0.7372, Loss: 0.2540
Epoch  34 Batch  790/1077 - Train Accuracy: 0.6961, Validation Accuracy: 0.7315, Loss: 0.2549
Epoch  34 Batch  800/1077 - Train Accuracy: 0.7539, Validation Accuracy: 0.7337, Loss: 0.2397
Epoch  34 Batch  810/1077 - Train Accuracy: 0.7675, Validation Accuracy: 0.7567, Loss: 0.2269
Epoch  34 Batch  820/1077 - Train Accuracy: 0.7145, Validation Accuracy: 0.7429, Loss: 0.2505
Epoch  34 Batch  830/1077 - Train Accuracy: 0.7215, Validation Accuracy: 0.7326, Loss: 0.2281
Epoch  34 Batch  840/1077 - Train Accuracy: 0.7648, Validation Accuracy: 0.7411, Loss: 0.2407
Epoch  34 Batch  850/1077 - Train Accuracy: 0.7429, Validation Accuracy: 0.7386, Loss: 0.2688
Epoch  34 Batch  860/1077 - Train Accuracy: 0.7396, Validation Accuracy: 0.7330, Loss: 0.2450
Epoch  34 Batch  870/1077 - Train Accuracy: 0.7356, Validation Accuracy: 0.7326, Loss: 0.2520
Epoch  34 Batch  880/1077 - Train Accuracy: 0.7934, Validation Accuracy: 0.7312, Loss: 0.2340
Epoch  34 Batch  890/1077 - Train Accuracy: 0.8118, Validation Accuracy: 0.7333, Loss: 0.2240
Epoch  34 Batch  900/1077 - Train Accuracy: 0.7949, Validation Accuracy: 0.7440, Loss: 0.2405
Epoch  34 Batch  910/1077 - Train Accuracy: 0.7615, Validation Accuracy: 0.7358, Loss: 0.2290
Epoch  34 Batch  920/1077 - Train Accuracy: 0.7523, Validation Accuracy: 0.7365, Loss: 0.2333
Epoch  34 Batch  930/1077 - Train Accuracy: 0.7770, Validation Accuracy: 0.7337, Loss: 0.2214
Epoch  34 Batch  940/1077 - Train Accuracy: 0.7637, Validation Accuracy: 0.7386, Loss: 0.2309
Epoch  34 Batch  950/1077 - Train Accuracy: 0.7682, Validation Accuracy: 0.7564, Loss: 0.2288
Epoch  34 Batch  960/1077 - Train Accuracy: 0.7511, Validation Accuracy: 0.7386, Loss: 0.2311
Epoch  34 Batch  970/1077 - Train Accuracy: 0.7613, Validation Accuracy: 0.7308, Loss: 0.2471
Epoch  34 Batch  980/1077 - Train Accuracy: 0.7172, Validation Accuracy: 0.7241, Loss: 0.2616
Epoch  34 Batch  990/1077 - Train Accuracy: 0.7348, Validation Accuracy: 0.7607, Loss: 0.2626
Epoch  34 Batch 1000/1077 - Train Accuracy: 0.7913, Validation Accuracy: 0.7422, Loss: 0.2232
Epoch  34 Batch 1010/1077 - Train Accuracy: 0.7582, Validation Accuracy: 0.7496, Loss: 0.2414
Epoch  34 Batch 1020/1077 - Train Accuracy: 0.7449, Validation Accuracy: 0.7433, Loss: 0.2322
Epoch  34 Batch 1030/1077 - Train Accuracy: 0.7434, Validation Accuracy: 0.7468, Loss: 0.2497
Epoch  34 Batch 1040/1077 - Train Accuracy: 0.7837, Validation Accuracy: 0.7354, Loss: 0.2574
Epoch  34 Batch 1050/1077 - Train Accuracy: 0.7172, Validation Accuracy: 0.7326, Loss: 0.2330
Epoch  34 Batch 1060/1077 - Train Accuracy: 0.8070, Validation Accuracy: 0.7408, Loss: 0.2225
Epoch  34 Batch 1070/1077 - Train Accuracy: 0.7383, Validation Accuracy: 0.7422, Loss: 0.2258
Epoch  35 Batch   10/1077 - Train Accuracy: 0.7866, Validation Accuracy: 0.7528, Loss: 0.2500
Epoch  35 Batch   20/1077 - Train Accuracy: 0.7559, Validation Accuracy: 0.7372, Loss: 0.2311
Epoch  35 Batch   30/1077 - Train Accuracy: 0.7922, Validation Accuracy: 0.7411, Loss: 0.2272
Epoch  35 Batch   40/1077 - Train Accuracy: 0.7762, Validation Accuracy: 0.7351, Loss: 0.2483
Epoch  35 Batch   50/1077 - Train Accuracy: 0.7477, Validation Accuracy: 0.7539, Loss: 0.2317
Epoch  35 Batch   60/1077 - Train Accuracy: 0.7608, Validation Accuracy: 0.7468, Loss: 0.2193
Epoch  35 Batch   70/1077 - Train Accuracy: 0.7932, Validation Accuracy: 0.7525, Loss: 0.2413
Epoch  35 Batch   80/1077 - Train Accuracy: 0.7520, Validation Accuracy: 0.7344, Loss: 0.2400
Epoch  35 Batch   90/1077 - Train Accuracy: 0.7418, Validation Accuracy: 0.7383, Loss: 0.2824
Epoch  35 Batch  100/1077 - Train Accuracy: 0.7410, Validation Accuracy: 0.7564, Loss: 0.2434
Epoch  35 Batch  110/1077 - Train Accuracy: 0.7613, Validation Accuracy: 0.7383, Loss: 0.2214
Epoch  35 Batch  120/1077 - Train Accuracy: 0.7723, Validation Accuracy: 0.7322, Loss: 0.2396
Epoch  35 Batch  130/1077 - Train Accuracy: 0.7433, Validation Accuracy: 0.7489, Loss: 0.2393
Epoch  35 Batch  140/1077 - Train Accuracy: 0.7673, Validation Accuracy: 0.7429, Loss: 0.2508
Epoch  35 Batch  150/1077 - Train Accuracy: 0.7812, Validation Accuracy: 0.7457, Loss: 0.2140
Epoch  35 Batch  160/1077 - Train Accuracy: 0.7625, Validation Accuracy: 0.7347, Loss: 0.2440
Epoch  35 Batch  170/1077 - Train Accuracy: 0.7191, Validation Accuracy: 0.7429, Loss: 0.2539
Epoch  35 Batch  180/1077 - Train Accuracy: 0.7730, Validation Accuracy: 0.7262, Loss: 0.2291
Epoch  35 Batch  190/1077 - Train Accuracy: 0.7937, Validation Accuracy: 0.7347, Loss: 0.2416
Epoch  35 Batch  200/1077 - Train Accuracy: 0.7734, Validation Accuracy: 0.7322, Loss: 0.2479
Epoch  35 Batch  210/1077 - Train Accuracy: 0.7820, Validation Accuracy: 0.7358, Loss: 0.2352
Epoch  35 Batch  220/1077 - Train Accuracy: 0.7812, Validation Accuracy: 0.7305, Loss: 0.2465
Epoch  35 Batch  230/1077 - Train Accuracy: 0.7400, Validation Accuracy: 0.7408, Loss: 0.2253
Epoch  35 Batch  240/1077 - Train Accuracy: 0.8180, Validation Accuracy: 0.7418, Loss: 0.2173
Epoch  35 Batch  250/1077 - Train Accuracy: 0.7734, Validation Accuracy: 0.7457, Loss: 0.2307
Epoch  35 Batch  260/1077 - Train Accuracy: 0.7850, Validation Accuracy: 0.7386, Loss: 0.2338
Epoch  35 Batch  270/1077 - Train Accuracy: 0.7645, Validation Accuracy: 0.7290, Loss: 0.2432
Epoch  35 Batch  280/1077 - Train Accuracy: 0.7664, Validation Accuracy: 0.7340, Loss: 0.2471
Epoch  35 Batch  290/1077 - Train Accuracy: 0.7277, Validation Accuracy: 0.7393, Loss: 0.2443
Epoch  35 Batch  300/1077 - Train Accuracy: 0.7887, Validation Accuracy: 0.7322, Loss: 0.2231
Epoch  35 Batch  310/1077 - Train Accuracy: 0.7266, Validation Accuracy: 0.7365, Loss: 0.2516
Epoch  35 Batch  320/1077 - Train Accuracy: 0.7965, Validation Accuracy: 0.7521, Loss: 0.2596
Epoch  35 Batch  330/1077 - Train Accuracy: 0.7742, Validation Accuracy: 0.7500, Loss: 0.2354
Epoch  35 Batch  340/1077 - Train Accuracy: 0.7636, Validation Accuracy: 0.7486, Loss: 0.2398
Epoch  35 Batch  350/1077 - Train Accuracy: 0.7523, Validation Accuracy: 0.7241, Loss: 0.2319
Epoch  35 Batch  360/1077 - Train Accuracy: 0.7387, Validation Accuracy: 0.7326, Loss: 0.2281
Epoch  35 Batch  370/1077 - Train Accuracy: 0.7920, Validation Accuracy: 0.7511, Loss: 0.2373
Epoch  35 Batch  380/1077 - Train Accuracy: 0.7738, Validation Accuracy: 0.7418, Loss: 0.2209
Epoch  35 Batch  390/1077 - Train Accuracy: 0.7035, Validation Accuracy: 0.7276, Loss: 0.2603
Epoch  35 Batch  400/1077 - Train Accuracy: 0.7660, Validation Accuracy: 0.7408, Loss: 0.2383
Epoch  35 Batch  410/1077 - Train Accuracy: 0.7558, Validation Accuracy: 0.7578, Loss: 0.2515
Epoch  35 Batch  420/1077 - Train Accuracy: 0.7785, Validation Accuracy: 0.7337, Loss: 0.2265
Epoch  35 Batch  430/1077 - Train Accuracy: 0.7375, Validation Accuracy: 0.7425, Loss: 0.2401
Epoch  35 Batch  440/1077 - Train Accuracy: 0.7266, Validation Accuracy: 0.7358, Loss: 0.2555
Epoch  35 Batch  450/1077 - Train Accuracy: 0.7840, Validation Accuracy: 0.7319, Loss: 0.2406
Epoch  35 Batch  460/1077 - Train Accuracy: 0.7578, Validation Accuracy: 0.7333, Loss: 0.2463
Epoch  35 Batch  470/1077 - Train Accuracy: 0.7599, Validation Accuracy: 0.7422, Loss: 0.2401
Epoch  35 Batch  480/1077 - Train Accuracy: 0.7632, Validation Accuracy: 0.7479, Loss: 0.2465
Epoch  35 Batch  490/1077 - Train Accuracy: 0.7207, Validation Accuracy: 0.7500, Loss: 0.2486
Epoch  35 Batch  500/1077 - Train Accuracy: 0.7945, Validation Accuracy: 0.7294, Loss: 0.2203
Epoch  35 Batch  510/1077 - Train Accuracy: 0.7836, Validation Accuracy: 0.7521, Loss: 0.2426
Epoch  35 Batch  520/1077 - Train Accuracy: 0.8237, Validation Accuracy: 0.7450, Loss: 0.2166
Epoch  35 Batch  530/1077 - Train Accuracy: 0.7219, Validation Accuracy: 0.7504, Loss: 0.2468
Epoch  35 Batch  540/1077 - Train Accuracy: 0.7758, Validation Accuracy: 0.7436, Loss: 0.2273
Epoch  35 Batch  550/1077 - Train Accuracy: 0.7348, Validation Accuracy: 0.7280, Loss: 0.2549
Epoch  35 Batch  560/1077 - Train Accuracy: 0.7586, Validation Accuracy: 0.7571, Loss: 0.2333
Epoch  35 Batch  570/1077 - Train Accuracy: 0.7586, Validation Accuracy: 0.7468, Loss: 0.2577
Epoch  35 Batch  580/1077 - Train Accuracy: 0.8028, Validation Accuracy: 0.7642, Loss: 0.2213
Epoch  35 Batch  590/1077 - Train Accuracy: 0.7294, Validation Accuracy: 0.7468, Loss: 0.2438
Epoch  35 Batch  600/1077 - Train Accuracy: 0.7738, Validation Accuracy: 0.7276, Loss: 0.2310
Epoch  35 Batch  610/1077 - Train Accuracy: 0.7299, Validation Accuracy: 0.7354, Loss: 0.2529
Epoch  35 Batch  620/1077 - Train Accuracy: 0.7449, Validation Accuracy: 0.7330, Loss: 0.2255
Epoch  35 Batch  630/1077 - Train Accuracy: 0.7566, Validation Accuracy: 0.7482, Loss: 0.2300
Epoch  35 Batch  640/1077 - Train Accuracy: 0.7775, Validation Accuracy: 0.7528, Loss: 0.2245
Epoch  35 Batch  650/1077 - Train Accuracy: 0.7504, Validation Accuracy: 0.7372, Loss: 0.2425
Epoch  35 Batch  660/1077 - Train Accuracy: 0.7809, Validation Accuracy: 0.7415, Loss: 0.2407
Epoch  35 Batch  670/1077 - Train Accuracy: 0.7862, Validation Accuracy: 0.7383, Loss: 0.2123
Epoch  35 Batch  680/1077 - Train Accuracy: 0.7504, Validation Accuracy: 0.7372, Loss: 0.2381
Epoch  35 Batch  690/1077 - Train Accuracy: 0.7621, Validation Accuracy: 0.7383, Loss: 0.2395
Epoch  35 Batch  700/1077 - Train Accuracy: 0.7703, Validation Accuracy: 0.7464, Loss: 0.2109
Epoch  35 Batch  710/1077 - Train Accuracy: 0.7242, Validation Accuracy: 0.7351, Loss: 0.2336
Epoch  35 Batch  720/1077 - Train Accuracy: 0.7492, Validation Accuracy: 0.7315, Loss: 0.2561
Epoch  35 Batch  730/1077 - Train Accuracy: 0.7578, Validation Accuracy: 0.7404, Loss: 0.2416
Epoch  35 Batch  740/1077 - Train Accuracy: 0.7586, Validation Accuracy: 0.7358, Loss: 0.2267
Epoch  35 Batch  750/1077 - Train Accuracy: 0.7648, Validation Accuracy: 0.7518, Loss: 0.2285
Epoch  35 Batch  760/1077 - Train Accuracy: 0.7672, Validation Accuracy: 0.7621, Loss: 0.2348
Epoch  35 Batch  770/1077 - Train Accuracy: 0.7660, Validation Accuracy: 0.7383, Loss: 0.2200
Epoch  35 Batch  780/1077 - Train Accuracy: 0.7477, Validation Accuracy: 0.7486, Loss: 0.2445
Epoch  35 Batch  790/1077 - Train Accuracy: 0.6859, Validation Accuracy: 0.7433, Loss: 0.2448
Epoch  35 Batch  800/1077 - Train Accuracy: 0.7648, Validation Accuracy: 0.7347, Loss: 0.2390
Epoch  35 Batch  810/1077 - Train Accuracy: 0.7857, Validation Accuracy: 0.7500, Loss: 0.2269
Epoch  35 Batch  820/1077 - Train Accuracy: 0.7215, Validation Accuracy: 0.7404, Loss: 0.2474
Epoch  35 Batch  830/1077 - Train Accuracy: 0.7414, Validation Accuracy: 0.7468, Loss: 0.2470
Epoch  35 Batch  840/1077 - Train Accuracy: 0.7586, Validation Accuracy: 0.7504, Loss: 0.2242
Epoch  35 Batch  850/1077 - Train Accuracy: 0.7429, Validation Accuracy: 0.7376, Loss: 0.2602
Epoch  35 Batch  860/1077 - Train Accuracy: 0.7377, Validation Accuracy: 0.7457, Loss: 0.2359
Epoch  35 Batch  870/1077 - Train Accuracy: 0.7492, Validation Accuracy: 0.7415, Loss: 0.2734
Epoch  35 Batch  880/1077 - Train Accuracy: 0.8051, Validation Accuracy: 0.7418, Loss: 0.2440
Epoch  35 Batch  890/1077 - Train Accuracy: 0.8192, Validation Accuracy: 0.7436, Loss: 0.2250
Epoch  35 Batch  900/1077 - Train Accuracy: 0.7887, Validation Accuracy: 0.7433, Loss: 0.2384
Epoch  35 Batch  910/1077 - Train Accuracy: 0.7872, Validation Accuracy: 0.7479, Loss: 0.2394
Epoch  35 Batch  920/1077 - Train Accuracy: 0.7711, Validation Accuracy: 0.7425, Loss: 0.2389
Epoch  35 Batch  930/1077 - Train Accuracy: 0.7820, Validation Accuracy: 0.7330, Loss: 0.2228
Epoch  35 Batch  940/1077 - Train Accuracy: 0.7711, Validation Accuracy: 0.7294, Loss: 0.2321
Epoch  35 Batch  950/1077 - Train Accuracy: 0.7701, Validation Accuracy: 0.7521, Loss: 0.2284
Epoch  35 Batch  960/1077 - Train Accuracy: 0.7675, Validation Accuracy: 0.7532, Loss: 0.2289
Epoch  35 Batch  970/1077 - Train Accuracy: 0.7555, Validation Accuracy: 0.7344, Loss: 0.2447
Epoch  35 Batch  980/1077 - Train Accuracy: 0.7195, Validation Accuracy: 0.7251, Loss: 0.2420
Epoch  35 Batch  990/1077 - Train Accuracy: 0.7352, Validation Accuracy: 0.7575, Loss: 0.2536
Epoch  35 Batch 1000/1077 - Train Accuracy: 0.7917, Validation Accuracy: 0.7575, Loss: 0.2144
Epoch  35 Batch 1010/1077 - Train Accuracy: 0.7586, Validation Accuracy: 0.7344, Loss: 0.2348
Epoch  35 Batch 1020/1077 - Train Accuracy: 0.7613, Validation Accuracy: 0.7393, Loss: 0.2265
Epoch  35 Batch 1030/1077 - Train Accuracy: 0.7379, Validation Accuracy: 0.7489, Loss: 0.2394
Epoch  35 Batch 1040/1077 - Train Accuracy: 0.7940, Validation Accuracy: 0.7422, Loss: 0.2374
Epoch  35 Batch 1050/1077 - Train Accuracy: 0.7082, Validation Accuracy: 0.7383, Loss: 0.2253
Epoch  35 Batch 1060/1077 - Train Accuracy: 0.8070, Validation Accuracy: 0.7290, Loss: 0.2214
Epoch  35 Batch 1070/1077 - Train Accuracy: 0.7344, Validation Accuracy: 0.7390, Loss: 0.2328
Epoch  36 Batch   10/1077 - Train Accuracy: 0.7932, Validation Accuracy: 0.7450, Loss: 0.2504
Epoch  36 Batch   20/1077 - Train Accuracy: 0.7461, Validation Accuracy: 0.7411, Loss: 0.2303
Epoch  36 Batch   30/1077 - Train Accuracy: 0.7852, Validation Accuracy: 0.7457, Loss: 0.2308
Epoch  36 Batch   40/1077 - Train Accuracy: 0.7715, Validation Accuracy: 0.7369, Loss: 0.2399
Epoch  36 Batch   50/1077 - Train Accuracy: 0.7500, Validation Accuracy: 0.7592, Loss: 0.2355
Epoch  36 Batch   60/1077 - Train Accuracy: 0.7731, Validation Accuracy: 0.7578, Loss: 0.2129
Epoch  36 Batch   70/1077 - Train Accuracy: 0.8014, Validation Accuracy: 0.7386, Loss: 0.2496
Epoch  36 Batch   80/1077 - Train Accuracy: 0.7574, Validation Accuracy: 0.7266, Loss: 0.2388
Epoch  36 Batch   90/1077 - Train Accuracy: 0.7258, Validation Accuracy: 0.7344, Loss: 0.2389
Epoch  36 Batch  100/1077 - Train Accuracy: 0.7504, Validation Accuracy: 0.7635, Loss: 0.2393
Epoch  36 Batch  110/1077 - Train Accuracy: 0.7859, Validation Accuracy: 0.7546, Loss: 0.2255
Epoch  36 Batch  120/1077 - Train Accuracy: 0.7730, Validation Accuracy: 0.7433, Loss: 0.2405
Epoch  36 Batch  130/1077 - Train Accuracy: 0.7463, Validation Accuracy: 0.7415, Loss: 0.2186
Epoch  36 Batch  140/1077 - Train Accuracy: 0.7636, Validation Accuracy: 0.7397, Loss: 0.2259
Epoch  36 Batch  150/1077 - Train Accuracy: 0.7798, Validation Accuracy: 0.7333, Loss: 0.2209
Epoch  36 Batch  160/1077 - Train Accuracy: 0.7637, Validation Accuracy: 0.7340, Loss: 0.2358
Epoch  36 Batch  170/1077 - Train Accuracy: 0.7160, Validation Accuracy: 0.7575, Loss: 0.2318
Epoch  36 Batch  180/1077 - Train Accuracy: 0.7711, Validation Accuracy: 0.7450, Loss: 0.2380
Epoch  36 Batch  190/1077 - Train Accuracy: 0.8066, Validation Accuracy: 0.7393, Loss: 0.2240
Epoch  36 Batch  200/1077 - Train Accuracy: 0.7695, Validation Accuracy: 0.7344, Loss: 0.2264
Epoch  36 Batch  210/1077 - Train Accuracy: 0.7742, Validation Accuracy: 0.7333, Loss: 0.2321
Epoch  36 Batch  220/1077 - Train Accuracy: 0.7763, Validation Accuracy: 0.7287, Loss: 0.2448
Epoch  36 Batch  230/1077 - Train Accuracy: 0.7593, Validation Accuracy: 0.7454, Loss: 0.2267
Epoch  36 Batch  240/1077 - Train Accuracy: 0.8160, Validation Accuracy: 0.7433, Loss: 0.2245
Epoch  36 Batch  250/1077 - Train Accuracy: 0.7738, Validation Accuracy: 0.7415, Loss: 0.2112
Epoch  36 Batch  260/1077 - Train Accuracy: 0.7708, Validation Accuracy: 0.7347, Loss: 0.2185
Epoch  36 Batch  270/1077 - Train Accuracy: 0.7711, Validation Accuracy: 0.7429, Loss: 0.2419
Epoch  36 Batch  280/1077 - Train Accuracy: 0.7680, Validation Accuracy: 0.7440, Loss: 0.2413
Epoch  36 Batch  290/1077 - Train Accuracy: 0.7570, Validation Accuracy: 0.7415, Loss: 0.2432
Epoch  36 Batch  300/1077 - Train Accuracy: 0.7771, Validation Accuracy: 0.7504, Loss: 0.2311
Epoch  36 Batch  310/1077 - Train Accuracy: 0.7316, Validation Accuracy: 0.7429, Loss: 0.2421
Epoch  36 Batch  320/1077 - Train Accuracy: 0.8000, Validation Accuracy: 0.7464, Loss: 0.2596
Epoch  36 Batch  330/1077 - Train Accuracy: 0.7855, Validation Accuracy: 0.7504, Loss: 0.2393
Epoch  36 Batch  340/1077 - Train Accuracy: 0.7669, Validation Accuracy: 0.7557, Loss: 0.2231
Epoch  36 Batch  350/1077 - Train Accuracy: 0.7641, Validation Accuracy: 0.7479, Loss: 0.2469
Epoch  36 Batch  360/1077 - Train Accuracy: 0.7328, Validation Accuracy: 0.7479, Loss: 0.2392
Epoch  36 Batch  370/1077 - Train Accuracy: 0.7946, Validation Accuracy: 0.7422, Loss: 0.2254
Epoch  36 Batch  380/1077 - Train Accuracy: 0.7727, Validation Accuracy: 0.7312, Loss: 0.2272
Epoch  36 Batch  390/1077 - Train Accuracy: 0.7102, Validation Accuracy: 0.7362, Loss: 0.2532
Epoch  36 Batch  400/1077 - Train Accuracy: 0.7793, Validation Accuracy: 0.7504, Loss: 0.2403
Epoch  36 Batch  410/1077 - Train Accuracy: 0.7508, Validation Accuracy: 0.7624, Loss: 0.2382
Epoch  36 Batch  420/1077 - Train Accuracy: 0.7773, Validation Accuracy: 0.7464, Loss: 0.2265
Epoch  36 Batch  430/1077 - Train Accuracy: 0.7320, Validation Accuracy: 0.7369, Loss: 0.2291
Epoch  36 Batch  440/1077 - Train Accuracy: 0.7195, Validation Accuracy: 0.7411, Loss: 0.2432
Epoch  36 Batch  450/1077 - Train Accuracy: 0.7957, Validation Accuracy: 0.7354, Loss: 0.2289
Epoch  36 Batch  460/1077 - Train Accuracy: 0.7566, Validation Accuracy: 0.7337, Loss: 0.2439
Epoch  36 Batch  470/1077 - Train Accuracy: 0.7907, Validation Accuracy: 0.7464, Loss: 0.2468
Epoch  36 Batch  480/1077 - Train Accuracy: 0.7677, Validation Accuracy: 0.7482, Loss: 0.2317
Epoch  36 Batch  490/1077 - Train Accuracy: 0.7312, Validation Accuracy: 0.7525, Loss: 0.2447
Epoch  36 Batch  500/1077 - Train Accuracy: 0.7832, Validation Accuracy: 0.7454, Loss: 0.2161
Epoch  36 Batch  510/1077 - Train Accuracy: 0.7887, Validation Accuracy: 0.7500, Loss: 0.2410
Epoch  36 Batch  520/1077 - Train Accuracy: 0.8155, Validation Accuracy: 0.7475, Loss: 0.2237
Epoch  36 Batch  530/1077 - Train Accuracy: 0.7148, Validation Accuracy: 0.7393, Loss: 0.2535
Epoch  36 Batch  540/1077 - Train Accuracy: 0.7836, Validation Accuracy: 0.7354, Loss: 0.2277
Epoch  36 Batch  550/1077 - Train Accuracy: 0.7387, Validation Accuracy: 0.7457, Loss: 0.2473
Epoch  36 Batch  560/1077 - Train Accuracy: 0.7684, Validation Accuracy: 0.7500, Loss: 0.2348
Epoch  36 Batch  570/1077 - Train Accuracy: 0.7488, Validation Accuracy: 0.7450, Loss: 0.2657
Epoch  36 Batch  580/1077 - Train Accuracy: 0.7924, Validation Accuracy: 0.7695, Loss: 0.2137
Epoch  36 Batch  590/1077 - Train Accuracy: 0.7368, Validation Accuracy: 0.7567, Loss: 0.2436
Epoch  36 Batch  600/1077 - Train Accuracy: 0.7638, Validation Accuracy: 0.7372, Loss: 0.2219
Epoch  36 Batch  610/1077 - Train Accuracy: 0.7336, Validation Accuracy: 0.7457, Loss: 0.2447
Epoch  36 Batch  620/1077 - Train Accuracy: 0.7488, Validation Accuracy: 0.7433, Loss: 0.2285
Epoch  36 Batch  630/1077 - Train Accuracy: 0.7523, Validation Accuracy: 0.7411, Loss: 0.2283
Epoch  36 Batch  640/1077 - Train Accuracy: 0.7865, Validation Accuracy: 0.7599, Loss: 0.2220
Epoch  36 Batch  650/1077 - Train Accuracy: 0.7492, Validation Accuracy: 0.7553, Loss: 0.2415
Epoch  36 Batch  660/1077 - Train Accuracy: 0.7824, Validation Accuracy: 0.7536, Loss: 0.2342
Epoch  36 Batch  670/1077 - Train Accuracy: 0.7912, Validation Accuracy: 0.7290, Loss: 0.2198
Epoch  36 Batch  680/1077 - Train Accuracy: 0.7496, Validation Accuracy: 0.7479, Loss: 0.2370
Epoch  36 Batch  690/1077 - Train Accuracy: 0.7629, Validation Accuracy: 0.7390, Loss: 0.2360
Epoch  36 Batch  700/1077 - Train Accuracy: 0.7766, Validation Accuracy: 0.7528, Loss: 0.2128
Epoch  36 Batch  710/1077 - Train Accuracy: 0.7234, Validation Accuracy: 0.7514, Loss: 0.2297
Epoch  36 Batch  720/1077 - Train Accuracy: 0.7418, Validation Accuracy: 0.7457, Loss: 0.2493
Epoch  36 Batch  730/1077 - Train Accuracy: 0.7555, Validation Accuracy: 0.7422, Loss: 0.2411
Epoch  36 Batch  740/1077 - Train Accuracy: 0.7668, Validation Accuracy: 0.7553, Loss: 0.2287
Epoch  36 Batch  750/1077 - Train Accuracy: 0.7812, Validation Accuracy: 0.7536, Loss: 0.2331
Epoch  36 Batch  760/1077 - Train Accuracy: 0.7566, Validation Accuracy: 0.7614, Loss: 0.2435
Epoch  36 Batch  770/1077 - Train Accuracy: 0.7667, Validation Accuracy: 0.7504, Loss: 0.2090
Epoch  36 Batch  780/1077 - Train Accuracy: 0.7398, Validation Accuracy: 0.7493, Loss: 0.2488
Epoch  36 Batch  790/1077 - Train Accuracy: 0.7012, Validation Accuracy: 0.7521, Loss: 0.2621
Epoch  36 Batch  800/1077 - Train Accuracy: 0.7457, Validation Accuracy: 0.7486, Loss: 0.2208
Epoch  36 Batch  810/1077 - Train Accuracy: 0.7645, Validation Accuracy: 0.7642, Loss: 0.2243
Epoch  36 Batch  820/1077 - Train Accuracy: 0.7082, Validation Accuracy: 0.7518, Loss: 0.2551
Epoch  36 Batch  830/1077 - Train Accuracy: 0.7273, Validation Accuracy: 0.7582, Loss: 0.2450
Epoch  36 Batch  840/1077 - Train Accuracy: 0.7582, Validation Accuracy: 0.7681, Loss: 0.2353
Epoch  36 Batch  850/1077 - Train Accuracy: 0.7567, Validation Accuracy: 0.7425, Loss: 0.2510
Epoch  36 Batch  860/1077 - Train Accuracy: 0.7437, Validation Accuracy: 0.7567, Loss: 0.2344
Epoch  36 Batch  870/1077 - Train Accuracy: 0.7442, Validation Accuracy: 0.7489, Loss: 0.2459
Epoch  36 Batch  880/1077 - Train Accuracy: 0.7992, Validation Accuracy: 0.7521, Loss: 0.2195
Epoch  36 Batch  890/1077 - Train Accuracy: 0.8136, Validation Accuracy: 0.7457, Loss: 0.2143
Epoch  36 Batch  900/1077 - Train Accuracy: 0.7941, Validation Accuracy: 0.7550, Loss: 0.2250
Epoch  36 Batch  910/1077 - Train Accuracy: 0.7757, Validation Accuracy: 0.7504, Loss: 0.2577
Epoch  36 Batch  920/1077 - Train Accuracy: 0.7770, Validation Accuracy: 0.7489, Loss: 0.2331
Epoch  36 Batch  930/1077 - Train Accuracy: 0.7859, Validation Accuracy: 0.7379, Loss: 0.2203
Epoch  36 Batch  940/1077 - Train Accuracy: 0.7891, Validation Accuracy: 0.7425, Loss: 0.2156
Epoch  36 Batch  950/1077 - Train Accuracy: 0.7753, Validation Accuracy: 0.7642, Loss: 0.2113
Epoch  36 Batch  960/1077 - Train Accuracy: 0.7567, Validation Accuracy: 0.7447, Loss: 0.2317
Epoch  36 Batch  970/1077 - Train Accuracy: 0.7539, Validation Accuracy: 0.7404, Loss: 0.2235
Epoch  36 Batch  980/1077 - Train Accuracy: 0.7227, Validation Accuracy: 0.7482, Loss: 0.2240
Epoch  36 Batch  990/1077 - Train Accuracy: 0.7381, Validation Accuracy: 0.7628, Loss: 0.2338
Epoch  36 Batch 1000/1077 - Train Accuracy: 0.7958, Validation Accuracy: 0.7642, Loss: 0.2157
Epoch  36 Batch 1010/1077 - Train Accuracy: 0.7633, Validation Accuracy: 0.7496, Loss: 0.2207
Epoch  36 Batch 1020/1077 - Train Accuracy: 0.7688, Validation Accuracy: 0.7436, Loss: 0.2175
Epoch  36 Batch 1030/1077 - Train Accuracy: 0.7504, Validation Accuracy: 0.7507, Loss: 0.2421
Epoch  36 Batch 1040/1077 - Train Accuracy: 0.7841, Validation Accuracy: 0.7404, Loss: 0.2354
Epoch  36 Batch 1050/1077 - Train Accuracy: 0.7125, Validation Accuracy: 0.7429, Loss: 0.2328
Epoch  36 Batch 1060/1077 - Train Accuracy: 0.8039, Validation Accuracy: 0.7418, Loss: 0.2203
Epoch  36 Batch 1070/1077 - Train Accuracy: 0.7445, Validation Accuracy: 0.7415, Loss: 0.2387
Epoch  37 Batch   10/1077 - Train Accuracy: 0.7812, Validation Accuracy: 0.7369, Loss: 0.2312
Epoch  37 Batch   20/1077 - Train Accuracy: 0.7426, Validation Accuracy: 0.7411, Loss: 0.2269
Epoch  37 Batch   30/1077 - Train Accuracy: 0.7902, Validation Accuracy: 0.7429, Loss: 0.2394
Epoch  37 Batch   40/1077 - Train Accuracy: 0.7840, Validation Accuracy: 0.7457, Loss: 0.2377
Epoch  37 Batch   50/1077 - Train Accuracy: 0.7594, Validation Accuracy: 0.7670, Loss: 0.2230
Epoch  37 Batch   60/1077 - Train Accuracy: 0.7723, Validation Accuracy: 0.7599, Loss: 0.2091
Epoch  37 Batch   70/1077 - Train Accuracy: 0.8104, Validation Accuracy: 0.7578, Loss: 0.2341
Epoch  37 Batch   80/1077 - Train Accuracy: 0.7562, Validation Accuracy: 0.7496, Loss: 0.2384
Epoch  37 Batch   90/1077 - Train Accuracy: 0.7332, Validation Accuracy: 0.7621, Loss: 0.2425
Epoch  37 Batch  100/1077 - Train Accuracy: 0.7527, Validation Accuracy: 0.7738, Loss: 0.2199
Epoch  37 Batch  110/1077 - Train Accuracy: 0.7797, Validation Accuracy: 0.7550, Loss: 0.2095
Epoch  37 Batch  120/1077 - Train Accuracy: 0.7812, Validation Accuracy: 0.7539, Loss: 0.2448
Epoch  37 Batch  130/1077 - Train Accuracy: 0.7474, Validation Accuracy: 0.7450, Loss: 0.2202
Epoch  37 Batch  140/1077 - Train Accuracy: 0.7632, Validation Accuracy: 0.7433, Loss: 0.2340
Epoch  37 Batch  150/1077 - Train Accuracy: 0.7775, Validation Accuracy: 0.7393, Loss: 0.2140
Epoch  37 Batch  160/1077 - Train Accuracy: 0.7488, Validation Accuracy: 0.7340, Loss: 0.2232
Epoch  37 Batch  170/1077 - Train Accuracy: 0.7324, Validation Accuracy: 0.7468, Loss: 0.2282
Epoch  37 Batch  180/1077 - Train Accuracy: 0.7668, Validation Accuracy: 0.7479, Loss: 0.2198
Epoch  37 Batch  190/1077 - Train Accuracy: 0.8027, Validation Accuracy: 0.7425, Loss: 0.2300
Epoch  37 Batch  200/1077 - Train Accuracy: 0.7680, Validation Accuracy: 0.7401, Loss: 0.2348
Epoch  37 Batch  210/1077 - Train Accuracy: 0.7798, Validation Accuracy: 0.7322, Loss: 0.2313
Epoch  37 Batch  220/1077 - Train Accuracy: 0.7891, Validation Accuracy: 0.7308, Loss: 0.2256
Epoch  37 Batch  230/1077 - Train Accuracy: 0.7600, Validation Accuracy: 0.7546, Loss: 0.2155
Epoch  37 Batch  240/1077 - Train Accuracy: 0.8176, Validation Accuracy: 0.7418, Loss: 0.2191
Epoch  37 Batch  250/1077 - Train Accuracy: 0.7802, Validation Accuracy: 0.7390, Loss: 0.2267
Epoch  37 Batch  260/1077 - Train Accuracy: 0.8028, Validation Accuracy: 0.7500, Loss: 0.2208
Epoch  37 Batch  270/1077 - Train Accuracy: 0.7695, Validation Accuracy: 0.7443, Loss: 0.2397
Epoch  37 Batch  280/1077 - Train Accuracy: 0.7641, Validation Accuracy: 0.7507, Loss: 0.2410
Epoch  37 Batch  290/1077 - Train Accuracy: 0.7605, Validation Accuracy: 0.7422, Loss: 0.2346
Epoch  37 Batch  300/1077 - Train Accuracy: 0.7636, Validation Accuracy: 0.7550, Loss: 0.2305
Epoch  37 Batch  310/1077 - Train Accuracy: 0.7371, Validation Accuracy: 0.7507, Loss: 0.2353
Epoch  37 Batch  320/1077 - Train Accuracy: 0.8012, Validation Accuracy: 0.7528, Loss: 0.2458
Epoch  37 Batch  330/1077 - Train Accuracy: 0.7625, Validation Accuracy: 0.7621, Loss: 0.2307
Epoch  37 Batch  340/1077 - Train Accuracy: 0.7738, Validation Accuracy: 0.7592, Loss: 0.2271
Epoch  37 Batch  350/1077 - Train Accuracy: 0.7520, Validation Accuracy: 0.7401, Loss: 0.2221
Epoch  37 Batch  360/1077 - Train Accuracy: 0.7422, Validation Accuracy: 0.7386, Loss: 0.2204
Epoch  37 Batch  370/1077 - Train Accuracy: 0.7861, Validation Accuracy: 0.7521, Loss: 0.2126
Epoch  37 Batch  380/1077 - Train Accuracy: 0.7781, Validation Accuracy: 0.7447, Loss: 0.2172
Epoch  37 Batch  390/1077 - Train Accuracy: 0.7156, Validation Accuracy: 0.7433, Loss: 0.2531
Epoch  37 Batch  400/1077 - Train Accuracy: 0.7922, Validation Accuracy: 0.7365, Loss: 0.2362
Epoch  37 Batch  410/1077 - Train Accuracy: 0.7566, Validation Accuracy: 0.7525, Loss: 0.2412
Epoch  37 Batch  420/1077 - Train Accuracy: 0.7840, Validation Accuracy: 0.7397, Loss: 0.2112
Epoch  37 Batch  430/1077 - Train Accuracy: 0.7352, Validation Accuracy: 0.7354, Loss: 0.2267
Epoch  37 Batch  440/1077 - Train Accuracy: 0.7395, Validation Accuracy: 0.7337, Loss: 0.2373
Epoch  37 Batch  450/1077 - Train Accuracy: 0.7961, Validation Accuracy: 0.7404, Loss: 0.2382
Epoch  37 Batch  460/1077 - Train Accuracy: 0.7414, Validation Accuracy: 0.7337, Loss: 0.2451
Epoch  37 Batch  470/1077 - Train Accuracy: 0.7553, Validation Accuracy: 0.7464, Loss: 0.2502
Epoch  37 Batch  480/1077 - Train Accuracy: 0.7529, Validation Accuracy: 0.7479, Loss: 0.2271
Epoch  37 Batch  490/1077 - Train Accuracy: 0.7332, Validation Accuracy: 0.7429, Loss: 0.2524
Epoch  37 Batch  500/1077 - Train Accuracy: 0.7969, Validation Accuracy: 0.7404, Loss: 0.2189
Epoch  37 Batch  510/1077 - Train Accuracy: 0.7934, Validation Accuracy: 0.7418, Loss: 0.2296
Epoch  37 Batch  520/1077 - Train Accuracy: 0.8181, Validation Accuracy: 0.7418, Loss: 0.2152
Epoch  37 Batch  530/1077 - Train Accuracy: 0.7172, Validation Accuracy: 0.7415, Loss: 0.2419
Epoch  37 Batch  540/1077 - Train Accuracy: 0.7863, Validation Accuracy: 0.7447, Loss: 0.2256
Epoch  37 Batch  550/1077 - Train Accuracy: 0.7309, Validation Accuracy: 0.7411, Loss: 0.2338
Epoch  37 Batch  560/1077 - Train Accuracy: 0.7656, Validation Accuracy: 0.7436, Loss: 0.2183
Epoch  37 Batch  570/1077 - Train Accuracy: 0.7850, Validation Accuracy: 0.7486, Loss: 0.2421
Epoch  37 Batch  580/1077 - Train Accuracy: 0.7943, Validation Accuracy: 0.7468, Loss: 0.2190
Epoch  37 Batch  590/1077 - Train Accuracy: 0.7418, Validation Accuracy: 0.7450, Loss: 0.2476
Epoch  37 Batch  600/1077 - Train Accuracy: 0.7697, Validation Accuracy: 0.7326, Loss: 0.2110
Epoch  37 Batch  610/1077 - Train Accuracy: 0.7475, Validation Accuracy: 0.7244, Loss: 0.2410
Epoch  37 Batch  620/1077 - Train Accuracy: 0.7629, Validation Accuracy: 0.7422, Loss: 0.2135
Epoch  37 Batch  630/1077 - Train Accuracy: 0.7504, Validation Accuracy: 0.7472, Loss: 0.2141
Epoch  37 Batch  640/1077 - Train Accuracy: 0.7794, Validation Accuracy: 0.7553, Loss: 0.2108
Epoch  37 Batch  650/1077 - Train Accuracy: 0.7574, Validation Accuracy: 0.7454, Loss: 0.2204
Epoch  37 Batch  660/1077 - Train Accuracy: 0.7867, Validation Accuracy: 0.7496, Loss: 0.2241
Epoch  37 Batch  670/1077 - Train Accuracy: 0.7887, Validation Accuracy: 0.7429, Loss: 0.2127
Epoch  37 Batch  680/1077 - Train Accuracy: 0.7615, Validation Accuracy: 0.7347, Loss: 0.2260
Epoch  37 Batch  690/1077 - Train Accuracy: 0.7633, Validation Accuracy: 0.7479, Loss: 0.2383
Epoch  37 Batch  700/1077 - Train Accuracy: 0.7727, Validation Accuracy: 0.7365, Loss: 0.2208
Epoch  37 Batch  710/1077 - Train Accuracy: 0.7414, Validation Accuracy: 0.7379, Loss: 0.2129
Epoch  37 Batch  720/1077 - Train Accuracy: 0.7516, Validation Accuracy: 0.7379, Loss: 0.2381
Epoch  37 Batch  730/1077 - Train Accuracy: 0.7457, Validation Accuracy: 0.7525, Loss: 0.2281
Epoch  37 Batch  740/1077 - Train Accuracy: 0.7766, Validation Accuracy: 0.7422, Loss: 0.2124
Epoch  37 Batch  750/1077 - Train Accuracy: 0.7836, Validation Accuracy: 0.7443, Loss: 0.2326
Epoch  37 Batch  760/1077 - Train Accuracy: 0.7648, Validation Accuracy: 0.7607, Loss: 0.2345
Epoch  37 Batch  770/1077 - Train Accuracy: 0.7719, Validation Accuracy: 0.7404, Loss: 0.2279
Epoch  37 Batch  780/1077 - Train Accuracy: 0.7469, Validation Accuracy: 0.7628, Loss: 0.2462
Epoch  37 Batch  790/1077 - Train Accuracy: 0.7012, Validation Accuracy: 0.7596, Loss: 0.2441
Epoch  37 Batch  800/1077 - Train Accuracy: 0.7625, Validation Accuracy: 0.7482, Loss: 0.2570
Epoch  37 Batch  810/1077 - Train Accuracy: 0.7701, Validation Accuracy: 0.7596, Loss: 0.2157
Epoch  37 Batch  820/1077 - Train Accuracy: 0.7176, Validation Accuracy: 0.7525, Loss: 0.2397
Epoch  37 Batch  830/1077 - Train Accuracy: 0.7379, Validation Accuracy: 0.7472, Loss: 0.2294
Epoch  37 Batch  840/1077 - Train Accuracy: 0.7695, Validation Accuracy: 0.7511, Loss: 0.2352
Epoch  37 Batch  850/1077 - Train Accuracy: 0.7522, Validation Accuracy: 0.7514, Loss: 0.2461
Epoch  37 Batch  860/1077 - Train Accuracy: 0.7400, Validation Accuracy: 0.7599, Loss: 0.2357
Epoch  37 Batch  870/1077 - Train Accuracy: 0.7430, Validation Accuracy: 0.7617, Loss: 0.2367
Epoch  37 Batch  880/1077 - Train Accuracy: 0.8000, Validation Accuracy: 0.7532, Loss: 0.2227
Epoch  37 Batch  890/1077 - Train Accuracy: 0.8077, Validation Accuracy: 0.7461, Loss: 0.2054
Epoch  37 Batch  900/1077 - Train Accuracy: 0.7785, Validation Accuracy: 0.7472, Loss: 0.2240
Epoch  37 Batch  910/1077 - Train Accuracy: 0.7946, Validation Accuracy: 0.7589, Loss: 0.2406
Epoch  37 Batch  920/1077 - Train Accuracy: 0.7957, Validation Accuracy: 0.7464, Loss: 0.2292
Epoch  37 Batch  930/1077 - Train Accuracy: 0.7715, Validation Accuracy: 0.7418, Loss: 0.2092
Epoch  37 Batch  940/1077 - Train Accuracy: 0.7641, Validation Accuracy: 0.7525, Loss: 0.2205
Epoch  37 Batch  950/1077 - Train Accuracy: 0.7857, Validation Accuracy: 0.7607, Loss: 0.2213
Epoch  37 Batch  960/1077 - Train Accuracy: 0.7719, Validation Accuracy: 0.7486, Loss: 0.2347
Epoch  37 Batch  970/1077 - Train Accuracy: 0.7672, Validation Accuracy: 0.7351, Loss: 0.2291
Epoch  37 Batch  980/1077 - Train Accuracy: 0.7309, Validation Accuracy: 0.7482, Loss: 0.2299
Epoch  37 Batch  990/1077 - Train Accuracy: 0.7525, Validation Accuracy: 0.7688, Loss: 0.2534
Epoch  37 Batch 1000/1077 - Train Accuracy: 0.8025, Validation Accuracy: 0.7578, Loss: 0.2192
Epoch  37 Batch 1010/1077 - Train Accuracy: 0.7598, Validation Accuracy: 0.7546, Loss: 0.2254
Epoch  37 Batch 1020/1077 - Train Accuracy: 0.7711, Validation Accuracy: 0.7511, Loss: 0.2039
Epoch  37 Batch 1030/1077 - Train Accuracy: 0.7348, Validation Accuracy: 0.7482, Loss: 0.2411
Epoch  37 Batch 1040/1077 - Train Accuracy: 0.7878, Validation Accuracy: 0.7450, Loss: 0.2449
Epoch  37 Batch 1050/1077 - Train Accuracy: 0.7117, Validation Accuracy: 0.7560, Loss: 0.2276
Epoch  37 Batch 1060/1077 - Train Accuracy: 0.7930, Validation Accuracy: 0.7493, Loss: 0.2217
Epoch  37 Batch 1070/1077 - Train Accuracy: 0.7340, Validation Accuracy: 0.7560, Loss: 0.2335
Epoch  38 Batch   10/1077 - Train Accuracy: 0.7911, Validation Accuracy: 0.7401, Loss: 0.2297
Epoch  38 Batch   20/1077 - Train Accuracy: 0.7465, Validation Accuracy: 0.7433, Loss: 0.2183
Epoch  38 Batch   30/1077 - Train Accuracy: 0.7910, Validation Accuracy: 0.7411, Loss: 0.2230
Epoch  38 Batch   40/1077 - Train Accuracy: 0.7930, Validation Accuracy: 0.7472, Loss: 0.2213
Epoch  38 Batch   50/1077 - Train Accuracy: 0.7684, Validation Accuracy: 0.7603, Loss: 0.2242
Epoch  38 Batch   60/1077 - Train Accuracy: 0.7738, Validation Accuracy: 0.7624, Loss: 0.2092
Epoch  38 Batch   70/1077 - Train Accuracy: 0.8067, Validation Accuracy: 0.7550, Loss: 0.2358
Epoch  38 Batch   80/1077 - Train Accuracy: 0.7664, Validation Accuracy: 0.7500, Loss: 0.2357
Epoch  38 Batch   90/1077 - Train Accuracy: 0.7430, Validation Accuracy: 0.7518, Loss: 0.2411
Epoch  38 Batch  100/1077 - Train Accuracy: 0.7668, Validation Accuracy: 0.7624, Loss: 0.2278
Epoch  38 Batch  110/1077 - Train Accuracy: 0.7699, Validation Accuracy: 0.7635, Loss: 0.2087
Epoch  38 Batch  120/1077 - Train Accuracy: 0.7766, Validation Accuracy: 0.7560, Loss: 0.2305
Epoch  38 Batch  130/1077 - Train Accuracy: 0.7459, Validation Accuracy: 0.7546, Loss: 0.2191
Epoch  38 Batch  140/1077 - Train Accuracy: 0.7656, Validation Accuracy: 0.7479, Loss: 0.2290
Epoch  38 Batch  150/1077 - Train Accuracy: 0.7790, Validation Accuracy: 0.7511, Loss: 0.2268
Epoch  38 Batch  160/1077 - Train Accuracy: 0.7582, Validation Accuracy: 0.7496, Loss: 0.2168
Epoch  38 Batch  170/1077 - Train Accuracy: 0.7305, Validation Accuracy: 0.7528, Loss: 0.2300
Epoch  38 Batch  180/1077 - Train Accuracy: 0.7668, Validation Accuracy: 0.7564, Loss: 0.2283
Epoch  38 Batch  190/1077 - Train Accuracy: 0.8117, Validation Accuracy: 0.7486, Loss: 0.2216
Epoch  38 Batch  200/1077 - Train Accuracy: 0.7676, Validation Accuracy: 0.7365, Loss: 0.2329
Epoch  38 Batch  210/1077 - Train Accuracy: 0.7835, Validation Accuracy: 0.7482, Loss: 0.2229
Epoch  38 Batch  220/1077 - Train Accuracy: 0.7743, Validation Accuracy: 0.7358, Loss: 0.2306
Epoch  38 Batch  230/1077 - Train Accuracy: 0.7667, Validation Accuracy: 0.7624, Loss: 0.2204
Epoch  38 Batch  240/1077 - Train Accuracy: 0.8324, Validation Accuracy: 0.7472, Loss: 0.2163
Epoch  38 Batch  250/1077 - Train Accuracy: 0.7823, Validation Accuracy: 0.7415, Loss: 0.2043
Epoch  38 Batch  260/1077 - Train Accuracy: 0.7879, Validation Accuracy: 0.7362, Loss: 0.2045
Epoch  38 Batch  270/1077 - Train Accuracy: 0.7758, Validation Accuracy: 0.7475, Loss: 0.2404
Epoch  38 Batch  280/1077 - Train Accuracy: 0.7738, Validation Accuracy: 0.7528, Loss: 0.2173
Epoch  38 Batch  290/1077 - Train Accuracy: 0.7758, Validation Accuracy: 0.7386, Loss: 0.2326
Epoch  38 Batch  300/1077 - Train Accuracy: 0.7788, Validation Accuracy: 0.7493, Loss: 0.2097
Epoch  38 Batch  310/1077 - Train Accuracy: 0.7320, Validation Accuracy: 0.7528, Loss: 0.2361
Epoch  38 Batch  320/1077 - Train Accuracy: 0.8023, Validation Accuracy: 0.7518, Loss: 0.2615
Epoch  38 Batch  330/1077 - Train Accuracy: 0.7801, Validation Accuracy: 0.7585, Loss: 0.2268
Epoch  38 Batch  340/1077 - Train Accuracy: 0.7825, Validation Accuracy: 0.7624, Loss: 0.2313
Epoch  38 Batch  350/1077 - Train Accuracy: 0.7551, Validation Accuracy: 0.7550, Loss: 0.2297
Epoch  38 Batch  360/1077 - Train Accuracy: 0.7402, Validation Accuracy: 0.7475, Loss: 0.2362
Epoch  38 Batch  370/1077 - Train Accuracy: 0.7868, Validation Accuracy: 0.7511, Loss: 0.2293
Epoch  38 Batch  380/1077 - Train Accuracy: 0.7711, Validation Accuracy: 0.7546, Loss: 0.2052
Epoch  38 Batch  390/1077 - Train Accuracy: 0.7129, Validation Accuracy: 0.7482, Loss: 0.2460
Epoch  38 Batch  400/1077 - Train Accuracy: 0.7887, Validation Accuracy: 0.7450, Loss: 0.2289
Epoch  38 Batch  410/1077 - Train Accuracy: 0.7570, Validation Accuracy: 0.7496, Loss: 0.2261
Epoch  38 Batch  420/1077 - Train Accuracy: 0.7922, Validation Accuracy: 0.7557, Loss: 0.2159
Epoch  38 Batch  430/1077 - Train Accuracy: 0.7305, Validation Accuracy: 0.7571, Loss: 0.2279
Epoch  38 Batch  440/1077 - Train Accuracy: 0.7395, Validation Accuracy: 0.7479, Loss: 0.2335
Epoch  38 Batch  450/1077 - Train Accuracy: 0.7957, Validation Accuracy: 0.7418, Loss: 0.2169
Epoch  38 Batch  460/1077 - Train Accuracy: 0.7426, Validation Accuracy: 0.7461, Loss: 0.2392
Epoch  38 Batch  470/1077 - Train Accuracy: 0.7771, Validation Accuracy: 0.7486, Loss: 0.2318
Epoch  38 Batch  480/1077 - Train Accuracy: 0.7541, Validation Accuracy: 0.7464, Loss: 0.2250
Epoch  38 Batch  490/1077 - Train Accuracy: 0.7445, Validation Accuracy: 0.7457, Loss: 0.2258
Epoch  38 Batch  500/1077 - Train Accuracy: 0.7922, Validation Accuracy: 0.7614, Loss: 0.2087
Epoch  38 Batch  510/1077 - Train Accuracy: 0.7902, Validation Accuracy: 0.7543, Loss: 0.2288
Epoch  38 Batch  520/1077 - Train Accuracy: 0.8438, Validation Accuracy: 0.7575, Loss: 0.2001
Epoch  38 Batch  530/1077 - Train Accuracy: 0.7227, Validation Accuracy: 0.7404, Loss: 0.2393
Epoch  38 Batch  540/1077 - Train Accuracy: 0.7746, Validation Accuracy: 0.7454, Loss: 0.2139
Epoch  38 Batch  550/1077 - Train Accuracy: 0.7402, Validation Accuracy: 0.7443, Loss: 0.2239
Epoch  38 Batch  560/1077 - Train Accuracy: 0.7699, Validation Accuracy: 0.7511, Loss: 0.2150
Epoch  38 Batch  570/1077 - Train Accuracy: 0.7767, Validation Accuracy: 0.7496, Loss: 0.2563
Epoch  38 Batch  580/1077 - Train Accuracy: 0.8028, Validation Accuracy: 0.7433, Loss: 0.2010
Epoch  38 Batch  590/1077 - Train Accuracy: 0.7405, Validation Accuracy: 0.7436, Loss: 0.2573
Epoch  38 Batch  600/1077 - Train Accuracy: 0.7809, Validation Accuracy: 0.7322, Loss: 0.2250
Epoch  38 Batch  610/1077 - Train Accuracy: 0.7500, Validation Accuracy: 0.7436, Loss: 0.2359
Epoch  38 Batch  620/1077 - Train Accuracy: 0.7668, Validation Accuracy: 0.7436, Loss: 0.2092
Epoch  38 Batch  630/1077 - Train Accuracy: 0.7418, Validation Accuracy: 0.7440, Loss: 0.2137
Epoch  38 Batch  640/1077 - Train Accuracy: 0.7783, Validation Accuracy: 0.7528, Loss: 0.2061
Epoch  38 Batch  650/1077 - Train Accuracy: 0.7648, Validation Accuracy: 0.7557, Loss: 0.2190
Epoch  38 Batch  660/1077 - Train Accuracy: 0.8027, Validation Accuracy: 0.7461, Loss: 0.2257
Epoch  38 Batch  670/1077 - Train Accuracy: 0.7884, Validation Accuracy: 0.7436, Loss: 0.2016
Epoch  38 Batch  680/1077 - Train Accuracy: 0.7608, Validation Accuracy: 0.7362, Loss: 0.2187
Epoch  38 Batch  690/1077 - Train Accuracy: 0.7684, Validation Accuracy: 0.7401, Loss: 0.2312
Epoch  38 Batch  700/1077 - Train Accuracy: 0.7906, Validation Accuracy: 0.7464, Loss: 0.2089
Epoch  38 Batch  710/1077 - Train Accuracy: 0.7285, Validation Accuracy: 0.7482, Loss: 0.2232
Epoch  38 Batch  720/1077 - Train Accuracy: 0.7590, Validation Accuracy: 0.7457, Loss: 0.2267
Epoch  38 Batch  730/1077 - Train Accuracy: 0.7453, Validation Accuracy: 0.7511, Loss: 0.2336
Epoch  38 Batch  740/1077 - Train Accuracy: 0.7715, Validation Accuracy: 0.7514, Loss: 0.2090
Epoch  38 Batch  750/1077 - Train Accuracy: 0.7777, Validation Accuracy: 0.7475, Loss: 0.2121
Epoch  38 Batch  760/1077 - Train Accuracy: 0.7633, Validation Accuracy: 0.7560, Loss: 0.2317
Epoch  38 Batch  770/1077 - Train Accuracy: 0.7727, Validation Accuracy: 0.7557, Loss: 0.2135
Epoch  38 Batch  780/1077 - Train Accuracy: 0.7434, Validation Accuracy: 0.7539, Loss: 0.2359
Epoch  38 Batch  790/1077 - Train Accuracy: 0.7051, Validation Accuracy: 0.7422, Loss: 0.2388
Epoch  38 Batch  800/1077 - Train Accuracy: 0.7586, Validation Accuracy: 0.7404, Loss: 0.2265
Epoch  38 Batch  810/1077 - Train Accuracy: 0.7608, Validation Accuracy: 0.7354, Loss: 0.2117
Epoch  38 Batch  820/1077 - Train Accuracy: 0.7164, Validation Accuracy: 0.7422, Loss: 0.2253
Epoch  38 Batch  830/1077 - Train Accuracy: 0.7355, Validation Accuracy: 0.7447, Loss: 0.2291
Epoch  38 Batch  840/1077 - Train Accuracy: 0.7746, Validation Accuracy: 0.7486, Loss: 0.2239
Epoch  38 Batch  850/1077 - Train Accuracy: 0.7478, Validation Accuracy: 0.7436, Loss: 0.2493
Epoch  38 Batch  860/1077 - Train Accuracy: 0.7556, Validation Accuracy: 0.7628, Loss: 0.2487
Epoch  38 Batch  870/1077 - Train Accuracy: 0.7475, Validation Accuracy: 0.7564, Loss: 0.2332
Epoch  38 Batch  880/1077 - Train Accuracy: 0.7934, Validation Accuracy: 0.7550, Loss: 0.2135
Epoch  38 Batch  890/1077 - Train Accuracy: 0.8162, Validation Accuracy: 0.7457, Loss: 0.2028
Epoch  38 Batch  900/1077 - Train Accuracy: 0.7977, Validation Accuracy: 0.7642, Loss: 0.2388
Epoch  38 Batch  910/1077 - Train Accuracy: 0.8051, Validation Accuracy: 0.7589, Loss: 0.2252
Epoch  38 Batch  920/1077 - Train Accuracy: 0.8020, Validation Accuracy: 0.7454, Loss: 0.2223
Epoch  38 Batch  930/1077 - Train Accuracy: 0.7902, Validation Accuracy: 0.7308, Loss: 0.2068
Epoch  38 Batch  940/1077 - Train Accuracy: 0.7809, Validation Accuracy: 0.7376, Loss: 0.2130
Epoch  38 Batch  950/1077 - Train Accuracy: 0.7749, Validation Accuracy: 0.7585, Loss: 0.2229
Epoch  38 Batch  960/1077 - Train Accuracy: 0.7686, Validation Accuracy: 0.7450, Loss: 0.2281
Epoch  38 Batch  970/1077 - Train Accuracy: 0.7750, Validation Accuracy: 0.7354, Loss: 0.2293
Epoch  38 Batch  980/1077 - Train Accuracy: 0.7289, Validation Accuracy: 0.7315, Loss: 0.2391
Epoch  38 Batch  990/1077 - Train Accuracy: 0.7471, Validation Accuracy: 0.7646, Loss: 0.2278
Epoch  38 Batch 1000/1077 - Train Accuracy: 0.8010, Validation Accuracy: 0.7560, Loss: 0.1995
Epoch  38 Batch 1010/1077 - Train Accuracy: 0.7648, Validation Accuracy: 0.7379, Loss: 0.2141
Epoch  38 Batch 1020/1077 - Train Accuracy: 0.7684, Validation Accuracy: 0.7525, Loss: 0.2017
Epoch  38 Batch 1030/1077 - Train Accuracy: 0.7398, Validation Accuracy: 0.7596, Loss: 0.2439
Epoch  38 Batch 1040/1077 - Train Accuracy: 0.7841, Validation Accuracy: 0.7379, Loss: 0.2430
Epoch  38 Batch 1050/1077 - Train Accuracy: 0.7145, Validation Accuracy: 0.7550, Loss: 0.2134
Epoch  38 Batch 1060/1077 - Train Accuracy: 0.7996, Validation Accuracy: 0.7443, Loss: 0.1953
Epoch  38 Batch 1070/1077 - Train Accuracy: 0.7438, Validation Accuracy: 0.7493, Loss: 0.2311
Epoch  39 Batch   10/1077 - Train Accuracy: 0.8026, Validation Accuracy: 0.7486, Loss: 0.2360
Epoch  39 Batch   20/1077 - Train Accuracy: 0.7484, Validation Accuracy: 0.7404, Loss: 0.2253
Epoch  39 Batch   30/1077 - Train Accuracy: 0.7883, Validation Accuracy: 0.7489, Loss: 0.2207
Epoch  39 Batch   40/1077 - Train Accuracy: 0.7977, Validation Accuracy: 0.7553, Loss: 0.2273
Epoch  39 Batch   50/1077 - Train Accuracy: 0.7496, Validation Accuracy: 0.7550, Loss: 0.2123
Epoch  39 Batch   60/1077 - Train Accuracy: 0.7824, Validation Accuracy: 0.7592, Loss: 0.2010
Epoch  39 Batch   70/1077 - Train Accuracy: 0.8088, Validation Accuracy: 0.7514, Loss: 0.2430
Epoch  39 Batch   80/1077 - Train Accuracy: 0.7637, Validation Accuracy: 0.7514, Loss: 0.2267
Epoch  39 Batch   90/1077 - Train Accuracy: 0.7566, Validation Accuracy: 0.7532, Loss: 0.2448
Epoch  39 Batch  100/1077 - Train Accuracy: 0.7527, Validation Accuracy: 0.7720, Loss: 0.2235
Epoch  39 Batch  110/1077 - Train Accuracy: 0.7816, Validation Accuracy: 0.7607, Loss: 0.2017
Epoch  39 Batch  120/1077 - Train Accuracy: 0.7883, Validation Accuracy: 0.7646, Loss: 0.2282
Epoch  39 Batch  130/1077 - Train Accuracy: 0.7414, Validation Accuracy: 0.7610, Loss: 0.2134
Epoch  39 Batch  140/1077 - Train Accuracy: 0.7825, Validation Accuracy: 0.7493, Loss: 0.2282
Epoch  39 Batch  150/1077 - Train Accuracy: 0.7824, Validation Accuracy: 0.7564, Loss: 0.2212
Epoch  39 Batch  160/1077 - Train Accuracy: 0.7637, Validation Accuracy: 0.7514, Loss: 0.2078
Epoch  39 Batch  170/1077 - Train Accuracy: 0.7469, Validation Accuracy: 0.7589, Loss: 0.2288
Epoch  39 Batch  180/1077 - Train Accuracy: 0.7684, Validation Accuracy: 0.7514, Loss: 0.2188
Epoch  39 Batch  190/1077 - Train Accuracy: 0.8094, Validation Accuracy: 0.7553, Loss: 0.2164
Epoch  39 Batch  200/1077 - Train Accuracy: 0.7738, Validation Accuracy: 0.7493, Loss: 0.2226
Epoch  39 Batch  210/1077 - Train Accuracy: 0.7872, Validation Accuracy: 0.7269, Loss: 0.2169
Epoch  39 Batch  220/1077 - Train Accuracy: 0.7767, Validation Accuracy: 0.7386, Loss: 0.2297
Epoch  39 Batch  230/1077 - Train Accuracy: 0.7660, Validation Accuracy: 0.7582, Loss: 0.2106
Epoch  39 Batch  240/1077 - Train Accuracy: 0.8246, Validation Accuracy: 0.7493, Loss: 0.2047
Epoch  39 Batch  250/1077 - Train Accuracy: 0.7713, Validation Accuracy: 0.7486, Loss: 0.2029
Epoch  39 Batch  260/1077 - Train Accuracy: 0.8013, Validation Accuracy: 0.7433, Loss: 0.1957
Epoch  39 Batch  270/1077 - Train Accuracy: 0.7723, Validation Accuracy: 0.7472, Loss: 0.2206
Epoch  39 Batch  280/1077 - Train Accuracy: 0.7727, Validation Accuracy: 0.7525, Loss: 0.2164
Epoch  39 Batch  290/1077 - Train Accuracy: 0.7609, Validation Accuracy: 0.7415, Loss: 0.2381
Epoch  39 Batch  300/1077 - Train Accuracy: 0.7969, Validation Accuracy: 0.7521, Loss: 0.2037
Epoch  39 Batch  310/1077 - Train Accuracy: 0.7270, Validation Accuracy: 0.7433, Loss: 0.2341
Epoch  39 Batch  320/1077 - Train Accuracy: 0.8035, Validation Accuracy: 0.7518, Loss: 0.2459
Epoch  39 Batch  330/1077 - Train Accuracy: 0.7793, Validation Accuracy: 0.7575, Loss: 0.2208
Epoch  39 Batch  340/1077 - Train Accuracy: 0.7751, Validation Accuracy: 0.7536, Loss: 0.2176
Epoch  39 Batch  350/1077 - Train Accuracy: 0.7566, Validation Accuracy: 0.7404, Loss: 0.2078
Epoch  39 Batch  360/1077 - Train Accuracy: 0.7562, Validation Accuracy: 0.7433, Loss: 0.2275
Epoch  39 Batch  370/1077 - Train Accuracy: 0.7831, Validation Accuracy: 0.7429, Loss: 0.2146
Epoch  39 Batch  380/1077 - Train Accuracy: 0.7730, Validation Accuracy: 0.7301, Loss: 0.2074
Epoch  39 Batch  390/1077 - Train Accuracy: 0.7172, Validation Accuracy: 0.7372, Loss: 0.2390
Epoch  39 Batch  400/1077 - Train Accuracy: 0.7891, Validation Accuracy: 0.7390, Loss: 0.2162
Epoch  39 Batch  410/1077 - Train Accuracy: 0.7722, Validation Accuracy: 0.7603, Loss: 0.2309
Epoch  39 Batch  420/1077 - Train Accuracy: 0.7902, Validation Accuracy: 0.7599, Loss: 0.2062
Epoch  39 Batch  430/1077 - Train Accuracy: 0.7406, Validation Accuracy: 0.7401, Loss: 0.2218
Epoch  39 Batch  440/1077 - Train Accuracy: 0.7332, Validation Accuracy: 0.7436, Loss: 0.2346
Epoch  39 Batch  450/1077 - Train Accuracy: 0.7918, Validation Accuracy: 0.7482, Loss: 0.2134
Epoch  39 Batch  460/1077 - Train Accuracy: 0.7410, Validation Accuracy: 0.7351, Loss: 0.2337
Epoch  39 Batch  470/1077 - Train Accuracy: 0.7878, Validation Accuracy: 0.7443, Loss: 0.2490
Epoch  39 Batch  480/1077 - Train Accuracy: 0.7652, Validation Accuracy: 0.7489, Loss: 0.2232
Epoch  39 Batch  490/1077 - Train Accuracy: 0.7516, Validation Accuracy: 0.7486, Loss: 0.2333
Epoch  39 Batch  500/1077 - Train Accuracy: 0.8023, Validation Accuracy: 0.7564, Loss: 0.2114
Epoch  39 Batch  510/1077 - Train Accuracy: 0.7871, Validation Accuracy: 0.7532, Loss: 0.2154
Epoch  39 Batch  520/1077 - Train Accuracy: 0.8311, Validation Accuracy: 0.7507, Loss: 0.1951
Epoch  39 Batch  530/1077 - Train Accuracy: 0.7340, Validation Accuracy: 0.7404, Loss: 0.2160
Epoch  39 Batch  540/1077 - Train Accuracy: 0.7887, Validation Accuracy: 0.7575, Loss: 0.2084
Epoch  39 Batch  550/1077 - Train Accuracy: 0.7453, Validation Accuracy: 0.7603, Loss: 0.2246
Epoch  39 Batch  560/1077 - Train Accuracy: 0.7621, Validation Accuracy: 0.7578, Loss: 0.2043
Epoch  39 Batch  570/1077 - Train Accuracy: 0.7734, Validation Accuracy: 0.7582, Loss: 0.2328
Epoch  39 Batch  580/1077 - Train Accuracy: 0.7909, Validation Accuracy: 0.7504, Loss: 0.1975
Epoch  39 Batch  590/1077 - Train Accuracy: 0.7360, Validation Accuracy: 0.7418, Loss: 0.2357
Epoch  39 Batch  600/1077 - Train Accuracy: 0.7827, Validation Accuracy: 0.7468, Loss: 0.2164
Epoch  39 Batch  610/1077 - Train Accuracy: 0.7648, Validation Accuracy: 0.7500, Loss: 0.2298
Epoch  39 Batch  620/1077 - Train Accuracy: 0.7668, Validation Accuracy: 0.7429, Loss: 0.2013
Epoch  39 Batch  630/1077 - Train Accuracy: 0.7500, Validation Accuracy: 0.7575, Loss: 0.2171
Epoch  39 Batch  640/1077 - Train Accuracy: 0.7690, Validation Accuracy: 0.7560, Loss: 0.2141
Epoch  39 Batch  650/1077 - Train Accuracy: 0.7566, Validation Accuracy: 0.7571, Loss: 0.2249
Epoch  39 Batch  660/1077 - Train Accuracy: 0.7875, Validation Accuracy: 0.7621, Loss: 0.2233
Epoch  39 Batch  670/1077 - Train Accuracy: 0.7876, Validation Accuracy: 0.7383, Loss: 0.2084
Epoch  39 Batch  680/1077 - Train Accuracy: 0.7667, Validation Accuracy: 0.7397, Loss: 0.2185
Epoch  39 Batch  690/1077 - Train Accuracy: 0.7844, Validation Accuracy: 0.7369, Loss: 0.2164
Epoch  39 Batch  700/1077 - Train Accuracy: 0.7805, Validation Accuracy: 0.7404, Loss: 0.2051
Epoch  39 Batch  710/1077 - Train Accuracy: 0.7301, Validation Accuracy: 0.7425, Loss: 0.2068
Epoch  39 Batch  720/1077 - Train Accuracy: 0.7636, Validation Accuracy: 0.7422, Loss: 0.2234
Epoch  39 Batch  730/1077 - Train Accuracy: 0.7656, Validation Accuracy: 0.7525, Loss: 0.2188
Epoch  39 Batch  740/1077 - Train Accuracy: 0.7734, Validation Accuracy: 0.7504, Loss: 0.2125
Epoch  39 Batch  750/1077 - Train Accuracy: 0.7750, Validation Accuracy: 0.7422, Loss: 0.2121
Epoch  39 Batch  760/1077 - Train Accuracy: 0.7754, Validation Accuracy: 0.7681, Loss: 0.2320
Epoch  39 Batch  770/1077 - Train Accuracy: 0.7645, Validation Accuracy: 0.7418, Loss: 0.1981
Epoch  39 Batch  780/1077 - Train Accuracy: 0.7648, Validation Accuracy: 0.7653, Loss: 0.2458
Epoch  39 Batch  790/1077 - Train Accuracy: 0.7102, Validation Accuracy: 0.7553, Loss: 0.2441
Epoch  39 Batch  800/1077 - Train Accuracy: 0.7637, Validation Accuracy: 0.7468, Loss: 0.2298
Epoch  39 Batch  810/1077 - Train Accuracy: 0.7731, Validation Accuracy: 0.7699, Loss: 0.2256
Epoch  39 Batch  820/1077 - Train Accuracy: 0.7172, Validation Accuracy: 0.7575, Loss: 0.2530
Epoch  39 Batch  830/1077 - Train Accuracy: 0.7336, Validation Accuracy: 0.7638, Loss: 0.2258
Epoch  39 Batch  840/1077 - Train Accuracy: 0.7871, Validation Accuracy: 0.7599, Loss: 0.2300
Epoch  39 Batch  850/1077 - Train Accuracy: 0.7533, Validation Accuracy: 0.7504, Loss: 0.2556
Epoch  39 Batch  860/1077 - Train Accuracy: 0.7708, Validation Accuracy: 0.7575, Loss: 0.2285
Epoch  39 Batch  870/1077 - Train Accuracy: 0.7562, Validation Accuracy: 0.7624, Loss: 0.2336
Epoch  39 Batch  880/1077 - Train Accuracy: 0.7914, Validation Accuracy: 0.7507, Loss: 0.2166
Epoch  39 Batch  890/1077 - Train Accuracy: 0.8207, Validation Accuracy: 0.7450, Loss: 0.2008
Epoch  39 Batch  900/1077 - Train Accuracy: 0.7918, Validation Accuracy: 0.7525, Loss: 0.2225
Epoch  39 Batch  910/1077 - Train Accuracy: 0.7965, Validation Accuracy: 0.7543, Loss: 0.2121
Epoch  39 Batch  920/1077 - Train Accuracy: 0.8102, Validation Accuracy: 0.7496, Loss: 0.2189
Epoch  39 Batch  930/1077 - Train Accuracy: 0.7898, Validation Accuracy: 0.7372, Loss: 0.2133
Epoch  39 Batch  940/1077 - Train Accuracy: 0.7777, Validation Accuracy: 0.7454, Loss: 0.2117
Epoch  39 Batch  950/1077 - Train Accuracy: 0.7857, Validation Accuracy: 0.7543, Loss: 0.2114
Epoch  39 Batch  960/1077 - Train Accuracy: 0.7775, Validation Accuracy: 0.7479, Loss: 0.2172
Epoch  39 Batch  970/1077 - Train Accuracy: 0.7645, Validation Accuracy: 0.7347, Loss: 0.2344
Epoch  39 Batch  980/1077 - Train Accuracy: 0.7238, Validation Accuracy: 0.7436, Loss: 0.2211
Epoch  39 Batch  990/1077 - Train Accuracy: 0.7521, Validation Accuracy: 0.7607, Loss: 0.2302
Epoch  39 Batch 1000/1077 - Train Accuracy: 0.8006, Validation Accuracy: 0.7550, Loss: 0.2004
Epoch  39 Batch 1010/1077 - Train Accuracy: 0.7574, Validation Accuracy: 0.7372, Loss: 0.2160
Epoch  39 Batch 1020/1077 - Train Accuracy: 0.7707, Validation Accuracy: 0.7362, Loss: 0.2148
Epoch  39 Batch 1030/1077 - Train Accuracy: 0.7531, Validation Accuracy: 0.7472, Loss: 0.2187
Epoch  39 Batch 1040/1077 - Train Accuracy: 0.8010, Validation Accuracy: 0.7429, Loss: 0.2330
Epoch  39 Batch 1050/1077 - Train Accuracy: 0.7422, Validation Accuracy: 0.7422, Loss: 0.2359
Epoch  39 Batch 1060/1077 - Train Accuracy: 0.8059, Validation Accuracy: 0.7354, Loss: 0.1980
Epoch  39 Batch 1070/1077 - Train Accuracy: 0.7461, Validation Accuracy: 0.7504, Loss: 0.2208
Epoch  40 Batch   10/1077 - Train Accuracy: 0.7718, Validation Accuracy: 0.7347, Loss: 0.2146
Epoch  40 Batch   20/1077 - Train Accuracy: 0.7684, Validation Accuracy: 0.7553, Loss: 0.2153
Epoch  40 Batch   30/1077 - Train Accuracy: 0.7910, Validation Accuracy: 0.7464, Loss: 0.2233
Epoch  40 Batch   40/1077 - Train Accuracy: 0.8066, Validation Accuracy: 0.7461, Loss: 0.2172
Epoch  40 Batch   50/1077 - Train Accuracy: 0.7438, Validation Accuracy: 0.7567, Loss: 0.2191
Epoch  40 Batch   60/1077 - Train Accuracy: 0.7865, Validation Accuracy: 0.7624, Loss: 0.2016
Epoch  40 Batch   70/1077 - Train Accuracy: 0.8067, Validation Accuracy: 0.7464, Loss: 0.2287
Epoch  40 Batch   80/1077 - Train Accuracy: 0.7695, Validation Accuracy: 0.7330, Loss: 0.2073
Epoch  40 Batch   90/1077 - Train Accuracy: 0.7328, Validation Accuracy: 0.7486, Loss: 0.2227
Epoch  40 Batch  100/1077 - Train Accuracy: 0.7520, Validation Accuracy: 0.7596, Loss: 0.2166
Epoch  40 Batch  110/1077 - Train Accuracy: 0.7805, Validation Accuracy: 0.7557, Loss: 0.2081
Epoch  40 Batch  120/1077 - Train Accuracy: 0.7891, Validation Accuracy: 0.7507, Loss: 0.2193
Epoch  40 Batch  130/1077 - Train Accuracy: 0.7541, Validation Accuracy: 0.7511, Loss: 0.2058
Epoch  40 Batch  140/1077 - Train Accuracy: 0.7829, Validation Accuracy: 0.7507, Loss: 0.2230
Epoch  40 Batch  150/1077 - Train Accuracy: 0.7969, Validation Accuracy: 0.7486, Loss: 0.2228
Epoch  40 Batch  160/1077 - Train Accuracy: 0.7754, Validation Accuracy: 0.7337, Loss: 0.2181
Epoch  40 Batch  170/1077 - Train Accuracy: 0.7418, Validation Accuracy: 0.7482, Loss: 0.2222
Epoch  40 Batch  180/1077 - Train Accuracy: 0.7848, Validation Accuracy: 0.7415, Loss: 0.2063
Epoch  40 Batch  190/1077 - Train Accuracy: 0.8211, Validation Accuracy: 0.7482, Loss: 0.2150
Epoch  40 Batch  200/1077 - Train Accuracy: 0.7680, Validation Accuracy: 0.7319, Loss: 0.2215
Epoch  40 Batch  210/1077 - Train Accuracy: 0.7939, Validation Accuracy: 0.7319, Loss: 0.2215
Epoch  40 Batch  220/1077 - Train Accuracy: 0.7825, Validation Accuracy: 0.7440, Loss: 0.2195
Epoch  40 Batch  230/1077 - Train Accuracy: 0.7731, Validation Accuracy: 0.7536, Loss: 0.2030
Epoch  40 Batch  240/1077 - Train Accuracy: 0.8246, Validation Accuracy: 0.7468, Loss: 0.1932
Epoch  40 Batch  250/1077 - Train Accuracy: 0.7752, Validation Accuracy: 0.7450, Loss: 0.1972
Epoch  40 Batch  260/1077 - Train Accuracy: 0.8065, Validation Accuracy: 0.7447, Loss: 0.2056
Epoch  40 Batch  270/1077 - Train Accuracy: 0.7758, Validation Accuracy: 0.7557, Loss: 0.2379
Epoch  40 Batch  280/1077 - Train Accuracy: 0.7691, Validation Accuracy: 0.7464, Loss: 0.2197
Epoch  40 Batch  290/1077 - Train Accuracy: 0.7789, Validation Accuracy: 0.7468, Loss: 0.2371
Epoch  40 Batch  300/1077 - Train Accuracy: 0.7858, Validation Accuracy: 0.7603, Loss: 0.2166
Epoch  40 Batch  310/1077 - Train Accuracy: 0.7246, Validation Accuracy: 0.7521, Loss: 0.2355
Epoch  40 Batch  320/1077 - Train Accuracy: 0.8082, Validation Accuracy: 0.7511, Loss: 0.2490
Epoch  40 Batch  330/1077 - Train Accuracy: 0.7883, Validation Accuracy: 0.7603, Loss: 0.2187
Epoch  40 Batch  340/1077 - Train Accuracy: 0.7837, Validation Accuracy: 0.7404, Loss: 0.2056
Epoch  40 Batch  350/1077 - Train Accuracy: 0.7574, Validation Accuracy: 0.7443, Loss: 0.2070
Epoch  40 Batch  360/1077 - Train Accuracy: 0.7547, Validation Accuracy: 0.7575, Loss: 0.2218
Epoch  40 Batch  370/1077 - Train Accuracy: 0.7969, Validation Accuracy: 0.7461, Loss: 0.2138
Epoch  40 Batch  380/1077 - Train Accuracy: 0.7746, Validation Accuracy: 0.7401, Loss: 0.2109
Epoch  40 Batch  390/1077 - Train Accuracy: 0.7207, Validation Accuracy: 0.7404, Loss: 0.2360
Epoch  40 Batch  400/1077 - Train Accuracy: 0.7898, Validation Accuracy: 0.7585, Loss: 0.2132
Epoch  40 Batch  410/1077 - Train Accuracy: 0.7574, Validation Accuracy: 0.7607, Loss: 0.2194
Epoch  40 Batch  420/1077 - Train Accuracy: 0.7871, Validation Accuracy: 0.7422, Loss: 0.2036
Epoch  40 Batch  430/1077 - Train Accuracy: 0.7555, Validation Accuracy: 0.7457, Loss: 0.2113
Epoch  40 Batch  440/1077 - Train Accuracy: 0.7379, Validation Accuracy: 0.7422, Loss: 0.2287
Epoch  40 Batch  450/1077 - Train Accuracy: 0.8000, Validation Accuracy: 0.7475, Loss: 0.2074
Epoch  40 Batch  460/1077 - Train Accuracy: 0.7445, Validation Accuracy: 0.7397, Loss: 0.2334
Epoch  40 Batch  470/1077 - Train Accuracy: 0.7804, Validation Accuracy: 0.7383, Loss: 0.2257
Epoch  40 Batch  480/1077 - Train Accuracy: 0.7710, Validation Accuracy: 0.7553, Loss: 0.2104
Epoch  40 Batch  490/1077 - Train Accuracy: 0.7348, Validation Accuracy: 0.7511, Loss: 0.2232
Epoch  40 Batch  500/1077 - Train Accuracy: 0.8008, Validation Accuracy: 0.7596, Loss: 0.1970
Epoch  40 Batch  510/1077 - Train Accuracy: 0.7918, Validation Accuracy: 0.7536, Loss: 0.2123
Epoch  40 Batch  520/1077 - Train Accuracy: 0.8289, Validation Accuracy: 0.7550, Loss: 0.1998
Epoch  40 Batch  530/1077 - Train Accuracy: 0.7352, Validation Accuracy: 0.7514, Loss: 0.2151
Epoch  40 Batch  540/1077 - Train Accuracy: 0.8121, Validation Accuracy: 0.7589, Loss: 0.1987
Epoch  40 Batch  550/1077 - Train Accuracy: 0.7438, Validation Accuracy: 0.7518, Loss: 0.2153
Epoch  40 Batch  560/1077 - Train Accuracy: 0.7680, Validation Accuracy: 0.7539, Loss: 0.2160
Epoch  40 Batch  570/1077 - Train Accuracy: 0.7677, Validation Accuracy: 0.7521, Loss: 0.2445
Epoch  40 Batch  580/1077 - Train Accuracy: 0.7999, Validation Accuracy: 0.7667, Loss: 0.1942
Epoch  40 Batch  590/1077 - Train Accuracy: 0.7447, Validation Accuracy: 0.7589, Loss: 0.2270
Epoch  40 Batch  600/1077 - Train Accuracy: 0.7987, Validation Accuracy: 0.7564, Loss: 0.2041
Epoch  40 Batch  610/1077 - Train Accuracy: 0.7664, Validation Accuracy: 0.7617, Loss: 0.2293
Epoch  40 Batch  620/1077 - Train Accuracy: 0.7773, Validation Accuracy: 0.7525, Loss: 0.1959
Epoch  40 Batch  630/1077 - Train Accuracy: 0.7496, Validation Accuracy: 0.7557, Loss: 0.2133
Epoch  40 Batch  640/1077 - Train Accuracy: 0.7984, Validation Accuracy: 0.7670, Loss: 0.2006
Epoch  40 Batch  650/1077 - Train Accuracy: 0.7562, Validation Accuracy: 0.7624, Loss: 0.1920
Epoch  40 Batch  660/1077 - Train Accuracy: 0.8000, Validation Accuracy: 0.7585, Loss: 0.2094
Epoch  40 Batch  670/1077 - Train Accuracy: 0.7898, Validation Accuracy: 0.7440, Loss: 0.2134
Epoch  40 Batch  680/1077 - Train Accuracy: 0.7604, Validation Accuracy: 0.7539, Loss: 0.2172
Epoch  40 Batch  690/1077 - Train Accuracy: 0.7809, Validation Accuracy: 0.7546, Loss: 0.2073
Epoch  40 Batch  700/1077 - Train Accuracy: 0.7699, Validation Accuracy: 0.7408, Loss: 0.2005
Epoch  40 Batch  710/1077 - Train Accuracy: 0.7301, Validation Accuracy: 0.7536, Loss: 0.2085
Epoch  40 Batch  720/1077 - Train Accuracy: 0.7574, Validation Accuracy: 0.7489, Loss: 0.2219
Epoch  40 Batch  730/1077 - Train Accuracy: 0.7617, Validation Accuracy: 0.7557, Loss: 0.2182
Epoch  40 Batch  740/1077 - Train Accuracy: 0.7832, Validation Accuracy: 0.7450, Loss: 0.2034
Epoch  40 Batch  750/1077 - Train Accuracy: 0.7867, Validation Accuracy: 0.7500, Loss: 0.2258
Epoch  40 Batch  760/1077 - Train Accuracy: 0.7734, Validation Accuracy: 0.7557, Loss: 0.2290
Epoch  40 Batch  770/1077 - Train Accuracy: 0.7783, Validation Accuracy: 0.7411, Loss: 0.1946
Epoch  40 Batch  780/1077 - Train Accuracy: 0.7773, Validation Accuracy: 0.7536, Loss: 0.2277
Epoch  40 Batch  790/1077 - Train Accuracy: 0.7031, Validation Accuracy: 0.7454, Loss: 0.2464
Epoch  40 Batch  800/1077 - Train Accuracy: 0.7664, Validation Accuracy: 0.7482, Loss: 0.2197
Epoch  40 Batch  810/1077 - Train Accuracy: 0.7779, Validation Accuracy: 0.7496, Loss: 0.2008
Epoch  40 Batch  820/1077 - Train Accuracy: 0.7219, Validation Accuracy: 0.7518, Loss: 0.2377
Epoch  40 Batch  830/1077 - Train Accuracy: 0.7465, Validation Accuracy: 0.7638, Loss: 0.2134
Epoch  40 Batch  840/1077 - Train Accuracy: 0.7855, Validation Accuracy: 0.7603, Loss: 0.2146
Epoch  40 Batch  850/1077 - Train Accuracy: 0.7403, Validation Accuracy: 0.7504, Loss: 0.2323
Epoch  40 Batch  860/1077 - Train Accuracy: 0.7679, Validation Accuracy: 0.7447, Loss: 0.2208
Epoch  40 Batch  870/1077 - Train Accuracy: 0.7648, Validation Accuracy: 0.7493, Loss: 0.2356
Epoch  40 Batch  880/1077 - Train Accuracy: 0.8059, Validation Accuracy: 0.7539, Loss: 0.2069
Epoch  40 Batch  890/1077 - Train Accuracy: 0.8300, Validation Accuracy: 0.7489, Loss: 0.2134
Epoch  40 Batch  900/1077 - Train Accuracy: 0.7926, Validation Accuracy: 0.7525, Loss: 0.2094
Epoch  40 Batch  910/1077 - Train Accuracy: 0.7961, Validation Accuracy: 0.7653, Loss: 0.2201
Epoch  40 Batch  920/1077 - Train Accuracy: 0.8133, Validation Accuracy: 0.7582, Loss: 0.2119
Epoch  40 Batch  930/1077 - Train Accuracy: 0.7891, Validation Accuracy: 0.7404, Loss: 0.2005
Epoch  40 Batch  940/1077 - Train Accuracy: 0.7797, Validation Accuracy: 0.7450, Loss: 0.2191
Epoch  40 Batch  950/1077 - Train Accuracy: 0.7850, Validation Accuracy: 0.7628, Loss: 0.1905
Epoch  40 Batch  960/1077 - Train Accuracy: 0.7675, Validation Accuracy: 0.7539, Loss: 0.2004
Epoch  40 Batch  970/1077 - Train Accuracy: 0.7680, Validation Accuracy: 0.7333, Loss: 0.2098
Epoch  40 Batch  980/1077 - Train Accuracy: 0.7336, Validation Accuracy: 0.7564, Loss: 0.2250
Epoch  40 Batch  990/1077 - Train Accuracy: 0.7595, Validation Accuracy: 0.7546, Loss: 0.2263
Epoch  40 Batch 1000/1077 - Train Accuracy: 0.8032, Validation Accuracy: 0.7685, Loss: 0.2028
Epoch  40 Batch 1010/1077 - Train Accuracy: 0.7660, Validation Accuracy: 0.7546, Loss: 0.2198
Epoch  40 Batch 1020/1077 - Train Accuracy: 0.7703, Validation Accuracy: 0.7489, Loss: 0.2018
Epoch  40 Batch 1030/1077 - Train Accuracy: 0.7496, Validation Accuracy: 0.7564, Loss: 0.2135
Epoch  40 Batch 1040/1077 - Train Accuracy: 0.7944, Validation Accuracy: 0.7447, Loss: 0.2233
Epoch  40 Batch 1050/1077 - Train Accuracy: 0.7145, Validation Accuracy: 0.7571, Loss: 0.2053
Epoch  40 Batch 1060/1077 - Train Accuracy: 0.7945, Validation Accuracy: 0.7621, Loss: 0.1936
Epoch  40 Batch 1070/1077 - Train Accuracy: 0.7570, Validation Accuracy: 0.7582, Loss: 0.2193
Epoch  41 Batch   10/1077 - Train Accuracy: 0.7899, Validation Accuracy: 0.7383, Loss: 0.2245
Epoch  41 Batch   20/1077 - Train Accuracy: 0.7719, Validation Accuracy: 0.7443, Loss: 0.2116
Epoch  41 Batch   30/1077 - Train Accuracy: 0.7855, Validation Accuracy: 0.7532, Loss: 0.2359
Epoch  41 Batch   40/1077 - Train Accuracy: 0.7988, Validation Accuracy: 0.7621, Loss: 0.2038
Epoch  41 Batch   50/1077 - Train Accuracy: 0.7598, Validation Accuracy: 0.7603, Loss: 0.2145
Epoch  41 Batch   60/1077 - Train Accuracy: 0.7917, Validation Accuracy: 0.7496, Loss: 0.1984
Epoch  41 Batch   70/1077 - Train Accuracy: 0.8072, Validation Accuracy: 0.7624, Loss: 0.2213
Epoch  41 Batch   80/1077 - Train Accuracy: 0.7730, Validation Accuracy: 0.7642, Loss: 0.2109
Epoch  41 Batch   90/1077 - Train Accuracy: 0.7613, Validation Accuracy: 0.7518, Loss: 0.2342
Epoch  41 Batch  100/1077 - Train Accuracy: 0.7617, Validation Accuracy: 0.7720, Loss: 0.2023
Epoch  41 Batch  110/1077 - Train Accuracy: 0.7852, Validation Accuracy: 0.7514, Loss: 0.2008
Epoch  41 Batch  120/1077 - Train Accuracy: 0.7898, Validation Accuracy: 0.7450, Loss: 0.2088
Epoch  41 Batch  130/1077 - Train Accuracy: 0.7504, Validation Accuracy: 0.7649, Loss: 0.2070
Epoch  41 Batch  140/1077 - Train Accuracy: 0.7858, Validation Accuracy: 0.7638, Loss: 0.2093
Epoch  41 Batch  150/1077 - Train Accuracy: 0.7894, Validation Accuracy: 0.7567, Loss: 0.2062
Epoch  41 Batch  160/1077 - Train Accuracy: 0.7695, Validation Accuracy: 0.7514, Loss: 0.2189
Epoch  41 Batch  170/1077 - Train Accuracy: 0.7273, Validation Accuracy: 0.7592, Loss: 0.2169
Epoch  41 Batch  180/1077 - Train Accuracy: 0.7918, Validation Accuracy: 0.7614, Loss: 0.1976
Epoch  41 Batch  190/1077 - Train Accuracy: 0.8285, Validation Accuracy: 0.7543, Loss: 0.2050
Epoch  41 Batch  200/1077 - Train Accuracy: 0.7543, Validation Accuracy: 0.7365, Loss: 0.2142
Epoch  41 Batch  210/1077 - Train Accuracy: 0.7883, Validation Accuracy: 0.7443, Loss: 0.2111
Epoch  41 Batch  220/1077 - Train Accuracy: 0.7850, Validation Accuracy: 0.7489, Loss: 0.2232
Epoch  41 Batch  230/1077 - Train Accuracy: 0.7682, Validation Accuracy: 0.7646, Loss: 0.1939
Epoch  41 Batch  240/1077 - Train Accuracy: 0.8320, Validation Accuracy: 0.7454, Loss: 0.2021
Epoch  41 Batch  250/1077 - Train Accuracy: 0.7773, Validation Accuracy: 0.7585, Loss: 0.1956
Epoch  41 Batch  260/1077 - Train Accuracy: 0.8088, Validation Accuracy: 0.7514, Loss: 0.1967
Epoch  41 Batch  270/1077 - Train Accuracy: 0.7777, Validation Accuracy: 0.7564, Loss: 0.2207
Epoch  41 Batch  280/1077 - Train Accuracy: 0.7852, Validation Accuracy: 0.7528, Loss: 0.2075
Epoch  41 Batch  290/1077 - Train Accuracy: 0.7902, Validation Accuracy: 0.7489, Loss: 0.2177
Epoch  41 Batch  300/1077 - Train Accuracy: 0.7928, Validation Accuracy: 0.7550, Loss: 0.2150
Epoch  41 Batch  310/1077 - Train Accuracy: 0.7426, Validation Accuracy: 0.7539, Loss: 0.2322
Epoch  41 Batch  320/1077 - Train Accuracy: 0.8125, Validation Accuracy: 0.7504, Loss: 0.2611
Epoch  41 Batch  330/1077 - Train Accuracy: 0.7902, Validation Accuracy: 0.7571, Loss: 0.2125
Epoch  41 Batch  340/1077 - Train Accuracy: 0.7825, Validation Accuracy: 0.7567, Loss: 0.2141
Epoch  41 Batch  350/1077 - Train Accuracy: 0.7711, Validation Accuracy: 0.7688, Loss: 0.2055
Epoch  41 Batch  360/1077 - Train Accuracy: 0.7660, Validation Accuracy: 0.7692, Loss: 0.1989
Epoch  41 Batch  370/1077 - Train Accuracy: 0.8017, Validation Accuracy: 0.7592, Loss: 0.2070
Epoch  41 Batch  380/1077 - Train Accuracy: 0.7750, Validation Accuracy: 0.7575, Loss: 0.1963
Epoch  41 Batch  390/1077 - Train Accuracy: 0.7250, Validation Accuracy: 0.7422, Loss: 0.2337
Epoch  41 Batch  400/1077 - Train Accuracy: 0.8031, Validation Accuracy: 0.7589, Loss: 0.2180
Epoch  41 Batch  410/1077 - Train Accuracy: 0.7693, Validation Accuracy: 0.7653, Loss: 0.2267
Epoch  41 Batch  420/1077 - Train Accuracy: 0.7914, Validation Accuracy: 0.7486, Loss: 0.1985
Epoch  41 Batch  430/1077 - Train Accuracy: 0.7527, Validation Accuracy: 0.7667, Loss: 0.2089
Epoch  41 Batch  440/1077 - Train Accuracy: 0.7355, Validation Accuracy: 0.7660, Loss: 0.2181
Epoch  41 Batch  450/1077 - Train Accuracy: 0.7871, Validation Accuracy: 0.7610, Loss: 0.2191
Epoch  41 Batch  460/1077 - Train Accuracy: 0.7469, Validation Accuracy: 0.7539, Loss: 0.2142
Epoch  41 Batch  470/1077 - Train Accuracy: 0.7829, Validation Accuracy: 0.7603, Loss: 0.2104
Epoch  41 Batch  480/1077 - Train Accuracy: 0.7808, Validation Accuracy: 0.7678, Loss: 0.2165
Epoch  41 Batch  490/1077 - Train Accuracy: 0.7410, Validation Accuracy: 0.7557, Loss: 0.2263
Epoch  41 Batch  500/1077 - Train Accuracy: 0.8035, Validation Accuracy: 0.7585, Loss: 0.2152
Epoch  41 Batch  510/1077 - Train Accuracy: 0.7961, Validation Accuracy: 0.7621, Loss: 0.2129
Epoch  41 Batch  520/1077 - Train Accuracy: 0.8516, Validation Accuracy: 0.7560, Loss: 0.1908
Epoch  41 Batch  530/1077 - Train Accuracy: 0.7402, Validation Accuracy: 0.7507, Loss: 0.2301
Epoch  41 Batch  540/1077 - Train Accuracy: 0.7926, Validation Accuracy: 0.7504, Loss: 0.1972
Epoch  41 Batch  550/1077 - Train Accuracy: 0.7355, Validation Accuracy: 0.7674, Loss: 0.2168
Epoch  41 Batch  560/1077 - Train Accuracy: 0.7723, Validation Accuracy: 0.7617, Loss: 0.2140
Epoch  41 Batch  570/1077 - Train Accuracy: 0.7771, Validation Accuracy: 0.7518, Loss: 0.2239
Epoch  41 Batch  580/1077 - Train Accuracy: 0.7961, Validation Accuracy: 0.7514, Loss: 0.1861
Epoch  41 Batch  590/1077 - Train Accuracy: 0.7488, Validation Accuracy: 0.7500, Loss: 0.2424
Epoch  41 Batch  600/1077 - Train Accuracy: 0.7883, Validation Accuracy: 0.7482, Loss: 0.2166
Epoch  41 Batch  610/1077 - Train Accuracy: 0.7701, Validation Accuracy: 0.7390, Loss: 0.2190
Epoch  41 Batch  620/1077 - Train Accuracy: 0.7711, Validation Accuracy: 0.7447, Loss: 0.2206
Epoch  41 Batch  630/1077 - Train Accuracy: 0.7398, Validation Accuracy: 0.7475, Loss: 0.2160
Epoch  41 Batch  640/1077 - Train Accuracy: 0.7839, Validation Accuracy: 0.7710, Loss: 0.1964
Epoch  41 Batch  650/1077 - Train Accuracy: 0.7469, Validation Accuracy: 0.7496, Loss: 0.2185
Epoch  41 Batch  660/1077 - Train Accuracy: 0.7965, Validation Accuracy: 0.7617, Loss: 0.2387
Epoch  41 Batch  670/1077 - Train Accuracy: 0.7852, Validation Accuracy: 0.7457, Loss: 0.2107
Epoch  41 Batch  680/1077 - Train Accuracy: 0.7649, Validation Accuracy: 0.7440, Loss: 0.2258
Epoch  41 Batch  690/1077 - Train Accuracy: 0.7848, Validation Accuracy: 0.7464, Loss: 0.2171
Epoch  41 Batch  700/1077 - Train Accuracy: 0.7871, Validation Accuracy: 0.7436, Loss: 0.2021
Epoch  41 Batch  710/1077 - Train Accuracy: 0.7457, Validation Accuracy: 0.7518, Loss: 0.1993
Epoch  41 Batch  720/1077 - Train Accuracy: 0.7586, Validation Accuracy: 0.7567, Loss: 0.2156
Epoch  41 Batch  730/1077 - Train Accuracy: 0.7664, Validation Accuracy: 0.7649, Loss: 0.2139
Epoch  41 Batch  740/1077 - Train Accuracy: 0.7816, Validation Accuracy: 0.7468, Loss: 0.2043
Epoch  41 Batch  750/1077 - Train Accuracy: 0.7789, Validation Accuracy: 0.7440, Loss: 0.2141
Epoch  41 Batch  760/1077 - Train Accuracy: 0.7711, Validation Accuracy: 0.7479, Loss: 0.2212
Epoch  41 Batch  770/1077 - Train Accuracy: 0.7742, Validation Accuracy: 0.7401, Loss: 0.2077
Epoch  41 Batch  780/1077 - Train Accuracy: 0.7547, Validation Accuracy: 0.7628, Loss: 0.2317
Epoch  41 Batch  790/1077 - Train Accuracy: 0.7094, Validation Accuracy: 0.7628, Loss: 0.2302
Epoch  41 Batch  800/1077 - Train Accuracy: 0.7715, Validation Accuracy: 0.7607, Loss: 0.2080
Epoch  41 Batch  810/1077 - Train Accuracy: 0.7719, Validation Accuracy: 0.7575, Loss: 0.1948
Epoch  41 Batch  820/1077 - Train Accuracy: 0.7383, Validation Accuracy: 0.7528, Loss: 0.2258
Epoch  41 Batch  830/1077 - Train Accuracy: 0.7508, Validation Accuracy: 0.7635, Loss: 0.2139
Epoch  41 Batch  840/1077 - Train Accuracy: 0.7785, Validation Accuracy: 0.7610, Loss: 0.2162
Epoch  41 Batch  850/1077 - Train Accuracy: 0.7586, Validation Accuracy: 0.7649, Loss: 0.2188
Epoch  41 Batch  860/1077 - Train Accuracy: 0.7615, Validation Accuracy: 0.7585, Loss: 0.2274
Epoch  41 Batch  870/1077 - Train Accuracy: 0.7541, Validation Accuracy: 0.7482, Loss: 0.2252
Epoch  41 Batch  880/1077 - Train Accuracy: 0.7969, Validation Accuracy: 0.7493, Loss: 0.2112
Epoch  41 Batch  890/1077 - Train Accuracy: 0.8292, Validation Accuracy: 0.7553, Loss: 0.1932
Epoch  41 Batch  900/1077 - Train Accuracy: 0.8035, Validation Accuracy: 0.7457, Loss: 0.2130
Epoch  41 Batch  910/1077 - Train Accuracy: 0.8036, Validation Accuracy: 0.7528, Loss: 0.2127
Epoch  41 Batch  920/1077 - Train Accuracy: 0.8238, Validation Accuracy: 0.7543, Loss: 0.2026
Epoch  41 Batch  930/1077 - Train Accuracy: 0.7980, Validation Accuracy: 0.7479, Loss: 0.1888
Epoch  41 Batch  940/1077 - Train Accuracy: 0.7922, Validation Accuracy: 0.7514, Loss: 0.1985
Epoch  41 Batch  950/1077 - Train Accuracy: 0.7835, Validation Accuracy: 0.7592, Loss: 0.1972
Epoch  41 Batch  960/1077 - Train Accuracy: 0.7764, Validation Accuracy: 0.7582, Loss: 0.2084
Epoch  41 Batch  970/1077 - Train Accuracy: 0.7781, Validation Accuracy: 0.7429, Loss: 0.2210
Epoch  41 Batch  980/1077 - Train Accuracy: 0.7551, Validation Accuracy: 0.7461, Loss: 0.2257
Epoch  41 Batch  990/1077 - Train Accuracy: 0.7627, Validation Accuracy: 0.7539, Loss: 0.2274
Epoch  41 Batch 1000/1077 - Train Accuracy: 0.8047, Validation Accuracy: 0.7614, Loss: 0.2001
Epoch  41 Batch 1010/1077 - Train Accuracy: 0.7773, Validation Accuracy: 0.7472, Loss: 0.2045
Epoch  41 Batch 1020/1077 - Train Accuracy: 0.7727, Validation Accuracy: 0.7610, Loss: 0.1908
Epoch  41 Batch 1030/1077 - Train Accuracy: 0.7500, Validation Accuracy: 0.7614, Loss: 0.2167
Epoch  41 Batch 1040/1077 - Train Accuracy: 0.7952, Validation Accuracy: 0.7582, Loss: 0.2047
Epoch  41 Batch 1050/1077 - Train Accuracy: 0.7238, Validation Accuracy: 0.7504, Loss: 0.2234
Epoch  41 Batch 1060/1077 - Train Accuracy: 0.8008, Validation Accuracy: 0.7422, Loss: 0.1859
Epoch  41 Batch 1070/1077 - Train Accuracy: 0.7574, Validation Accuracy: 0.7518, Loss: 0.2089
Epoch  42 Batch   10/1077 - Train Accuracy: 0.7944, Validation Accuracy: 0.7489, Loss: 0.2151
Epoch  42 Batch   20/1077 - Train Accuracy: 0.7520, Validation Accuracy: 0.7607, Loss: 0.2145
Epoch  42 Batch   30/1077 - Train Accuracy: 0.8039, Validation Accuracy: 0.7557, Loss: 0.2102
Epoch  42 Batch   40/1077 - Train Accuracy: 0.8133, Validation Accuracy: 0.7567, Loss: 0.2084
Epoch  42 Batch   50/1077 - Train Accuracy: 0.7625, Validation Accuracy: 0.7638, Loss: 0.2141
Epoch  42 Batch   60/1077 - Train Accuracy: 0.7958, Validation Accuracy: 0.7532, Loss: 0.2028
Epoch  42 Batch   70/1077 - Train Accuracy: 0.8191, Validation Accuracy: 0.7486, Loss: 0.2174
Epoch  42 Batch   80/1077 - Train Accuracy: 0.7773, Validation Accuracy: 0.7571, Loss: 0.2129
Epoch  42 Batch   90/1077 - Train Accuracy: 0.7586, Validation Accuracy: 0.7567, Loss: 0.2140
Epoch  42 Batch  100/1077 - Train Accuracy: 0.7668, Validation Accuracy: 0.7674, Loss: 0.2110
Epoch  42 Batch  110/1077 - Train Accuracy: 0.7773, Validation Accuracy: 0.7578, Loss: 0.1902
Epoch  42 Batch  120/1077 - Train Accuracy: 0.7926, Validation Accuracy: 0.7592, Loss: 0.2312
Epoch  42 Batch  130/1077 - Train Accuracy: 0.7515, Validation Accuracy: 0.7681, Loss: 0.2037
Epoch  42 Batch  140/1077 - Train Accuracy: 0.7792, Validation Accuracy: 0.7550, Loss: 0.2198
Epoch  42 Batch  150/1077 - Train Accuracy: 0.7906, Validation Accuracy: 0.7518, Loss: 0.1935
Epoch  42 Batch  160/1077 - Train Accuracy: 0.7719, Validation Accuracy: 0.7546, Loss: 0.2116
Epoch  42 Batch  170/1077 - Train Accuracy: 0.7441, Validation Accuracy: 0.7599, Loss: 0.2217
Epoch  42 Batch  180/1077 - Train Accuracy: 0.7797, Validation Accuracy: 0.7532, Loss: 0.2012
Epoch  42 Batch  190/1077 - Train Accuracy: 0.8238, Validation Accuracy: 0.7468, Loss: 0.2013
Epoch  42 Batch  200/1077 - Train Accuracy: 0.7590, Validation Accuracy: 0.7425, Loss: 0.2156
Epoch  42 Batch  210/1077 - Train Accuracy: 0.7906, Validation Accuracy: 0.7472, Loss: 0.2045
Epoch  42 Batch  220/1077 - Train Accuracy: 0.7866, Validation Accuracy: 0.7532, Loss: 0.2173
Epoch  42 Batch  230/1077 - Train Accuracy: 0.7619, Validation Accuracy: 0.7575, Loss: 0.1993
Epoch  42 Batch  240/1077 - Train Accuracy: 0.8227, Validation Accuracy: 0.7418, Loss: 0.1982
Epoch  42 Batch  250/1077 - Train Accuracy: 0.7816, Validation Accuracy: 0.7468, Loss: 0.1983
Epoch  42 Batch  260/1077 - Train Accuracy: 0.8136, Validation Accuracy: 0.7525, Loss: 0.1889
Epoch  42 Batch  270/1077 - Train Accuracy: 0.7758, Validation Accuracy: 0.7603, Loss: 0.2240
Epoch  42 Batch  280/1077 - Train Accuracy: 0.7762, Validation Accuracy: 0.7560, Loss: 0.2111
Epoch  42 Batch  290/1077 - Train Accuracy: 0.7801, Validation Accuracy: 0.7603, Loss: 0.2238
Epoch  42 Batch  300/1077 - Train Accuracy: 0.7874, Validation Accuracy: 0.7525, Loss: 0.2079
Epoch  42 Batch  310/1077 - Train Accuracy: 0.7484, Validation Accuracy: 0.7504, Loss: 0.2242
Epoch  42 Batch  320/1077 - Train Accuracy: 0.8039, Validation Accuracy: 0.7624, Loss: 0.2560
Epoch  42 Batch  330/1077 - Train Accuracy: 0.7922, Validation Accuracy: 0.7624, Loss: 0.2071
Epoch  42 Batch  340/1077 - Train Accuracy: 0.7817, Validation Accuracy: 0.7489, Loss: 0.2140
Epoch  42 Batch  350/1077 - Train Accuracy: 0.7680, Validation Accuracy: 0.7646, Loss: 0.2047
Epoch  42 Batch  360/1077 - Train Accuracy: 0.7613, Validation Accuracy: 0.7450, Loss: 0.1984
Epoch  42 Batch  370/1077 - Train Accuracy: 0.8025, Validation Accuracy: 0.7550, Loss: 0.2056
Epoch  42 Batch  380/1077 - Train Accuracy: 0.7855, Validation Accuracy: 0.7596, Loss: 0.1889
Epoch  42 Batch  390/1077 - Train Accuracy: 0.7301, Validation Accuracy: 0.7418, Loss: 0.2240
Epoch  42 Batch  400/1077 - Train Accuracy: 0.7848, Validation Accuracy: 0.7450, Loss: 0.2096
Epoch  42 Batch  410/1077 - Train Accuracy: 0.7767, Validation Accuracy: 0.7710, Loss: 0.2251
Epoch  42 Batch  420/1077 - Train Accuracy: 0.7840, Validation Accuracy: 0.7472, Loss: 0.2041
Epoch  42 Batch  430/1077 - Train Accuracy: 0.7555, Validation Accuracy: 0.7532, Loss: 0.2057
Epoch  42 Batch  440/1077 - Train Accuracy: 0.7371, Validation Accuracy: 0.7500, Loss: 0.2312
Epoch  42 Batch  450/1077 - Train Accuracy: 0.7969, Validation Accuracy: 0.7475, Loss: 0.1934
Epoch  42 Batch  460/1077 - Train Accuracy: 0.7477, Validation Accuracy: 0.7514, Loss: 0.2190
Epoch  42 Batch  470/1077 - Train Accuracy: 0.7887, Validation Accuracy: 0.7546, Loss: 0.2179
Epoch  42 Batch  480/1077 - Train Accuracy: 0.7697, Validation Accuracy: 0.7564, Loss: 0.2183
Epoch  42 Batch  490/1077 - Train Accuracy: 0.7633, Validation Accuracy: 0.7578, Loss: 0.2157
Epoch  42 Batch  500/1077 - Train Accuracy: 0.7930, Validation Accuracy: 0.7614, Loss: 0.2002
Epoch  42 Batch  510/1077 - Train Accuracy: 0.7883, Validation Accuracy: 0.7557, Loss: 0.2093
Epoch  42 Batch  520/1077 - Train Accuracy: 0.8389, Validation Accuracy: 0.7411, Loss: 0.1854
Epoch  42 Batch  530/1077 - Train Accuracy: 0.7297, Validation Accuracy: 0.7493, Loss: 0.2152
Epoch  42 Batch  540/1077 - Train Accuracy: 0.8121, Validation Accuracy: 0.7585, Loss: 0.2040
Epoch  42 Batch  550/1077 - Train Accuracy: 0.7445, Validation Accuracy: 0.7518, Loss: 0.2179
Epoch  42 Batch  560/1077 - Train Accuracy: 0.7738, Validation Accuracy: 0.7536, Loss: 0.1949
Epoch  42 Batch  570/1077 - Train Accuracy: 0.7681, Validation Accuracy: 0.7486, Loss: 0.2140
Epoch  42 Batch  580/1077 - Train Accuracy: 0.7913, Validation Accuracy: 0.7464, Loss: 0.1962
Epoch  42 Batch  590/1077 - Train Accuracy: 0.7373, Validation Accuracy: 0.7564, Loss: 0.2310
Epoch  42 Batch  600/1077 - Train Accuracy: 0.7824, Validation Accuracy: 0.7472, Loss: 0.2029
Epoch  42 Batch  610/1077 - Train Accuracy: 0.7619, Validation Accuracy: 0.7422, Loss: 0.2179
Epoch  42 Batch  620/1077 - Train Accuracy: 0.7738, Validation Accuracy: 0.7372, Loss: 0.2008
Epoch  42 Batch  630/1077 - Train Accuracy: 0.7512, Validation Accuracy: 0.7567, Loss: 0.2081
Epoch  42 Batch  640/1077 - Train Accuracy: 0.7738, Validation Accuracy: 0.7628, Loss: 0.1998
Epoch  42 Batch  650/1077 - Train Accuracy: 0.7422, Validation Accuracy: 0.7447, Loss: 0.2170
Epoch  42 Batch  660/1077 - Train Accuracy: 0.8082, Validation Accuracy: 0.7518, Loss: 0.1988
Epoch  42 Batch  670/1077 - Train Accuracy: 0.7990, Validation Accuracy: 0.7475, Loss: 0.1875
Epoch  42 Batch  680/1077 - Train Accuracy: 0.7701, Validation Accuracy: 0.7489, Loss: 0.2017
Epoch  42 Batch  690/1077 - Train Accuracy: 0.7926, Validation Accuracy: 0.7621, Loss: 0.2059
Epoch  42 Batch  700/1077 - Train Accuracy: 0.7840, Validation Accuracy: 0.7617, Loss: 0.1977
Epoch  42 Batch  710/1077 - Train Accuracy: 0.7277, Validation Accuracy: 0.7479, Loss: 0.2001
Epoch  42 Batch  720/1077 - Train Accuracy: 0.7570, Validation Accuracy: 0.7337, Loss: 0.2268
Epoch  42 Batch  730/1077 - Train Accuracy: 0.7582, Validation Accuracy: 0.7560, Loss: 0.2178
Epoch  42 Batch  740/1077 - Train Accuracy: 0.7742, Validation Accuracy: 0.7638, Loss: 0.2019
Epoch  42 Batch  750/1077 - Train Accuracy: 0.7863, Validation Accuracy: 0.7518, Loss: 0.1993
Epoch  42 Batch  760/1077 - Train Accuracy: 0.7801, Validation Accuracy: 0.7638, Loss: 0.2040
Epoch  42 Batch  770/1077 - Train Accuracy: 0.7809, Validation Accuracy: 0.7610, Loss: 0.1883
Epoch  42 Batch  780/1077 - Train Accuracy: 0.7680, Validation Accuracy: 0.7699, Loss: 0.2344
Epoch  42 Batch  790/1077 - Train Accuracy: 0.7074, Validation Accuracy: 0.7621, Loss: 0.2211
Epoch  42 Batch  800/1077 - Train Accuracy: 0.7594, Validation Accuracy: 0.7667, Loss: 0.2077
Epoch  42 Batch  810/1077 - Train Accuracy: 0.7671, Validation Accuracy: 0.7635, Loss: 0.1953
Epoch  42 Batch  820/1077 - Train Accuracy: 0.7438, Validation Accuracy: 0.7596, Loss: 0.2268
Epoch  42 Batch  830/1077 - Train Accuracy: 0.7598, Validation Accuracy: 0.7749, Loss: 0.2077
Epoch  42 Batch  840/1077 - Train Accuracy: 0.7871, Validation Accuracy: 0.7681, Loss: 0.2153
Epoch  42 Batch  850/1077 - Train Accuracy: 0.7533, Validation Accuracy: 0.7599, Loss: 0.2211
Epoch  42 Batch  860/1077 - Train Accuracy: 0.7604, Validation Accuracy: 0.7528, Loss: 0.2159
Epoch  42 Batch  870/1077 - Train Accuracy: 0.7578, Validation Accuracy: 0.7717, Loss: 0.2161
Epoch  42 Batch  880/1077 - Train Accuracy: 0.8109, Validation Accuracy: 0.7585, Loss: 0.2014
Epoch  42 Batch  890/1077 - Train Accuracy: 0.8177, Validation Accuracy: 0.7337, Loss: 0.2008
Epoch  42 Batch  900/1077 - Train Accuracy: 0.8055, Validation Accuracy: 0.7631, Loss: 0.2069
Epoch  42 Batch  910/1077 - Train Accuracy: 0.8051, Validation Accuracy: 0.7628, Loss: 0.2148
Epoch  42 Batch  920/1077 - Train Accuracy: 0.8023, Validation Accuracy: 0.7575, Loss: 0.2217
Epoch  42 Batch  930/1077 - Train Accuracy: 0.7832, Validation Accuracy: 0.7532, Loss: 0.1911
Epoch  42 Batch  940/1077 - Train Accuracy: 0.7930, Validation Accuracy: 0.7592, Loss: 0.2060
Epoch  42 Batch  950/1077 - Train Accuracy: 0.7831, Validation Accuracy: 0.7546, Loss: 0.2039
Epoch  42 Batch  960/1077 - Train Accuracy: 0.7649, Validation Accuracy: 0.7706, Loss: 0.2106
Epoch  42 Batch  970/1077 - Train Accuracy: 0.7629, Validation Accuracy: 0.7521, Loss: 0.2108
Epoch  42 Batch  980/1077 - Train Accuracy: 0.7410, Validation Accuracy: 0.7532, Loss: 0.2181
Epoch  42 Batch  990/1077 - Train Accuracy: 0.7706, Validation Accuracy: 0.7638, Loss: 0.2144
Epoch  42 Batch 1000/1077 - Train Accuracy: 0.8036, Validation Accuracy: 0.7614, Loss: 0.2039
Epoch  42 Batch 1010/1077 - Train Accuracy: 0.7930, Validation Accuracy: 0.7575, Loss: 0.1993
Epoch  42 Batch 1020/1077 - Train Accuracy: 0.7742, Validation Accuracy: 0.7500, Loss: 0.2106
Epoch  42 Batch 1030/1077 - Train Accuracy: 0.7539, Validation Accuracy: 0.7631, Loss: 0.2298
Epoch  42 Batch 1040/1077 - Train Accuracy: 0.8014, Validation Accuracy: 0.7390, Loss: 0.2085
Epoch  42 Batch 1050/1077 - Train Accuracy: 0.7348, Validation Accuracy: 0.7560, Loss: 0.1994
Epoch  42 Batch 1060/1077 - Train Accuracy: 0.8051, Validation Accuracy: 0.7621, Loss: 0.1965
Epoch  42 Batch 1070/1077 - Train Accuracy: 0.7555, Validation Accuracy: 0.7621, Loss: 0.2188
Epoch  43 Batch   10/1077 - Train Accuracy: 0.8080, Validation Accuracy: 0.7532, Loss: 0.2282
Epoch  43 Batch   20/1077 - Train Accuracy: 0.7574, Validation Accuracy: 0.7536, Loss: 0.1981
Epoch  43 Batch   30/1077 - Train Accuracy: 0.8008, Validation Accuracy: 0.7596, Loss: 0.2129
Epoch  43 Batch   40/1077 - Train Accuracy: 0.8055, Validation Accuracy: 0.7614, Loss: 0.2118
Epoch  43 Batch   50/1077 - Train Accuracy: 0.7598, Validation Accuracy: 0.7710, Loss: 0.2012
Epoch  43 Batch   60/1077 - Train Accuracy: 0.7932, Validation Accuracy: 0.7717, Loss: 0.1952
Epoch  43 Batch   70/1077 - Train Accuracy: 0.8055, Validation Accuracy: 0.7521, Loss: 0.2162
Epoch  43 Batch   80/1077 - Train Accuracy: 0.7801, Validation Accuracy: 0.7567, Loss: 0.2146
Epoch  43 Batch   90/1077 - Train Accuracy: 0.7500, Validation Accuracy: 0.7592, Loss: 0.2215
Epoch  43 Batch  100/1077 - Train Accuracy: 0.7512, Validation Accuracy: 0.7670, Loss: 0.2038
Epoch  43 Batch  110/1077 - Train Accuracy: 0.7801, Validation Accuracy: 0.7631, Loss: 0.1937
Epoch  43 Batch  120/1077 - Train Accuracy: 0.8020, Validation Accuracy: 0.7702, Loss: 0.2264
Epoch  43 Batch  130/1077 - Train Accuracy: 0.7496, Validation Accuracy: 0.7599, Loss: 0.2044
Epoch  43 Batch  140/1077 - Train Accuracy: 0.7837, Validation Accuracy: 0.7660, Loss: 0.2286
Epoch  43 Batch  150/1077 - Train Accuracy: 0.8025, Validation Accuracy: 0.7631, Loss: 0.2053
Epoch  43 Batch  160/1077 - Train Accuracy: 0.7801, Validation Accuracy: 0.7596, Loss: 0.2033
Epoch  43 Batch  170/1077 - Train Accuracy: 0.7316, Validation Accuracy: 0.7564, Loss: 0.2187
Epoch  43 Batch  180/1077 - Train Accuracy: 0.7770, Validation Accuracy: 0.7514, Loss: 0.2025
Epoch  43 Batch  190/1077 - Train Accuracy: 0.8199, Validation Accuracy: 0.7560, Loss: 0.2081
Epoch  43 Batch  200/1077 - Train Accuracy: 0.7641, Validation Accuracy: 0.7525, Loss: 0.2090
Epoch  43 Batch  210/1077 - Train Accuracy: 0.7946, Validation Accuracy: 0.7475, Loss: 0.2003
Epoch  43 Batch  220/1077 - Train Accuracy: 0.7919, Validation Accuracy: 0.7543, Loss: 0.2108
Epoch  43 Batch  230/1077 - Train Accuracy: 0.7693, Validation Accuracy: 0.7482, Loss: 0.1937
Epoch  43 Batch  240/1077 - Train Accuracy: 0.8207, Validation Accuracy: 0.7553, Loss: 0.2030
Epoch  43 Batch  250/1077 - Train Accuracy: 0.7749, Validation Accuracy: 0.7450, Loss: 0.2040
Epoch  43 Batch  260/1077 - Train Accuracy: 0.8173, Validation Accuracy: 0.7500, Loss: 0.1955
Epoch  43 Batch  270/1077 - Train Accuracy: 0.7727, Validation Accuracy: 0.7638, Loss: 0.2196
Epoch  43 Batch  280/1077 - Train Accuracy: 0.7801, Validation Accuracy: 0.7631, Loss: 0.2138
Epoch  43 Batch  290/1077 - Train Accuracy: 0.7816, Validation Accuracy: 0.7493, Loss: 0.2358
Epoch  43 Batch  300/1077 - Train Accuracy: 0.7763, Validation Accuracy: 0.7582, Loss: 0.1982
Epoch  43 Batch  310/1077 - Train Accuracy: 0.7582, Validation Accuracy: 0.7560, Loss: 0.2152
Epoch  43 Batch  320/1077 - Train Accuracy: 0.8066, Validation Accuracy: 0.7532, Loss: 0.2441
Epoch  43 Batch  330/1077 - Train Accuracy: 0.8027, Validation Accuracy: 0.7550, Loss: 0.2209
Epoch  43 Batch  340/1077 - Train Accuracy: 0.7784, Validation Accuracy: 0.7504, Loss: 0.2097
Epoch  43 Batch  350/1077 - Train Accuracy: 0.7641, Validation Accuracy: 0.7628, Loss: 0.2057
Epoch  43 Batch  360/1077 - Train Accuracy: 0.7668, Validation Accuracy: 0.7539, Loss: 0.1968
Epoch  43 Batch  370/1077 - Train Accuracy: 0.7932, Validation Accuracy: 0.7543, Loss: 0.1949
Epoch  43 Batch  380/1077 - Train Accuracy: 0.7828, Validation Accuracy: 0.7596, Loss: 0.2066
Epoch  43 Batch  390/1077 - Train Accuracy: 0.7461, Validation Accuracy: 0.7475, Loss: 0.2289
Epoch  43 Batch  400/1077 - Train Accuracy: 0.7898, Validation Accuracy: 0.7536, Loss: 0.2097
Epoch  43 Batch  410/1077 - Train Accuracy: 0.7722, Validation Accuracy: 0.7731, Loss: 0.2244
Epoch  43 Batch  420/1077 - Train Accuracy: 0.7820, Validation Accuracy: 0.7567, Loss: 0.1983
Epoch  43 Batch  430/1077 - Train Accuracy: 0.7551, Validation Accuracy: 0.7457, Loss: 0.2035
Epoch  43 Batch  440/1077 - Train Accuracy: 0.7500, Validation Accuracy: 0.7536, Loss: 0.2134
Epoch  43 Batch  450/1077 - Train Accuracy: 0.7996, Validation Accuracy: 0.7539, Loss: 0.2000
Epoch  43 Batch  460/1077 - Train Accuracy: 0.7375, Validation Accuracy: 0.7436, Loss: 0.2086
Epoch  43 Batch  470/1077 - Train Accuracy: 0.7874, Validation Accuracy: 0.7468, Loss: 0.2194
Epoch  43 Batch  480/1077 - Train Accuracy: 0.7599, Validation Accuracy: 0.7489, Loss: 0.2072
Epoch  43 Batch  490/1077 - Train Accuracy: 0.7535, Validation Accuracy: 0.7614, Loss: 0.2139
Epoch  43 Batch  500/1077 - Train Accuracy: 0.7996, Validation Accuracy: 0.7610, Loss: 0.2056
Epoch  43 Batch  510/1077 - Train Accuracy: 0.8004, Validation Accuracy: 0.7635, Loss: 0.1983
Epoch  43 Batch  520/1077 - Train Accuracy: 0.8434, Validation Accuracy: 0.7585, Loss: 0.1887
Epoch  43 Batch  530/1077 - Train Accuracy: 0.7426, Validation Accuracy: 0.7578, Loss: 0.2185
Epoch  43 Batch  540/1077 - Train Accuracy: 0.7871, Validation Accuracy: 0.7553, Loss: 0.1911
Epoch  43 Batch  550/1077 - Train Accuracy: 0.7445, Validation Accuracy: 0.7464, Loss: 0.2172
Epoch  43 Batch  560/1077 - Train Accuracy: 0.7809, Validation Accuracy: 0.7610, Loss: 0.1895
Epoch  43 Batch  570/1077 - Train Accuracy: 0.7685, Validation Accuracy: 0.7479, Loss: 0.2271
Epoch  43 Batch  580/1077 - Train Accuracy: 0.7999, Validation Accuracy: 0.7536, Loss: 0.1856
Epoch  43 Batch  590/1077 - Train Accuracy: 0.7434, Validation Accuracy: 0.7482, Loss: 0.2296
Epoch  43 Batch  600/1077 - Train Accuracy: 0.7954, Validation Accuracy: 0.7585, Loss: 0.1867
Epoch  43 Batch  610/1077 - Train Accuracy: 0.7697, Validation Accuracy: 0.7518, Loss: 0.2147
Epoch  43 Batch  620/1077 - Train Accuracy: 0.7789, Validation Accuracy: 0.7461, Loss: 0.1942
Epoch  43 Batch  630/1077 - Train Accuracy: 0.7434, Validation Accuracy: 0.7688, Loss: 0.2065
Epoch  43 Batch  640/1077 - Train Accuracy: 0.7764, Validation Accuracy: 0.7802, Loss: 0.2037
Epoch  43 Batch  650/1077 - Train Accuracy: 0.7602, Validation Accuracy: 0.7543, Loss: 0.2076
Epoch  43 Batch  660/1077 - Train Accuracy: 0.8035, Validation Accuracy: 0.7607, Loss: 0.2050
Epoch  43 Batch  670/1077 - Train Accuracy: 0.7820, Validation Accuracy: 0.7493, Loss: 0.1928
Epoch  43 Batch  680/1077 - Train Accuracy: 0.7485, Validation Accuracy: 0.7585, Loss: 0.2254
Epoch  43 Batch  690/1077 - Train Accuracy: 0.7902, Validation Accuracy: 0.7603, Loss: 0.2116
Epoch  43 Batch  700/1077 - Train Accuracy: 0.7918, Validation Accuracy: 0.7536, Loss: 0.2046
Epoch  43 Batch  710/1077 - Train Accuracy: 0.7383, Validation Accuracy: 0.7393, Loss: 0.2064
Epoch  43 Batch  720/1077 - Train Accuracy: 0.7599, Validation Accuracy: 0.7670, Loss: 0.2430
Epoch  43 Batch  730/1077 - Train Accuracy: 0.7469, Validation Accuracy: 0.7653, Loss: 0.2108
Epoch  43 Batch  740/1077 - Train Accuracy: 0.7762, Validation Accuracy: 0.7532, Loss: 0.2073
Epoch  43 Batch  750/1077 - Train Accuracy: 0.7766, Validation Accuracy: 0.7607, Loss: 0.2038
Epoch  43 Batch  760/1077 - Train Accuracy: 0.7770, Validation Accuracy: 0.7567, Loss: 0.2102
Epoch  43 Batch  770/1077 - Train Accuracy: 0.7872, Validation Accuracy: 0.7603, Loss: 0.1878
Epoch  43 Batch  780/1077 - Train Accuracy: 0.7668, Validation Accuracy: 0.7720, Loss: 0.2247
Epoch  43 Batch  790/1077 - Train Accuracy: 0.7066, Validation Accuracy: 0.7642, Loss: 0.2178
Epoch  43 Batch  800/1077 - Train Accuracy: 0.7641, Validation Accuracy: 0.7539, Loss: 0.2040
Epoch  43 Batch  810/1077 - Train Accuracy: 0.7731, Validation Accuracy: 0.7621, Loss: 0.1860
Epoch  43 Batch  820/1077 - Train Accuracy: 0.7359, Validation Accuracy: 0.7546, Loss: 0.2217
Epoch  43 Batch  830/1077 - Train Accuracy: 0.7465, Validation Accuracy: 0.7557, Loss: 0.2037
Epoch  43 Batch  840/1077 - Train Accuracy: 0.7816, Validation Accuracy: 0.7564, Loss: 0.2075
Epoch  43 Batch  850/1077 - Train Accuracy: 0.7455, Validation Accuracy: 0.7670, Loss: 0.2482
Epoch  43 Batch  860/1077 - Train Accuracy: 0.7526, Validation Accuracy: 0.7631, Loss: 0.2152
Epoch  43 Batch  870/1077 - Train Accuracy: 0.7521, Validation Accuracy: 0.7660, Loss: 0.2161
Epoch  43 Batch  880/1077 - Train Accuracy: 0.7996, Validation Accuracy: 0.7525, Loss: 0.1942
Epoch  43 Batch  890/1077 - Train Accuracy: 0.8318, Validation Accuracy: 0.7560, Loss: 0.1878
Epoch  43 Batch  900/1077 - Train Accuracy: 0.7969, Validation Accuracy: 0.7500, Loss: 0.2125
Epoch  43 Batch  910/1077 - Train Accuracy: 0.8080, Validation Accuracy: 0.7521, Loss: 0.2212
Epoch  43 Batch  920/1077 - Train Accuracy: 0.8102, Validation Accuracy: 0.7546, Loss: 0.2055
Epoch  43 Batch  930/1077 - Train Accuracy: 0.7875, Validation Accuracy: 0.7475, Loss: 0.1954
Epoch  43 Batch  940/1077 - Train Accuracy: 0.7805, Validation Accuracy: 0.7539, Loss: 0.1953
Epoch  43 Batch  950/1077 - Train Accuracy: 0.7842, Validation Accuracy: 0.7550, Loss: 0.1912
Epoch  43 Batch  960/1077 - Train Accuracy: 0.7693, Validation Accuracy: 0.7415, Loss: 0.1954
Epoch  43 Batch  970/1077 - Train Accuracy: 0.7738, Validation Accuracy: 0.7475, Loss: 0.2105
Epoch  43 Batch  980/1077 - Train Accuracy: 0.7277, Validation Accuracy: 0.7567, Loss: 0.2180
Epoch  43 Batch  990/1077 - Train Accuracy: 0.7455, Validation Accuracy: 0.7607, Loss: 0.2157
Epoch  43 Batch 1000/1077 - Train Accuracy: 0.8080, Validation Accuracy: 0.7582, Loss: 0.2052
Epoch  43 Batch 1010/1077 - Train Accuracy: 0.7820, Validation Accuracy: 0.7745, Loss: 0.1988
Epoch  43 Batch 1020/1077 - Train Accuracy: 0.7617, Validation Accuracy: 0.7592, Loss: 0.1890
Epoch  43 Batch 1030/1077 - Train Accuracy: 0.7480, Validation Accuracy: 0.7592, Loss: 0.2188
Epoch  43 Batch 1040/1077 - Train Accuracy: 0.8059, Validation Accuracy: 0.7475, Loss: 0.1979
Epoch  43 Batch 1050/1077 - Train Accuracy: 0.7406, Validation Accuracy: 0.7638, Loss: 0.2015
Epoch  43 Batch 1060/1077 - Train Accuracy: 0.8070, Validation Accuracy: 0.7603, Loss: 0.1868
Epoch  43 Batch 1070/1077 - Train Accuracy: 0.7508, Validation Accuracy: 0.7720, Loss: 0.2176
Epoch  44 Batch   10/1077 - Train Accuracy: 0.7956, Validation Accuracy: 0.7646, Loss: 0.2244
Epoch  44 Batch   20/1077 - Train Accuracy: 0.7734, Validation Accuracy: 0.7500, Loss: 0.2026
Epoch  44 Batch   30/1077 - Train Accuracy: 0.7898, Validation Accuracy: 0.7546, Loss: 0.2029
Epoch  44 Batch   40/1077 - Train Accuracy: 0.8078, Validation Accuracy: 0.7710, Loss: 0.1995
Epoch  44 Batch   50/1077 - Train Accuracy: 0.7605, Validation Accuracy: 0.7663, Loss: 0.2042
Epoch  44 Batch   60/1077 - Train Accuracy: 0.7805, Validation Accuracy: 0.7614, Loss: 0.1815
Epoch  44 Batch   70/1077 - Train Accuracy: 0.8203, Validation Accuracy: 0.7706, Loss: 0.2181
Epoch  44 Batch   80/1077 - Train Accuracy: 0.7730, Validation Accuracy: 0.7663, Loss: 0.2063
Epoch  44 Batch   90/1077 - Train Accuracy: 0.7430, Validation Accuracy: 0.7717, Loss: 0.2132
Epoch  44 Batch  100/1077 - Train Accuracy: 0.7551, Validation Accuracy: 0.7812, Loss: 0.2119
Epoch  44 Batch  110/1077 - Train Accuracy: 0.7859, Validation Accuracy: 0.7663, Loss: 0.1885
Epoch  44 Batch  120/1077 - Train Accuracy: 0.7969, Validation Accuracy: 0.7745, Loss: 0.2208
Epoch  44 Batch  130/1077 - Train Accuracy: 0.7485, Validation Accuracy: 0.7749, Loss: 0.2037
Epoch  44 Batch  140/1077 - Train Accuracy: 0.7804, Validation Accuracy: 0.7607, Loss: 0.2093
Epoch  44 Batch  150/1077 - Train Accuracy: 0.7943, Validation Accuracy: 0.7607, Loss: 0.2060
Epoch  44 Batch  160/1077 - Train Accuracy: 0.7695, Validation Accuracy: 0.7560, Loss: 0.2048
Epoch  44 Batch  170/1077 - Train Accuracy: 0.7469, Validation Accuracy: 0.7578, Loss: 0.2028
Epoch  44 Batch  180/1077 - Train Accuracy: 0.7949, Validation Accuracy: 0.7599, Loss: 0.1895
Epoch  44 Batch  190/1077 - Train Accuracy: 0.8203, Validation Accuracy: 0.7614, Loss: 0.2025
Epoch  44 Batch  200/1077 - Train Accuracy: 0.7711, Validation Accuracy: 0.7770, Loss: 0.2196
Epoch  44 Batch  210/1077 - Train Accuracy: 0.7887, Validation Accuracy: 0.7507, Loss: 0.2066
Epoch  44 Batch  220/1077 - Train Accuracy: 0.7817, Validation Accuracy: 0.7550, Loss: 0.2071
Epoch  44 Batch  230/1077 - Train Accuracy: 0.7682, Validation Accuracy: 0.7585, Loss: 0.2007
Epoch  44 Batch  240/1077 - Train Accuracy: 0.8246, Validation Accuracy: 0.7575, Loss: 0.2129
Epoch  44 Batch  250/1077 - Train Accuracy: 0.7859, Validation Accuracy: 0.7642, Loss: 0.2005
Epoch  44 Batch  260/1077 - Train Accuracy: 0.8162, Validation Accuracy: 0.7628, Loss: 0.1891
Epoch  44 Batch  270/1077 - Train Accuracy: 0.7762, Validation Accuracy: 0.7638, Loss: 0.2144
Epoch  44 Batch  280/1077 - Train Accuracy: 0.7703, Validation Accuracy: 0.7649, Loss: 0.2049
Epoch  44 Batch  290/1077 - Train Accuracy: 0.7895, Validation Accuracy: 0.7557, Loss: 0.2253
Epoch  44 Batch  300/1077 - Train Accuracy: 0.7845, Validation Accuracy: 0.7592, Loss: 0.2076
Epoch  44 Batch  310/1077 - Train Accuracy: 0.7570, Validation Accuracy: 0.7564, Loss: 0.2220
Epoch  44 Batch  320/1077 - Train Accuracy: 0.8152, Validation Accuracy: 0.7653, Loss: 0.2486
Epoch  44 Batch  330/1077 - Train Accuracy: 0.7879, Validation Accuracy: 0.7592, Loss: 0.2157
Epoch  44 Batch  340/1077 - Train Accuracy: 0.7903, Validation Accuracy: 0.7596, Loss: 0.2054
Epoch  44 Batch  350/1077 - Train Accuracy: 0.7805, Validation Accuracy: 0.7667, Loss: 0.2000
Epoch  44 Batch  360/1077 - Train Accuracy: 0.7742, Validation Accuracy: 0.7642, Loss: 0.1892
Epoch  44 Batch  370/1077 - Train Accuracy: 0.7943, Validation Accuracy: 0.7660, Loss: 0.1987
Epoch  44 Batch  380/1077 - Train Accuracy: 0.7730, Validation Accuracy: 0.7589, Loss: 0.1840
Epoch  44 Batch  390/1077 - Train Accuracy: 0.7480, Validation Accuracy: 0.7500, Loss: 0.2319
Epoch  44 Batch  400/1077 - Train Accuracy: 0.7973, Validation Accuracy: 0.7628, Loss: 0.2100
Epoch  44 Batch  410/1077 - Train Accuracy: 0.7734, Validation Accuracy: 0.7546, Loss: 0.2257
Epoch  44 Batch  420/1077 - Train Accuracy: 0.7895, Validation Accuracy: 0.7614, Loss: 0.1871
Epoch  44 Batch  430/1077 - Train Accuracy: 0.7555, Validation Accuracy: 0.7621, Loss: 0.1939
Epoch  44 Batch  440/1077 - Train Accuracy: 0.7477, Validation Accuracy: 0.7546, Loss: 0.2224
Epoch  44 Batch  450/1077 - Train Accuracy: 0.8027, Validation Accuracy: 0.7489, Loss: 0.2119
Epoch  44 Batch  460/1077 - Train Accuracy: 0.7566, Validation Accuracy: 0.7486, Loss: 0.2103
Epoch  44 Batch  470/1077 - Train Accuracy: 0.7800, Validation Accuracy: 0.7461, Loss: 0.2062
Epoch  44 Batch  480/1077 - Train Accuracy: 0.7763, Validation Accuracy: 0.7589, Loss: 0.2092
Epoch  44 Batch  490/1077 - Train Accuracy: 0.7555, Validation Accuracy: 0.7582, Loss: 0.1966
Epoch  44 Batch  500/1077 - Train Accuracy: 0.8156, Validation Accuracy: 0.7596, Loss: 0.1861
Epoch  44 Batch  510/1077 - Train Accuracy: 0.8090, Validation Accuracy: 0.7642, Loss: 0.2143
Epoch  44 Batch  520/1077 - Train Accuracy: 0.8452, Validation Accuracy: 0.7589, Loss: 0.1780
Epoch  44 Batch  530/1077 - Train Accuracy: 0.7406, Validation Accuracy: 0.7585, Loss: 0.2118
Epoch  44 Batch  540/1077 - Train Accuracy: 0.7949, Validation Accuracy: 0.7667, Loss: 0.1874
Epoch  44 Batch  550/1077 - Train Accuracy: 0.7445, Validation Accuracy: 0.7621, Loss: 0.2010
Epoch  44 Batch  560/1077 - Train Accuracy: 0.7828, Validation Accuracy: 0.7667, Loss: 0.2069
Epoch  44 Batch  570/1077 - Train Accuracy: 0.7792, Validation Accuracy: 0.7479, Loss: 0.2179
Epoch  44 Batch  580/1077 - Train Accuracy: 0.8017, Validation Accuracy: 0.7692, Loss: 0.1798
Epoch  44 Batch  590/1077 - Train Accuracy: 0.7521, Validation Accuracy: 0.7592, Loss: 0.2260
Epoch  44 Batch  600/1077 - Train Accuracy: 0.7902, Validation Accuracy: 0.7699, Loss: 0.1879
Epoch  44 Batch  610/1077 - Train Accuracy: 0.7693, Validation Accuracy: 0.7692, Loss: 0.2067
Epoch  44 Batch  620/1077 - Train Accuracy: 0.7801, Validation Accuracy: 0.7599, Loss: 0.2006
Epoch  44 Batch  630/1077 - Train Accuracy: 0.7500, Validation Accuracy: 0.7578, Loss: 0.2129
Epoch  44 Batch  640/1077 - Train Accuracy: 0.7835, Validation Accuracy: 0.7578, Loss: 0.1907
Epoch  44 Batch  650/1077 - Train Accuracy: 0.7637, Validation Accuracy: 0.7624, Loss: 0.1970
Epoch  44 Batch  660/1077 - Train Accuracy: 0.8035, Validation Accuracy: 0.7585, Loss: 0.1951
Epoch  44 Batch  670/1077 - Train Accuracy: 0.7962, Validation Accuracy: 0.7550, Loss: 0.1842
Epoch  44 Batch  680/1077 - Train Accuracy: 0.7504, Validation Accuracy: 0.7642, Loss: 0.2262
Epoch  44 Batch  690/1077 - Train Accuracy: 0.8000, Validation Accuracy: 0.7592, Loss: 0.2062
Epoch  44 Batch  700/1077 - Train Accuracy: 0.7988, Validation Accuracy: 0.7642, Loss: 0.1950
Epoch  44 Batch  710/1077 - Train Accuracy: 0.7500, Validation Accuracy: 0.7578, Loss: 0.2098
Epoch  44 Batch  720/1077 - Train Accuracy: 0.7677, Validation Accuracy: 0.7479, Loss: 0.2138
Epoch  44 Batch  730/1077 - Train Accuracy: 0.7480, Validation Accuracy: 0.7745, Loss: 0.2053
Epoch  44 Batch  740/1077 - Train Accuracy: 0.7844, Validation Accuracy: 0.7575, Loss: 0.1994
Epoch  44 Batch  750/1077 - Train Accuracy: 0.7680, Validation Accuracy: 0.7518, Loss: 0.2047
Epoch  44 Batch  760/1077 - Train Accuracy: 0.7781, Validation Accuracy: 0.7667, Loss: 0.2121
Epoch  44 Batch  770/1077 - Train Accuracy: 0.7753, Validation Accuracy: 0.7546, Loss: 0.1888
Epoch  44 Batch  780/1077 - Train Accuracy: 0.7652, Validation Accuracy: 0.7663, Loss: 0.2338
Epoch  44 Batch  790/1077 - Train Accuracy: 0.7102, Validation Accuracy: 0.7759, Loss: 0.2197
Epoch  44 Batch  800/1077 - Train Accuracy: 0.7672, Validation Accuracy: 0.7564, Loss: 0.1994
Epoch  44 Batch  810/1077 - Train Accuracy: 0.7757, Validation Accuracy: 0.7603, Loss: 0.1982
Epoch  44 Batch  820/1077 - Train Accuracy: 0.7473, Validation Accuracy: 0.7553, Loss: 0.2220
Epoch  44 Batch  830/1077 - Train Accuracy: 0.7527, Validation Accuracy: 0.7585, Loss: 0.2052
Epoch  44 Batch  840/1077 - Train Accuracy: 0.7836, Validation Accuracy: 0.7571, Loss: 0.2074
Epoch  44 Batch  850/1077 - Train Accuracy: 0.7507, Validation Accuracy: 0.7599, Loss: 0.2284
Epoch  44 Batch  860/1077 - Train Accuracy: 0.7641, Validation Accuracy: 0.7582, Loss: 0.2106
Epoch  44 Batch  870/1077 - Train Accuracy: 0.7496, Validation Accuracy: 0.7631, Loss: 0.2119
Epoch  44 Batch  880/1077 - Train Accuracy: 0.8121, Validation Accuracy: 0.7617, Loss: 0.1984
Epoch  44 Batch  890/1077 - Train Accuracy: 0.8296, Validation Accuracy: 0.7461, Loss: 0.1908
Epoch  44 Batch  900/1077 - Train Accuracy: 0.7992, Validation Accuracy: 0.7546, Loss: 0.1954
Epoch  44 Batch  910/1077 - Train Accuracy: 0.8025, Validation Accuracy: 0.7628, Loss: 0.1898
Epoch  44 Batch  920/1077 - Train Accuracy: 0.7867, Validation Accuracy: 0.7461, Loss: 0.2122
Epoch  44 Batch  930/1077 - Train Accuracy: 0.7852, Validation Accuracy: 0.7464, Loss: 0.1857
Epoch  44 Batch  940/1077 - Train Accuracy: 0.7816, Validation Accuracy: 0.7571, Loss: 0.1971
Epoch  44 Batch  950/1077 - Train Accuracy: 0.7749, Validation Accuracy: 0.7486, Loss: 0.1907
Epoch  44 Batch  960/1077 - Train Accuracy: 0.7768, Validation Accuracy: 0.7649, Loss: 0.1949
Epoch  44 Batch  970/1077 - Train Accuracy: 0.7719, Validation Accuracy: 0.7578, Loss: 0.2108
Epoch  44 Batch  980/1077 - Train Accuracy: 0.7473, Validation Accuracy: 0.7628, Loss: 0.2183
Epoch  44 Batch  990/1077 - Train Accuracy: 0.7516, Validation Accuracy: 0.7663, Loss: 0.2098
Epoch  44 Batch 1000/1077 - Train Accuracy: 0.7987, Validation Accuracy: 0.7504, Loss: 0.1913
Epoch  44 Batch 1010/1077 - Train Accuracy: 0.8039, Validation Accuracy: 0.7596, Loss: 0.2013
Epoch  44 Batch 1020/1077 - Train Accuracy: 0.7789, Validation Accuracy: 0.7532, Loss: 0.1905
Epoch  44 Batch 1030/1077 - Train Accuracy: 0.7566, Validation Accuracy: 0.7649, Loss: 0.2129
Epoch  44 Batch 1040/1077 - Train Accuracy: 0.8109, Validation Accuracy: 0.7511, Loss: 0.1986
Epoch  44 Batch 1050/1077 - Train Accuracy: 0.7297, Validation Accuracy: 0.7504, Loss: 0.1911
Epoch  44 Batch 1060/1077 - Train Accuracy: 0.8078, Validation Accuracy: 0.7649, Loss: 0.1761
Epoch  44 Batch 1070/1077 - Train Accuracy: 0.7676, Validation Accuracy: 0.7624, Loss: 0.2115
Epoch  45 Batch   10/1077 - Train Accuracy: 0.7952, Validation Accuracy: 0.7567, Loss: 0.2090
Epoch  45 Batch   20/1077 - Train Accuracy: 0.7672, Validation Accuracy: 0.7699, Loss: 0.1919
Epoch  45 Batch   30/1077 - Train Accuracy: 0.7992, Validation Accuracy: 0.7603, Loss: 0.2071
Epoch  45 Batch   40/1077 - Train Accuracy: 0.8207, Validation Accuracy: 0.7599, Loss: 0.2038
Epoch  45 Batch   50/1077 - Train Accuracy: 0.7438, Validation Accuracy: 0.7702, Loss: 0.1987
Epoch  45 Batch   60/1077 - Train Accuracy: 0.7961, Validation Accuracy: 0.7667, Loss: 0.1830
Epoch  45 Batch   70/1077 - Train Accuracy: 0.8121, Validation Accuracy: 0.7585, Loss: 0.1954
Epoch  45 Batch   80/1077 - Train Accuracy: 0.7789, Validation Accuracy: 0.7557, Loss: 0.1992
Epoch  45 Batch   90/1077 - Train Accuracy: 0.7633, Validation Accuracy: 0.7681, Loss: 0.2123
Epoch  45 Batch  100/1077 - Train Accuracy: 0.7520, Validation Accuracy: 0.7670, Loss: 0.2002
Epoch  45 Batch  110/1077 - Train Accuracy: 0.7797, Validation Accuracy: 0.7578, Loss: 0.1914
Epoch  45 Batch  120/1077 - Train Accuracy: 0.7961, Validation Accuracy: 0.7578, Loss: 0.2150
Epoch  45 Batch  130/1077 - Train Accuracy: 0.7440, Validation Accuracy: 0.7603, Loss: 0.2042
Epoch  45 Batch  140/1077 - Train Accuracy: 0.7924, Validation Accuracy: 0.7599, Loss: 0.1982
Epoch  45 Batch  150/1077 - Train Accuracy: 0.7943, Validation Accuracy: 0.7603, Loss: 0.1958
Epoch  45 Batch  160/1077 - Train Accuracy: 0.7734, Validation Accuracy: 0.7507, Loss: 0.1993
Epoch  45 Batch  170/1077 - Train Accuracy: 0.7391, Validation Accuracy: 0.7713, Loss: 0.2132
Epoch  45 Batch  180/1077 - Train Accuracy: 0.7891, Validation Accuracy: 0.7631, Loss: 0.2036
Epoch  45 Batch  190/1077 - Train Accuracy: 0.8301, Validation Accuracy: 0.7475, Loss: 0.2012
Epoch  45 Batch  200/1077 - Train Accuracy: 0.7691, Validation Accuracy: 0.7607, Loss: 0.1979
Epoch  45 Batch  210/1077 - Train Accuracy: 0.7950, Validation Accuracy: 0.7621, Loss: 0.2047
Epoch  45 Batch  220/1077 - Train Accuracy: 0.7780, Validation Accuracy: 0.7585, Loss: 0.2148
Epoch  45 Batch  230/1077 - Train Accuracy: 0.7675, Validation Accuracy: 0.7589, Loss: 0.1989
Epoch  45 Batch  240/1077 - Train Accuracy: 0.8297, Validation Accuracy: 0.7482, Loss: 0.1991
Epoch  45 Batch  250/1077 - Train Accuracy: 0.7781, Validation Accuracy: 0.7525, Loss: 0.1954
Epoch  45 Batch  260/1077 - Train Accuracy: 0.8010, Validation Accuracy: 0.7528, Loss: 0.1862
Epoch  45 Batch  270/1077 - Train Accuracy: 0.7816, Validation Accuracy: 0.7507, Loss: 0.2038
Epoch  45 Batch  280/1077 - Train Accuracy: 0.7883, Validation Accuracy: 0.7685, Loss: 0.1934
Epoch  45 Batch  290/1077 - Train Accuracy: 0.7887, Validation Accuracy: 0.7596, Loss: 0.2334
Epoch  45 Batch  300/1077 - Train Accuracy: 0.7948, Validation Accuracy: 0.7475, Loss: 0.1996
Epoch  45 Batch  310/1077 - Train Accuracy: 0.7461, Validation Accuracy: 0.7511, Loss: 0.2199
Epoch  45 Batch  320/1077 - Train Accuracy: 0.8219, Validation Accuracy: 0.7464, Loss: 0.2449
Epoch  45 Batch  330/1077 - Train Accuracy: 0.7855, Validation Accuracy: 0.7468, Loss: 0.2139
Epoch  45 Batch  340/1077 - Train Accuracy: 0.7961, Validation Accuracy: 0.7599, Loss: 0.2028
Epoch  45 Batch  350/1077 - Train Accuracy: 0.7801, Validation Accuracy: 0.7688, Loss: 0.1984
Epoch  45 Batch  360/1077 - Train Accuracy: 0.7754, Validation Accuracy: 0.7635, Loss: 0.1882
Epoch  45 Batch  370/1077 - Train Accuracy: 0.7965, Validation Accuracy: 0.7660, Loss: 0.1960
Epoch  45 Batch  380/1077 - Train Accuracy: 0.7723, Validation Accuracy: 0.7550, Loss: 0.1867
Epoch  45 Batch  390/1077 - Train Accuracy: 0.7543, Validation Accuracy: 0.7525, Loss: 0.2225
Epoch  45 Batch  400/1077 - Train Accuracy: 0.7941, Validation Accuracy: 0.7496, Loss: 0.1983
Epoch  45 Batch  410/1077 - Train Accuracy: 0.7656, Validation Accuracy: 0.7614, Loss: 0.2078
Epoch  45 Batch  420/1077 - Train Accuracy: 0.8055, Validation Accuracy: 0.7642, Loss: 0.1836
Epoch  45 Batch  430/1077 - Train Accuracy: 0.7473, Validation Accuracy: 0.7596, Loss: 0.1947
Epoch  45 Batch  440/1077 - Train Accuracy: 0.7551, Validation Accuracy: 0.7603, Loss: 0.2176
Epoch  45 Batch  450/1077 - Train Accuracy: 0.8125, Validation Accuracy: 0.7582, Loss: 0.1979
Epoch  45 Batch  460/1077 - Train Accuracy: 0.7520, Validation Accuracy: 0.7536, Loss: 0.2090
Epoch  45 Batch  470/1077 - Train Accuracy: 0.7726, Validation Accuracy: 0.7543, Loss: 0.2017
Epoch  45 Batch  480/1077 - Train Accuracy: 0.7718, Validation Accuracy: 0.7472, Loss: 0.1990
Epoch  45 Batch  490/1077 - Train Accuracy: 0.7539, Validation Accuracy: 0.7511, Loss: 0.2058
Epoch  45 Batch  500/1077 - Train Accuracy: 0.8180, Validation Accuracy: 0.7496, Loss: 0.1968
Epoch  45 Batch  510/1077 - Train Accuracy: 0.7914, Validation Accuracy: 0.7592, Loss: 0.1882
Epoch  45 Batch  520/1077 - Train Accuracy: 0.8456, Validation Accuracy: 0.7567, Loss: 0.1814
Epoch  45 Batch  530/1077 - Train Accuracy: 0.7484, Validation Accuracy: 0.7628, Loss: 0.2106
Epoch  45 Batch  540/1077 - Train Accuracy: 0.8035, Validation Accuracy: 0.7628, Loss: 0.1908
Epoch  45 Batch  550/1077 - Train Accuracy: 0.7492, Validation Accuracy: 0.7539, Loss: 0.2011
Epoch  45 Batch  560/1077 - Train Accuracy: 0.7766, Validation Accuracy: 0.7539, Loss: 0.1974
Epoch  45 Batch  570/1077 - Train Accuracy: 0.7722, Validation Accuracy: 0.7525, Loss: 0.2220
Epoch  45 Batch  580/1077 - Train Accuracy: 0.8002, Validation Accuracy: 0.7514, Loss: 0.1881
Epoch  45 Batch  590/1077 - Train Accuracy: 0.7508, Validation Accuracy: 0.7585, Loss: 0.2191
Epoch  45 Batch  600/1077 - Train Accuracy: 0.7943, Validation Accuracy: 0.7560, Loss: 0.2022
Epoch  45 Batch  610/1077 - Train Accuracy: 0.7685, Validation Accuracy: 0.7578, Loss: 0.2148
Epoch  45 Batch  620/1077 - Train Accuracy: 0.7652, Validation Accuracy: 0.7482, Loss: 0.1890
Epoch  45 Batch  630/1077 - Train Accuracy: 0.7543, Validation Accuracy: 0.7614, Loss: 0.1854
Epoch  45 Batch  640/1077 - Train Accuracy: 0.7805, Validation Accuracy: 0.7681, Loss: 0.2004
Epoch  45 Batch  650/1077 - Train Accuracy: 0.7578, Validation Accuracy: 0.7759, Loss: 0.1990
Epoch  45 Batch  660/1077 - Train Accuracy: 0.7859, Validation Accuracy: 0.7656, Loss: 0.2049
Epoch  45 Batch  670/1077 - Train Accuracy: 0.7944, Validation Accuracy: 0.7500, Loss: 0.2024
Epoch  45 Batch  680/1077 - Train Accuracy: 0.7645, Validation Accuracy: 0.7571, Loss: 0.2173
Epoch  45 Batch  690/1077 - Train Accuracy: 0.7812, Validation Accuracy: 0.7536, Loss: 0.2119
Epoch  45 Batch  700/1077 - Train Accuracy: 0.7840, Validation Accuracy: 0.7539, Loss: 0.1936
Epoch  45 Batch  710/1077 - Train Accuracy: 0.7270, Validation Accuracy: 0.7592, Loss: 0.1885
Epoch  45 Batch  720/1077 - Train Accuracy: 0.7710, Validation Accuracy: 0.7567, Loss: 0.2087
Epoch  45 Batch  730/1077 - Train Accuracy: 0.7695, Validation Accuracy: 0.7706, Loss: 0.1948
Epoch  45 Batch  740/1077 - Train Accuracy: 0.7809, Validation Accuracy: 0.7507, Loss: 0.1921
Epoch  45 Batch  750/1077 - Train Accuracy: 0.7664, Validation Accuracy: 0.7610, Loss: 0.2039
Epoch  45 Batch  760/1077 - Train Accuracy: 0.7773, Validation Accuracy: 0.7717, Loss: 0.2053
Epoch  45 Batch  770/1077 - Train Accuracy: 0.7961, Validation Accuracy: 0.7646, Loss: 0.1790
Epoch  45 Batch  780/1077 - Train Accuracy: 0.7617, Validation Accuracy: 0.7528, Loss: 0.2105
Epoch  45 Batch  790/1077 - Train Accuracy: 0.7109, Validation Accuracy: 0.7571, Loss: 0.2256
Epoch  45 Batch  800/1077 - Train Accuracy: 0.7668, Validation Accuracy: 0.7553, Loss: 0.2015
Epoch  45 Batch  810/1077 - Train Accuracy: 0.7705, Validation Accuracy: 0.7578, Loss: 0.2100
Epoch  45 Batch  820/1077 - Train Accuracy: 0.7289, Validation Accuracy: 0.7550, Loss: 0.2310
Epoch  45 Batch  830/1077 - Train Accuracy: 0.7457, Validation Accuracy: 0.7596, Loss: 0.2186
Epoch  45 Batch  840/1077 - Train Accuracy: 0.7879, Validation Accuracy: 0.7592, Loss: 0.1954
Epoch  45 Batch  850/1077 - Train Accuracy: 0.7467, Validation Accuracy: 0.7571, Loss: 0.2197
Epoch  45 Batch  860/1077 - Train Accuracy: 0.7537, Validation Accuracy: 0.7496, Loss: 0.2053
Epoch  45 Batch  870/1077 - Train Accuracy: 0.7660, Validation Accuracy: 0.7582, Loss: 0.2038
Epoch  45 Batch  880/1077 - Train Accuracy: 0.8113, Validation Accuracy: 0.7457, Loss: 0.1991
Epoch  45 Batch  890/1077 - Train Accuracy: 0.8300, Validation Accuracy: 0.7422, Loss: 0.1868
Epoch  45 Batch  900/1077 - Train Accuracy: 0.8082, Validation Accuracy: 0.7596, Loss: 0.1958
Epoch  45 Batch  910/1077 - Train Accuracy: 0.8114, Validation Accuracy: 0.7599, Loss: 0.2194
Epoch  45 Batch  920/1077 - Train Accuracy: 0.7918, Validation Accuracy: 0.7603, Loss: 0.1986
Epoch  45 Batch  930/1077 - Train Accuracy: 0.7910, Validation Accuracy: 0.7582, Loss: 0.1916
Epoch  45 Batch  940/1077 - Train Accuracy: 0.7914, Validation Accuracy: 0.7631, Loss: 0.1924
Epoch  45 Batch  950/1077 - Train Accuracy: 0.7824, Validation Accuracy: 0.7702, Loss: 0.1858
Epoch  45 Batch  960/1077 - Train Accuracy: 0.7719, Validation Accuracy: 0.7702, Loss: 0.2072
Epoch  45 Batch  970/1077 - Train Accuracy: 0.7891, Validation Accuracy: 0.7589, Loss: 0.2045
Epoch  45 Batch  980/1077 - Train Accuracy: 0.7484, Validation Accuracy: 0.7649, Loss: 0.2042
Epoch  45 Batch  990/1077 - Train Accuracy: 0.7599, Validation Accuracy: 0.7642, Loss: 0.2130
Epoch  45 Batch 1000/1077 - Train Accuracy: 0.8036, Validation Accuracy: 0.7631, Loss: 0.1910
Epoch  45 Batch 1010/1077 - Train Accuracy: 0.7859, Validation Accuracy: 0.7511, Loss: 0.1972
Epoch  45 Batch 1020/1077 - Train Accuracy: 0.7695, Validation Accuracy: 0.7607, Loss: 0.2056
Epoch  45 Batch 1030/1077 - Train Accuracy: 0.7586, Validation Accuracy: 0.7567, Loss: 0.2099
Epoch  45 Batch 1040/1077 - Train Accuracy: 0.7956, Validation Accuracy: 0.7635, Loss: 0.2046
Epoch  45 Batch 1050/1077 - Train Accuracy: 0.7395, Validation Accuracy: 0.7596, Loss: 0.1924
Epoch  45 Batch 1060/1077 - Train Accuracy: 0.8043, Validation Accuracy: 0.7557, Loss: 0.1785
Epoch  45 Batch 1070/1077 - Train Accuracy: 0.7484, Validation Accuracy: 0.7592, Loss: 0.2083
Epoch  46 Batch   10/1077 - Train Accuracy: 0.7899, Validation Accuracy: 0.7614, Loss: 0.2018
Epoch  46 Batch   20/1077 - Train Accuracy: 0.7680, Validation Accuracy: 0.7546, Loss: 0.1870
Epoch  46 Batch   30/1077 - Train Accuracy: 0.8094, Validation Accuracy: 0.7592, Loss: 0.1997
Epoch  46 Batch   40/1077 - Train Accuracy: 0.8168, Validation Accuracy: 0.7628, Loss: 0.1998
Epoch  46 Batch   50/1077 - Train Accuracy: 0.7539, Validation Accuracy: 0.7724, Loss: 0.1833
Epoch  46 Batch   60/1077 - Train Accuracy: 0.7920, Validation Accuracy: 0.7710, Loss: 0.1835
Epoch  46 Batch   70/1077 - Train Accuracy: 0.8039, Validation Accuracy: 0.7507, Loss: 0.1919
Epoch  46 Batch   80/1077 - Train Accuracy: 0.7773, Validation Accuracy: 0.7525, Loss: 0.2048
Epoch  46 Batch   90/1077 - Train Accuracy: 0.7516, Validation Accuracy: 0.7592, Loss: 0.2008
Epoch  46 Batch  100/1077 - Train Accuracy: 0.7566, Validation Accuracy: 0.7649, Loss: 0.1990
Epoch  46 Batch  110/1077 - Train Accuracy: 0.7840, Validation Accuracy: 0.7734, Loss: 0.1758
Epoch  46 Batch  120/1077 - Train Accuracy: 0.8074, Validation Accuracy: 0.7646, Loss: 0.2095
Epoch  46 Batch  130/1077 - Train Accuracy: 0.7474, Validation Accuracy: 0.7685, Loss: 0.1964
Epoch  46 Batch  140/1077 - Train Accuracy: 0.7734, Validation Accuracy: 0.7617, Loss: 0.2119
Epoch  46 Batch  150/1077 - Train Accuracy: 0.8136, Validation Accuracy: 0.7628, Loss: 0.2041
Epoch  46 Batch  160/1077 - Train Accuracy: 0.7777, Validation Accuracy: 0.7631, Loss: 0.1933
Epoch  46 Batch  170/1077 - Train Accuracy: 0.7363, Validation Accuracy: 0.7638, Loss: 0.2052
Epoch  46 Batch  180/1077 - Train Accuracy: 0.7961, Validation Accuracy: 0.7635, Loss: 0.1838
Epoch  46 Batch  190/1077 - Train Accuracy: 0.8344, Validation Accuracy: 0.7575, Loss: 0.1958
Epoch  46 Batch  200/1077 - Train Accuracy: 0.7688, Validation Accuracy: 0.7578, Loss: 0.1969
Epoch  46 Batch  210/1077 - Train Accuracy: 0.7924, Validation Accuracy: 0.7528, Loss: 0.2039
Epoch  46 Batch  220/1077 - Train Accuracy: 0.7808, Validation Accuracy: 0.7550, Loss: 0.2085
Epoch  46 Batch  230/1077 - Train Accuracy: 0.7798, Validation Accuracy: 0.7575, Loss: 0.1873
Epoch  46 Batch  240/1077 - Train Accuracy: 0.8324, Validation Accuracy: 0.7617, Loss: 0.1851
Epoch  46 Batch  250/1077 - Train Accuracy: 0.7777, Validation Accuracy: 0.7536, Loss: 0.1954
Epoch  46 Batch  260/1077 - Train Accuracy: 0.8125, Validation Accuracy: 0.7557, Loss: 0.1906
Epoch  46 Batch  270/1077 - Train Accuracy: 0.7664, Validation Accuracy: 0.7614, Loss: 0.2140
Epoch  46 Batch  280/1077 - Train Accuracy: 0.7840, Validation Accuracy: 0.7536, Loss: 0.2172
Epoch  46 Batch  290/1077 - Train Accuracy: 0.7926, Validation Accuracy: 0.7649, Loss: 0.2116
Epoch  46 Batch  300/1077 - Train Accuracy: 0.7808, Validation Accuracy: 0.7649, Loss: 0.1896
Epoch  46 Batch  310/1077 - Train Accuracy: 0.7578, Validation Accuracy: 0.7614, Loss: 0.2075
Epoch  46 Batch  320/1077 - Train Accuracy: 0.8164, Validation Accuracy: 0.7553, Loss: 0.2329
Epoch  46 Batch  330/1077 - Train Accuracy: 0.7918, Validation Accuracy: 0.7575, Loss: 0.1864
Epoch  46 Batch  340/1077 - Train Accuracy: 0.7673, Validation Accuracy: 0.7756, Loss: 0.1932
Epoch  46 Batch  350/1077 - Train Accuracy: 0.7574, Validation Accuracy: 0.7731, Loss: 0.1968
Epoch  46 Batch  360/1077 - Train Accuracy: 0.7715, Validation Accuracy: 0.7596, Loss: 0.2000
Epoch  46 Batch  370/1077 - Train Accuracy: 0.7902, Validation Accuracy: 0.7578, Loss: 0.1979
Epoch  46 Batch  380/1077 - Train Accuracy: 0.7688, Validation Accuracy: 0.7599, Loss: 0.1942
Epoch  46 Batch  390/1077 - Train Accuracy: 0.7504, Validation Accuracy: 0.7482, Loss: 0.2218
Epoch  46 Batch  400/1077 - Train Accuracy: 0.7930, Validation Accuracy: 0.7571, Loss: 0.1995
Epoch  46 Batch  410/1077 - Train Accuracy: 0.7726, Validation Accuracy: 0.7599, Loss: 0.2192
Epoch  46 Batch  420/1077 - Train Accuracy: 0.8012, Validation Accuracy: 0.7493, Loss: 0.1917
Epoch  46 Batch  430/1077 - Train Accuracy: 0.7441, Validation Accuracy: 0.7532, Loss: 0.1916
Epoch  46 Batch  440/1077 - Train Accuracy: 0.7496, Validation Accuracy: 0.7578, Loss: 0.2033
Epoch  46 Batch  450/1077 - Train Accuracy: 0.8145, Validation Accuracy: 0.7628, Loss: 0.1895
Epoch  46 Batch  460/1077 - Train Accuracy: 0.7484, Validation Accuracy: 0.7557, Loss: 0.2001
Epoch  46 Batch  470/1077 - Train Accuracy: 0.8076, Validation Accuracy: 0.7528, Loss: 0.1963
Epoch  46 Batch  480/1077 - Train Accuracy: 0.7759, Validation Accuracy: 0.7525, Loss: 0.2037
Epoch  46 Batch  490/1077 - Train Accuracy: 0.7621, Validation Accuracy: 0.7674, Loss: 0.1955
Epoch  46 Batch  500/1077 - Train Accuracy: 0.8137, Validation Accuracy: 0.7724, Loss: 0.1920
Epoch  46 Batch  510/1077 - Train Accuracy: 0.8027, Validation Accuracy: 0.7656, Loss: 0.1920
Epoch  46 Batch  520/1077 - Train Accuracy: 0.8434, Validation Accuracy: 0.7589, Loss: 0.1686
Epoch  46 Batch  530/1077 - Train Accuracy: 0.7531, Validation Accuracy: 0.7571, Loss: 0.2129
Epoch  46 Batch  540/1077 - Train Accuracy: 0.8070, Validation Accuracy: 0.7624, Loss: 0.1961
Epoch  46 Batch  550/1077 - Train Accuracy: 0.7441, Validation Accuracy: 0.7543, Loss: 0.2006
Epoch  46 Batch  560/1077 - Train Accuracy: 0.7918, Validation Accuracy: 0.7631, Loss: 0.1903
Epoch  46 Batch  570/1077 - Train Accuracy: 0.7734, Validation Accuracy: 0.7596, Loss: 0.2030
Epoch  46 Batch  580/1077 - Train Accuracy: 0.8013, Validation Accuracy: 0.7575, Loss: 0.1710
Epoch  46 Batch  590/1077 - Train Accuracy: 0.7603, Validation Accuracy: 0.7638, Loss: 0.2191
Epoch  46 Batch  600/1077 - Train Accuracy: 0.8047, Validation Accuracy: 0.7500, Loss: 0.1910
Epoch  46 Batch  610/1077 - Train Accuracy: 0.7644, Validation Accuracy: 0.7525, Loss: 0.2072
Epoch  46 Batch  620/1077 - Train Accuracy: 0.7836, Validation Accuracy: 0.7578, Loss: 0.1787
Epoch  46 Batch  630/1077 - Train Accuracy: 0.7602, Validation Accuracy: 0.7631, Loss: 0.1886
Epoch  46 Batch  640/1077 - Train Accuracy: 0.7928, Validation Accuracy: 0.7717, Loss: 0.1925
Epoch  46 Batch  650/1077 - Train Accuracy: 0.7547, Validation Accuracy: 0.7621, Loss: 0.2016
Epoch  46 Batch  660/1077 - Train Accuracy: 0.7965, Validation Accuracy: 0.7685, Loss: 0.1986
Epoch  46 Batch  670/1077 - Train Accuracy: 0.7915, Validation Accuracy: 0.7663, Loss: 0.1856
Epoch  46 Batch  680/1077 - Train Accuracy: 0.7526, Validation Accuracy: 0.7628, Loss: 0.2007
Epoch  46 Batch  690/1077 - Train Accuracy: 0.7887, Validation Accuracy: 0.7653, Loss: 0.2012
Epoch  46 Batch  700/1077 - Train Accuracy: 0.7883, Validation Accuracy: 0.7546, Loss: 0.1843
Epoch  46 Batch  710/1077 - Train Accuracy: 0.7449, Validation Accuracy: 0.7649, Loss: 0.1914
Epoch  46 Batch  720/1077 - Train Accuracy: 0.7796, Validation Accuracy: 0.7553, Loss: 0.2048
Epoch  46 Batch  730/1077 - Train Accuracy: 0.7559, Validation Accuracy: 0.7756, Loss: 0.2106
Epoch  46 Batch  740/1077 - Train Accuracy: 0.7781, Validation Accuracy: 0.7749, Loss: 0.1889
Epoch  46 Batch  750/1077 - Train Accuracy: 0.7789, Validation Accuracy: 0.7820, Loss: 0.1968
Epoch  46 Batch  760/1077 - Train Accuracy: 0.7730, Validation Accuracy: 0.7749, Loss: 0.2149
Epoch  46 Batch  770/1077 - Train Accuracy: 0.7786, Validation Accuracy: 0.7617, Loss: 0.1829
Epoch  46 Batch  780/1077 - Train Accuracy: 0.7688, Validation Accuracy: 0.7472, Loss: 0.2252
Epoch  46 Batch  790/1077 - Train Accuracy: 0.7023, Validation Accuracy: 0.7656, Loss: 0.2232
Epoch  46 Batch  800/1077 - Train Accuracy: 0.7766, Validation Accuracy: 0.7663, Loss: 0.1931
Epoch  46 Batch  810/1077 - Train Accuracy: 0.7727, Validation Accuracy: 0.7507, Loss: 0.1757
Epoch  46 Batch  820/1077 - Train Accuracy: 0.7500, Validation Accuracy: 0.7646, Loss: 0.2132
Epoch  46 Batch  830/1077 - Train Accuracy: 0.7434, Validation Accuracy: 0.7578, Loss: 0.1973
Epoch  46 Batch  840/1077 - Train Accuracy: 0.7961, Validation Accuracy: 0.7578, Loss: 0.1944
Epoch  46 Batch  850/1077 - Train Accuracy: 0.7511, Validation Accuracy: 0.7724, Loss: 0.2129
Epoch  46 Batch  860/1077 - Train Accuracy: 0.7649, Validation Accuracy: 0.7635, Loss: 0.2027
Epoch  46 Batch  870/1077 - Train Accuracy: 0.7603, Validation Accuracy: 0.7617, Loss: 0.1968
Epoch  46 Batch  880/1077 - Train Accuracy: 0.8086, Validation Accuracy: 0.7635, Loss: 0.1880
Epoch  46 Batch  890/1077 - Train Accuracy: 0.8214, Validation Accuracy: 0.7571, Loss: 0.1763
Epoch  46 Batch  900/1077 - Train Accuracy: 0.8105, Validation Accuracy: 0.7464, Loss: 0.2046
Epoch  46 Batch  910/1077 - Train Accuracy: 0.8077, Validation Accuracy: 0.7635, Loss: 0.1980
Epoch  46 Batch  920/1077 - Train Accuracy: 0.7926, Validation Accuracy: 0.7560, Loss: 0.2043
Epoch  46 Batch  930/1077 - Train Accuracy: 0.7867, Validation Accuracy: 0.7443, Loss: 0.1840
Epoch  46 Batch  940/1077 - Train Accuracy: 0.7895, Validation Accuracy: 0.7511, Loss: 0.1933
Epoch  46 Batch  950/1077 - Train Accuracy: 0.7835, Validation Accuracy: 0.7575, Loss: 0.1855
Epoch  46 Batch  960/1077 - Train Accuracy: 0.7727, Validation Accuracy: 0.7603, Loss: 0.1931
Epoch  46 Batch  970/1077 - Train Accuracy: 0.7988, Validation Accuracy: 0.7713, Loss: 0.2171
Epoch  46 Batch  980/1077 - Train Accuracy: 0.7473, Validation Accuracy: 0.7752, Loss: 0.2099
Epoch  46 Batch  990/1077 - Train Accuracy: 0.7784, Validation Accuracy: 0.7834, Loss: 0.2149
Epoch  46 Batch 1000/1077 - Train Accuracy: 0.8088, Validation Accuracy: 0.7599, Loss: 0.1791
Epoch  46 Batch 1010/1077 - Train Accuracy: 0.7879, Validation Accuracy: 0.7603, Loss: 0.1890
Epoch  46 Batch 1020/1077 - Train Accuracy: 0.7770, Validation Accuracy: 0.7667, Loss: 0.1836
Epoch  46 Batch 1030/1077 - Train Accuracy: 0.7559, Validation Accuracy: 0.7663, Loss: 0.2000
Epoch  46 Batch 1040/1077 - Train Accuracy: 0.8014, Validation Accuracy: 0.7663, Loss: 0.2050
Epoch  46 Batch 1050/1077 - Train Accuracy: 0.7180, Validation Accuracy: 0.7532, Loss: 0.1924
Epoch  46 Batch 1060/1077 - Train Accuracy: 0.8129, Validation Accuracy: 0.7646, Loss: 0.1678
Epoch  46 Batch 1070/1077 - Train Accuracy: 0.7453, Validation Accuracy: 0.7514, Loss: 0.1992
Epoch  47 Batch   10/1077 - Train Accuracy: 0.7952, Validation Accuracy: 0.7525, Loss: 0.2049
Epoch  47 Batch   20/1077 - Train Accuracy: 0.7746, Validation Accuracy: 0.7610, Loss: 0.1748
Epoch  47 Batch   30/1077 - Train Accuracy: 0.8039, Validation Accuracy: 0.7678, Loss: 0.1903
Epoch  47 Batch   40/1077 - Train Accuracy: 0.8191, Validation Accuracy: 0.7660, Loss: 0.1925
Epoch  47 Batch   50/1077 - Train Accuracy: 0.7535, Validation Accuracy: 0.7628, Loss: 0.2067
Epoch  47 Batch   60/1077 - Train Accuracy: 0.7801, Validation Accuracy: 0.7596, Loss: 0.1780
Epoch  47 Batch   70/1077 - Train Accuracy: 0.8240, Validation Accuracy: 0.7546, Loss: 0.1990
Epoch  47 Batch   80/1077 - Train Accuracy: 0.7770, Validation Accuracy: 0.7663, Loss: 0.2001
Epoch  47 Batch   90/1077 - Train Accuracy: 0.7422, Validation Accuracy: 0.7621, Loss: 0.2149
Epoch  47 Batch  100/1077 - Train Accuracy: 0.7547, Validation Accuracy: 0.7681, Loss: 0.2095
Epoch  47 Batch  110/1077 - Train Accuracy: 0.7859, Validation Accuracy: 0.7749, Loss: 0.1809
Epoch  47 Batch  120/1077 - Train Accuracy: 0.8152, Validation Accuracy: 0.7670, Loss: 0.1916
Epoch  47 Batch  130/1077 - Train Accuracy: 0.7541, Validation Accuracy: 0.7674, Loss: 0.1992
Epoch  47 Batch  140/1077 - Train Accuracy: 0.7882, Validation Accuracy: 0.7621, Loss: 0.2038
Epoch  47 Batch  150/1077 - Train Accuracy: 0.8028, Validation Accuracy: 0.7642, Loss: 0.1915
Epoch  47 Batch  160/1077 - Train Accuracy: 0.7723, Validation Accuracy: 0.7475, Loss: 0.1880
Epoch  47 Batch  170/1077 - Train Accuracy: 0.7309, Validation Accuracy: 0.7649, Loss: 0.2001
Epoch  47 Batch  180/1077 - Train Accuracy: 0.7984, Validation Accuracy: 0.7596, Loss: 0.1831
Epoch  47 Batch  190/1077 - Train Accuracy: 0.8395, Validation Accuracy: 0.7681, Loss: 0.1969
Epoch  47 Batch  200/1077 - Train Accuracy: 0.7676, Validation Accuracy: 0.7631, Loss: 0.2130
Epoch  47 Batch  210/1077 - Train Accuracy: 0.8010, Validation Accuracy: 0.7678, Loss: 0.2022
Epoch  47 Batch  220/1077 - Train Accuracy: 0.7956, Validation Accuracy: 0.7603, Loss: 0.2306
Epoch  47 Batch  230/1077 - Train Accuracy: 0.7786, Validation Accuracy: 0.7610, Loss: 0.1909
Epoch  47 Batch  240/1077 - Train Accuracy: 0.8254, Validation Accuracy: 0.7500, Loss: 0.1996
Epoch  47 Batch  250/1077 - Train Accuracy: 0.7848, Validation Accuracy: 0.7614, Loss: 0.1891
Epoch  47 Batch  260/1077 - Train Accuracy: 0.8214, Validation Accuracy: 0.7539, Loss: 0.1736
Epoch  47 Batch  270/1077 - Train Accuracy: 0.7688, Validation Accuracy: 0.7692, Loss: 0.2101
Epoch  47 Batch  280/1077 - Train Accuracy: 0.7840, Validation Accuracy: 0.7596, Loss: 0.1914
Epoch  47 Batch  290/1077 - Train Accuracy: 0.7887, Validation Accuracy: 0.7582, Loss: 0.2089
Epoch  47 Batch  300/1077 - Train Accuracy: 0.7788, Validation Accuracy: 0.7567, Loss: 0.1823
Epoch  47 Batch  310/1077 - Train Accuracy: 0.7559, Validation Accuracy: 0.7710, Loss: 0.1958
Epoch  47 Batch  320/1077 - Train Accuracy: 0.8133, Validation Accuracy: 0.7628, Loss: 0.2266
Epoch  47 Batch  330/1077 - Train Accuracy: 0.7922, Validation Accuracy: 0.7589, Loss: 0.2035
Epoch  47 Batch  340/1077 - Train Accuracy: 0.7944, Validation Accuracy: 0.7678, Loss: 0.2032
Epoch  47 Batch  350/1077 - Train Accuracy: 0.7805, Validation Accuracy: 0.7734, Loss: 0.1868
Epoch  47 Batch  360/1077 - Train Accuracy: 0.7852, Validation Accuracy: 0.7667, Loss: 0.1723
Epoch  47 Batch  370/1077 - Train Accuracy: 0.7954, Validation Accuracy: 0.7695, Loss: 0.1909
Epoch  47 Batch  380/1077 - Train Accuracy: 0.7879, Validation Accuracy: 0.7500, Loss: 0.1773
Epoch  47 Batch  390/1077 - Train Accuracy: 0.7508, Validation Accuracy: 0.7621, Loss: 0.2143
Epoch  47 Batch  400/1077 - Train Accuracy: 0.7984, Validation Accuracy: 0.7511, Loss: 0.2083
Epoch  47 Batch  410/1077 - Train Accuracy: 0.7747, Validation Accuracy: 0.7582, Loss: 0.2062
Epoch  47 Batch  420/1077 - Train Accuracy: 0.8023, Validation Accuracy: 0.7589, Loss: 0.1783
Epoch  47 Batch  430/1077 - Train Accuracy: 0.7418, Validation Accuracy: 0.7660, Loss: 0.1816
Epoch  47 Batch  440/1077 - Train Accuracy: 0.7430, Validation Accuracy: 0.7695, Loss: 0.2132
Epoch  47 Batch  450/1077 - Train Accuracy: 0.8117, Validation Accuracy: 0.7528, Loss: 0.1862
Epoch  47 Batch  460/1077 - Train Accuracy: 0.7402, Validation Accuracy: 0.7585, Loss: 0.2048
Epoch  47 Batch  470/1077 - Train Accuracy: 0.7936, Validation Accuracy: 0.7472, Loss: 0.2119
Epoch  47 Batch  480/1077 - Train Accuracy: 0.7833, Validation Accuracy: 0.7649, Loss: 0.2090
Epoch  47 Batch  490/1077 - Train Accuracy: 0.7629, Validation Accuracy: 0.7610, Loss: 0.1995
Epoch  47 Batch  500/1077 - Train Accuracy: 0.8219, Validation Accuracy: 0.7631, Loss: 0.1852
Epoch  47 Batch  510/1077 - Train Accuracy: 0.8031, Validation Accuracy: 0.7550, Loss: 0.1948
Epoch  47 Batch  520/1077 - Train Accuracy: 0.8631, Validation Accuracy: 0.7521, Loss: 0.1670
Epoch  47 Batch  530/1077 - Train Accuracy: 0.7500, Validation Accuracy: 0.7628, Loss: 0.2095
Epoch  47 Batch  540/1077 - Train Accuracy: 0.7914, Validation Accuracy: 0.7585, Loss: 0.1928
Epoch  47 Batch  550/1077 - Train Accuracy: 0.7578, Validation Accuracy: 0.7681, Loss: 0.2073
Epoch  47 Batch  560/1077 - Train Accuracy: 0.7734, Validation Accuracy: 0.7582, Loss: 0.1909
Epoch  47 Batch  570/1077 - Train Accuracy: 0.7812, Validation Accuracy: 0.7564, Loss: 0.2144
Epoch  47 Batch  580/1077 - Train Accuracy: 0.7935, Validation Accuracy: 0.7599, Loss: 0.1735
Epoch  47 Batch  590/1077 - Train Accuracy: 0.7537, Validation Accuracy: 0.7621, Loss: 0.2097
Epoch  47 Batch  600/1077 - Train Accuracy: 0.7999, Validation Accuracy: 0.7642, Loss: 0.1860
Epoch  47 Batch  610/1077 - Train Accuracy: 0.7784, Validation Accuracy: 0.7500, Loss: 0.2056
Epoch  47 Batch  620/1077 - Train Accuracy: 0.7852, Validation Accuracy: 0.7692, Loss: 0.1792
Epoch  47 Batch  630/1077 - Train Accuracy: 0.7664, Validation Accuracy: 0.7759, Loss: 0.1965
Epoch  47 Batch  640/1077 - Train Accuracy: 0.7824, Validation Accuracy: 0.7887, Loss: 0.1821
Epoch  47 Batch  650/1077 - Train Accuracy: 0.7555, Validation Accuracy: 0.7734, Loss: 0.1965
Epoch  47 Batch  660/1077 - Train Accuracy: 0.7906, Validation Accuracy: 0.7798, Loss: 0.2046
Epoch  47 Batch  670/1077 - Train Accuracy: 0.7788, Validation Accuracy: 0.7770, Loss: 0.2223
Epoch  47 Batch  680/1077 - Train Accuracy: 0.7693, Validation Accuracy: 0.7663, Loss: 0.2118
Epoch  47 Batch  690/1077 - Train Accuracy: 0.7895, Validation Accuracy: 0.7638, Loss: 0.1970
Epoch  47 Batch  700/1077 - Train Accuracy: 0.7945, Validation Accuracy: 0.7511, Loss: 0.1816
Epoch  47 Batch  710/1077 - Train Accuracy: 0.7449, Validation Accuracy: 0.7543, Loss: 0.2041
Epoch  47 Batch  720/1077 - Train Accuracy: 0.7771, Validation Accuracy: 0.7610, Loss: 0.2023
Epoch  47 Batch  730/1077 - Train Accuracy: 0.7613, Validation Accuracy: 0.7710, Loss: 0.1896
Epoch  47 Batch  740/1077 - Train Accuracy: 0.7785, Validation Accuracy: 0.7628, Loss: 0.1877
Epoch  47 Batch  750/1077 - Train Accuracy: 0.7957, Validation Accuracy: 0.7614, Loss: 0.1871
Epoch  47 Batch  760/1077 - Train Accuracy: 0.7727, Validation Accuracy: 0.7603, Loss: 0.2022
Epoch  47 Batch  770/1077 - Train Accuracy: 0.7928, Validation Accuracy: 0.7681, Loss: 0.1803
Epoch  47 Batch  780/1077 - Train Accuracy: 0.7672, Validation Accuracy: 0.7624, Loss: 0.2122
Epoch  47 Batch  790/1077 - Train Accuracy: 0.7117, Validation Accuracy: 0.7575, Loss: 0.2098
Epoch  47 Batch  800/1077 - Train Accuracy: 0.7855, Validation Accuracy: 0.7596, Loss: 0.2031
Epoch  47 Batch  810/1077 - Train Accuracy: 0.7768, Validation Accuracy: 0.7653, Loss: 0.1843
Epoch  47 Batch  820/1077 - Train Accuracy: 0.7508, Validation Accuracy: 0.7653, Loss: 0.2089
Epoch  47 Batch  830/1077 - Train Accuracy: 0.7652, Validation Accuracy: 0.7781, Loss: 0.2038
Epoch  47 Batch  840/1077 - Train Accuracy: 0.7918, Validation Accuracy: 0.7724, Loss: 0.2044
Epoch  47 Batch  850/1077 - Train Accuracy: 0.7533, Validation Accuracy: 0.7770, Loss: 0.2154
Epoch  47 Batch  860/1077 - Train Accuracy: 0.7589, Validation Accuracy: 0.7756, Loss: 0.2130
Epoch  47 Batch  870/1077 - Train Accuracy: 0.7627, Validation Accuracy: 0.7702, Loss: 0.1958
Epoch  47 Batch  880/1077 - Train Accuracy: 0.8121, Validation Accuracy: 0.7621, Loss: 0.1924
Epoch  47 Batch  890/1077 - Train Accuracy: 0.8322, Validation Accuracy: 0.7617, Loss: 0.1919
Epoch  47 Batch  900/1077 - Train Accuracy: 0.8051, Validation Accuracy: 0.7674, Loss: 0.1975
Epoch  47 Batch  910/1077 - Train Accuracy: 0.8084, Validation Accuracy: 0.7717, Loss: 0.1951
Epoch  47 Batch  920/1077 - Train Accuracy: 0.8180, Validation Accuracy: 0.7713, Loss: 0.1856
Epoch  47 Batch  930/1077 - Train Accuracy: 0.7887, Validation Accuracy: 0.7475, Loss: 0.1926
Epoch  47 Batch  940/1077 - Train Accuracy: 0.7902, Validation Accuracy: 0.7646, Loss: 0.1847
Epoch  47 Batch  950/1077 - Train Accuracy: 0.7928, Validation Accuracy: 0.7720, Loss: 0.1977
Epoch  47 Batch  960/1077 - Train Accuracy: 0.7775, Validation Accuracy: 0.7656, Loss: 0.2009
Epoch  47 Batch  970/1077 - Train Accuracy: 0.7918, Validation Accuracy: 0.7536, Loss: 0.2010
Epoch  47 Batch  980/1077 - Train Accuracy: 0.7461, Validation Accuracy: 0.7674, Loss: 0.2173
Epoch  47 Batch  990/1077 - Train Accuracy: 0.7743, Validation Accuracy: 0.7756, Loss: 0.2217
Epoch  47 Batch 1000/1077 - Train Accuracy: 0.8013, Validation Accuracy: 0.7578, Loss: 0.1860
Epoch  47 Batch 1010/1077 - Train Accuracy: 0.7723, Validation Accuracy: 0.7656, Loss: 0.1977
Epoch  47 Batch 1020/1077 - Train Accuracy: 0.7762, Validation Accuracy: 0.7628, Loss: 0.1859
Epoch  47 Batch 1030/1077 - Train Accuracy: 0.7543, Validation Accuracy: 0.7518, Loss: 0.2094
Epoch  47 Batch 1040/1077 - Train Accuracy: 0.8043, Validation Accuracy: 0.7511, Loss: 0.1910
Epoch  47 Batch 1050/1077 - Train Accuracy: 0.7488, Validation Accuracy: 0.7695, Loss: 0.1957
Epoch  47 Batch 1060/1077 - Train Accuracy: 0.8137, Validation Accuracy: 0.7436, Loss: 0.1731
Epoch  47 Batch 1070/1077 - Train Accuracy: 0.7609, Validation Accuracy: 0.7557, Loss: 0.1971
Epoch  48 Batch   10/1077 - Train Accuracy: 0.7981, Validation Accuracy: 0.7621, Loss: 0.2086
Epoch  48 Batch   20/1077 - Train Accuracy: 0.7812, Validation Accuracy: 0.7667, Loss: 0.1928
Epoch  48 Batch   30/1077 - Train Accuracy: 0.7980, Validation Accuracy: 0.7670, Loss: 0.1927
Epoch  48 Batch   40/1077 - Train Accuracy: 0.8184, Validation Accuracy: 0.7489, Loss: 0.1952
Epoch  48 Batch   50/1077 - Train Accuracy: 0.7680, Validation Accuracy: 0.7692, Loss: 0.1951
Epoch  48 Batch   60/1077 - Train Accuracy: 0.7902, Validation Accuracy: 0.7621, Loss: 0.1676
Epoch  48 Batch   70/1077 - Train Accuracy: 0.8125, Validation Accuracy: 0.7592, Loss: 0.1890
Epoch  48 Batch   80/1077 - Train Accuracy: 0.7742, Validation Accuracy: 0.7692, Loss: 0.1882
Epoch  48 Batch   90/1077 - Train Accuracy: 0.7484, Validation Accuracy: 0.7642, Loss: 0.2067
Epoch  48 Batch  100/1077 - Train Accuracy: 0.7648, Validation Accuracy: 0.7717, Loss: 0.1931
Epoch  48 Batch  110/1077 - Train Accuracy: 0.7820, Validation Accuracy: 0.7667, Loss: 0.1779
Epoch  48 Batch  120/1077 - Train Accuracy: 0.8090, Validation Accuracy: 0.7773, Loss: 0.2018
Epoch  48 Batch  130/1077 - Train Accuracy: 0.7485, Validation Accuracy: 0.7642, Loss: 0.2033
Epoch  48 Batch  140/1077 - Train Accuracy: 0.7956, Validation Accuracy: 0.7631, Loss: 0.1949
Epoch  48 Batch  150/1077 - Train Accuracy: 0.7839, Validation Accuracy: 0.7628, Loss: 0.1958
Epoch  48 Batch  160/1077 - Train Accuracy: 0.7754, Validation Accuracy: 0.7571, Loss: 0.1914
Epoch  48 Batch  170/1077 - Train Accuracy: 0.7582, Validation Accuracy: 0.7646, Loss: 0.2024
Epoch  48 Batch  180/1077 - Train Accuracy: 0.7828, Validation Accuracy: 0.7638, Loss: 0.1795
Epoch  48 Batch  190/1077 - Train Accuracy: 0.8430, Validation Accuracy: 0.7649, Loss: 0.1992
Epoch  48 Batch  200/1077 - Train Accuracy: 0.7734, Validation Accuracy: 0.7649, Loss: 0.1911
Epoch  48 Batch  210/1077 - Train Accuracy: 0.8065, Validation Accuracy: 0.7638, Loss: 0.1852
Epoch  48 Batch  220/1077 - Train Accuracy: 0.7887, Validation Accuracy: 0.7567, Loss: 0.2047
Epoch  48 Batch  230/1077 - Train Accuracy: 0.7768, Validation Accuracy: 0.7706, Loss: 0.1839
Epoch  48 Batch  240/1077 - Train Accuracy: 0.8305, Validation Accuracy: 0.7727, Loss: 0.1761
Epoch  48 Batch  250/1077 - Train Accuracy: 0.7798, Validation Accuracy: 0.7702, Loss: 0.1804
Epoch  48 Batch  260/1077 - Train Accuracy: 0.8196, Validation Accuracy: 0.7635, Loss: 0.1785
Epoch  48 Batch  270/1077 - Train Accuracy: 0.7715, Validation Accuracy: 0.7699, Loss: 0.2003
Epoch  48 Batch  280/1077 - Train Accuracy: 0.7941, Validation Accuracy: 0.7695, Loss: 0.2034
Epoch  48 Batch  290/1077 - Train Accuracy: 0.7734, Validation Accuracy: 0.7557, Loss: 0.2165
Epoch  48 Batch  300/1077 - Train Accuracy: 0.7887, Validation Accuracy: 0.7603, Loss: 0.1757
Epoch  48 Batch  310/1077 - Train Accuracy: 0.7469, Validation Accuracy: 0.7688, Loss: 0.2036
Epoch  48 Batch  320/1077 - Train Accuracy: 0.8219, Validation Accuracy: 0.7713, Loss: 0.2291
Epoch  48 Batch  330/1077 - Train Accuracy: 0.7965, Validation Accuracy: 0.7638, Loss: 0.1852
Epoch  48 Batch  340/1077 - Train Accuracy: 0.7874, Validation Accuracy: 0.7678, Loss: 0.1872
Epoch  48 Batch  350/1077 - Train Accuracy: 0.7871, Validation Accuracy: 0.7720, Loss: 0.1929
Epoch  48 Batch  360/1077 - Train Accuracy: 0.7762, Validation Accuracy: 0.7621, Loss: 0.1780
Epoch  48 Batch  370/1077 - Train Accuracy: 0.7980, Validation Accuracy: 0.7738, Loss: 0.1840
Epoch  48 Batch  380/1077 - Train Accuracy: 0.7766, Validation Accuracy: 0.7692, Loss: 0.1769
Epoch  48 Batch  390/1077 - Train Accuracy: 0.7570, Validation Accuracy: 0.7724, Loss: 0.2094
Epoch  48 Batch  400/1077 - Train Accuracy: 0.7922, Validation Accuracy: 0.7631, Loss: 0.1995
Epoch  48 Batch  410/1077 - Train Accuracy: 0.7792, Validation Accuracy: 0.7727, Loss: 0.2207
Epoch  48 Batch  420/1077 - Train Accuracy: 0.8066, Validation Accuracy: 0.7670, Loss: 0.1769
Epoch  48 Batch  430/1077 - Train Accuracy: 0.7605, Validation Accuracy: 0.7685, Loss: 0.1808
Epoch  48 Batch  440/1077 - Train Accuracy: 0.7578, Validation Accuracy: 0.7731, Loss: 0.2074
Epoch  48 Batch  450/1077 - Train Accuracy: 0.8059, Validation Accuracy: 0.7653, Loss: 0.2035
Epoch  48 Batch  460/1077 - Train Accuracy: 0.7527, Validation Accuracy: 0.7631, Loss: 0.2073
Epoch  48 Batch  470/1077 - Train Accuracy: 0.7915, Validation Accuracy: 0.7617, Loss: 0.1977
Epoch  48 Batch  480/1077 - Train Accuracy: 0.7751, Validation Accuracy: 0.7649, Loss: 0.2035
Epoch  48 Batch  490/1077 - Train Accuracy: 0.7562, Validation Accuracy: 0.7621, Loss: 0.1993
Epoch  48 Batch  500/1077 - Train Accuracy: 0.8164, Validation Accuracy: 0.7731, Loss: 0.1744
Epoch  48 Batch  510/1077 - Train Accuracy: 0.8023, Validation Accuracy: 0.7756, Loss: 0.2104
Epoch  48 Batch  520/1077 - Train Accuracy: 0.8527, Validation Accuracy: 0.7717, Loss: 0.1640
Epoch  48 Batch  530/1077 - Train Accuracy: 0.7621, Validation Accuracy: 0.7727, Loss: 0.1962
Epoch  48 Batch  540/1077 - Train Accuracy: 0.8051, Validation Accuracy: 0.7610, Loss: 0.1833
Epoch  48 Batch  550/1077 - Train Accuracy: 0.7555, Validation Accuracy: 0.7681, Loss: 0.2001
Epoch  48 Batch  560/1077 - Train Accuracy: 0.7953, Validation Accuracy: 0.7773, Loss: 0.1773
Epoch  48 Batch  570/1077 - Train Accuracy: 0.7800, Validation Accuracy: 0.7663, Loss: 0.1996
Epoch  48 Batch  580/1077 - Train Accuracy: 0.7984, Validation Accuracy: 0.7585, Loss: 0.1708
Epoch  48 Batch  590/1077 - Train Accuracy: 0.7586, Validation Accuracy: 0.7699, Loss: 0.2060
Epoch  48 Batch  600/1077 - Train Accuracy: 0.8069, Validation Accuracy: 0.7816, Loss: 0.1960
Epoch  48 Batch  610/1077 - Train Accuracy: 0.7730, Validation Accuracy: 0.7759, Loss: 0.1964
Epoch  48 Batch  620/1077 - Train Accuracy: 0.7883, Validation Accuracy: 0.7631, Loss: 0.1775
Epoch  48 Batch  630/1077 - Train Accuracy: 0.7465, Validation Accuracy: 0.7752, Loss: 0.1984
Epoch  48 Batch  640/1077 - Train Accuracy: 0.7835, Validation Accuracy: 0.7884, Loss: 0.1908
Epoch  48 Batch  650/1077 - Train Accuracy: 0.7676, Validation Accuracy: 0.7692, Loss: 0.1915
Epoch  48 Batch  660/1077 - Train Accuracy: 0.8074, Validation Accuracy: 0.7770, Loss: 0.1902
Epoch  48 Batch  670/1077 - Train Accuracy: 0.8001, Validation Accuracy: 0.7635, Loss: 0.1922
Epoch  48 Batch  680/1077 - Train Accuracy: 0.7712, Validation Accuracy: 0.7788, Loss: 0.2246
Epoch  48 Batch  690/1077 - Train Accuracy: 0.7953, Validation Accuracy: 0.7685, Loss: 0.1913
Epoch  48 Batch  700/1077 - Train Accuracy: 0.7902, Validation Accuracy: 0.7582, Loss: 0.1762
Epoch  48 Batch  710/1077 - Train Accuracy: 0.7570, Validation Accuracy: 0.7589, Loss: 0.1790
Epoch  48 Batch  720/1077 - Train Accuracy: 0.7817, Validation Accuracy: 0.7720, Loss: 0.2077
Epoch  48 Batch  730/1077 - Train Accuracy: 0.7387, Validation Accuracy: 0.7624, Loss: 0.2025
Epoch  48 Batch  740/1077 - Train Accuracy: 0.7836, Validation Accuracy: 0.7610, Loss: 0.1884
Epoch  48 Batch  750/1077 - Train Accuracy: 0.7898, Validation Accuracy: 0.7674, Loss: 0.1827
Epoch  48 Batch  760/1077 - Train Accuracy: 0.7812, Validation Accuracy: 0.7702, Loss: 0.2059
Epoch  48 Batch  770/1077 - Train Accuracy: 0.7946, Validation Accuracy: 0.7756, Loss: 0.1822
Epoch  48 Batch  780/1077 - Train Accuracy: 0.7738, Validation Accuracy: 0.7475, Loss: 0.2168
Epoch  48 Batch  790/1077 - Train Accuracy: 0.7059, Validation Accuracy: 0.7635, Loss: 0.2048
Epoch  48 Batch  800/1077 - Train Accuracy: 0.7777, Validation Accuracy: 0.7631, Loss: 0.1879
Epoch  48 Batch  810/1077 - Train Accuracy: 0.7705, Validation Accuracy: 0.7770, Loss: 0.1875
Epoch  48 Batch  820/1077 - Train Accuracy: 0.7418, Validation Accuracy: 0.7745, Loss: 0.2020
Epoch  48 Batch  830/1077 - Train Accuracy: 0.7512, Validation Accuracy: 0.7727, Loss: 0.2088
Epoch  48 Batch  840/1077 - Train Accuracy: 0.8113, Validation Accuracy: 0.7884, Loss: 0.1814
Epoch  48 Batch  850/1077 - Train Accuracy: 0.7440, Validation Accuracy: 0.7791, Loss: 0.2249
Epoch  48 Batch  860/1077 - Train Accuracy: 0.7496, Validation Accuracy: 0.7770, Loss: 0.1962
Epoch  48 Batch  870/1077 - Train Accuracy: 0.7607, Validation Accuracy: 0.7720, Loss: 0.2044
Epoch  48 Batch  880/1077 - Train Accuracy: 0.8184, Validation Accuracy: 0.7699, Loss: 0.1809
Epoch  48 Batch  890/1077 - Train Accuracy: 0.8307, Validation Accuracy: 0.7649, Loss: 0.1942
Epoch  48 Batch  900/1077 - Train Accuracy: 0.8098, Validation Accuracy: 0.7621, Loss: 0.4114
Epoch  48 Batch  910/1077 - Train Accuracy: 0.8054, Validation Accuracy: 0.7688, Loss: 0.2779
Epoch  48 Batch  920/1077 - Train Accuracy: 0.7883, Validation Accuracy: 0.7681, Loss: 0.2211
Epoch  48 Batch  930/1077 - Train Accuracy: 0.7836, Validation Accuracy: 0.7638, Loss: 0.1965
Epoch  48 Batch  940/1077 - Train Accuracy: 0.7871, Validation Accuracy: 0.7660, Loss: 0.1849
Epoch  48 Batch  950/1077 - Train Accuracy: 0.7853, Validation Accuracy: 0.7628, Loss: 0.1772
Epoch  48 Batch  960/1077 - Train Accuracy: 0.7909, Validation Accuracy: 0.7621, Loss: 0.1983
Epoch  48 Batch  970/1077 - Train Accuracy: 0.7891, Validation Accuracy: 0.7681, Loss: 0.1948
Epoch  48 Batch  980/1077 - Train Accuracy: 0.7445, Validation Accuracy: 0.7741, Loss: 0.2042
Epoch  48 Batch  990/1077 - Train Accuracy: 0.7804, Validation Accuracy: 0.7820, Loss: 0.1950
Epoch  48 Batch 1000/1077 - Train Accuracy: 0.8088, Validation Accuracy: 0.7830, Loss: 0.1818
Epoch  48 Batch 1010/1077 - Train Accuracy: 0.7781, Validation Accuracy: 0.7663, Loss: 0.2275
Epoch  48 Batch 1020/1077 - Train Accuracy: 0.7668, Validation Accuracy: 0.7607, Loss: 0.1804
Epoch  48 Batch 1030/1077 - Train Accuracy: 0.7836, Validation Accuracy: 0.7667, Loss: 0.1979
Epoch  48 Batch 1040/1077 - Train Accuracy: 0.8026, Validation Accuracy: 0.7624, Loss: 0.1948
Epoch  48 Batch 1050/1077 - Train Accuracy: 0.7496, Validation Accuracy: 0.7567, Loss: 0.1948
Epoch  48 Batch 1060/1077 - Train Accuracy: 0.8176, Validation Accuracy: 0.7653, Loss: 0.1672
Epoch  48 Batch 1070/1077 - Train Accuracy: 0.7652, Validation Accuracy: 0.7699, Loss: 0.2023
Epoch  49 Batch   10/1077 - Train Accuracy: 0.8080, Validation Accuracy: 0.7681, Loss: 0.1877
Epoch  49 Batch   20/1077 - Train Accuracy: 0.7754, Validation Accuracy: 0.7795, Loss: 0.1789
Epoch  49 Batch   30/1077 - Train Accuracy: 0.8027, Validation Accuracy: 0.7692, Loss: 0.1852
Epoch  49 Batch   40/1077 - Train Accuracy: 0.8168, Validation Accuracy: 0.7805, Loss: 0.1868
Epoch  49 Batch   50/1077 - Train Accuracy: 0.7512, Validation Accuracy: 0.7720, Loss: 0.1925
Epoch  49 Batch   60/1077 - Train Accuracy: 0.8017, Validation Accuracy: 0.7777, Loss: 0.1761
Epoch  49 Batch   70/1077 - Train Accuracy: 0.8244, Validation Accuracy: 0.7674, Loss: 0.1943
Epoch  49 Batch   80/1077 - Train Accuracy: 0.7762, Validation Accuracy: 0.7621, Loss: 0.2004
Epoch  49 Batch   90/1077 - Train Accuracy: 0.7578, Validation Accuracy: 0.7674, Loss: 0.2098
Epoch  49 Batch  100/1077 - Train Accuracy: 0.7648, Validation Accuracy: 0.7752, Loss: 0.1903
Epoch  49 Batch  110/1077 - Train Accuracy: 0.7867, Validation Accuracy: 0.7727, Loss: 0.1728
Epoch  49 Batch  120/1077 - Train Accuracy: 0.8055, Validation Accuracy: 0.7784, Loss: 0.1949
Epoch  49 Batch  130/1077 - Train Accuracy: 0.7493, Validation Accuracy: 0.7756, Loss: 0.1807
Epoch  49 Batch  140/1077 - Train Accuracy: 0.7961, Validation Accuracy: 0.7695, Loss: 0.1964
Epoch  49 Batch  150/1077 - Train Accuracy: 0.7954, Validation Accuracy: 0.7557, Loss: 0.1860
Epoch  49 Batch  160/1077 - Train Accuracy: 0.7723, Validation Accuracy: 0.7578, Loss: 0.2029
Epoch  49 Batch  170/1077 - Train Accuracy: 0.7531, Validation Accuracy: 0.7681, Loss: 0.2068
Epoch  49 Batch  180/1077 - Train Accuracy: 0.7996, Validation Accuracy: 0.7763, Loss: 0.1854
Epoch  49 Batch  190/1077 - Train Accuracy: 0.8387, Validation Accuracy: 0.7635, Loss: 0.1901
Epoch  49 Batch  200/1077 - Train Accuracy: 0.7754, Validation Accuracy: 0.7550, Loss: 0.2003
Epoch  49 Batch  210/1077 - Train Accuracy: 0.8021, Validation Accuracy: 0.7713, Loss: 0.1809
Epoch  49 Batch  220/1077 - Train Accuracy: 0.7895, Validation Accuracy: 0.7653, Loss: 0.1889
Epoch  49 Batch  230/1077 - Train Accuracy: 0.7853, Validation Accuracy: 0.7674, Loss: 0.2011
Epoch  49 Batch  240/1077 - Train Accuracy: 0.8422, Validation Accuracy: 0.7681, Loss: 0.1881
Epoch  49 Batch  250/1077 - Train Accuracy: 0.7908, Validation Accuracy: 0.7727, Loss: 0.1822
Epoch  49 Batch  260/1077 - Train Accuracy: 0.8144, Validation Accuracy: 0.7724, Loss: 0.1670
Epoch  49 Batch  270/1077 - Train Accuracy: 0.7902, Validation Accuracy: 0.7695, Loss: 0.2088
Epoch  49 Batch  280/1077 - Train Accuracy: 0.7945, Validation Accuracy: 0.7624, Loss: 0.2030
Epoch  49 Batch  290/1077 - Train Accuracy: 0.7820, Validation Accuracy: 0.7766, Loss: 0.2040
Epoch  49 Batch  300/1077 - Train Accuracy: 0.7829, Validation Accuracy: 0.7734, Loss: 0.1877
Epoch  49 Batch  310/1077 - Train Accuracy: 0.7418, Validation Accuracy: 0.7678, Loss: 0.2106
Epoch  49 Batch  320/1077 - Train Accuracy: 0.8273, Validation Accuracy: 0.7695, Loss: 0.2401
Epoch  49 Batch  330/1077 - Train Accuracy: 0.7973, Validation Accuracy: 0.7628, Loss: 0.1913
Epoch  49 Batch  340/1077 - Train Accuracy: 0.7903, Validation Accuracy: 0.7678, Loss: 0.1879
Epoch  49 Batch  350/1077 - Train Accuracy: 0.7855, Validation Accuracy: 0.7749, Loss: 0.2231
Epoch  49 Batch  360/1077 - Train Accuracy: 0.7895, Validation Accuracy: 0.7702, Loss: 0.1790
Epoch  49 Batch  370/1077 - Train Accuracy: 0.8181, Validation Accuracy: 0.7702, Loss: 0.1910
Epoch  49 Batch  380/1077 - Train Accuracy: 0.7770, Validation Accuracy: 0.7660, Loss: 0.1799
Epoch  49 Batch  390/1077 - Train Accuracy: 0.7547, Validation Accuracy: 0.7678, Loss: 0.2218
Epoch  49 Batch  400/1077 - Train Accuracy: 0.8027, Validation Accuracy: 0.7646, Loss: 0.1898
Epoch  49 Batch  410/1077 - Train Accuracy: 0.7804, Validation Accuracy: 0.7781, Loss: 0.2065
Epoch  49 Batch  420/1077 - Train Accuracy: 0.8113, Validation Accuracy: 0.7749, Loss: 0.1931
Epoch  49 Batch  430/1077 - Train Accuracy: 0.7496, Validation Accuracy: 0.7610, Loss: 0.1715
Epoch  49 Batch  440/1077 - Train Accuracy: 0.7473, Validation Accuracy: 0.7702, Loss: 0.2000
Epoch  49 Batch  450/1077 - Train Accuracy: 0.8094, Validation Accuracy: 0.7695, Loss: 0.1789
Epoch  49 Batch  460/1077 - Train Accuracy: 0.7426, Validation Accuracy: 0.7567, Loss: 0.1945
Epoch  49 Batch  470/1077 - Train Accuracy: 0.8022, Validation Accuracy: 0.7585, Loss: 0.1895
Epoch  49 Batch  480/1077 - Train Accuracy: 0.7730, Validation Accuracy: 0.7631, Loss: 0.2007
Epoch  49 Batch  490/1077 - Train Accuracy: 0.7609, Validation Accuracy: 0.7631, Loss: 0.2041
Epoch  49 Batch  500/1077 - Train Accuracy: 0.8164, Validation Accuracy: 0.7713, Loss: 0.1824
Epoch  49 Batch  510/1077 - Train Accuracy: 0.8105, Validation Accuracy: 0.7727, Loss: 0.1956
Epoch  49 Batch  520/1077 - Train Accuracy: 0.8512, Validation Accuracy: 0.7791, Loss: 0.1746
Epoch  49 Batch  530/1077 - Train Accuracy: 0.7637, Validation Accuracy: 0.7674, Loss: 0.1852
Epoch  49 Batch  540/1077 - Train Accuracy: 0.7918, Validation Accuracy: 0.7678, Loss: 0.1774
Epoch  49 Batch  550/1077 - Train Accuracy: 0.7492, Validation Accuracy: 0.7614, Loss: 0.1923
Epoch  49 Batch  560/1077 - Train Accuracy: 0.7969, Validation Accuracy: 0.7624, Loss: 0.1693
Epoch  49 Batch  570/1077 - Train Accuracy: 0.7796, Validation Accuracy: 0.7596, Loss: 0.1990
Epoch  49 Batch  580/1077 - Train Accuracy: 0.8028, Validation Accuracy: 0.7589, Loss: 0.1668
Epoch  49 Batch  590/1077 - Train Accuracy: 0.7586, Validation Accuracy: 0.7617, Loss: 0.2124
Epoch  49 Batch  600/1077 - Train Accuracy: 0.8136, Validation Accuracy: 0.7749, Loss: 0.1918
Epoch  49 Batch  610/1077 - Train Accuracy: 0.7734, Validation Accuracy: 0.7638, Loss: 0.2034
Epoch  49 Batch  620/1077 - Train Accuracy: 0.7773, Validation Accuracy: 0.7543, Loss: 0.1677
Epoch  49 Batch  630/1077 - Train Accuracy: 0.7590, Validation Accuracy: 0.7621, Loss: 0.1879
Epoch  49 Batch  640/1077 - Train Accuracy: 0.7801, Validation Accuracy: 0.7663, Loss: 0.1725
Epoch  49 Batch  650/1077 - Train Accuracy: 0.7590, Validation Accuracy: 0.7706, Loss: 0.2015
Epoch  49 Batch  660/1077 - Train Accuracy: 0.8027, Validation Accuracy: 0.7855, Loss: 0.1986
Epoch  49 Batch  670/1077 - Train Accuracy: 0.7983, Validation Accuracy: 0.7628, Loss: 0.1790
Epoch  49 Batch  680/1077 - Train Accuracy: 0.7667, Validation Accuracy: 0.7727, Loss: 0.2062
Epoch  49 Batch  690/1077 - Train Accuracy: 0.7828, Validation Accuracy: 0.7781, Loss: 0.1838
Epoch  49 Batch  700/1077 - Train Accuracy: 0.7984, Validation Accuracy: 0.7724, Loss: 0.1735
Epoch  49 Batch  710/1077 - Train Accuracy: 0.7480, Validation Accuracy: 0.7599, Loss: 0.1730
Epoch  49 Batch  720/1077 - Train Accuracy: 0.7850, Validation Accuracy: 0.7685, Loss: 0.2005
Epoch  49 Batch  730/1077 - Train Accuracy: 0.7750, Validation Accuracy: 0.7752, Loss: 0.1819
Epoch  49 Batch  740/1077 - Train Accuracy: 0.7805, Validation Accuracy: 0.7734, Loss: 0.1899
Epoch  49 Batch  750/1077 - Train Accuracy: 0.7852, Validation Accuracy: 0.7695, Loss: 0.1819
Epoch  49 Batch  760/1077 - Train Accuracy: 0.7727, Validation Accuracy: 0.7706, Loss: 0.1928
Epoch  49 Batch  770/1077 - Train Accuracy: 0.7812, Validation Accuracy: 0.7688, Loss: 0.1686
Epoch  49 Batch  780/1077 - Train Accuracy: 0.7766, Validation Accuracy: 0.7518, Loss: 0.2037
Epoch  49 Batch  790/1077 - Train Accuracy: 0.7023, Validation Accuracy: 0.7720, Loss: 0.2050
Epoch  49 Batch  800/1077 - Train Accuracy: 0.7828, Validation Accuracy: 0.7866, Loss: 0.1800
Epoch  49 Batch  810/1077 - Train Accuracy: 0.7679, Validation Accuracy: 0.7688, Loss: 0.1790
Epoch  49 Batch  820/1077 - Train Accuracy: 0.7391, Validation Accuracy: 0.7724, Loss: 0.1965
Epoch  49 Batch  830/1077 - Train Accuracy: 0.7508, Validation Accuracy: 0.7756, Loss: 0.1987
Epoch  49 Batch  840/1077 - Train Accuracy: 0.8070, Validation Accuracy: 0.7773, Loss: 0.1891
Epoch  49 Batch  850/1077 - Train Accuracy: 0.7478, Validation Accuracy: 0.7756, Loss: 0.2229
Epoch  49 Batch  860/1077 - Train Accuracy: 0.7764, Validation Accuracy: 0.7724, Loss: 0.2029
Epoch  49 Batch  870/1077 - Train Accuracy: 0.7632, Validation Accuracy: 0.7710, Loss: 0.1923
Epoch  49 Batch  880/1077 - Train Accuracy: 0.8059, Validation Accuracy: 0.7660, Loss: 0.1810
Epoch  49 Batch  890/1077 - Train Accuracy: 0.8173, Validation Accuracy: 0.7720, Loss: 0.1936
Epoch  49 Batch  900/1077 - Train Accuracy: 0.8133, Validation Accuracy: 0.7763, Loss: 0.1976
Epoch  49 Batch  910/1077 - Train Accuracy: 0.8036, Validation Accuracy: 0.7773, Loss: 0.2131
Epoch  49 Batch  920/1077 - Train Accuracy: 0.7699, Validation Accuracy: 0.7805, Loss: 0.2149
Epoch  49 Batch  930/1077 - Train Accuracy: 0.8004, Validation Accuracy: 0.7724, Loss: 0.1781
Epoch  49 Batch  940/1077 - Train Accuracy: 0.7937, Validation Accuracy: 0.7635, Loss: 0.1896
Epoch  49 Batch  950/1077 - Train Accuracy: 0.7716, Validation Accuracy: 0.7798, Loss: 0.1786
Epoch  49 Batch  960/1077 - Train Accuracy: 0.7909, Validation Accuracy: 0.7752, Loss: 0.1904
Epoch  49 Batch  970/1077 - Train Accuracy: 0.7996, Validation Accuracy: 0.7599, Loss: 0.1893
Epoch  49 Batch  980/1077 - Train Accuracy: 0.7449, Validation Accuracy: 0.7663, Loss: 0.2104
Epoch  49 Batch  990/1077 - Train Accuracy: 0.7664, Validation Accuracy: 0.7848, Loss: 0.1914
Epoch  49 Batch 1000/1077 - Train Accuracy: 0.8006, Validation Accuracy: 0.7695, Loss: 0.1791
Epoch  49 Batch 1010/1077 - Train Accuracy: 0.7801, Validation Accuracy: 0.7749, Loss: 0.1849
Epoch  49 Batch 1020/1077 - Train Accuracy: 0.7668, Validation Accuracy: 0.7749, Loss: 0.1662
Epoch  49 Batch 1030/1077 - Train Accuracy: 0.7582, Validation Accuracy: 0.7710, Loss: 0.1856
Epoch  49 Batch 1040/1077 - Train Accuracy: 0.7932, Validation Accuracy: 0.7681, Loss: 0.1770
Epoch  49 Batch 1050/1077 - Train Accuracy: 0.7461, Validation Accuracy: 0.7685, Loss: 0.1818
Epoch  49 Batch 1060/1077 - Train Accuracy: 0.8121, Validation Accuracy: 0.7717, Loss: 0.1723
Epoch  49 Batch 1070/1077 - Train Accuracy: 0.7562, Validation Accuracy: 0.7649, Loss: 0.1964
Epoch  50 Batch   10/1077 - Train Accuracy: 0.8018, Validation Accuracy: 0.7681, Loss: 0.1924
Epoch  50 Batch   20/1077 - Train Accuracy: 0.7734, Validation Accuracy: 0.7756, Loss: 0.1883
Epoch  50 Batch   30/1077 - Train Accuracy: 0.8176, Validation Accuracy: 0.7734, Loss: 0.1953
Epoch  50 Batch   40/1077 - Train Accuracy: 0.8332, Validation Accuracy: 0.7812, Loss: 0.1855
Epoch  50 Batch   50/1077 - Train Accuracy: 0.7570, Validation Accuracy: 0.7855, Loss: 0.1877
Epoch  50 Batch   60/1077 - Train Accuracy: 0.7984, Validation Accuracy: 0.7752, Loss: 0.1734
Epoch  50 Batch   70/1077 - Train Accuracy: 0.8302, Validation Accuracy: 0.7685, Loss: 0.2021
Epoch  50 Batch   80/1077 - Train Accuracy: 0.7762, Validation Accuracy: 0.7699, Loss: 0.1795
Epoch  50 Batch   90/1077 - Train Accuracy: 0.7656, Validation Accuracy: 0.7710, Loss: 0.1978
Epoch  50 Batch  100/1077 - Train Accuracy: 0.7680, Validation Accuracy: 0.7841, Loss: 0.1847
Epoch  50 Batch  110/1077 - Train Accuracy: 0.7930, Validation Accuracy: 0.7766, Loss: 0.1700
Epoch  50 Batch  120/1077 - Train Accuracy: 0.8043, Validation Accuracy: 0.7741, Loss: 0.2102
Epoch  50 Batch  130/1077 - Train Accuracy: 0.7597, Validation Accuracy: 0.7738, Loss: 0.1961
Epoch  50 Batch  140/1077 - Train Accuracy: 0.7985, Validation Accuracy: 0.7681, Loss: 0.1978
Epoch  50 Batch  150/1077 - Train Accuracy: 0.7965, Validation Accuracy: 0.7603, Loss: 0.1805
Epoch  50 Batch  160/1077 - Train Accuracy: 0.7875, Validation Accuracy: 0.7642, Loss: 0.1879
Epoch  50 Batch  170/1077 - Train Accuracy: 0.7504, Validation Accuracy: 0.7766, Loss: 0.1972
Epoch  50 Batch  180/1077 - Train Accuracy: 0.7980, Validation Accuracy: 0.7567, Loss: 0.1763
Epoch  50 Batch  190/1077 - Train Accuracy: 0.8313, Validation Accuracy: 0.7589, Loss: 0.1980
Epoch  50 Batch  200/1077 - Train Accuracy: 0.7777, Validation Accuracy: 0.7805, Loss: 0.1994
Epoch  50 Batch  210/1077 - Train Accuracy: 0.7976, Validation Accuracy: 0.7621, Loss: 0.1843
Epoch  50 Batch  220/1077 - Train Accuracy: 0.7891, Validation Accuracy: 0.7614, Loss: 0.1992
Epoch  50 Batch  230/1077 - Train Accuracy: 0.7827, Validation Accuracy: 0.7663, Loss: 0.1885
Epoch  50 Batch  240/1077 - Train Accuracy: 0.8250, Validation Accuracy: 0.7685, Loss: 0.1849
Epoch  50 Batch  250/1077 - Train Accuracy: 0.7773, Validation Accuracy: 0.7695, Loss: 0.1885
Epoch  50 Batch  260/1077 - Train Accuracy: 0.8110, Validation Accuracy: 0.7731, Loss: 0.1776
Epoch  50 Batch  270/1077 - Train Accuracy: 0.7984, Validation Accuracy: 0.7788, Loss: 0.2179
Epoch  50 Batch  280/1077 - Train Accuracy: 0.7961, Validation Accuracy: 0.7681, Loss: 0.1877
Epoch  50 Batch  290/1077 - Train Accuracy: 0.7766, Validation Accuracy: 0.7731, Loss: 0.2054
Epoch  50 Batch  300/1077 - Train Accuracy: 0.7887, Validation Accuracy: 0.7699, Loss: 0.1831
Epoch  50 Batch  310/1077 - Train Accuracy: 0.7551, Validation Accuracy: 0.7820, Loss: 0.2040
Epoch  50 Batch  320/1077 - Train Accuracy: 0.8383, Validation Accuracy: 0.7830, Loss: 0.2192
Epoch  50 Batch  330/1077 - Train Accuracy: 0.7969, Validation Accuracy: 0.7770, Loss: 0.1897
Epoch  50 Batch  340/1077 - Train Accuracy: 0.7784, Validation Accuracy: 0.7841, Loss: 0.1935
Epoch  50 Batch  350/1077 - Train Accuracy: 0.7918, Validation Accuracy: 0.7788, Loss: 0.1765
Epoch  50 Batch  360/1077 - Train Accuracy: 0.7949, Validation Accuracy: 0.7770, Loss: 0.1926
Epoch  50 Batch  370/1077 - Train Accuracy: 0.7924, Validation Accuracy: 0.7798, Loss: 0.1859
Epoch  50 Batch  380/1077 - Train Accuracy: 0.7910, Validation Accuracy: 0.7681, Loss: 0.1810
Epoch  50 Batch  390/1077 - Train Accuracy: 0.7582, Validation Accuracy: 0.7734, Loss: 0.2096
Epoch  50 Batch  400/1077 - Train Accuracy: 0.7941, Validation Accuracy: 0.7578, Loss: 0.1838
Epoch  50 Batch  410/1077 - Train Accuracy: 0.7763, Validation Accuracy: 0.7681, Loss: 0.1972
Epoch  50 Batch  420/1077 - Train Accuracy: 0.8066, Validation Accuracy: 0.7773, Loss: 0.1760
Epoch  50 Batch  430/1077 - Train Accuracy: 0.7582, Validation Accuracy: 0.7745, Loss: 0.1994
Epoch  50 Batch  440/1077 - Train Accuracy: 0.7453, Validation Accuracy: 0.7710, Loss: 0.1917
Epoch  50 Batch  450/1077 - Train Accuracy: 0.8078, Validation Accuracy: 0.7681, Loss: 0.1888
Epoch  50 Batch  460/1077 - Train Accuracy: 0.7484, Validation Accuracy: 0.7702, Loss: 0.1950
Epoch  50 Batch  470/1077 - Train Accuracy: 0.8174, Validation Accuracy: 0.7702, Loss: 0.1916
Epoch  50 Batch  480/1077 - Train Accuracy: 0.7747, Validation Accuracy: 0.7663, Loss: 0.1933
Epoch  50 Batch  490/1077 - Train Accuracy: 0.7473, Validation Accuracy: 0.7564, Loss: 0.1995
Epoch  50 Batch  500/1077 - Train Accuracy: 0.8102, Validation Accuracy: 0.7749, Loss: 0.1730
Epoch  50 Batch  510/1077 - Train Accuracy: 0.8117, Validation Accuracy: 0.7720, Loss: 0.1975
Epoch  50 Batch  520/1077 - Train Accuracy: 0.8490, Validation Accuracy: 0.7731, Loss: 0.1736
Epoch  50 Batch  530/1077 - Train Accuracy: 0.7492, Validation Accuracy: 0.7816, Loss: 0.1990
Epoch  50 Batch  540/1077 - Train Accuracy: 0.8187, Validation Accuracy: 0.7631, Loss: 0.1747
Epoch  50 Batch  550/1077 - Train Accuracy: 0.7555, Validation Accuracy: 0.7592, Loss: 0.1977
Epoch  50 Batch  560/1077 - Train Accuracy: 0.7922, Validation Accuracy: 0.7685, Loss: 0.1849
Epoch  50 Batch  570/1077 - Train Accuracy: 0.7775, Validation Accuracy: 0.7720, Loss: 0.2060
Epoch  50 Batch  580/1077 - Train Accuracy: 0.8129, Validation Accuracy: 0.7777, Loss: 0.1635
Epoch  50 Batch  590/1077 - Train Accuracy: 0.7451, Validation Accuracy: 0.7699, Loss: 0.2025
Epoch  50 Batch  600/1077 - Train Accuracy: 0.8054, Validation Accuracy: 0.7834, Loss: 0.1968
Epoch  50 Batch  610/1077 - Train Accuracy: 0.7784, Validation Accuracy: 0.7823, Loss: 0.1857
Epoch  50 Batch  620/1077 - Train Accuracy: 0.7781, Validation Accuracy: 0.7784, Loss: 0.1840
Epoch  50 Batch  630/1077 - Train Accuracy: 0.7574, Validation Accuracy: 0.7791, Loss: 0.1884
Epoch  50 Batch  640/1077 - Train Accuracy: 0.7950, Validation Accuracy: 0.7791, Loss: 0.1844
Epoch  50 Batch  650/1077 - Train Accuracy: 0.7824, Validation Accuracy: 0.7859, Loss: 0.1959
Epoch  50 Batch  660/1077 - Train Accuracy: 0.8137, Validation Accuracy: 0.7784, Loss: 0.2006
Epoch  50 Batch  670/1077 - Train Accuracy: 0.7969, Validation Accuracy: 0.7766, Loss: 0.1705
Epoch  50 Batch  680/1077 - Train Accuracy: 0.7645, Validation Accuracy: 0.7773, Loss: 0.1975
Epoch  50 Batch  690/1077 - Train Accuracy: 0.7988, Validation Accuracy: 0.7773, Loss: 0.1881
Epoch  50 Batch  700/1077 - Train Accuracy: 0.8094, Validation Accuracy: 0.7713, Loss: 0.1690
Epoch  50 Batch  710/1077 - Train Accuracy: 0.7641, Validation Accuracy: 0.7607, Loss: 0.1772
Epoch  50 Batch  720/1077 - Train Accuracy: 0.7845, Validation Accuracy: 0.7578, Loss: 0.1947
Epoch  50 Batch  730/1077 - Train Accuracy: 0.7418, Validation Accuracy: 0.7635, Loss: 0.1881
Epoch  50 Batch  740/1077 - Train Accuracy: 0.7812, Validation Accuracy: 0.7706, Loss: 0.1838
Epoch  50 Batch  750/1077 - Train Accuracy: 0.7828, Validation Accuracy: 0.7741, Loss: 0.2011
Epoch  50 Batch  760/1077 - Train Accuracy: 0.7805, Validation Accuracy: 0.7667, Loss: 0.1886
Epoch  50 Batch  770/1077 - Train Accuracy: 0.7909, Validation Accuracy: 0.7777, Loss: 0.1767
Epoch  50 Batch  780/1077 - Train Accuracy: 0.7695, Validation Accuracy: 0.7670, Loss: 0.2039
Epoch  50 Batch  790/1077 - Train Accuracy: 0.7168, Validation Accuracy: 0.7681, Loss: 0.2017
Epoch  50 Batch  800/1077 - Train Accuracy: 0.7746, Validation Accuracy: 0.7678, Loss: 0.1791
Epoch  50 Batch  810/1077 - Train Accuracy: 0.7783, Validation Accuracy: 0.7717, Loss: 0.1692
Epoch  50 Batch  820/1077 - Train Accuracy: 0.7492, Validation Accuracy: 0.7788, Loss: 0.1950
Epoch  50 Batch  830/1077 - Train Accuracy: 0.7598, Validation Accuracy: 0.7752, Loss: 0.2011
Epoch  50 Batch  840/1077 - Train Accuracy: 0.8059, Validation Accuracy: 0.7812, Loss: 0.1812
Epoch  50 Batch  850/1077 - Train Accuracy: 0.7362, Validation Accuracy: 0.7720, Loss: 0.2187
Epoch  50 Batch  860/1077 - Train Accuracy: 0.7742, Validation Accuracy: 0.7681, Loss: 0.1965
Epoch  50 Batch  870/1077 - Train Accuracy: 0.7578, Validation Accuracy: 0.7603, Loss: 0.1843
Epoch  50 Batch  880/1077 - Train Accuracy: 0.8258, Validation Accuracy: 0.7777, Loss: 0.1839
Epoch  50 Batch  890/1077 - Train Accuracy: 0.8359, Validation Accuracy: 0.7830, Loss: 0.1860
Epoch  50 Batch  900/1077 - Train Accuracy: 0.8086, Validation Accuracy: 0.7699, Loss: 0.1850
Epoch  50 Batch  910/1077 - Train Accuracy: 0.8125, Validation Accuracy: 0.7752, Loss: 0.1887
Epoch  50 Batch  920/1077 - Train Accuracy: 0.7809, Validation Accuracy: 0.7773, Loss: 0.1893
Epoch  50 Batch  930/1077 - Train Accuracy: 0.7852, Validation Accuracy: 0.7798, Loss: 0.1798
Epoch  50 Batch  940/1077 - Train Accuracy: 0.8043, Validation Accuracy: 0.7670, Loss: 0.1806
Epoch  50 Batch  950/1077 - Train Accuracy: 0.7812, Validation Accuracy: 0.7656, Loss: 0.1788
Epoch  50 Batch  960/1077 - Train Accuracy: 0.8002, Validation Accuracy: 0.7628, Loss: 0.2001
Epoch  50 Batch  970/1077 - Train Accuracy: 0.8004, Validation Accuracy: 0.7649, Loss: 0.1855
Epoch  50 Batch  980/1077 - Train Accuracy: 0.7480, Validation Accuracy: 0.7663, Loss: 0.2065
Epoch  50 Batch  990/1077 - Train Accuracy: 0.7891, Validation Accuracy: 0.7752, Loss: 0.1941
Epoch  50 Batch 1000/1077 - Train Accuracy: 0.8114, Validation Accuracy: 0.7720, Loss: 0.1751
Epoch  50 Batch 1010/1077 - Train Accuracy: 0.7711, Validation Accuracy: 0.7727, Loss: 0.1787
Epoch  50 Batch 1020/1077 - Train Accuracy: 0.7656, Validation Accuracy: 0.7631, Loss: 0.1843
Epoch  50 Batch 1030/1077 - Train Accuracy: 0.7707, Validation Accuracy: 0.7685, Loss: 0.1891
Epoch  50 Batch 1040/1077 - Train Accuracy: 0.8018, Validation Accuracy: 0.7589, Loss: 0.1876
Epoch  50 Batch 1050/1077 - Train Accuracy: 0.7332, Validation Accuracy: 0.7592, Loss: 0.1879
Epoch  50 Batch 1060/1077 - Train Accuracy: 0.8191, Validation Accuracy: 0.7727, Loss: 0.1640
Epoch  50 Batch 1070/1077 - Train Accuracy: 0.7652, Validation Accuracy: 0.7649, Loss: 0.2014
Epoch  51 Batch   10/1077 - Train Accuracy: 0.7845, Validation Accuracy: 0.7692, Loss: 0.1959
Epoch  51 Batch   20/1077 - Train Accuracy: 0.7785, Validation Accuracy: 0.7734, Loss: 0.1833
Epoch  51 Batch   30/1077 - Train Accuracy: 0.8094, Validation Accuracy: 0.7674, Loss: 0.1880
Epoch  51 Batch   40/1077 - Train Accuracy: 0.8164, Validation Accuracy: 0.7631, Loss: 0.1928
Epoch  51 Batch   50/1077 - Train Accuracy: 0.7754, Validation Accuracy: 0.7812, Loss: 0.1814
Epoch  51 Batch   60/1077 - Train Accuracy: 0.7939, Validation Accuracy: 0.7763, Loss: 0.1710
Epoch  51 Batch   70/1077 - Train Accuracy: 0.8294, Validation Accuracy: 0.7727, Loss: 0.1853
Epoch  51 Batch   80/1077 - Train Accuracy: 0.7809, Validation Accuracy: 0.7678, Loss: 0.1808
Epoch  51 Batch   90/1077 - Train Accuracy: 0.7527, Validation Accuracy: 0.7805, Loss: 0.1956
Epoch  51 Batch  100/1077 - Train Accuracy: 0.7805, Validation Accuracy: 0.7830, Loss: 0.1837
Epoch  51 Batch  110/1077 - Train Accuracy: 0.7879, Validation Accuracy: 0.7752, Loss: 0.1704
Epoch  51 Batch  120/1077 - Train Accuracy: 0.8125, Validation Accuracy: 0.7738, Loss: 0.1923
Epoch  51 Batch  130/1077 - Train Accuracy: 0.7615, Validation Accuracy: 0.7781, Loss: 0.1865
Epoch  51 Batch  140/1077 - Train Accuracy: 0.7850, Validation Accuracy: 0.7763, Loss: 0.1917
Epoch  51 Batch  150/1077 - Train Accuracy: 0.7965, Validation Accuracy: 0.7656, Loss: 0.1867
Epoch  51 Batch  160/1077 - Train Accuracy: 0.7953, Validation Accuracy: 0.7621, Loss: 0.2518
Epoch  51 Batch  170/1077 - Train Accuracy: 0.7625, Validation Accuracy: 0.7802, Loss: 0.1935
Epoch  51 Batch  180/1077 - Train Accuracy: 0.7922, Validation Accuracy: 0.7777, Loss: 0.1892
Epoch  51 Batch  190/1077 - Train Accuracy: 0.8387, Validation Accuracy: 0.7844, Loss: 0.1780
Epoch  51 Batch  200/1077 - Train Accuracy: 0.7848, Validation Accuracy: 0.7685, Loss: 0.2069
Epoch  51 Batch  210/1077 - Train Accuracy: 0.7954, Validation Accuracy: 0.7912, Loss: 0.1894
Epoch  51 Batch  220/1077 - Train Accuracy: 0.7919, Validation Accuracy: 0.7674, Loss: 0.1947
Epoch  51 Batch  230/1077 - Train Accuracy: 0.7972, Validation Accuracy: 0.7663, Loss: 0.1766
Epoch  51 Batch  240/1077 - Train Accuracy: 0.8406, Validation Accuracy: 0.7802, Loss: 0.1741
Epoch  51 Batch  250/1077 - Train Accuracy: 0.7834, Validation Accuracy: 0.7752, Loss: 0.1731
Epoch  51 Batch  260/1077 - Train Accuracy: 0.8158, Validation Accuracy: 0.7713, Loss: 0.1736
Epoch  51 Batch  270/1077 - Train Accuracy: 0.7867, Validation Accuracy: 0.7880, Loss: 0.2101
Epoch  51 Batch  280/1077 - Train Accuracy: 0.7914, Validation Accuracy: 0.7820, Loss: 0.1823
Epoch  51 Batch  290/1077 - Train Accuracy: 0.7762, Validation Accuracy: 0.7749, Loss: 0.1956
Epoch  51 Batch  300/1077 - Train Accuracy: 0.7817, Validation Accuracy: 0.7695, Loss: 0.1795
Epoch  51 Batch  310/1077 - Train Accuracy: 0.7484, Validation Accuracy: 0.7720, Loss: 0.1972
Epoch  51 Batch  320/1077 - Train Accuracy: 0.8230, Validation Accuracy: 0.7816, Loss: 0.2260
Epoch  51 Batch  330/1077 - Train Accuracy: 0.7910, Validation Accuracy: 0.7713, Loss: 0.1852
Epoch  51 Batch  340/1077 - Train Accuracy: 0.7821, Validation Accuracy: 0.7702, Loss: 0.1911
Epoch  51 Batch  350/1077 - Train Accuracy: 0.7852, Validation Accuracy: 0.7763, Loss: 0.1938
Epoch  51 Batch  360/1077 - Train Accuracy: 0.7762, Validation Accuracy: 0.7745, Loss: 0.1860
Epoch  51 Batch  370/1077 - Train Accuracy: 0.8047, Validation Accuracy: 0.7734, Loss: 0.1826
Epoch  51 Batch  380/1077 - Train Accuracy: 0.7887, Validation Accuracy: 0.7724, Loss: 0.1826
Epoch  51 Batch  390/1077 - Train Accuracy: 0.7609, Validation Accuracy: 0.7766, Loss: 0.2067
Epoch  51 Batch  400/1077 - Train Accuracy: 0.8000, Validation Accuracy: 0.7663, Loss: 0.1950
Epoch  51 Batch  410/1077 - Train Accuracy: 0.7771, Validation Accuracy: 0.7713, Loss: 0.2044
Epoch  51 Batch  420/1077 - Train Accuracy: 0.8207, Validation Accuracy: 0.7692, Loss: 0.1747
Epoch  51 Batch  430/1077 - Train Accuracy: 0.7512, Validation Accuracy: 0.7670, Loss: 0.1782
Epoch  51 Batch  440/1077 - Train Accuracy: 0.7496, Validation Accuracy: 0.7692, Loss: 0.2086
Epoch  51 Batch  450/1077 - Train Accuracy: 0.8258, Validation Accuracy: 0.7756, Loss: 0.1843
Epoch  51 Batch  460/1077 - Train Accuracy: 0.7371, Validation Accuracy: 0.7546, Loss: 0.1920
Epoch  51 Batch  470/1077 - Train Accuracy: 0.8043, Validation Accuracy: 0.7635, Loss: 0.1916
Epoch  51 Batch  480/1077 - Train Accuracy: 0.7965, Validation Accuracy: 0.7656, Loss: 0.1812
Epoch  51 Batch  490/1077 - Train Accuracy: 0.7660, Validation Accuracy: 0.7649, Loss: 0.1924
Epoch  51 Batch  500/1077 - Train Accuracy: 0.8180, Validation Accuracy: 0.7635, Loss: 0.1718
Epoch  51 Batch  510/1077 - Train Accuracy: 0.8203, Validation Accuracy: 0.7713, Loss: 0.1878
Epoch  51 Batch  520/1077 - Train Accuracy: 0.8501, Validation Accuracy: 0.7763, Loss: 0.1713
Epoch  51 Batch  530/1077 - Train Accuracy: 0.7602, Validation Accuracy: 0.7788, Loss: 0.1836
Epoch  51 Batch  540/1077 - Train Accuracy: 0.7945, Validation Accuracy: 0.7710, Loss: 0.1781
Epoch  51 Batch  550/1077 - Train Accuracy: 0.7527, Validation Accuracy: 0.7749, Loss: 0.1934
Epoch  51 Batch  560/1077 - Train Accuracy: 0.7977, Validation Accuracy: 0.7731, Loss: 0.1735
Epoch  51 Batch  570/1077 - Train Accuracy: 0.7821, Validation Accuracy: 0.7812, Loss: 0.1916
Epoch  51 Batch  580/1077 - Train Accuracy: 0.7950, Validation Accuracy: 0.7724, Loss: 0.1676
Epoch  51 Batch  590/1077 - Train Accuracy: 0.7549, Validation Accuracy: 0.7759, Loss: 0.2050
Epoch  51 Batch  600/1077 - Train Accuracy: 0.8058, Validation Accuracy: 0.7830, Loss: 0.1802
Epoch  51 Batch  610/1077 - Train Accuracy: 0.7701, Validation Accuracy: 0.7812, Loss: 0.1848
Epoch  51 Batch  620/1077 - Train Accuracy: 0.7793, Validation Accuracy: 0.7678, Loss: 0.1716
Epoch  51 Batch  630/1077 - Train Accuracy: 0.7621, Validation Accuracy: 0.7848, Loss: 0.1736
Epoch  51 Batch  640/1077 - Train Accuracy: 0.7757, Validation Accuracy: 0.7791, Loss: 0.1667
Epoch  51 Batch  650/1077 - Train Accuracy: 0.7766, Validation Accuracy: 0.7770, Loss: 0.1809
Epoch  51 Batch  660/1077 - Train Accuracy: 0.7996, Validation Accuracy: 0.7763, Loss: 0.1931
Epoch  51 Batch  670/1077 - Train Accuracy: 0.7933, Validation Accuracy: 0.7852, Loss: 0.1721
Epoch  51 Batch  680/1077 - Train Accuracy: 0.7693, Validation Accuracy: 0.7649, Loss: 0.1860
Epoch  51 Batch  690/1077 - Train Accuracy: 0.7957, Validation Accuracy: 0.7702, Loss: 0.1823
Epoch  51 Batch  700/1077 - Train Accuracy: 0.8051, Validation Accuracy: 0.7731, Loss: 0.1806
Epoch  51 Batch  710/1077 - Train Accuracy: 0.7480, Validation Accuracy: 0.7699, Loss: 0.1880
Epoch  51 Batch  720/1077 - Train Accuracy: 0.7932, Validation Accuracy: 0.7607, Loss: 0.1946
Epoch  51 Batch  730/1077 - Train Accuracy: 0.7516, Validation Accuracy: 0.7702, Loss: 0.1923
Epoch  51 Batch  740/1077 - Train Accuracy: 0.7910, Validation Accuracy: 0.7717, Loss: 0.1894
Epoch  51 Batch  750/1077 - Train Accuracy: 0.7746, Validation Accuracy: 0.7713, Loss: 0.1747
Epoch  51 Batch  760/1077 - Train Accuracy: 0.7723, Validation Accuracy: 0.7805, Loss: 0.1835
Epoch  51 Batch  770/1077 - Train Accuracy: 0.8013, Validation Accuracy: 0.7660, Loss: 0.1705
Epoch  51 Batch  780/1077 - Train Accuracy: 0.7680, Validation Accuracy: 0.7610, Loss: 0.1999
Epoch  51 Batch  790/1077 - Train Accuracy: 0.7184, Validation Accuracy: 0.7667, Loss: 0.1942
Epoch  51 Batch  800/1077 - Train Accuracy: 0.7750, Validation Accuracy: 0.7738, Loss: 0.1957
Epoch  51 Batch  810/1077 - Train Accuracy: 0.7701, Validation Accuracy: 0.7827, Loss: 0.1711
Epoch  51 Batch  820/1077 - Train Accuracy: 0.7453, Validation Accuracy: 0.7873, Loss: 0.1932
Epoch  51 Batch  830/1077 - Train Accuracy: 0.7605, Validation Accuracy: 0.7802, Loss: 0.1875
Epoch  51 Batch  840/1077 - Train Accuracy: 0.8090, Validation Accuracy: 0.7876, Loss: 0.1986
Epoch  51 Batch  850/1077 - Train Accuracy: 0.7440, Validation Accuracy: 0.7791, Loss: 0.2079
Epoch  51 Batch  860/1077 - Train Accuracy: 0.7671, Validation Accuracy: 0.7706, Loss: 0.1968
Epoch  51 Batch  870/1077 - Train Accuracy: 0.7689, Validation Accuracy: 0.7646, Loss: 0.2054
Epoch  51 Batch  880/1077 - Train Accuracy: 0.8086, Validation Accuracy: 0.7788, Loss: 0.1812
Epoch  51 Batch  890/1077 - Train Accuracy: 0.8371, Validation Accuracy: 0.7784, Loss: 0.1680
Epoch  51 Batch  900/1077 - Train Accuracy: 0.8133, Validation Accuracy: 0.7706, Loss: 0.1834
Epoch  51 Batch  910/1077 - Train Accuracy: 0.8147, Validation Accuracy: 0.7688, Loss: 0.2016
Epoch  51 Batch  920/1077 - Train Accuracy: 0.7895, Validation Accuracy: 0.7713, Loss: 0.1939
Epoch  51 Batch  930/1077 - Train Accuracy: 0.8063, Validation Accuracy: 0.7798, Loss: 0.1844
Epoch  51 Batch  940/1077 - Train Accuracy: 0.7984, Validation Accuracy: 0.7812, Loss: 0.1823
Epoch  51 Batch  950/1077 - Train Accuracy: 0.7965, Validation Accuracy: 0.7752, Loss: 0.1731
Epoch  51 Batch  960/1077 - Train Accuracy: 0.7764, Validation Accuracy: 0.7823, Loss: 0.1771
Epoch  51 Batch  970/1077 - Train Accuracy: 0.7875, Validation Accuracy: 0.7770, Loss: 0.1817
Epoch  51 Batch  980/1077 - Train Accuracy: 0.7453, Validation Accuracy: 0.7859, Loss: 0.2065
Epoch  51 Batch  990/1077 - Train Accuracy: 0.7714, Validation Accuracy: 0.7695, Loss: 0.2038
Epoch  51 Batch 1000/1077 - Train Accuracy: 0.8065, Validation Accuracy: 0.7756, Loss: 0.1681
Epoch  51 Batch 1010/1077 - Train Accuracy: 0.7836, Validation Accuracy: 0.7830, Loss: 0.1828
Epoch  51 Batch 1020/1077 - Train Accuracy: 0.7617, Validation Accuracy: 0.7773, Loss: 0.1771
Epoch  51 Batch 1030/1077 - Train Accuracy: 0.7773, Validation Accuracy: 0.7674, Loss: 0.1923
Epoch  51 Batch 1040/1077 - Train Accuracy: 0.8010, Validation Accuracy: 0.7656, Loss: 0.1847
Epoch  51 Batch 1050/1077 - Train Accuracy: 0.7383, Validation Accuracy: 0.7663, Loss: 0.1910
Epoch  51 Batch 1060/1077 - Train Accuracy: 0.8113, Validation Accuracy: 0.7752, Loss: 0.1769
Epoch  51 Batch 1070/1077 - Train Accuracy: 0.7613, Validation Accuracy: 0.7692, Loss: 0.1916
Epoch  52 Batch   10/1077 - Train Accuracy: 0.8030, Validation Accuracy: 0.7681, Loss: 0.2101
Epoch  52 Batch   20/1077 - Train Accuracy: 0.7848, Validation Accuracy: 0.7692, Loss: 0.1681
Epoch  52 Batch   30/1077 - Train Accuracy: 0.8090, Validation Accuracy: 0.7717, Loss: 0.2093
Epoch  52 Batch   40/1077 - Train Accuracy: 0.8262, Validation Accuracy: 0.7887, Loss: 0.1934
Epoch  52 Batch   50/1077 - Train Accuracy: 0.7621, Validation Accuracy: 0.7731, Loss: 0.1939
Epoch  52 Batch   60/1077 - Train Accuracy: 0.7887, Validation Accuracy: 0.7692, Loss: 0.1704
Epoch  52 Batch   70/1077 - Train Accuracy: 0.8232, Validation Accuracy: 0.7749, Loss: 0.1961
Epoch  52 Batch   80/1077 - Train Accuracy: 0.7754, Validation Accuracy: 0.7731, Loss: 0.1885
Epoch  52 Batch   90/1077 - Train Accuracy: 0.7453, Validation Accuracy: 0.7773, Loss: 0.1915
Epoch  52 Batch  100/1077 - Train Accuracy: 0.7641, Validation Accuracy: 0.7830, Loss: 0.1805
Epoch  52 Batch  110/1077 - Train Accuracy: 0.7879, Validation Accuracy: 0.7869, Loss: 0.1668
Epoch  52 Batch  120/1077 - Train Accuracy: 0.8148, Validation Accuracy: 0.7816, Loss: 0.1910
Epoch  52 Batch  130/1077 - Train Accuracy: 0.7578, Validation Accuracy: 0.7923, Loss: 0.1779
Epoch  52 Batch  140/1077 - Train Accuracy: 0.7924, Validation Accuracy: 0.7859, Loss: 0.1869
Epoch  52 Batch  150/1077 - Train Accuracy: 0.8013, Validation Accuracy: 0.7788, Loss: 0.1864
Epoch  52 Batch  160/1077 - Train Accuracy: 0.8070, Validation Accuracy: 0.7688, Loss: 0.1853
Epoch  52 Batch  170/1077 - Train Accuracy: 0.7469, Validation Accuracy: 0.7678, Loss: 0.1755
Epoch  52 Batch  180/1077 - Train Accuracy: 0.7957, Validation Accuracy: 0.7727, Loss: 0.1724
Epoch  52 Batch  190/1077 - Train Accuracy: 0.8320, Validation Accuracy: 0.7649, Loss: 0.1880
Epoch  52 Batch  200/1077 - Train Accuracy: 0.7770, Validation Accuracy: 0.7681, Loss: 0.1858
Epoch  52 Batch  210/1077 - Train Accuracy: 0.8017, Validation Accuracy: 0.7724, Loss: 0.1776
Epoch  52 Batch  220/1077 - Train Accuracy: 0.7899, Validation Accuracy: 0.7688, Loss: 0.1856
Epoch  52 Batch  230/1077 - Train Accuracy: 0.7876, Validation Accuracy: 0.7795, Loss: 0.1751
Epoch  52 Batch  240/1077 - Train Accuracy: 0.8543, Validation Accuracy: 0.7667, Loss: 0.1922
Epoch  52 Batch  250/1077 - Train Accuracy: 0.7848, Validation Accuracy: 0.7720, Loss: 0.1649
Epoch  52 Batch  260/1077 - Train Accuracy: 0.8140, Validation Accuracy: 0.7741, Loss: 0.1668
Epoch  52 Batch  270/1077 - Train Accuracy: 0.7797, Validation Accuracy: 0.7734, Loss: 0.2047
Epoch  52 Batch  280/1077 - Train Accuracy: 0.8023, Validation Accuracy: 0.7784, Loss: 0.1816
Epoch  52 Batch  290/1077 - Train Accuracy: 0.7801, Validation Accuracy: 0.7781, Loss: 0.1994
Epoch  52 Batch  300/1077 - Train Accuracy: 0.7825, Validation Accuracy: 0.7702, Loss: 0.1710
Epoch  52 Batch  310/1077 - Train Accuracy: 0.7590, Validation Accuracy: 0.7759, Loss: 0.1992
Epoch  52 Batch  320/1077 - Train Accuracy: 0.8301, Validation Accuracy: 0.7681, Loss: 0.2373
Epoch  52 Batch  330/1077 - Train Accuracy: 0.7996, Validation Accuracy: 0.7638, Loss: 0.1839
Epoch  52 Batch  340/1077 - Train Accuracy: 0.7817, Validation Accuracy: 0.7624, Loss: 0.2005
Epoch  52 Batch  350/1077 - Train Accuracy: 0.7805, Validation Accuracy: 0.7592, Loss: 0.1777
Epoch  52 Batch  360/1077 - Train Accuracy: 0.7875, Validation Accuracy: 0.7738, Loss: 0.1777
Epoch  52 Batch  370/1077 - Train Accuracy: 0.8092, Validation Accuracy: 0.7830, Loss: 0.1735
Epoch  52 Batch  380/1077 - Train Accuracy: 0.7918, Validation Accuracy: 0.7859, Loss: 0.1763
Epoch  52 Batch  390/1077 - Train Accuracy: 0.7617, Validation Accuracy: 0.7820, Loss: 0.2063
Epoch  52 Batch  400/1077 - Train Accuracy: 0.7855, Validation Accuracy: 0.7834, Loss: 0.1876
Epoch  52 Batch  410/1077 - Train Accuracy: 0.7640, Validation Accuracy: 0.7724, Loss: 0.2203
Epoch  52 Batch  420/1077 - Train Accuracy: 0.8094, Validation Accuracy: 0.7791, Loss: 0.1672
Epoch  52 Batch  430/1077 - Train Accuracy: 0.7504, Validation Accuracy: 0.7773, Loss: 0.1787
Epoch  52 Batch  440/1077 - Train Accuracy: 0.7555, Validation Accuracy: 0.7738, Loss: 0.1963
Epoch  52 Batch  450/1077 - Train Accuracy: 0.8355, Validation Accuracy: 0.7674, Loss: 0.1773
Epoch  52 Batch  460/1077 - Train Accuracy: 0.7441, Validation Accuracy: 0.7692, Loss: 0.1949
Epoch  52 Batch  470/1077 - Train Accuracy: 0.8137, Validation Accuracy: 0.7731, Loss: 0.1773
Epoch  52 Batch  480/1077 - Train Accuracy: 0.7784, Validation Accuracy: 0.7734, Loss: 0.2013
Epoch  52 Batch  490/1077 - Train Accuracy: 0.7457, Validation Accuracy: 0.7635, Loss: 0.1977
Epoch  52 Batch  500/1077 - Train Accuracy: 0.8258, Validation Accuracy: 0.7827, Loss: 0.1674
Epoch  52 Batch  510/1077 - Train Accuracy: 0.8211, Validation Accuracy: 0.7766, Loss: 0.1895
Epoch  52 Batch  520/1077 - Train Accuracy: 0.8501, Validation Accuracy: 0.7752, Loss: 0.1616
Epoch  52 Batch  530/1077 - Train Accuracy: 0.7578, Validation Accuracy: 0.7802, Loss: 0.1831
Epoch  52 Batch  540/1077 - Train Accuracy: 0.7969, Validation Accuracy: 0.7830, Loss: 0.1776
Epoch  52 Batch  550/1077 - Train Accuracy: 0.7617, Validation Accuracy: 0.7663, Loss: 0.1908
Epoch  52 Batch  560/1077 - Train Accuracy: 0.7820, Validation Accuracy: 0.7791, Loss: 0.1807
Epoch  52 Batch  570/1077 - Train Accuracy: 0.7862, Validation Accuracy: 0.7855, Loss: 0.2147
Epoch  52 Batch  580/1077 - Train Accuracy: 0.8065, Validation Accuracy: 0.7745, Loss: 0.1572
Epoch  52 Batch  590/1077 - Train Accuracy: 0.7574, Validation Accuracy: 0.7770, Loss: 0.2081
Epoch  52 Batch  600/1077 - Train Accuracy: 0.8162, Validation Accuracy: 0.7788, Loss: 0.1720
Epoch  52 Batch  610/1077 - Train Accuracy: 0.7734, Validation Accuracy: 0.7749, Loss: 0.1951
Epoch  52 Batch  620/1077 - Train Accuracy: 0.7895, Validation Accuracy: 0.7756, Loss: 0.1592
Epoch  52 Batch  630/1077 - Train Accuracy: 0.7629, Validation Accuracy: 0.7727, Loss: 0.1847
Epoch  52 Batch  640/1077 - Train Accuracy: 0.7842, Validation Accuracy: 0.7791, Loss: 0.1763
Epoch  52 Batch  650/1077 - Train Accuracy: 0.7727, Validation Accuracy: 0.7880, Loss: 0.1931
Epoch  52 Batch  660/1077 - Train Accuracy: 0.7957, Validation Accuracy: 0.7894, Loss: 0.1866
Epoch  52 Batch  670/1077 - Train Accuracy: 0.7972, Validation Accuracy: 0.7745, Loss: 0.1804
Epoch  52 Batch  680/1077 - Train Accuracy: 0.7682, Validation Accuracy: 0.7784, Loss: 0.1928
Epoch  52 Batch  690/1077 - Train Accuracy: 0.7992, Validation Accuracy: 0.7745, Loss: 0.1790
Epoch  52 Batch  700/1077 - Train Accuracy: 0.7984, Validation Accuracy: 0.7638, Loss: 0.1636
Epoch  52 Batch  710/1077 - Train Accuracy: 0.7586, Validation Accuracy: 0.7685, Loss: 0.1764
Epoch  52 Batch  720/1077 - Train Accuracy: 0.8006, Validation Accuracy: 0.7773, Loss: 0.1803
Epoch  52 Batch  730/1077 - Train Accuracy: 0.7590, Validation Accuracy: 0.7770, Loss: 0.2009
Epoch  52 Batch  740/1077 - Train Accuracy: 0.7852, Validation Accuracy: 0.7649, Loss: 0.1769
Epoch  52 Batch  750/1077 - Train Accuracy: 0.7887, Validation Accuracy: 0.7841, Loss: 0.1920
Epoch  52 Batch  760/1077 - Train Accuracy: 0.7828, Validation Accuracy: 0.7805, Loss: 0.1884
Epoch  52 Batch  770/1077 - Train Accuracy: 0.7924, Validation Accuracy: 0.7781, Loss: 0.1733
Epoch  52 Batch  780/1077 - Train Accuracy: 0.7680, Validation Accuracy: 0.7798, Loss: 0.1979
Epoch  52 Batch  790/1077 - Train Accuracy: 0.7207, Validation Accuracy: 0.7798, Loss: 0.1978
Epoch  52 Batch  800/1077 - Train Accuracy: 0.7770, Validation Accuracy: 0.7887, Loss: 0.1776
Epoch  52 Batch  810/1077 - Train Accuracy: 0.7723, Validation Accuracy: 0.7738, Loss: 0.1676
Epoch  52 Batch  820/1077 - Train Accuracy: 0.7453, Validation Accuracy: 0.7763, Loss: 0.1918
Epoch  52 Batch  830/1077 - Train Accuracy: 0.7629, Validation Accuracy: 0.7717, Loss: 0.1899
Epoch  52 Batch  840/1077 - Train Accuracy: 0.8121, Validation Accuracy: 0.7795, Loss: 0.1717
Epoch  52 Batch  850/1077 - Train Accuracy: 0.7407, Validation Accuracy: 0.7781, Loss: 0.2022
Epoch  52 Batch  860/1077 - Train Accuracy: 0.7775, Validation Accuracy: 0.7784, Loss: 0.1841
Epoch  52 Batch  870/1077 - Train Accuracy: 0.7714, Validation Accuracy: 0.7713, Loss: 0.1844
Epoch  52 Batch  880/1077 - Train Accuracy: 0.8156, Validation Accuracy: 0.7791, Loss: 0.1678
Epoch  52 Batch  890/1077 - Train Accuracy: 0.8393, Validation Accuracy: 0.7724, Loss: 0.1590
Epoch  52 Batch  900/1077 - Train Accuracy: 0.8219, Validation Accuracy: 0.7685, Loss: 0.1785
Epoch  52 Batch  910/1077 - Train Accuracy: 0.8006, Validation Accuracy: 0.7660, Loss: 0.1780
Epoch  52 Batch  920/1077 - Train Accuracy: 0.7855, Validation Accuracy: 0.7788, Loss: 0.1975
Epoch  52 Batch  930/1077 - Train Accuracy: 0.8082, Validation Accuracy: 0.7784, Loss: 0.1810
Epoch  52 Batch  940/1077 - Train Accuracy: 0.7883, Validation Accuracy: 0.7749, Loss: 0.1699
Epoch  52 Batch  950/1077 - Train Accuracy: 0.7898, Validation Accuracy: 0.7766, Loss: 0.1690
Epoch  52 Batch  960/1077 - Train Accuracy: 0.7894, Validation Accuracy: 0.7791, Loss: 0.1845
Epoch  52 Batch  970/1077 - Train Accuracy: 0.7934, Validation Accuracy: 0.7734, Loss: 0.1812
Epoch  52 Batch  980/1077 - Train Accuracy: 0.7453, Validation Accuracy: 0.7805, Loss: 0.1988
Epoch  52 Batch  990/1077 - Train Accuracy: 0.7788, Validation Accuracy: 0.7802, Loss: 0.1841
Epoch  52 Batch 1000/1077 - Train Accuracy: 0.8121, Validation Accuracy: 0.7756, Loss: 0.1758
Epoch  52 Batch 1010/1077 - Train Accuracy: 0.7688, Validation Accuracy: 0.7734, Loss: 0.1719
Epoch  52 Batch 1020/1077 - Train Accuracy: 0.7715, Validation Accuracy: 0.7816, Loss: 0.1711
Epoch  52 Batch 1030/1077 - Train Accuracy: 0.7629, Validation Accuracy: 0.7724, Loss: 0.1811
Epoch  52 Batch 1040/1077 - Train Accuracy: 0.8080, Validation Accuracy: 0.7653, Loss: 0.1963
Epoch  52 Batch 1050/1077 - Train Accuracy: 0.7410, Validation Accuracy: 0.7678, Loss: 0.2006
Epoch  52 Batch 1060/1077 - Train Accuracy: 0.8172, Validation Accuracy: 0.7727, Loss: 0.1585
Epoch  52 Batch 1070/1077 - Train Accuracy: 0.7691, Validation Accuracy: 0.7791, Loss: 0.1805
Epoch  53 Batch   10/1077 - Train Accuracy: 0.7969, Validation Accuracy: 0.7812, Loss: 0.1829
Epoch  53 Batch   20/1077 - Train Accuracy: 0.7773, Validation Accuracy: 0.7873, Loss: 0.1648
Epoch  53 Batch   30/1077 - Train Accuracy: 0.8184, Validation Accuracy: 0.7830, Loss: 0.1805
Epoch  53 Batch   40/1077 - Train Accuracy: 0.8230, Validation Accuracy: 0.7745, Loss: 0.1765
Epoch  53 Batch   50/1077 - Train Accuracy: 0.7707, Validation Accuracy: 0.7848, Loss: 0.1894
Epoch  53 Batch   60/1077 - Train Accuracy: 0.8140, Validation Accuracy: 0.7749, Loss: 0.1702
Epoch  53 Batch   70/1077 - Train Accuracy: 0.8166, Validation Accuracy: 0.7692, Loss: 0.1836
Epoch  53 Batch   80/1077 - Train Accuracy: 0.7766, Validation Accuracy: 0.7809, Loss: 0.1811
Epoch  53 Batch   90/1077 - Train Accuracy: 0.7590, Validation Accuracy: 0.7820, Loss: 0.1874
Epoch  53 Batch  100/1077 - Train Accuracy: 0.7652, Validation Accuracy: 0.7784, Loss: 0.1735
Epoch  53 Batch  110/1077 - Train Accuracy: 0.7914, Validation Accuracy: 0.7734, Loss: 0.1619
Epoch  53 Batch  120/1077 - Train Accuracy: 0.8066, Validation Accuracy: 0.7816, Loss: 0.2051
Epoch  53 Batch  130/1077 - Train Accuracy: 0.7645, Validation Accuracy: 0.7770, Loss: 0.1793
Epoch  53 Batch  140/1077 - Train Accuracy: 0.8039, Validation Accuracy: 0.7781, Loss: 0.1845
Epoch  53 Batch  150/1077 - Train Accuracy: 0.8062, Validation Accuracy: 0.7734, Loss: 0.1692
Epoch  53 Batch  160/1077 - Train Accuracy: 0.7902, Validation Accuracy: 0.7585, Loss: 0.1817
Epoch  53 Batch  170/1077 - Train Accuracy: 0.7465, Validation Accuracy: 0.7763, Loss: 0.1927
Epoch  53 Batch  180/1077 - Train Accuracy: 0.8059, Validation Accuracy: 0.7759, Loss: 0.1793
Epoch  53 Batch  190/1077 - Train Accuracy: 0.8387, Validation Accuracy: 0.7756, Loss: 0.1784
Epoch  53 Batch  200/1077 - Train Accuracy: 0.7934, Validation Accuracy: 0.7876, Loss: 0.1789
Epoch  53 Batch  210/1077 - Train Accuracy: 0.7984, Validation Accuracy: 0.7667, Loss: 0.1883
Epoch  53 Batch  220/1077 - Train Accuracy: 0.7928, Validation Accuracy: 0.7695, Loss: 0.1860
Epoch  53 Batch  230/1077 - Train Accuracy: 0.7876, Validation Accuracy: 0.7802, Loss: 0.1746
Epoch  53 Batch  240/1077 - Train Accuracy: 0.8316, Validation Accuracy: 0.7702, Loss: 0.1709
Epoch  53 Batch  250/1077 - Train Accuracy: 0.7923, Validation Accuracy: 0.7766, Loss: 0.1948
Epoch  53 Batch  260/1077 - Train Accuracy: 0.8240, Validation Accuracy: 0.7848, Loss: 0.1773
Epoch  53 Batch  270/1077 - Train Accuracy: 0.7824, Validation Accuracy: 0.7827, Loss: 0.2116
Epoch  53 Batch  280/1077 - Train Accuracy: 0.7941, Validation Accuracy: 0.7855, Loss: 0.1843
Epoch  53 Batch  290/1077 - Train Accuracy: 0.7809, Validation Accuracy: 0.7795, Loss: 0.1975
Epoch  53 Batch  300/1077 - Train Accuracy: 0.7850, Validation Accuracy: 0.7731, Loss: 0.1940
Epoch  53 Batch  310/1077 - Train Accuracy: 0.7527, Validation Accuracy: 0.7773, Loss: 0.1920
Epoch  53 Batch  320/1077 - Train Accuracy: 0.8336, Validation Accuracy: 0.7724, Loss: 0.2148
Epoch  53 Batch  330/1077 - Train Accuracy: 0.7918, Validation Accuracy: 0.7699, Loss: 0.1793
Epoch  53 Batch  340/1077 - Train Accuracy: 0.7845, Validation Accuracy: 0.7642, Loss: 0.1698
Epoch  53 Batch  350/1077 - Train Accuracy: 0.7863, Validation Accuracy: 0.7766, Loss: 0.1778
Epoch  53 Batch  360/1077 - Train Accuracy: 0.7867, Validation Accuracy: 0.7802, Loss: 0.1774
Epoch  53 Batch  370/1077 - Train Accuracy: 0.7991, Validation Accuracy: 0.7784, Loss: 0.1800
Epoch  53 Batch  380/1077 - Train Accuracy: 0.7937, Validation Accuracy: 0.7741, Loss: 0.1596
Epoch  53 Batch  390/1077 - Train Accuracy: 0.7531, Validation Accuracy: 0.7812, Loss: 0.1985
Epoch  53 Batch  400/1077 - Train Accuracy: 0.8109, Validation Accuracy: 0.7678, Loss: 0.2024
Epoch  53 Batch  410/1077 - Train Accuracy: 0.7673, Validation Accuracy: 0.7770, Loss: 0.2038
Epoch  53 Batch  420/1077 - Train Accuracy: 0.8137, Validation Accuracy: 0.7749, Loss: 0.1807
Epoch  53 Batch  430/1077 - Train Accuracy: 0.7570, Validation Accuracy: 0.7724, Loss: 0.1763
Epoch  53 Batch  440/1077 - Train Accuracy: 0.7516, Validation Accuracy: 0.7702, Loss: 0.2044
Epoch  53 Batch  450/1077 - Train Accuracy: 0.8258, Validation Accuracy: 0.7660, Loss: 0.1702
Epoch  53 Batch  460/1077 - Train Accuracy: 0.7445, Validation Accuracy: 0.7607, Loss: 0.1860
Epoch  53 Batch  470/1077 - Train Accuracy: 0.7981, Validation Accuracy: 0.7571, Loss: 0.1773
Epoch  53 Batch  480/1077 - Train Accuracy: 0.7800, Validation Accuracy: 0.7940, Loss: 0.1907
Epoch  53 Batch  490/1077 - Train Accuracy: 0.7688, Validation Accuracy: 0.7738, Loss: 0.1855
Epoch  53 Batch  500/1077 - Train Accuracy: 0.8262, Validation Accuracy: 0.7713, Loss: 0.1766
Epoch  53 Batch  510/1077 - Train Accuracy: 0.8090, Validation Accuracy: 0.7844, Loss: 0.1906
Epoch  53 Batch  520/1077 - Train Accuracy: 0.8527, Validation Accuracy: 0.7763, Loss: 0.1615
Epoch  53 Batch  530/1077 - Train Accuracy: 0.7652, Validation Accuracy: 0.7678, Loss: 0.1878
Epoch  53 Batch  540/1077 - Train Accuracy: 0.7934, Validation Accuracy: 0.7667, Loss: 0.1782
Epoch  53 Batch  550/1077 - Train Accuracy: 0.7652, Validation Accuracy: 0.7741, Loss: 0.1820
Epoch  53 Batch  560/1077 - Train Accuracy: 0.8039, Validation Accuracy: 0.7727, Loss: 0.1740
Epoch  53 Batch  570/1077 - Train Accuracy: 0.7825, Validation Accuracy: 0.7717, Loss: 0.1898
Epoch  53 Batch  580/1077 - Train Accuracy: 0.8043, Validation Accuracy: 0.7738, Loss: 0.1598
Epoch  53 Batch  590/1077 - Train Accuracy: 0.7623, Validation Accuracy: 0.7752, Loss: 0.1937
Epoch  53 Batch  600/1077 - Train Accuracy: 0.8181, Validation Accuracy: 0.7805, Loss: 0.1752
Epoch  53 Batch  610/1077 - Train Accuracy: 0.7825, Validation Accuracy: 0.7876, Loss: 0.1764
Epoch  53 Batch  620/1077 - Train Accuracy: 0.7809, Validation Accuracy: 0.7692, Loss: 0.1676
Epoch  53 Batch  630/1077 - Train Accuracy: 0.7684, Validation Accuracy: 0.7766, Loss: 0.1766
Epoch  53 Batch  640/1077 - Train Accuracy: 0.7842, Validation Accuracy: 0.7901, Loss: 0.1638
Epoch  53 Batch  650/1077 - Train Accuracy: 0.7758, Validation Accuracy: 0.7908, Loss: 0.1810
Epoch  53 Batch  660/1077 - Train Accuracy: 0.8039, Validation Accuracy: 0.7852, Loss: 0.1840
Epoch  53 Batch  670/1077 - Train Accuracy: 0.7969, Validation Accuracy: 0.7766, Loss: 0.1705
Epoch  53 Batch  680/1077 - Train Accuracy: 0.7738, Validation Accuracy: 0.7738, Loss: 0.1877
Epoch  53 Batch  690/1077 - Train Accuracy: 0.8113, Validation Accuracy: 0.7809, Loss: 0.1762
Epoch  53 Batch  700/1077 - Train Accuracy: 0.7973, Validation Accuracy: 0.7823, Loss: 0.1685
Epoch  53 Batch  710/1077 - Train Accuracy: 0.7574, Validation Accuracy: 0.7837, Loss: 0.1721
Epoch  53 Batch  720/1077 - Train Accuracy: 0.7882, Validation Accuracy: 0.7791, Loss: 0.1906
Epoch  53 Batch  730/1077 - Train Accuracy: 0.7578, Validation Accuracy: 0.7791, Loss: 0.1920
Epoch  53 Batch  740/1077 - Train Accuracy: 0.7770, Validation Accuracy: 0.7880, Loss: 0.1761
Epoch  53 Batch  750/1077 - Train Accuracy: 0.7816, Validation Accuracy: 0.7869, Loss: 0.1870
Epoch  53 Batch  760/1077 - Train Accuracy: 0.7812, Validation Accuracy: 0.7912, Loss: 0.1881
Epoch  53 Batch  770/1077 - Train Accuracy: 0.7891, Validation Accuracy: 0.7919, Loss: 0.1707
Epoch  53 Batch  780/1077 - Train Accuracy: 0.7789, Validation Accuracy: 0.7773, Loss: 0.1996
Epoch  53 Batch  790/1077 - Train Accuracy: 0.7195, Validation Accuracy: 0.7741, Loss: 0.1977
Epoch  53 Batch  800/1077 - Train Accuracy: 0.7754, Validation Accuracy: 0.7855, Loss: 0.1721
Epoch  53 Batch  810/1077 - Train Accuracy: 0.7731, Validation Accuracy: 0.7891, Loss: 0.1683
Epoch  53 Batch  820/1077 - Train Accuracy: 0.7414, Validation Accuracy: 0.7894, Loss: 0.1913
Epoch  53 Batch  830/1077 - Train Accuracy: 0.7566, Validation Accuracy: 0.7745, Loss: 0.1839
Epoch  53 Batch  840/1077 - Train Accuracy: 0.8133, Validation Accuracy: 0.7873, Loss: 0.1859
Epoch  53 Batch  850/1077 - Train Accuracy: 0.7563, Validation Accuracy: 0.7841, Loss: 0.2080
Epoch  53 Batch  860/1077 - Train Accuracy: 0.7794, Validation Accuracy: 0.7841, Loss: 0.1840
Epoch  53 Batch  870/1077 - Train Accuracy: 0.7607, Validation Accuracy: 0.7699, Loss: 0.1954
Epoch  53 Batch  880/1077 - Train Accuracy: 0.8109, Validation Accuracy: 0.7859, Loss: 0.1748
Epoch  53 Batch  890/1077 - Train Accuracy: 0.8426, Validation Accuracy: 0.7823, Loss: 0.1723
Epoch  53 Batch  900/1077 - Train Accuracy: 0.8137, Validation Accuracy: 0.7759, Loss: 0.1872
Epoch  53 Batch  910/1077 - Train Accuracy: 0.8010, Validation Accuracy: 0.7756, Loss: 0.1954
Epoch  53 Batch  920/1077 - Train Accuracy: 0.7840, Validation Accuracy: 0.7887, Loss: 0.1826
Epoch  53 Batch  930/1077 - Train Accuracy: 0.8012, Validation Accuracy: 0.7741, Loss: 0.1853
Epoch  53 Batch  940/1077 - Train Accuracy: 0.7965, Validation Accuracy: 0.7795, Loss: 0.1654
Epoch  53 Batch  950/1077 - Train Accuracy: 0.7820, Validation Accuracy: 0.7724, Loss: 0.1736
Epoch  53 Batch  960/1077 - Train Accuracy: 0.7824, Validation Accuracy: 0.7681, Loss: 0.1736
Epoch  53 Batch  970/1077 - Train Accuracy: 0.7937, Validation Accuracy: 0.7756, Loss: 0.1811
Epoch  53 Batch  980/1077 - Train Accuracy: 0.7410, Validation Accuracy: 0.7766, Loss: 0.2030
Epoch  53 Batch  990/1077 - Train Accuracy: 0.7722, Validation Accuracy: 0.7827, Loss: 0.1800
Epoch  53 Batch 1000/1077 - Train Accuracy: 0.8121, Validation Accuracy: 0.7688, Loss: 0.1664
Epoch  53 Batch 1010/1077 - Train Accuracy: 0.7840, Validation Accuracy: 0.7731, Loss: 0.1717
Epoch  53 Batch 1020/1077 - Train Accuracy: 0.7645, Validation Accuracy: 0.7756, Loss: 0.1775
Epoch  53 Batch 1030/1077 - Train Accuracy: 0.7695, Validation Accuracy: 0.7784, Loss: 0.2045
Epoch  53 Batch 1040/1077 - Train Accuracy: 0.8039, Validation Accuracy: 0.7727, Loss: 0.1796
Epoch  53 Batch 1050/1077 - Train Accuracy: 0.7594, Validation Accuracy: 0.7830, Loss: 0.1747
Epoch  53 Batch 1060/1077 - Train Accuracy: 0.8109, Validation Accuracy: 0.7788, Loss: 0.1605
Epoch  53 Batch 1070/1077 - Train Accuracy: 0.7637, Validation Accuracy: 0.7766, Loss: 0.1817
Epoch  54 Batch   10/1077 - Train Accuracy: 0.8240, Validation Accuracy: 0.7802, Loss: 0.1886
Epoch  54 Batch   20/1077 - Train Accuracy: 0.7688, Validation Accuracy: 0.7777, Loss: 0.1743
Epoch  54 Batch   30/1077 - Train Accuracy: 0.8070, Validation Accuracy: 0.7805, Loss: 0.1708
Epoch  54 Batch   40/1077 - Train Accuracy: 0.8332, Validation Accuracy: 0.7816, Loss: 0.1733
Epoch  54 Batch   50/1077 - Train Accuracy: 0.7641, Validation Accuracy: 0.7862, Loss: 0.1807
Epoch  54 Batch   60/1077 - Train Accuracy: 0.7984, Validation Accuracy: 0.7805, Loss: 0.1744
Epoch  54 Batch   70/1077 - Train Accuracy: 0.8331, Validation Accuracy: 0.7848, Loss: 0.1982
Epoch  54 Batch   80/1077 - Train Accuracy: 0.7703, Validation Accuracy: 0.7802, Loss: 0.2033
Epoch  54 Batch   90/1077 - Train Accuracy: 0.7605, Validation Accuracy: 0.7759, Loss: 0.1897
Epoch  54 Batch  100/1077 - Train Accuracy: 0.7617, Validation Accuracy: 0.7784, Loss: 0.1705
Epoch  54 Batch  110/1077 - Train Accuracy: 0.7945, Validation Accuracy: 0.7912, Loss: 0.1654
Epoch  54 Batch  120/1077 - Train Accuracy: 0.8133, Validation Accuracy: 0.7944, Loss: 0.1771
Epoch  54 Batch  130/1077 - Train Accuracy: 0.7630, Validation Accuracy: 0.7862, Loss: 0.1724
Epoch  54 Batch  140/1077 - Train Accuracy: 0.7891, Validation Accuracy: 0.7784, Loss: 0.1822
Epoch  54 Batch  150/1077 - Train Accuracy: 0.7906, Validation Accuracy: 0.7738, Loss: 0.1785
Epoch  54 Batch  160/1077 - Train Accuracy: 0.8012, Validation Accuracy: 0.7816, Loss: 0.1751
Epoch  54 Batch  170/1077 - Train Accuracy: 0.7695, Validation Accuracy: 0.7681, Loss: 0.1902
Epoch  54 Batch  180/1077 - Train Accuracy: 0.8047, Validation Accuracy: 0.7756, Loss: 0.1683
Epoch  54 Batch  190/1077 - Train Accuracy: 0.8527, Validation Accuracy: 0.7784, Loss: 0.1888
Epoch  54 Batch  200/1077 - Train Accuracy: 0.7770, Validation Accuracy: 0.7752, Loss: 0.1884
Epoch  54 Batch  210/1077 - Train Accuracy: 0.7939, Validation Accuracy: 0.7770, Loss: 0.1782
Epoch  54 Batch  220/1077 - Train Accuracy: 0.7854, Validation Accuracy: 0.7834, Loss: 0.1785
Epoch  54 Batch  230/1077 - Train Accuracy: 0.7913, Validation Accuracy: 0.7873, Loss: 0.1710
Epoch  54 Batch  240/1077 - Train Accuracy: 0.8418, Validation Accuracy: 0.7820, Loss: 0.1800
Epoch  54 Batch  250/1077 - Train Accuracy: 0.7805, Validation Accuracy: 0.7692, Loss: 0.1659
Epoch  54 Batch  260/1077 - Train Accuracy: 0.8095, Validation Accuracy: 0.7930, Loss: 0.1653
Epoch  54 Batch  270/1077 - Train Accuracy: 0.7922, Validation Accuracy: 0.7823, Loss: 0.2016
Epoch  54 Batch  280/1077 - Train Accuracy: 0.8027, Validation Accuracy: 0.7756, Loss: 0.1927
Epoch  54 Batch  290/1077 - Train Accuracy: 0.7863, Validation Accuracy: 0.7837, Loss: 0.1795
Epoch  54 Batch  300/1077 - Train Accuracy: 0.7796, Validation Accuracy: 0.7656, Loss: 0.1751
Epoch  54 Batch  310/1077 - Train Accuracy: 0.7578, Validation Accuracy: 0.7741, Loss: 0.1981
Epoch  54 Batch  320/1077 - Train Accuracy: 0.8105, Validation Accuracy: 0.7844, Loss: 0.2340
Epoch  54 Batch  330/1077 - Train Accuracy: 0.7871, Validation Accuracy: 0.7812, Loss: 0.1772
Epoch  54 Batch  340/1077 - Train Accuracy: 0.7804, Validation Accuracy: 0.7812, Loss: 0.1903
Epoch  54 Batch  350/1077 - Train Accuracy: 0.7746, Validation Accuracy: 0.7781, Loss: 0.1670
Epoch  54 Batch  360/1077 - Train Accuracy: 0.7801, Validation Accuracy: 0.7759, Loss: 0.1853
Epoch  54 Batch  370/1077 - Train Accuracy: 0.8047, Validation Accuracy: 0.7763, Loss: 0.1723
Epoch  54 Batch  380/1077 - Train Accuracy: 0.8000, Validation Accuracy: 0.7738, Loss: 0.1594
Epoch  54 Batch  390/1077 - Train Accuracy: 0.7605, Validation Accuracy: 0.7827, Loss: 0.1998
Epoch  54 Batch  400/1077 - Train Accuracy: 0.7984, Validation Accuracy: 0.7731, Loss: 0.1883
Epoch  54 Batch  410/1077 - Train Accuracy: 0.7796, Validation Accuracy: 0.7777, Loss: 0.2026
Epoch  54 Batch  420/1077 - Train Accuracy: 0.8164, Validation Accuracy: 0.7773, Loss: 0.1598
Epoch  54 Batch  430/1077 - Train Accuracy: 0.7570, Validation Accuracy: 0.7713, Loss: 0.1824
Epoch  54 Batch  440/1077 - Train Accuracy: 0.7480, Validation Accuracy: 0.7731, Loss: 0.2204
Epoch  54 Batch  450/1077 - Train Accuracy: 0.8281, Validation Accuracy: 0.7738, Loss: 0.1796
Epoch  54 Batch  460/1077 - Train Accuracy: 0.7520, Validation Accuracy: 0.7607, Loss: 0.1879
Epoch  54 Batch  470/1077 - Train Accuracy: 0.7952, Validation Accuracy: 0.7749, Loss: 0.1819
Epoch  54 Batch  480/1077 - Train Accuracy: 0.7800, Validation Accuracy: 0.7624, Loss: 0.1768
Epoch  54 Batch  490/1077 - Train Accuracy: 0.7617, Validation Accuracy: 0.7802, Loss: 0.1870
Epoch  54 Batch  500/1077 - Train Accuracy: 0.8219, Validation Accuracy: 0.7876, Loss: 0.1694
Epoch  54 Batch  510/1077 - Train Accuracy: 0.8121, Validation Accuracy: 0.7784, Loss: 0.1843
Epoch  54 Batch  520/1077 - Train Accuracy: 0.8434, Validation Accuracy: 0.7727, Loss: 0.1650
Epoch  54 Batch  530/1077 - Train Accuracy: 0.7523, Validation Accuracy: 0.7681, Loss: 0.1894
Epoch  54 Batch  540/1077 - Train Accuracy: 0.8074, Validation Accuracy: 0.7880, Loss: 0.1713
Epoch  54 Batch  550/1077 - Train Accuracy: 0.7660, Validation Accuracy: 0.7781, Loss: 0.1962
Epoch  54 Batch  560/1077 - Train Accuracy: 0.7980, Validation Accuracy: 0.7894, Loss: 0.1811
Epoch  54 Batch  570/1077 - Train Accuracy: 0.7928, Validation Accuracy: 0.7876, Loss: 0.1797
Epoch  54 Batch  580/1077 - Train Accuracy: 0.8062, Validation Accuracy: 0.7784, Loss: 0.1555
Epoch  54 Batch  590/1077 - Train Accuracy: 0.7669, Validation Accuracy: 0.7809, Loss: 0.1932
Epoch  54 Batch  600/1077 - Train Accuracy: 0.8218, Validation Accuracy: 0.7951, Loss: 0.1755
Epoch  54 Batch  610/1077 - Train Accuracy: 0.7681, Validation Accuracy: 0.7901, Loss: 0.1879
Epoch  54 Batch  620/1077 - Train Accuracy: 0.7770, Validation Accuracy: 0.7894, Loss: 0.1609
Epoch  54 Batch  630/1077 - Train Accuracy: 0.7625, Validation Accuracy: 0.7884, Loss: 0.1740
Epoch  54 Batch  640/1077 - Train Accuracy: 0.7961, Validation Accuracy: 0.8018, Loss: 0.1677
Epoch  54 Batch  650/1077 - Train Accuracy: 0.7840, Validation Accuracy: 0.7955, Loss: 0.1771
Epoch  54 Batch  660/1077 - Train Accuracy: 0.8023, Validation Accuracy: 0.7937, Loss: 0.1687
Epoch  54 Batch  670/1077 - Train Accuracy: 0.8011, Validation Accuracy: 0.7933, Loss: 0.1634
Epoch  54 Batch  680/1077 - Train Accuracy: 0.7798, Validation Accuracy: 0.7887, Loss: 0.1870
Epoch  54 Batch  690/1077 - Train Accuracy: 0.8051, Validation Accuracy: 0.7905, Loss: 0.1753
Epoch  54 Batch  700/1077 - Train Accuracy: 0.8164, Validation Accuracy: 0.7784, Loss: 0.1730
Epoch  54 Batch  710/1077 - Train Accuracy: 0.7348, Validation Accuracy: 0.7773, Loss: 0.1894
Epoch  54 Batch  720/1077 - Train Accuracy: 0.7919, Validation Accuracy: 0.7919, Loss: 0.1946
Epoch  54 Batch  730/1077 - Train Accuracy: 0.7496, Validation Accuracy: 0.7741, Loss: 0.1728
Epoch  54 Batch  740/1077 - Train Accuracy: 0.7801, Validation Accuracy: 0.7614, Loss: 0.1671
Epoch  54 Batch  750/1077 - Train Accuracy: 0.7754, Validation Accuracy: 0.7830, Loss: 0.1726
Epoch  54 Batch  760/1077 - Train Accuracy: 0.7891, Validation Accuracy: 0.7862, Loss: 0.1859
Epoch  54 Batch  770/1077 - Train Accuracy: 0.7909, Validation Accuracy: 0.7859, Loss: 0.1666
Epoch  54 Batch  780/1077 - Train Accuracy: 0.7742, Validation Accuracy: 0.7784, Loss: 0.1931
Epoch  54 Batch  790/1077 - Train Accuracy: 0.7180, Validation Accuracy: 0.7656, Loss: 0.1903
Epoch  54 Batch  800/1077 - Train Accuracy: 0.7871, Validation Accuracy: 0.7770, Loss: 0.1681
Epoch  54 Batch  810/1077 - Train Accuracy: 0.7879, Validation Accuracy: 0.7763, Loss: 0.1765
Epoch  54 Batch  820/1077 - Train Accuracy: 0.7551, Validation Accuracy: 0.7894, Loss: 0.1986
Epoch  54 Batch  830/1077 - Train Accuracy: 0.7711, Validation Accuracy: 0.7816, Loss: 0.1731
Epoch  54 Batch  840/1077 - Train Accuracy: 0.8117, Validation Accuracy: 0.7908, Loss: 0.1659
Epoch  54 Batch  850/1077 - Train Accuracy: 0.7478, Validation Accuracy: 0.7841, Loss: 0.2072
Epoch  54 Batch  860/1077 - Train Accuracy: 0.7835, Validation Accuracy: 0.7805, Loss: 0.1853
Epoch  54 Batch  870/1077 - Train Accuracy: 0.7714, Validation Accuracy: 0.7837, Loss: 0.1876
Epoch  54 Batch  880/1077 - Train Accuracy: 0.8141, Validation Accuracy: 0.7781, Loss: 0.1722
Epoch  54 Batch  890/1077 - Train Accuracy: 0.8408, Validation Accuracy: 0.7827, Loss: 0.1700
Epoch  54 Batch  900/1077 - Train Accuracy: 0.8273, Validation Accuracy: 0.7802, Loss: 0.2074
Epoch  54 Batch  910/1077 - Train Accuracy: 0.8095, Validation Accuracy: 0.7887, Loss: 0.1901
Epoch  54 Batch  920/1077 - Train Accuracy: 0.7875, Validation Accuracy: 0.7901, Loss: 0.1741
Epoch  54 Batch  930/1077 - Train Accuracy: 0.8020, Validation Accuracy: 0.7933, Loss: 0.1725
Epoch  54 Batch  940/1077 - Train Accuracy: 0.8047, Validation Accuracy: 0.7844, Loss: 0.1718
Epoch  54 Batch  950/1077 - Train Accuracy: 0.7917, Validation Accuracy: 0.7802, Loss: 0.1637
Epoch  54 Batch  960/1077 - Train Accuracy: 0.7958, Validation Accuracy: 0.7788, Loss: 0.1771
Epoch  54 Batch  970/1077 - Train Accuracy: 0.7988, Validation Accuracy: 0.7816, Loss: 0.2007
Epoch  54 Batch  980/1077 - Train Accuracy: 0.7480, Validation Accuracy: 0.7844, Loss: 0.1964
Epoch  54 Batch  990/1077 - Train Accuracy: 0.7874, Validation Accuracy: 0.7891, Loss: 0.1840
Epoch  54 Batch 1000/1077 - Train Accuracy: 0.8125, Validation Accuracy: 0.7798, Loss: 0.1691
Epoch  54 Batch 1010/1077 - Train Accuracy: 0.8020, Validation Accuracy: 0.7891, Loss: 0.1772
Epoch  54 Batch 1020/1077 - Train Accuracy: 0.7730, Validation Accuracy: 0.7855, Loss: 0.1793
Epoch  54 Batch 1030/1077 - Train Accuracy: 0.7711, Validation Accuracy: 0.7837, Loss: 0.1887
Epoch  54 Batch 1040/1077 - Train Accuracy: 0.8076, Validation Accuracy: 0.7812, Loss: 0.1734
Epoch  54 Batch 1050/1077 - Train Accuracy: 0.7422, Validation Accuracy: 0.7855, Loss: 0.1846
Epoch  54 Batch 1060/1077 - Train Accuracy: 0.8273, Validation Accuracy: 0.7820, Loss: 0.1613
Epoch  54 Batch 1070/1077 - Train Accuracy: 0.7805, Validation Accuracy: 0.7809, Loss: 0.1868
Epoch  55 Batch   10/1077 - Train Accuracy: 0.8117, Validation Accuracy: 0.7837, Loss: 0.1800
Epoch  55 Batch   20/1077 - Train Accuracy: 0.7758, Validation Accuracy: 0.7781, Loss: 0.1688
Epoch  55 Batch   30/1077 - Train Accuracy: 0.8078, Validation Accuracy: 0.7752, Loss: 0.1752
Epoch  55 Batch   40/1077 - Train Accuracy: 0.8281, Validation Accuracy: 0.7859, Loss: 0.1808
Epoch  55 Batch   50/1077 - Train Accuracy: 0.7711, Validation Accuracy: 0.7759, Loss: 0.1819
Epoch  55 Batch   60/1077 - Train Accuracy: 0.8065, Validation Accuracy: 0.7710, Loss: 0.1537
Epoch  55 Batch   70/1077 - Train Accuracy: 0.8154, Validation Accuracy: 0.7763, Loss: 0.1834
Epoch  55 Batch   80/1077 - Train Accuracy: 0.7766, Validation Accuracy: 0.7834, Loss: 0.1819
Epoch  55 Batch   90/1077 - Train Accuracy: 0.7641, Validation Accuracy: 0.7777, Loss: 0.1930
Epoch  55 Batch  100/1077 - Train Accuracy: 0.7418, Validation Accuracy: 0.7809, Loss: 0.2399
Epoch  55 Batch  110/1077 - Train Accuracy: 0.8023, Validation Accuracy: 0.7798, Loss: 0.1694
Epoch  55 Batch  120/1077 - Train Accuracy: 0.8227, Validation Accuracy: 0.7773, Loss: 0.1985
Epoch  55 Batch  130/1077 - Train Accuracy: 0.7645, Validation Accuracy: 0.7841, Loss: 0.1824
Epoch  55 Batch  140/1077 - Train Accuracy: 0.8183, Validation Accuracy: 0.7766, Loss: 0.1805
Epoch  55 Batch  150/1077 - Train Accuracy: 0.7972, Validation Accuracy: 0.7802, Loss: 0.1653
Epoch  55 Batch  160/1077 - Train Accuracy: 0.8070, Validation Accuracy: 0.7791, Loss: 0.1764
Epoch  55 Batch  170/1077 - Train Accuracy: 0.7609, Validation Accuracy: 0.7720, Loss: 0.2094
Epoch  55 Batch  180/1077 - Train Accuracy: 0.7973, Validation Accuracy: 0.7741, Loss: 0.2621
Epoch  55 Batch  190/1077 - Train Accuracy: 0.8492, Validation Accuracy: 0.7795, Loss: 0.1821
Epoch  55 Batch  200/1077 - Train Accuracy: 0.7879, Validation Accuracy: 0.7866, Loss: 0.1946
Epoch  55 Batch  210/1077 - Train Accuracy: 0.7913, Validation Accuracy: 0.7802, Loss: 0.1845
Epoch  55 Batch  220/1077 - Train Accuracy: 0.7919, Validation Accuracy: 0.7905, Loss: 0.1765
Epoch  55 Batch  230/1077 - Train Accuracy: 0.7932, Validation Accuracy: 0.7898, Loss: 0.1627
Epoch  55 Batch  240/1077 - Train Accuracy: 0.8418, Validation Accuracy: 0.7859, Loss: 0.1685
Epoch  55 Batch  250/1077 - Train Accuracy: 0.7937, Validation Accuracy: 0.7873, Loss: 0.1700
Epoch  55 Batch  260/1077 - Train Accuracy: 0.8054, Validation Accuracy: 0.7827, Loss: 0.1642
Epoch  55 Batch  270/1077 - Train Accuracy: 0.7797, Validation Accuracy: 0.7841, Loss: 0.1888
Epoch  55 Batch  280/1077 - Train Accuracy: 0.8023, Validation Accuracy: 0.7912, Loss: 0.1894
Epoch  55 Batch  290/1077 - Train Accuracy: 0.7828, Validation Accuracy: 0.7894, Loss: 0.1957
Epoch  55 Batch  300/1077 - Train Accuracy: 0.7903, Validation Accuracy: 0.7749, Loss: 0.1693
Epoch  55 Batch  310/1077 - Train Accuracy: 0.7668, Validation Accuracy: 0.7777, Loss: 0.1925
Epoch  55 Batch  320/1077 - Train Accuracy: 0.8250, Validation Accuracy: 0.7724, Loss: 0.2226
Epoch  55 Batch  330/1077 - Train Accuracy: 0.7957, Validation Accuracy: 0.7805, Loss: 0.1882
Epoch  55 Batch  340/1077 - Train Accuracy: 0.7887, Validation Accuracy: 0.7816, Loss: 0.1704
Epoch  55 Batch  350/1077 - Train Accuracy: 0.7879, Validation Accuracy: 0.7798, Loss: 0.1616
Epoch  55 Batch  360/1077 - Train Accuracy: 0.7883, Validation Accuracy: 0.7837, Loss: 0.1833
Epoch  55 Batch  370/1077 - Train Accuracy: 0.7972, Validation Accuracy: 0.7855, Loss: 0.1662
Epoch  55 Batch  380/1077 - Train Accuracy: 0.7922, Validation Accuracy: 0.7848, Loss: 0.1674
Epoch  55 Batch  390/1077 - Train Accuracy: 0.7555, Validation Accuracy: 0.7805, Loss: 0.2050
Epoch  55 Batch  400/1077 - Train Accuracy: 0.7957, Validation Accuracy: 0.7869, Loss: 0.2007
Epoch  55 Batch  410/1077 - Train Accuracy: 0.7767, Validation Accuracy: 0.7880, Loss: 0.1888
Epoch  55 Batch  420/1077 - Train Accuracy: 0.8313, Validation Accuracy: 0.7820, Loss: 0.1881
Epoch  55 Batch  430/1077 - Train Accuracy: 0.7578, Validation Accuracy: 0.7738, Loss: 0.1820
Epoch  55 Batch  440/1077 - Train Accuracy: 0.7453, Validation Accuracy: 0.7741, Loss: 0.1972
Epoch  55 Batch  450/1077 - Train Accuracy: 0.8242, Validation Accuracy: 0.7734, Loss: 0.1863
Epoch  55 Batch  460/1077 - Train Accuracy: 0.7570, Validation Accuracy: 0.7781, Loss: 0.1987
Epoch  55 Batch  470/1077 - Train Accuracy: 0.8014, Validation Accuracy: 0.7781, Loss: 0.1868
Epoch  55 Batch  480/1077 - Train Accuracy: 0.7833, Validation Accuracy: 0.7880, Loss: 0.1806
Epoch  55 Batch  490/1077 - Train Accuracy: 0.7551, Validation Accuracy: 0.7866, Loss: 0.1872
Epoch  55 Batch  500/1077 - Train Accuracy: 0.8281, Validation Accuracy: 0.7859, Loss: 0.1610
Epoch  55 Batch  510/1077 - Train Accuracy: 0.8035, Validation Accuracy: 0.7752, Loss: 0.1797
Epoch  55 Batch  520/1077 - Train Accuracy: 0.8464, Validation Accuracy: 0.7894, Loss: 0.1603
Epoch  55 Batch  530/1077 - Train Accuracy: 0.7539, Validation Accuracy: 0.7852, Loss: 0.1807
Epoch  55 Batch  540/1077 - Train Accuracy: 0.7914, Validation Accuracy: 0.7798, Loss: 0.1831
Epoch  55 Batch  550/1077 - Train Accuracy: 0.7633, Validation Accuracy: 0.7873, Loss: 0.1914
Epoch  55 Batch  560/1077 - Train Accuracy: 0.8047, Validation Accuracy: 0.7905, Loss: 0.1697
Epoch  55 Batch  570/1077 - Train Accuracy: 0.7882, Validation Accuracy: 0.7841, Loss: 0.1882
Epoch  55 Batch  580/1077 - Train Accuracy: 0.7865, Validation Accuracy: 0.7667, Loss: 0.1497
Epoch  55 Batch  590/1077 - Train Accuracy: 0.7673, Validation Accuracy: 0.7837, Loss: 0.1911
Epoch  55 Batch  600/1077 - Train Accuracy: 0.8088, Validation Accuracy: 0.7951, Loss: 0.1736
Epoch  55 Batch  610/1077 - Train Accuracy: 0.7747, Validation Accuracy: 0.7834, Loss: 0.1788
Epoch  55 Batch  620/1077 - Train Accuracy: 0.7844, Validation Accuracy: 0.7830, Loss: 0.1725
Epoch  55 Batch  630/1077 - Train Accuracy: 0.7840, Validation Accuracy: 0.7820, Loss: 0.1828
Epoch  55 Batch  640/1077 - Train Accuracy: 0.7850, Validation Accuracy: 0.7855, Loss: 0.1646
Epoch  55 Batch  650/1077 - Train Accuracy: 0.7766, Validation Accuracy: 0.7841, Loss: 0.1775
Epoch  55 Batch  660/1077 - Train Accuracy: 0.7922, Validation Accuracy: 0.7880, Loss: 0.1744
Epoch  55 Batch  670/1077 - Train Accuracy: 0.7979, Validation Accuracy: 0.7820, Loss: 0.1690
Epoch  55 Batch  680/1077 - Train Accuracy: 0.7727, Validation Accuracy: 0.7777, Loss: 0.1725
Epoch  55 Batch  690/1077 - Train Accuracy: 0.8066, Validation Accuracy: 0.7763, Loss: 0.1717
Epoch  55 Batch  700/1077 - Train Accuracy: 0.7945, Validation Accuracy: 0.7745, Loss: 0.1868
Epoch  55 Batch  710/1077 - Train Accuracy: 0.7414, Validation Accuracy: 0.7905, Loss: 0.1786
Epoch  55 Batch  720/1077 - Train Accuracy: 0.8006, Validation Accuracy: 0.7777, Loss: 0.1887
Epoch  55 Batch  730/1077 - Train Accuracy: 0.7613, Validation Accuracy: 0.7610, Loss: 0.1820
Epoch  55 Batch  740/1077 - Train Accuracy: 0.7805, Validation Accuracy: 0.7674, Loss: 0.1569
Epoch  55 Batch  750/1077 - Train Accuracy: 0.7887, Validation Accuracy: 0.7734, Loss: 0.1707
Epoch  55 Batch  760/1077 - Train Accuracy: 0.7824, Validation Accuracy: 0.7784, Loss: 0.1848
Epoch  55 Batch  770/1077 - Train Accuracy: 0.8039, Validation Accuracy: 0.7947, Loss: 0.1512
Epoch  55 Batch  780/1077 - Train Accuracy: 0.7824, Validation Accuracy: 0.7720, Loss: 0.1855
Epoch  55 Batch  790/1077 - Train Accuracy: 0.7234, Validation Accuracy: 0.7660, Loss: 0.2017
Epoch  55 Batch  800/1077 - Train Accuracy: 0.7906, Validation Accuracy: 0.7862, Loss: 0.1738
Epoch  55 Batch  810/1077 - Train Accuracy: 0.7656, Validation Accuracy: 0.7876, Loss: 0.1807
Epoch  55 Batch  820/1077 - Train Accuracy: 0.7512, Validation Accuracy: 0.7908, Loss: 0.1868
Epoch  55 Batch  830/1077 - Train Accuracy: 0.7562, Validation Accuracy: 0.7770, Loss: 0.1874
Epoch  55 Batch  840/1077 - Train Accuracy: 0.8156, Validation Accuracy: 0.7919, Loss: 0.1781
Epoch  55 Batch  850/1077 - Train Accuracy: 0.7493, Validation Accuracy: 0.7827, Loss: 0.2011
Epoch  55 Batch  860/1077 - Train Accuracy: 0.7839, Validation Accuracy: 0.7827, Loss: 0.1906
Epoch  55 Batch  870/1077 - Train Accuracy: 0.7681, Validation Accuracy: 0.7710, Loss: 0.2069
Epoch  55 Batch  880/1077 - Train Accuracy: 0.8145, Validation Accuracy: 0.7855, Loss: 0.1687
Epoch  55 Batch  890/1077 - Train Accuracy: 0.8378, Validation Accuracy: 0.7802, Loss: 0.1658
Epoch  55 Batch  900/1077 - Train Accuracy: 0.8316, Validation Accuracy: 0.7816, Loss: 0.1729
Epoch  55 Batch  910/1077 - Train Accuracy: 0.8121, Validation Accuracy: 0.7834, Loss: 0.1880
Epoch  55 Batch  920/1077 - Train Accuracy: 0.7937, Validation Accuracy: 0.7802, Loss: 0.1716
Epoch  55 Batch  930/1077 - Train Accuracy: 0.8047, Validation Accuracy: 0.7852, Loss: 0.1595
Epoch  55 Batch  940/1077 - Train Accuracy: 0.8094, Validation Accuracy: 0.7894, Loss: 0.1688
Epoch  55 Batch  950/1077 - Train Accuracy: 0.8114, Validation Accuracy: 0.7781, Loss: 0.1646
Epoch  55 Batch  960/1077 - Train Accuracy: 0.7987, Validation Accuracy: 0.7855, Loss: 0.1728
Epoch  55 Batch  970/1077 - Train Accuracy: 0.7965, Validation Accuracy: 0.7695, Loss: 0.1729
Epoch  55 Batch  980/1077 - Train Accuracy: 0.7363, Validation Accuracy: 0.7738, Loss: 0.1833
Epoch  55 Batch  990/1077 - Train Accuracy: 0.7833, Validation Accuracy: 0.7812, Loss: 0.1833
Epoch  55 Batch 1000/1077 - Train Accuracy: 0.8106, Validation Accuracy: 0.7795, Loss: 0.1726
Epoch  55 Batch 1010/1077 - Train Accuracy: 0.7918, Validation Accuracy: 0.7834, Loss: 0.1777
Epoch  55 Batch 1020/1077 - Train Accuracy: 0.7582, Validation Accuracy: 0.7940, Loss: 0.1740
Epoch  55 Batch 1030/1077 - Train Accuracy: 0.7551, Validation Accuracy: 0.7901, Loss: 0.1854
Epoch  55 Batch 1040/1077 - Train Accuracy: 0.8055, Validation Accuracy: 0.7955, Loss: 0.1766
Epoch  55 Batch 1050/1077 - Train Accuracy: 0.7445, Validation Accuracy: 0.7784, Loss: 0.1718
Epoch  55 Batch 1060/1077 - Train Accuracy: 0.8184, Validation Accuracy: 0.7834, Loss: 0.1548
Epoch  55 Batch 1070/1077 - Train Accuracy: 0.7824, Validation Accuracy: 0.7788, Loss: 0.1758
Epoch  56 Batch   10/1077 - Train Accuracy: 0.8146, Validation Accuracy: 0.7926, Loss: 0.1791
Epoch  56 Batch   20/1077 - Train Accuracy: 0.7820, Validation Accuracy: 0.7940, Loss: 0.1785
Epoch  56 Batch   30/1077 - Train Accuracy: 0.7996, Validation Accuracy: 0.7848, Loss: 0.1772
Epoch  56 Batch   40/1077 - Train Accuracy: 0.8117, Validation Accuracy: 0.7944, Loss: 0.1710
Epoch  56 Batch   50/1077 - Train Accuracy: 0.7652, Validation Accuracy: 0.7884, Loss: 0.1708
Epoch  56 Batch   60/1077 - Train Accuracy: 0.8121, Validation Accuracy: 0.7781, Loss: 0.1544
Epoch  56 Batch   70/1077 - Train Accuracy: 0.8417, Validation Accuracy: 0.7720, Loss: 0.1667
Epoch  56 Batch   80/1077 - Train Accuracy: 0.7910, Validation Accuracy: 0.7788, Loss: 0.1696
Epoch  56 Batch   90/1077 - Train Accuracy: 0.7516, Validation Accuracy: 0.7763, Loss: 0.1788
Epoch  56 Batch  100/1077 - Train Accuracy: 0.7621, Validation Accuracy: 0.7898, Loss: 0.1656
Epoch  56 Batch  110/1077 - Train Accuracy: 0.8016, Validation Accuracy: 0.7919, Loss: 0.1554
Epoch  56 Batch  120/1077 - Train Accuracy: 0.8180, Validation Accuracy: 0.7866, Loss: 0.1764
Epoch  56 Batch  130/1077 - Train Accuracy: 0.7679, Validation Accuracy: 0.7873, Loss: 0.1716
Epoch  56 Batch  140/1077 - Train Accuracy: 0.7928, Validation Accuracy: 0.7848, Loss: 0.1864
Epoch  56 Batch  150/1077 - Train Accuracy: 0.8065, Validation Accuracy: 0.7869, Loss: 0.1655
Epoch  56 Batch  160/1077 - Train Accuracy: 0.8012, Validation Accuracy: 0.7678, Loss: 0.1813
Epoch  56 Batch  170/1077 - Train Accuracy: 0.7668, Validation Accuracy: 0.7788, Loss: 0.1774
Epoch  56 Batch  180/1077 - Train Accuracy: 0.8078, Validation Accuracy: 0.7781, Loss: 0.1688
Epoch  56 Batch  190/1077 - Train Accuracy: 0.8426, Validation Accuracy: 0.7738, Loss: 0.1757
Epoch  56 Batch  200/1077 - Train Accuracy: 0.7926, Validation Accuracy: 0.7834, Loss: 0.1837
Epoch  56 Batch  210/1077 - Train Accuracy: 0.7924, Validation Accuracy: 0.7805, Loss: 0.1698
Epoch  56 Batch  220/1077 - Train Accuracy: 0.7882, Validation Accuracy: 0.7681, Loss: 0.1766
Epoch  56 Batch  230/1077 - Train Accuracy: 0.7820, Validation Accuracy: 0.7741, Loss: 0.1860
Epoch  56 Batch  240/1077 - Train Accuracy: 0.8473, Validation Accuracy: 0.7713, Loss: 0.1801
Epoch  56 Batch  250/1077 - Train Accuracy: 0.7859, Validation Accuracy: 0.7720, Loss: 0.1672
Epoch  56 Batch  260/1077 - Train Accuracy: 0.8196, Validation Accuracy: 0.7795, Loss: 0.1847
Epoch  56 Batch  270/1077 - Train Accuracy: 0.7934, Validation Accuracy: 0.7763, Loss: 0.1903
Epoch  56 Batch  280/1077 - Train Accuracy: 0.8043, Validation Accuracy: 0.7820, Loss: 0.1953
Epoch  56 Batch  290/1077 - Train Accuracy: 0.7891, Validation Accuracy: 0.7713, Loss: 0.2059
Epoch  56 Batch  300/1077 - Train Accuracy: 0.7862, Validation Accuracy: 0.7734, Loss: 0.1684
Epoch  56 Batch  310/1077 - Train Accuracy: 0.7617, Validation Accuracy: 0.7788, Loss: 0.1827
Epoch  56 Batch  320/1077 - Train Accuracy: 0.8176, Validation Accuracy: 0.7837, Loss: 0.1967
Epoch  56 Batch  330/1077 - Train Accuracy: 0.7934, Validation Accuracy: 0.7820, Loss: 0.1699
Epoch  56 Batch  340/1077 - Train Accuracy: 0.7928, Validation Accuracy: 0.7795, Loss: 0.1677
Epoch  56 Batch  350/1077 - Train Accuracy: 0.7766, Validation Accuracy: 0.7859, Loss: 0.1782
Epoch  56 Batch  360/1077 - Train Accuracy: 0.7852, Validation Accuracy: 0.7731, Loss: 0.1686
Epoch  56 Batch  370/1077 - Train Accuracy: 0.8144, Validation Accuracy: 0.7837, Loss: 0.1658
Epoch  56 Batch  380/1077 - Train Accuracy: 0.7961, Validation Accuracy: 0.7915, Loss: 0.1765
Epoch  56 Batch  390/1077 - Train Accuracy: 0.7547, Validation Accuracy: 0.7791, Loss: 0.1881
Epoch  56 Batch  400/1077 - Train Accuracy: 0.8078, Validation Accuracy: 0.7695, Loss: 0.1863
Epoch  56 Batch  410/1077 - Train Accuracy: 0.7681, Validation Accuracy: 0.7898, Loss: 0.1882
Epoch  56 Batch  420/1077 - Train Accuracy: 0.8270, Validation Accuracy: 0.7844, Loss: 0.1563
Epoch  56 Batch  430/1077 - Train Accuracy: 0.7742, Validation Accuracy: 0.7738, Loss: 0.1668
Epoch  56 Batch  440/1077 - Train Accuracy: 0.7469, Validation Accuracy: 0.7646, Loss: 0.1862
Epoch  56 Batch  450/1077 - Train Accuracy: 0.8234, Validation Accuracy: 0.7685, Loss: 0.1698
Epoch  56 Batch  460/1077 - Train Accuracy: 0.7539, Validation Accuracy: 0.7844, Loss: 0.1797
Epoch  56 Batch  470/1077 - Train Accuracy: 0.8104, Validation Accuracy: 0.7784, Loss: 0.1755
Epoch  56 Batch  480/1077 - Train Accuracy: 0.7821, Validation Accuracy: 0.7805, Loss: 0.1752
Epoch  56 Batch  490/1077 - Train Accuracy: 0.7637, Validation Accuracy: 0.7855, Loss: 0.1775
Epoch  56 Batch  500/1077 - Train Accuracy: 0.8289, Validation Accuracy: 0.7781, Loss: 0.1698
Epoch  56 Batch  510/1077 - Train Accuracy: 0.8223, Validation Accuracy: 0.7795, Loss: 0.1811
Epoch  56 Batch  520/1077 - Train Accuracy: 0.8486, Validation Accuracy: 0.7685, Loss: 0.1510
Epoch  56 Batch  530/1077 - Train Accuracy: 0.7543, Validation Accuracy: 0.7830, Loss: 0.1810
Epoch  56 Batch  540/1077 - Train Accuracy: 0.8055, Validation Accuracy: 0.7766, Loss: 0.1669
Epoch  56 Batch  550/1077 - Train Accuracy: 0.7586, Validation Accuracy: 0.7773, Loss: 0.1791
Epoch  56 Batch  560/1077 - Train Accuracy: 0.7984, Validation Accuracy: 0.7724, Loss: 0.1693
Epoch  56 Batch  570/1077 - Train Accuracy: 0.7854, Validation Accuracy: 0.7859, Loss: 0.1943
Epoch  56 Batch  580/1077 - Train Accuracy: 0.7980, Validation Accuracy: 0.7805, Loss: 0.1456
Epoch  56 Batch  590/1077 - Train Accuracy: 0.7611, Validation Accuracy: 0.7855, Loss: 0.2172
Epoch  56 Batch  600/1077 - Train Accuracy: 0.8125, Validation Accuracy: 0.7763, Loss: 0.1788
Epoch  56 Batch  610/1077 - Train Accuracy: 0.7710, Validation Accuracy: 0.7763, Loss: 0.1962
Epoch  56 Batch  620/1077 - Train Accuracy: 0.7820, Validation Accuracy: 0.7741, Loss: 0.1655
Epoch  56 Batch  630/1077 - Train Accuracy: 0.7723, Validation Accuracy: 0.7812, Loss: 0.1784
Epoch  56 Batch  640/1077 - Train Accuracy: 0.7902, Validation Accuracy: 0.7837, Loss: 0.1705
Epoch  56 Batch  650/1077 - Train Accuracy: 0.7828, Validation Accuracy: 0.7848, Loss: 0.1788
Epoch  56 Batch  660/1077 - Train Accuracy: 0.8004, Validation Accuracy: 0.7912, Loss: 0.1736
Epoch  56 Batch  670/1077 - Train Accuracy: 0.7894, Validation Accuracy: 0.7891, Loss: 0.1658
Epoch  56 Batch  680/1077 - Train Accuracy: 0.7719, Validation Accuracy: 0.7741, Loss: 0.2075
Epoch  56 Batch  690/1077 - Train Accuracy: 0.8105, Validation Accuracy: 0.7773, Loss: 0.1765
Epoch  56 Batch  700/1077 - Train Accuracy: 0.7945, Validation Accuracy: 0.7873, Loss: 0.1657
Epoch  56 Batch  710/1077 - Train Accuracy: 0.7480, Validation Accuracy: 0.7837, Loss: 0.1698
Epoch  56 Batch  720/1077 - Train Accuracy: 0.7981, Validation Accuracy: 0.7848, Loss: 0.1887
Epoch  56 Batch  730/1077 - Train Accuracy: 0.7762, Validation Accuracy: 0.7745, Loss: 0.1669
Epoch  56 Batch  740/1077 - Train Accuracy: 0.7898, Validation Accuracy: 0.7663, Loss: 0.1672
Epoch  56 Batch  750/1077 - Train Accuracy: 0.7895, Validation Accuracy: 0.7823, Loss: 0.1794
Epoch  56 Batch  760/1077 - Train Accuracy: 0.7773, Validation Accuracy: 0.7724, Loss: 0.1817
Epoch  56 Batch  770/1077 - Train Accuracy: 0.7831, Validation Accuracy: 0.7908, Loss: 0.1568
Epoch  56 Batch  780/1077 - Train Accuracy: 0.7812, Validation Accuracy: 0.7912, Loss: 0.1931
Epoch  56 Batch  790/1077 - Train Accuracy: 0.7242, Validation Accuracy: 0.7937, Loss: 0.1957
Epoch  56 Batch  800/1077 - Train Accuracy: 0.7875, Validation Accuracy: 0.7908, Loss: 0.1772
Epoch  56 Batch  810/1077 - Train Accuracy: 0.7563, Validation Accuracy: 0.7837, Loss: 0.1654
Epoch  56 Batch  820/1077 - Train Accuracy: 0.7551, Validation Accuracy: 0.7841, Loss: 0.1904
Epoch  56 Batch  830/1077 - Train Accuracy: 0.7582, Validation Accuracy: 0.7912, Loss: 0.1759
Epoch  56 Batch  840/1077 - Train Accuracy: 0.8113, Validation Accuracy: 0.7937, Loss: 0.1729
Epoch  56 Batch  850/1077 - Train Accuracy: 0.7541, Validation Accuracy: 0.7866, Loss: 0.2002
Epoch  56 Batch  860/1077 - Train Accuracy: 0.7857, Validation Accuracy: 0.7891, Loss: 0.1792
Epoch  56 Batch  870/1077 - Train Accuracy: 0.7767, Validation Accuracy: 0.7841, Loss: 0.1775
Epoch  56 Batch  880/1077 - Train Accuracy: 0.8168, Validation Accuracy: 0.7947, Loss: 0.1584
Epoch  56 Batch  890/1077 - Train Accuracy: 0.8471, Validation Accuracy: 0.7901, Loss: 0.1763
Epoch  56 Batch  900/1077 - Train Accuracy: 0.8238, Validation Accuracy: 0.7987, Loss: 0.1686
Epoch  56 Batch  910/1077 - Train Accuracy: 0.8181, Validation Accuracy: 0.7983, Loss: 0.1840
Epoch  56 Batch  920/1077 - Train Accuracy: 0.7875, Validation Accuracy: 0.7908, Loss: 0.1802
Epoch  56 Batch  930/1077 - Train Accuracy: 0.8098, Validation Accuracy: 0.7859, Loss: 0.1835
Epoch  56 Batch  940/1077 - Train Accuracy: 0.8020, Validation Accuracy: 0.7884, Loss: 0.1641
Epoch  56 Batch  950/1077 - Train Accuracy: 0.8099, Validation Accuracy: 0.7763, Loss: 0.1660
Epoch  56 Batch  960/1077 - Train Accuracy: 0.7902, Validation Accuracy: 0.7798, Loss: 0.1696
Epoch  56 Batch  970/1077 - Train Accuracy: 0.8059, Validation Accuracy: 0.7734, Loss: 0.1687
Epoch  56 Batch  980/1077 - Train Accuracy: 0.7375, Validation Accuracy: 0.7734, Loss: 0.1959
Epoch  56 Batch  990/1077 - Train Accuracy: 0.7940, Validation Accuracy: 0.7827, Loss: 0.1772
Epoch  56 Batch 1000/1077 - Train Accuracy: 0.8192, Validation Accuracy: 0.7823, Loss: 0.1660
Epoch  56 Batch 1010/1077 - Train Accuracy: 0.7953, Validation Accuracy: 0.7837, Loss: 0.1715
Epoch  56 Batch 1020/1077 - Train Accuracy: 0.7730, Validation Accuracy: 0.7848, Loss: 0.1668
Epoch  56 Batch 1030/1077 - Train Accuracy: 0.7629, Validation Accuracy: 0.7816, Loss: 0.1767
Epoch  56 Batch 1040/1077 - Train Accuracy: 0.8067, Validation Accuracy: 0.7649, Loss: 0.1787
Epoch  56 Batch 1050/1077 - Train Accuracy: 0.7520, Validation Accuracy: 0.7699, Loss: 0.1693
Epoch  56 Batch 1060/1077 - Train Accuracy: 0.8219, Validation Accuracy: 0.7791, Loss: 0.1460
Epoch  56 Batch 1070/1077 - Train Accuracy: 0.7766, Validation Accuracy: 0.7773, Loss: 0.1841
Epoch  57 Batch   10/1077 - Train Accuracy: 0.8018, Validation Accuracy: 0.7873, Loss: 0.1938
Epoch  57 Batch   20/1077 - Train Accuracy: 0.7703, Validation Accuracy: 0.7756, Loss: 0.1555
Epoch  57 Batch   30/1077 - Train Accuracy: 0.8258, Validation Accuracy: 0.7859, Loss: 0.1838
Epoch  57 Batch   40/1077 - Train Accuracy: 0.8141, Validation Accuracy: 0.7876, Loss: 0.1716
Epoch  57 Batch   50/1077 - Train Accuracy: 0.7770, Validation Accuracy: 0.8004, Loss: 0.1747
Epoch  57 Batch   60/1077 - Train Accuracy: 0.8002, Validation Accuracy: 0.7898, Loss: 0.1716
Epoch  57 Batch   70/1077 - Train Accuracy: 0.8380, Validation Accuracy: 0.7908, Loss: 0.1870
Epoch  57 Batch   80/1077 - Train Accuracy: 0.7750, Validation Accuracy: 0.7830, Loss: 0.1802
Epoch  57 Batch   90/1077 - Train Accuracy: 0.7551, Validation Accuracy: 0.7859, Loss: 0.1839
Epoch  57 Batch  100/1077 - Train Accuracy: 0.7555, Validation Accuracy: 0.7894, Loss: 0.1588
Epoch  57 Batch  110/1077 - Train Accuracy: 0.8008, Validation Accuracy: 0.7852, Loss: 0.1564
Epoch  57 Batch  120/1077 - Train Accuracy: 0.8172, Validation Accuracy: 0.7866, Loss: 0.1759
Epoch  57 Batch  130/1077 - Train Accuracy: 0.7682, Validation Accuracy: 0.7908, Loss: 0.1763
Epoch  57 Batch  140/1077 - Train Accuracy: 0.7969, Validation Accuracy: 0.7770, Loss: 0.1757
Epoch  57 Batch  150/1077 - Train Accuracy: 0.8118, Validation Accuracy: 0.7816, Loss: 0.1675
Epoch  57 Batch  160/1077 - Train Accuracy: 0.7914, Validation Accuracy: 0.7841, Loss: 0.1810
Epoch  57 Batch  170/1077 - Train Accuracy: 0.7801, Validation Accuracy: 0.7727, Loss: 0.1795
Epoch  57 Batch  180/1077 - Train Accuracy: 0.8008, Validation Accuracy: 0.7809, Loss: 0.1687
Epoch  57 Batch  190/1077 - Train Accuracy: 0.8477, Validation Accuracy: 0.7855, Loss: 0.1785
Epoch  57 Batch  200/1077 - Train Accuracy: 0.7937, Validation Accuracy: 0.7773, Loss: 0.1794
Epoch  57 Batch  210/1077 - Train Accuracy: 0.8058, Validation Accuracy: 0.7788, Loss: 0.1714
Epoch  57 Batch  220/1077 - Train Accuracy: 0.7833, Validation Accuracy: 0.7805, Loss: 0.1792
Epoch  57 Batch  230/1077 - Train Accuracy: 0.7987, Validation Accuracy: 0.7915, Loss: 0.1727
Epoch  57 Batch  240/1077 - Train Accuracy: 0.8441, Validation Accuracy: 0.7773, Loss: 0.1624
Epoch  57 Batch  250/1077 - Train Accuracy: 0.7823, Validation Accuracy: 0.7752, Loss: 0.1637
Epoch  57 Batch  260/1077 - Train Accuracy: 0.8173, Validation Accuracy: 0.7844, Loss: 0.1502
Epoch  57 Batch  270/1077 - Train Accuracy: 0.7969, Validation Accuracy: 0.7869, Loss: 0.2042
Epoch  57 Batch  280/1077 - Train Accuracy: 0.8070, Validation Accuracy: 0.7912, Loss: 0.1718
Epoch  57 Batch  290/1077 - Train Accuracy: 0.7777, Validation Accuracy: 0.7749, Loss: 0.1920
Epoch  57 Batch  300/1077 - Train Accuracy: 0.7862, Validation Accuracy: 0.7649, Loss: 0.1651
Epoch  57 Batch  310/1077 - Train Accuracy: 0.7504, Validation Accuracy: 0.7820, Loss: 0.1892
Epoch  57 Batch  320/1077 - Train Accuracy: 0.8242, Validation Accuracy: 0.7848, Loss: 0.2257
Epoch  57 Batch  330/1077 - Train Accuracy: 0.7691, Validation Accuracy: 0.7724, Loss: 0.1831
Epoch  57 Batch  340/1077 - Train Accuracy: 0.7911, Validation Accuracy: 0.7777, Loss: 0.1809
Epoch  57 Batch  350/1077 - Train Accuracy: 0.7910, Validation Accuracy: 0.7781, Loss: 0.1677
Epoch  57 Batch  360/1077 - Train Accuracy: 0.7902, Validation Accuracy: 0.7827, Loss: 0.1585
Epoch  57 Batch  370/1077 - Train Accuracy: 0.8047, Validation Accuracy: 0.7802, Loss: 0.1706
Epoch  57 Batch  380/1077 - Train Accuracy: 0.7922, Validation Accuracy: 0.7770, Loss: 0.1740
Epoch  57 Batch  390/1077 - Train Accuracy: 0.7695, Validation Accuracy: 0.7933, Loss: 0.1930
Epoch  57 Batch  400/1077 - Train Accuracy: 0.8023, Validation Accuracy: 0.7876, Loss: 0.1826
Epoch  57 Batch  410/1077 - Train Accuracy: 0.7792, Validation Accuracy: 0.7905, Loss: 0.1905
Epoch  57 Batch  420/1077 - Train Accuracy: 0.8250, Validation Accuracy: 0.7827, Loss: 0.1584
Epoch  57 Batch  430/1077 - Train Accuracy: 0.7770, Validation Accuracy: 0.7841, Loss: 0.1608
Epoch  57 Batch  440/1077 - Train Accuracy: 0.7410, Validation Accuracy: 0.7802, Loss: 0.1933
Epoch  57 Batch  450/1077 - Train Accuracy: 0.8250, Validation Accuracy: 0.7741, Loss: 0.1895
Epoch  57 Batch  460/1077 - Train Accuracy: 0.7555, Validation Accuracy: 0.7617, Loss: 0.1928
Epoch  57 Batch  470/1077 - Train Accuracy: 0.8178, Validation Accuracy: 0.7628, Loss: 0.1831
Epoch  57 Batch  480/1077 - Train Accuracy: 0.7767, Validation Accuracy: 0.7688, Loss: 0.1702
Epoch  57 Batch  490/1077 - Train Accuracy: 0.7684, Validation Accuracy: 0.7805, Loss: 0.1771
Epoch  57 Batch  500/1077 - Train Accuracy: 0.8313, Validation Accuracy: 0.7830, Loss: 0.1570
Epoch  57 Batch  510/1077 - Train Accuracy: 0.8191, Validation Accuracy: 0.7905, Loss: 0.1740
Epoch  57 Batch  520/1077 - Train Accuracy: 0.8501, Validation Accuracy: 0.7823, Loss: 0.1476
Epoch  57 Batch  530/1077 - Train Accuracy: 0.7594, Validation Accuracy: 0.7841, Loss: 0.1782
Epoch  57 Batch  540/1077 - Train Accuracy: 0.8121, Validation Accuracy: 0.7855, Loss: 0.1554
Epoch  57 Batch  550/1077 - Train Accuracy: 0.7762, Validation Accuracy: 0.7809, Loss: 0.1733
Epoch  57 Batch  560/1077 - Train Accuracy: 0.7941, Validation Accuracy: 0.7926, Loss: 0.1658
Epoch  57 Batch  570/1077 - Train Accuracy: 0.7821, Validation Accuracy: 0.7866, Loss: 0.1772
Epoch  57 Batch  580/1077 - Train Accuracy: 0.8006, Validation Accuracy: 0.7830, Loss: 0.1579
Epoch  57 Batch  590/1077 - Train Accuracy: 0.7590, Validation Accuracy: 0.7802, Loss: 0.1855
Epoch  57 Batch  600/1077 - Train Accuracy: 0.8199, Validation Accuracy: 0.7923, Loss: 0.1755
Epoch  57 Batch  610/1077 - Train Accuracy: 0.7928, Validation Accuracy: 0.7837, Loss: 0.1728
Epoch  57 Batch  620/1077 - Train Accuracy: 0.7715, Validation Accuracy: 0.7852, Loss: 0.1625
Epoch  57 Batch  630/1077 - Train Accuracy: 0.7801, Validation Accuracy: 0.7855, Loss: 0.1757
Epoch  57 Batch  640/1077 - Train Accuracy: 0.7920, Validation Accuracy: 0.7823, Loss: 0.1610
Epoch  57 Batch  650/1077 - Train Accuracy: 0.7918, Validation Accuracy: 0.7994, Loss: 0.1795
Epoch  57 Batch  660/1077 - Train Accuracy: 0.8012, Validation Accuracy: 0.8008, Loss: 0.1653
Epoch  57 Batch  670/1077 - Train Accuracy: 0.7937, Validation Accuracy: 0.7873, Loss: 0.1654
Epoch  57 Batch  680/1077 - Train Accuracy: 0.7731, Validation Accuracy: 0.7933, Loss: 0.1969
Epoch  57 Batch  690/1077 - Train Accuracy: 0.8031, Validation Accuracy: 0.7802, Loss: 0.1914
Epoch  57 Batch  700/1077 - Train Accuracy: 0.8094, Validation Accuracy: 0.7884, Loss: 0.1531
Epoch  57 Batch  710/1077 - Train Accuracy: 0.7387, Validation Accuracy: 0.7791, Loss: 0.1745
Epoch  57 Batch  720/1077 - Train Accuracy: 0.7919, Validation Accuracy: 0.7695, Loss: 0.1780
Epoch  57 Batch  730/1077 - Train Accuracy: 0.7750, Validation Accuracy: 0.7766, Loss: 0.1816
Epoch  57 Batch  740/1077 - Train Accuracy: 0.7883, Validation Accuracy: 0.7770, Loss: 0.1739
Epoch  57 Batch  750/1077 - Train Accuracy: 0.7715, Validation Accuracy: 0.7891, Loss: 0.1681
Epoch  57 Batch  760/1077 - Train Accuracy: 0.7785, Validation Accuracy: 0.7855, Loss: 0.1801
Epoch  57 Batch  770/1077 - Train Accuracy: 0.8151, Validation Accuracy: 0.7905, Loss: 0.1690
Epoch  57 Batch  780/1077 - Train Accuracy: 0.7828, Validation Accuracy: 0.7802, Loss: 0.1941
Epoch  57 Batch  790/1077 - Train Accuracy: 0.7219, Validation Accuracy: 0.7887, Loss: 0.1851
Epoch  57 Batch  800/1077 - Train Accuracy: 0.7879, Validation Accuracy: 0.7944, Loss: 0.1666
Epoch  57 Batch  810/1077 - Train Accuracy: 0.7775, Validation Accuracy: 0.7781, Loss: 0.1560
Epoch  57 Batch  820/1077 - Train Accuracy: 0.7461, Validation Accuracy: 0.7894, Loss: 0.1780
Epoch  57 Batch  830/1077 - Train Accuracy: 0.7730, Validation Accuracy: 0.7841, Loss: 0.1776
Epoch  57 Batch  840/1077 - Train Accuracy: 0.8199, Validation Accuracy: 0.7784, Loss: 0.1655
Epoch  57 Batch  850/1077 - Train Accuracy: 0.7537, Validation Accuracy: 0.7759, Loss: 0.2043
Epoch  57 Batch  860/1077 - Train Accuracy: 0.7932, Validation Accuracy: 0.7731, Loss: 0.1748
Epoch  57 Batch  870/1077 - Train Accuracy: 0.7693, Validation Accuracy: 0.7844, Loss: 0.1875
Epoch  57 Batch  880/1077 - Train Accuracy: 0.8168, Validation Accuracy: 0.7901, Loss: 0.1614
Epoch  57 Batch  890/1077 - Train Accuracy: 0.8534, Validation Accuracy: 0.7891, Loss: 0.1667
Epoch  57 Batch  900/1077 - Train Accuracy: 0.8297, Validation Accuracy: 0.7837, Loss: 0.1740
Epoch  57 Batch  910/1077 - Train Accuracy: 0.8129, Validation Accuracy: 0.7859, Loss: 0.1759
Epoch  57 Batch  920/1077 - Train Accuracy: 0.7852, Validation Accuracy: 0.7926, Loss: 0.1808
Epoch  57 Batch  930/1077 - Train Accuracy: 0.7988, Validation Accuracy: 0.7848, Loss: 0.1745
Epoch  57 Batch  940/1077 - Train Accuracy: 0.8063, Validation Accuracy: 0.7781, Loss: 0.1691
Epoch  57 Batch  950/1077 - Train Accuracy: 0.8025, Validation Accuracy: 0.7777, Loss: 0.1657
Epoch  57 Batch  960/1077 - Train Accuracy: 0.7861, Validation Accuracy: 0.7763, Loss: 0.1729
Epoch  57 Batch  970/1077 - Train Accuracy: 0.7883, Validation Accuracy: 0.7674, Loss: 0.1868
Epoch  57 Batch  980/1077 - Train Accuracy: 0.7734, Validation Accuracy: 0.7777, Loss: 0.1853
Epoch  57 Batch  990/1077 - Train Accuracy: 0.7775, Validation Accuracy: 0.7830, Loss: 0.1734
Epoch  57 Batch 1000/1077 - Train Accuracy: 0.7984, Validation Accuracy: 0.7777, Loss: 0.1658
Epoch  57 Batch 1010/1077 - Train Accuracy: 0.8059, Validation Accuracy: 0.7738, Loss: 0.2110
Epoch  57 Batch 1020/1077 - Train Accuracy: 0.7688, Validation Accuracy: 0.7766, Loss: 0.1700
Epoch  57 Batch 1030/1077 - Train Accuracy: 0.7809, Validation Accuracy: 0.7841, Loss: 0.1881
Epoch  57 Batch 1040/1077 - Train Accuracy: 0.8191, Validation Accuracy: 0.7678, Loss: 0.1919
Epoch  57 Batch 1050/1077 - Train Accuracy: 0.7555, Validation Accuracy: 0.7820, Loss: 0.1725
Epoch  57 Batch 1060/1077 - Train Accuracy: 0.8152, Validation Accuracy: 0.7912, Loss: 0.1606
Epoch  57 Batch 1070/1077 - Train Accuracy: 0.7828, Validation Accuracy: 0.7589, Loss: 0.1787
Epoch  58 Batch   10/1077 - Train Accuracy: 0.8137, Validation Accuracy: 0.7848, Loss: 0.1894
Epoch  58 Batch   20/1077 - Train Accuracy: 0.7684, Validation Accuracy: 0.7781, Loss: 0.1615
Epoch  58 Batch   30/1077 - Train Accuracy: 0.8055, Validation Accuracy: 0.7731, Loss: 0.1751
Epoch  58 Batch   40/1077 - Train Accuracy: 0.8277, Validation Accuracy: 0.7841, Loss: 0.1786
Epoch  58 Batch   50/1077 - Train Accuracy: 0.7719, Validation Accuracy: 0.7820, Loss: 0.1737
Epoch  58 Batch   60/1077 - Train Accuracy: 0.8051, Validation Accuracy: 0.7749, Loss: 0.1548
Epoch  58 Batch   70/1077 - Train Accuracy: 0.8405, Validation Accuracy: 0.7784, Loss: 0.1697
Epoch  58 Batch   80/1077 - Train Accuracy: 0.7844, Validation Accuracy: 0.7759, Loss: 0.1671
Epoch  58 Batch   90/1077 - Train Accuracy: 0.7590, Validation Accuracy: 0.7884, Loss: 0.1943
Epoch  58 Batch  100/1077 - Train Accuracy: 0.7520, Validation Accuracy: 0.7940, Loss: 0.1660
Epoch  58 Batch  110/1077 - Train Accuracy: 0.8047, Validation Accuracy: 0.7848, Loss: 0.1567
Epoch  58 Batch  120/1077 - Train Accuracy: 0.8094, Validation Accuracy: 0.7812, Loss: 0.1743
Epoch  58 Batch  130/1077 - Train Accuracy: 0.7723, Validation Accuracy: 0.7848, Loss: 0.1610
Epoch  58 Batch  140/1077 - Train Accuracy: 0.7961, Validation Accuracy: 0.7841, Loss: 0.1818
Epoch  58 Batch  150/1077 - Train Accuracy: 0.8051, Validation Accuracy: 0.7834, Loss: 0.1727
Epoch  58 Batch  160/1077 - Train Accuracy: 0.8031, Validation Accuracy: 0.7752, Loss: 0.1718
Epoch  58 Batch  170/1077 - Train Accuracy: 0.7801, Validation Accuracy: 0.7795, Loss: 0.1843
Epoch  58 Batch  180/1077 - Train Accuracy: 0.8270, Validation Accuracy: 0.7788, Loss: 0.1628
Epoch  58 Batch  190/1077 - Train Accuracy: 0.8426, Validation Accuracy: 0.7823, Loss: 0.1601
Epoch  58 Batch  200/1077 - Train Accuracy: 0.7863, Validation Accuracy: 0.7830, Loss: 0.2090
Epoch  58 Batch  210/1077 - Train Accuracy: 0.7906, Validation Accuracy: 0.7844, Loss: 0.1723
Epoch  58 Batch  220/1077 - Train Accuracy: 0.7998, Validation Accuracy: 0.7731, Loss: 0.1676
Epoch  58 Batch  230/1077 - Train Accuracy: 0.7958, Validation Accuracy: 0.7802, Loss: 0.1668
Epoch  58 Batch  240/1077 - Train Accuracy: 0.8453, Validation Accuracy: 0.7827, Loss: 0.1541
Epoch  58 Batch  250/1077 - Train Accuracy: 0.7908, Validation Accuracy: 0.7852, Loss: 0.1627
Epoch  58 Batch  260/1077 - Train Accuracy: 0.8118, Validation Accuracy: 0.7912, Loss: 0.1523
Epoch  58 Batch  270/1077 - Train Accuracy: 0.7930, Validation Accuracy: 0.7887, Loss: 0.1914
Epoch  58 Batch  280/1077 - Train Accuracy: 0.7969, Validation Accuracy: 0.7798, Loss: 0.1722
Epoch  58 Batch  290/1077 - Train Accuracy: 0.7852, Validation Accuracy: 0.7841, Loss: 0.1864
Epoch  58 Batch  300/1077 - Train Accuracy: 0.7887, Validation Accuracy: 0.7830, Loss: 0.1652
Epoch  58 Batch  310/1077 - Train Accuracy: 0.7582, Validation Accuracy: 0.7784, Loss: 0.2120
Epoch  58 Batch  320/1077 - Train Accuracy: 0.8180, Validation Accuracy: 0.7763, Loss: 0.2128
Epoch  58 Batch  330/1077 - Train Accuracy: 0.7902, Validation Accuracy: 0.7827, Loss: 0.1674
Epoch  58 Batch  340/1077 - Train Accuracy: 0.7911, Validation Accuracy: 0.7763, Loss: 0.1660
Epoch  58 Batch  350/1077 - Train Accuracy: 0.7836, Validation Accuracy: 0.7710, Loss: 0.1636
Epoch  58 Batch  360/1077 - Train Accuracy: 0.7723, Validation Accuracy: 0.7692, Loss: 0.1547
Epoch  58 Batch  370/1077 - Train Accuracy: 0.8140, Validation Accuracy: 0.7869, Loss: 0.1668
Epoch  58 Batch  380/1077 - Train Accuracy: 0.7996, Validation Accuracy: 0.7873, Loss: 0.1668
Epoch  58 Batch  390/1077 - Train Accuracy: 0.7605, Validation Accuracy: 0.7923, Loss: 0.2000
Epoch  58 Batch  400/1077 - Train Accuracy: 0.8078, Validation Accuracy: 0.7873, Loss: 0.1708
Epoch  58 Batch  410/1077 - Train Accuracy: 0.7697, Validation Accuracy: 0.7781, Loss: 0.1853
Epoch  58 Batch  420/1077 - Train Accuracy: 0.8223, Validation Accuracy: 0.7876, Loss: 0.1795
Epoch  58 Batch  430/1077 - Train Accuracy: 0.7676, Validation Accuracy: 0.7887, Loss: 0.1637
Epoch  58 Batch  440/1077 - Train Accuracy: 0.7719, Validation Accuracy: 0.7816, Loss: 0.1966
Epoch  58 Batch  450/1077 - Train Accuracy: 0.8273, Validation Accuracy: 0.7812, Loss: 0.1705
Epoch  58 Batch  460/1077 - Train Accuracy: 0.7383, Validation Accuracy: 0.7685, Loss: 0.1787
Epoch  58 Batch  470/1077 - Train Accuracy: 0.8117, Validation Accuracy: 0.7741, Loss: 0.1697
Epoch  58 Batch  480/1077 - Train Accuracy: 0.7817, Validation Accuracy: 0.7891, Loss: 0.1878
Epoch  58 Batch  490/1077 - Train Accuracy: 0.7652, Validation Accuracy: 0.7923, Loss: 0.1702
Epoch  58 Batch  500/1077 - Train Accuracy: 0.8230, Validation Accuracy: 0.7802, Loss: 0.1653
Epoch  58 Batch  510/1077 - Train Accuracy: 0.8129, Validation Accuracy: 0.7745, Loss: 0.1693
Epoch  58 Batch  520/1077 - Train Accuracy: 0.8404, Validation Accuracy: 0.7972, Loss: 0.1561
Epoch  58 Batch  530/1077 - Train Accuracy: 0.7680, Validation Accuracy: 0.7834, Loss: 0.1710
Epoch  58 Batch  540/1077 - Train Accuracy: 0.8137, Validation Accuracy: 0.7791, Loss: 0.1578
Epoch  58 Batch  550/1077 - Train Accuracy: 0.7703, Validation Accuracy: 0.7795, Loss: 0.1795
Epoch  58 Batch  560/1077 - Train Accuracy: 0.8012, Validation Accuracy: 0.7869, Loss: 0.1672
Epoch  58 Batch  570/1077 - Train Accuracy: 0.7845, Validation Accuracy: 0.7862, Loss: 0.1904
Epoch  58 Batch  580/1077 - Train Accuracy: 0.7861, Validation Accuracy: 0.7915, Loss: 0.1542
Epoch  58 Batch  590/1077 - Train Accuracy: 0.7553, Validation Accuracy: 0.7933, Loss: 0.1822
Epoch  58 Batch  600/1077 - Train Accuracy: 0.8196, Validation Accuracy: 0.7905, Loss: 0.1736
Epoch  58 Batch  610/1077 - Train Accuracy: 0.7775, Validation Accuracy: 0.7894, Loss: 0.1871
Epoch  58 Batch  620/1077 - Train Accuracy: 0.7801, Validation Accuracy: 0.7784, Loss: 0.1606
Epoch  58 Batch  630/1077 - Train Accuracy: 0.7676, Validation Accuracy: 0.7891, Loss: 0.1691
Epoch  58 Batch  640/1077 - Train Accuracy: 0.7906, Validation Accuracy: 0.8029, Loss: 0.1565
Epoch  58 Batch  650/1077 - Train Accuracy: 0.7852, Validation Accuracy: 0.7923, Loss: 0.1688
Epoch  58 Batch  660/1077 - Train Accuracy: 0.8078, Validation Accuracy: 0.7947, Loss: 0.1777
Epoch  58 Batch  670/1077 - Train Accuracy: 0.7947, Validation Accuracy: 0.7979, Loss: 0.1538
Epoch  58 Batch  680/1077 - Train Accuracy: 0.7790, Validation Accuracy: 0.7940, Loss: 0.1850
Epoch  58 Batch  690/1077 - Train Accuracy: 0.8156, Validation Accuracy: 0.7809, Loss: 0.1687
Epoch  58 Batch  700/1077 - Train Accuracy: 0.8105, Validation Accuracy: 0.7830, Loss: 0.1649
Epoch  58 Batch  710/1077 - Train Accuracy: 0.7387, Validation Accuracy: 0.7788, Loss: 0.1663
Epoch  58 Batch  720/1077 - Train Accuracy: 0.8002, Validation Accuracy: 0.7848, Loss: 0.1859
Epoch  58 Batch  730/1077 - Train Accuracy: 0.7793, Validation Accuracy: 0.7798, Loss: 0.1783
Epoch  58 Batch  740/1077 - Train Accuracy: 0.7891, Validation Accuracy: 0.7781, Loss: 0.1596
Epoch  58 Batch  750/1077 - Train Accuracy: 0.7746, Validation Accuracy: 0.7933, Loss: 0.1584
Epoch  58 Batch  760/1077 - Train Accuracy: 0.7812, Validation Accuracy: 0.7841, Loss: 0.1810
Epoch  58 Batch  770/1077 - Train Accuracy: 0.8125, Validation Accuracy: 0.8004, Loss: 0.1548
Epoch  58 Batch  780/1077 - Train Accuracy: 0.7801, Validation Accuracy: 0.7812, Loss: 0.1997
Epoch  58 Batch  790/1077 - Train Accuracy: 0.7238, Validation Accuracy: 0.7951, Loss: 0.1944
Epoch  58 Batch  800/1077 - Train Accuracy: 0.7766, Validation Accuracy: 0.7894, Loss: 0.1669
Epoch  58 Batch  810/1077 - Train Accuracy: 0.7827, Validation Accuracy: 0.7844, Loss: 0.1695
Epoch  58 Batch  820/1077 - Train Accuracy: 0.7512, Validation Accuracy: 0.7887, Loss: 0.2015
Epoch  58 Batch  830/1077 - Train Accuracy: 0.7699, Validation Accuracy: 0.7816, Loss: 0.1786
Epoch  58 Batch  840/1077 - Train Accuracy: 0.8098, Validation Accuracy: 0.7972, Loss: 0.1578
Epoch  58 Batch  850/1077 - Train Accuracy: 0.7530, Validation Accuracy: 0.7944, Loss: 0.2006
Epoch  58 Batch  860/1077 - Train Accuracy: 0.7879, Validation Accuracy: 0.7880, Loss: 0.1795
Epoch  58 Batch  870/1077 - Train Accuracy: 0.7743, Validation Accuracy: 0.7944, Loss: 0.1730
Epoch  58 Batch  880/1077 - Train Accuracy: 0.8086, Validation Accuracy: 0.7866, Loss: 0.1639
Epoch  58 Batch  890/1077 - Train Accuracy: 0.8411, Validation Accuracy: 0.7908, Loss: 0.1554
Epoch  58 Batch  900/1077 - Train Accuracy: 0.8309, Validation Accuracy: 0.7951, Loss: 0.1673
Epoch  58 Batch  910/1077 - Train Accuracy: 0.8084, Validation Accuracy: 0.7933, Loss: 0.1816
Epoch  58 Batch  920/1077 - Train Accuracy: 0.7906, Validation Accuracy: 0.7912, Loss: 0.1668
Epoch  58 Batch  930/1077 - Train Accuracy: 0.7965, Validation Accuracy: 0.7898, Loss: 0.1542
Epoch  58 Batch  940/1077 - Train Accuracy: 0.8184, Validation Accuracy: 0.7841, Loss: 0.1586
Epoch  58 Batch  950/1077 - Train Accuracy: 0.7906, Validation Accuracy: 0.7905, Loss: 0.1600
Epoch  58 Batch  960/1077 - Train Accuracy: 0.7909, Validation Accuracy: 0.7884, Loss: 0.1746
Epoch  58 Batch  970/1077 - Train Accuracy: 0.7992, Validation Accuracy: 0.7678, Loss: 0.1711
Epoch  58 Batch  980/1077 - Train Accuracy: 0.7465, Validation Accuracy: 0.7823, Loss: 0.1842
Epoch  58 Batch  990/1077 - Train Accuracy: 0.7862, Validation Accuracy: 0.7805, Loss: 0.1827
Epoch  58 Batch 1000/1077 - Train Accuracy: 0.8025, Validation Accuracy: 0.7887, Loss: 0.1661
Epoch  58 Batch 1010/1077 - Train Accuracy: 0.8086, Validation Accuracy: 0.7987, Loss: 0.1727
Epoch  58 Batch 1020/1077 - Train Accuracy: 0.7777, Validation Accuracy: 0.7784, Loss: 0.1602
Epoch  58 Batch 1030/1077 - Train Accuracy: 0.7820, Validation Accuracy: 0.7923, Loss: 0.1803
Epoch  58 Batch 1040/1077 - Train Accuracy: 0.8224, Validation Accuracy: 0.7724, Loss: 0.1656
Epoch  58 Batch 1050/1077 - Train Accuracy: 0.7621, Validation Accuracy: 0.7763, Loss: 0.1625
Epoch  58 Batch 1060/1077 - Train Accuracy: 0.8219, Validation Accuracy: 0.7777, Loss: 0.1511
Epoch  58 Batch 1070/1077 - Train Accuracy: 0.7770, Validation Accuracy: 0.7830, Loss: 0.1864
Epoch  59 Batch   10/1077 - Train Accuracy: 0.8063, Validation Accuracy: 0.7773, Loss: 0.1794
Epoch  59 Batch   20/1077 - Train Accuracy: 0.7773, Validation Accuracy: 0.7717, Loss: 0.1629
Epoch  59 Batch   30/1077 - Train Accuracy: 0.8207, Validation Accuracy: 0.7702, Loss: 0.1727
Epoch  59 Batch   40/1077 - Train Accuracy: 0.8184, Validation Accuracy: 0.7766, Loss: 0.1692
Epoch  59 Batch   50/1077 - Train Accuracy: 0.7730, Validation Accuracy: 0.7802, Loss: 0.1722
Epoch  59 Batch   60/1077 - Train Accuracy: 0.8132, Validation Accuracy: 0.7663, Loss: 0.1666
Epoch  59 Batch   70/1077 - Train Accuracy: 0.8368, Validation Accuracy: 0.7734, Loss: 0.1701
Epoch  59 Batch   80/1077 - Train Accuracy: 0.7809, Validation Accuracy: 0.7752, Loss: 0.1810
Epoch  59 Batch   90/1077 - Train Accuracy: 0.7570, Validation Accuracy: 0.7983, Loss: 0.1631
Epoch  59 Batch  100/1077 - Train Accuracy: 0.7805, Validation Accuracy: 0.7848, Loss: 0.1669
Epoch  59 Batch  110/1077 - Train Accuracy: 0.8090, Validation Accuracy: 0.7958, Loss: 0.1569
Epoch  59 Batch  120/1077 - Train Accuracy: 0.8191, Validation Accuracy: 0.7763, Loss: 0.1815
Epoch  59 Batch  130/1077 - Train Accuracy: 0.7667, Validation Accuracy: 0.7898, Loss: 0.1684
Epoch  59 Batch  140/1077 - Train Accuracy: 0.8002, Validation Accuracy: 0.7724, Loss: 0.1836
Epoch  59 Batch  150/1077 - Train Accuracy: 0.8051, Validation Accuracy: 0.7866, Loss: 0.1646
Epoch  59 Batch  160/1077 - Train Accuracy: 0.8082, Validation Accuracy: 0.7876, Loss: 0.1570
Epoch  59 Batch  170/1077 - Train Accuracy: 0.7711, Validation Accuracy: 0.7773, Loss: 0.1777
Epoch  59 Batch  180/1077 - Train Accuracy: 0.8090, Validation Accuracy: 0.7844, Loss: 0.1601
Epoch  59 Batch  190/1077 - Train Accuracy: 0.8480, Validation Accuracy: 0.7972, Loss: 0.1551
Epoch  59 Batch  200/1077 - Train Accuracy: 0.7852, Validation Accuracy: 0.7997, Loss: 0.1726
Epoch  59 Batch  210/1077 - Train Accuracy: 0.8051, Validation Accuracy: 0.7752, Loss: 0.1622
Epoch  59 Batch  220/1077 - Train Accuracy: 0.7956, Validation Accuracy: 0.7674, Loss: 0.1704
Epoch  59 Batch  230/1077 - Train Accuracy: 0.7820, Validation Accuracy: 0.7791, Loss: 0.1674
Epoch  59 Batch  240/1077 - Train Accuracy: 0.8406, Validation Accuracy: 0.7731, Loss: 0.1696
Epoch  59 Batch  250/1077 - Train Accuracy: 0.7969, Validation Accuracy: 0.7866, Loss: 0.1857
Epoch  59 Batch  260/1077 - Train Accuracy: 0.8129, Validation Accuracy: 0.7930, Loss: 0.1553
Epoch  59 Batch  270/1077 - Train Accuracy: 0.8008, Validation Accuracy: 0.7862, Loss: 0.1758
Epoch  59 Batch  280/1077 - Train Accuracy: 0.8004, Validation Accuracy: 0.7699, Loss: 0.1693
Epoch  59 Batch  290/1077 - Train Accuracy: 0.7848, Validation Accuracy: 0.7820, Loss: 0.1821
Epoch  59 Batch  300/1077 - Train Accuracy: 0.7837, Validation Accuracy: 0.7749, Loss: 0.1639
Epoch  59 Batch  310/1077 - Train Accuracy: 0.7672, Validation Accuracy: 0.7947, Loss: 0.1696
Epoch  59 Batch  320/1077 - Train Accuracy: 0.8297, Validation Accuracy: 0.7891, Loss: 0.2149
Epoch  59 Batch  330/1077 - Train Accuracy: 0.8082, Validation Accuracy: 0.7891, Loss: 0.1657
Epoch  59 Batch  340/1077 - Train Accuracy: 0.7854, Validation Accuracy: 0.7773, Loss: 0.1598
Epoch  59 Batch  350/1077 - Train Accuracy: 0.7945, Validation Accuracy: 0.7752, Loss: 0.1630
Epoch  59 Batch  360/1077 - Train Accuracy: 0.7766, Validation Accuracy: 0.7678, Loss: 0.1686
Epoch  59 Batch  370/1077 - Train Accuracy: 0.8185, Validation Accuracy: 0.7756, Loss: 0.1634
Epoch  59 Batch  380/1077 - Train Accuracy: 0.7934, Validation Accuracy: 0.7734, Loss: 0.1589
Epoch  59 Batch  390/1077 - Train Accuracy: 0.7648, Validation Accuracy: 0.7834, Loss: 0.1832
Epoch  59 Batch  400/1077 - Train Accuracy: 0.8090, Validation Accuracy: 0.7859, Loss: 0.1628
Epoch  59 Batch  410/1077 - Train Accuracy: 0.7738, Validation Accuracy: 0.7837, Loss: 0.1806
Epoch  59 Batch  420/1077 - Train Accuracy: 0.8293, Validation Accuracy: 0.7873, Loss: 0.1545
Epoch  59 Batch  430/1077 - Train Accuracy: 0.7562, Validation Accuracy: 0.7816, Loss: 0.1771
Epoch  59 Batch  440/1077 - Train Accuracy: 0.7527, Validation Accuracy: 0.7802, Loss: 0.1767
Epoch  59 Batch  450/1077 - Train Accuracy: 0.8332, Validation Accuracy: 0.7734, Loss: 0.1560
Epoch  59 Batch  460/1077 - Train Accuracy: 0.7484, Validation Accuracy: 0.7756, Loss: 0.1763
Epoch  59 Batch  470/1077 - Train Accuracy: 0.8092, Validation Accuracy: 0.7791, Loss: 0.1750
Epoch  59 Batch  480/1077 - Train Accuracy: 0.7718, Validation Accuracy: 0.7884, Loss: 0.1681
Epoch  59 Batch  490/1077 - Train Accuracy: 0.7680, Validation Accuracy: 0.7805, Loss: 0.1832
Epoch  59 Batch  500/1077 - Train Accuracy: 0.8266, Validation Accuracy: 0.7844, Loss: 0.1493
Epoch  59 Batch  510/1077 - Train Accuracy: 0.8195, Validation Accuracy: 0.7741, Loss: 0.1714
Epoch  59 Batch  520/1077 - Train Accuracy: 0.8430, Validation Accuracy: 0.7791, Loss: 0.1589
Epoch  59 Batch  530/1077 - Train Accuracy: 0.7609, Validation Accuracy: 0.7756, Loss: 0.1709
Epoch  59 Batch  540/1077 - Train Accuracy: 0.8039, Validation Accuracy: 0.7837, Loss: 0.1734
Epoch  59 Batch  550/1077 - Train Accuracy: 0.7641, Validation Accuracy: 0.7891, Loss: 0.1816
Epoch  59 Batch  560/1077 - Train Accuracy: 0.8074, Validation Accuracy: 0.7809, Loss: 0.1567
Epoch  59 Batch  570/1077 - Train Accuracy: 0.7866, Validation Accuracy: 0.7798, Loss: 0.1853
Epoch  59 Batch  580/1077 - Train Accuracy: 0.7917, Validation Accuracy: 0.7791, Loss: 0.1633
Epoch  59 Batch  590/1077 - Train Accuracy: 0.7701, Validation Accuracy: 0.7869, Loss: 0.1867
Epoch  59 Batch  600/1077 - Train Accuracy: 0.8058, Validation Accuracy: 0.7880, Loss: 0.1673
Epoch  59 Batch  610/1077 - Train Accuracy: 0.7775, Validation Accuracy: 0.7763, Loss: 0.1682
Epoch  59 Batch  620/1077 - Train Accuracy: 0.7883, Validation Accuracy: 0.7727, Loss: 0.1449
Epoch  59 Batch  630/1077 - Train Accuracy: 0.7809, Validation Accuracy: 0.7887, Loss: 0.1733
Epoch  59 Batch  640/1077 - Train Accuracy: 0.7876, Validation Accuracy: 0.7891, Loss: 0.1526
Epoch  59 Batch  650/1077 - Train Accuracy: 0.7887, Validation Accuracy: 0.8118, Loss: 0.1737
Epoch  59 Batch  660/1077 - Train Accuracy: 0.8113, Validation Accuracy: 0.8026, Loss: 0.1762
Epoch  59 Batch  670/1077 - Train Accuracy: 0.7930, Validation Accuracy: 0.7820, Loss: 0.1526
Epoch  59 Batch  680/1077 - Train Accuracy: 0.7753, Validation Accuracy: 0.7962, Loss: 0.1709
Epoch  59 Batch  690/1077 - Train Accuracy: 0.8039, Validation Accuracy: 0.7887, Loss: 0.1681
Epoch  59 Batch  700/1077 - Train Accuracy: 0.7973, Validation Accuracy: 0.7841, Loss: 0.1601
Epoch  59 Batch  710/1077 - Train Accuracy: 0.7609, Validation Accuracy: 0.7869, Loss: 0.1749
Epoch  59 Batch  720/1077 - Train Accuracy: 0.7998, Validation Accuracy: 0.7834, Loss: 0.1697
Epoch  59 Batch  730/1077 - Train Accuracy: 0.7527, Validation Accuracy: 0.7752, Loss: 0.1760
Epoch  59 Batch  740/1077 - Train Accuracy: 0.7859, Validation Accuracy: 0.7749, Loss: 0.1758
Epoch  59 Batch  750/1077 - Train Accuracy: 0.7805, Validation Accuracy: 0.7951, Loss: 0.1638
Epoch  59 Batch  760/1077 - Train Accuracy: 0.7848, Validation Accuracy: 0.7777, Loss: 0.1681
Epoch  59 Batch  770/1077 - Train Accuracy: 0.8077, Validation Accuracy: 0.7898, Loss: 0.1644
Epoch  59 Batch  780/1077 - Train Accuracy: 0.7816, Validation Accuracy: 0.7812, Loss: 0.1911
Epoch  59 Batch  790/1077 - Train Accuracy: 0.7262, Validation Accuracy: 0.7873, Loss: 0.1874
Epoch  59 Batch  800/1077 - Train Accuracy: 0.7766, Validation Accuracy: 0.7844, Loss: 0.1774
Epoch  59 Batch  810/1077 - Train Accuracy: 0.7768, Validation Accuracy: 0.7898, Loss: 0.1561
Epoch  59 Batch  820/1077 - Train Accuracy: 0.7484, Validation Accuracy: 0.7884, Loss: 0.1873
Epoch  59 Batch  830/1077 - Train Accuracy: 0.7727, Validation Accuracy: 0.8001, Loss: 0.1604
Epoch  59 Batch  840/1077 - Train Accuracy: 0.8031, Validation Accuracy: 0.7891, Loss: 0.1614
Epoch  59 Batch  850/1077 - Train Accuracy: 0.7489, Validation Accuracy: 0.7841, Loss: 0.1890
Epoch  59 Batch  860/1077 - Train Accuracy: 0.7935, Validation Accuracy: 0.7869, Loss: 0.1752
Epoch  59 Batch  870/1077 - Train Accuracy: 0.7845, Validation Accuracy: 0.7741, Loss: 0.1679
Epoch  59 Batch  880/1077 - Train Accuracy: 0.8211, Validation Accuracy: 0.7699, Loss: 0.1562
Epoch  59 Batch  890/1077 - Train Accuracy: 0.8371, Validation Accuracy: 0.7816, Loss: 0.1727
Epoch  59 Batch  900/1077 - Train Accuracy: 0.8234, Validation Accuracy: 0.7809, Loss: 0.1810
Epoch  59 Batch  910/1077 - Train Accuracy: 0.8185, Validation Accuracy: 0.7816, Loss: 0.1737
Epoch  59 Batch  920/1077 - Train Accuracy: 0.8012, Validation Accuracy: 0.7884, Loss: 0.1604
Epoch  59 Batch  930/1077 - Train Accuracy: 0.8000, Validation Accuracy: 0.7937, Loss: 0.1689
Epoch  59 Batch  940/1077 - Train Accuracy: 0.8016, Validation Accuracy: 0.7919, Loss: 0.1582
Epoch  59 Batch  950/1077 - Train Accuracy: 0.7987, Validation Accuracy: 0.7820, Loss: 0.1582
Epoch  59 Batch  960/1077 - Train Accuracy: 0.7872, Validation Accuracy: 0.7912, Loss: 0.1659
Epoch  59 Batch  970/1077 - Train Accuracy: 0.7992, Validation Accuracy: 0.7770, Loss: 0.1877
Epoch  59 Batch  980/1077 - Train Accuracy: 0.7570, Validation Accuracy: 0.7855, Loss: 0.1753
Epoch  59 Batch  990/1077 - Train Accuracy: 0.7878, Validation Accuracy: 0.7884, Loss: 0.1797
Epoch  59 Batch 1000/1077 - Train Accuracy: 0.8110, Validation Accuracy: 0.7940, Loss: 0.1668
Epoch  59 Batch 1010/1077 - Train Accuracy: 0.7918, Validation Accuracy: 0.7901, Loss: 0.1693
Epoch  59 Batch 1020/1077 - Train Accuracy: 0.7867, Validation Accuracy: 0.7820, Loss: 0.1676
Epoch  59 Batch 1030/1077 - Train Accuracy: 0.7871, Validation Accuracy: 0.7834, Loss: 0.1859
Epoch  59 Batch 1040/1077 - Train Accuracy: 0.8154, Validation Accuracy: 0.7688, Loss: 0.1709
Epoch  59 Batch 1050/1077 - Train Accuracy: 0.7602, Validation Accuracy: 0.7734, Loss: 0.1757
Epoch  59 Batch 1060/1077 - Train Accuracy: 0.8336, Validation Accuracy: 0.7731, Loss: 0.1612
Epoch  59 Batch 1070/1077 - Train Accuracy: 0.7719, Validation Accuracy: 0.7784, Loss: 0.1730
Model Trained and Saved
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Save-Parameters">Save Parameters<a class="anchor-link" href="#Save-Parameters">&#182;</a></h3><p>Save the <code>batch_size</code> and <code>save_path</code> parameters for inference.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="c1"># Save parameters for checkpoint</span>
<span class="n">helper</span><span class="o">.</span><span class="n">save_params</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">NameError</span>                                 Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-1-466fdc464732&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">      3</span> &#34;&#34;&#34;
<span class="ansi-green-intense-fg ansi-bold">      4</span> <span class="ansi-red-fg"># Save parameters for checkpoint</span>
<span class="ansi-green-fg">----&gt; 5</span><span class="ansi-red-fg"> </span>helper<span class="ansi-blue-fg">.</span>save_params<span class="ansi-blue-fg">(</span>save_path<span class="ansi-blue-fg">)</span>

<span class="ansi-red-fg">NameError</span>: name &#39;helper&#39; is not defined</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Checkpoint">Checkpoint<a class="anchor-link" href="#Checkpoint">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">helper</span>
<span class="kn">import</span> <span class="nn">problem_unittests</span> <span class="k">as</span> <span class="nn">tests</span>

<span class="n">_</span><span class="p">,</span> <span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">),</span> <span class="p">(</span><span class="n">source_int_to_vocab</span><span class="p">,</span> <span class="n">target_int_to_vocab</span><span class="p">)</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess</span><span class="p">()</span>
<span class="n">load_path</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_params</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Sentence-to-Sequence">Sentence to Sequence<a class="anchor-link" href="#Sentence-to-Sequence">&#182;</a></h2><p>To feed a sentence into the model for translation, you first need to preprocess it.  Implement the function <code>sentence_to_seq()</code> to preprocess new sentences.</p>
<ul>
<li>Convert the sentence to lowercase</li>
<li>Convert words into ids using <code>vocab_to_int</code><ul>
<li>Convert words not in the vocabulary, to the <code>&lt;UNK&gt;</code> word id.</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">sentence_to_seq</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">vocab_to_int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert a sentence to a sequence of ids</span>
<span class="sd">    :param sentence: String</span>
<span class="sd">    :param vocab_to_int: Dictionary to go from the words to an id</span>
<span class="sd">    :return: List of word ids</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>

    <span class="n">sentence</span> <span class="o">=</span> <span class="n">sentence</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="n">sentence_ids</span> <span class="o">=</span> <span class="p">[</span><span class="n">vocab_to_int</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="k">if</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">vocab_to_int</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">else</span> <span class="n">vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;UNK&gt;&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">()]</span>
    <span class="k">return</span> <span class="n">sentence_ids</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_sentence_to_seq</span><span class="p">(</span><span class="n">sentence_to_seq</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Translate">Translate<a class="anchor-link" href="#Translate">&#182;</a></h2><p>This will translate <code>translate_sentence</code> from English to French.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">translate_sentence</span> <span class="o">=</span> <span class="s1">&#39;he saw a old yellow truck .&#39;</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">translate_sentence</span> <span class="o">=</span> <span class="n">sentence_to_seq</span><span class="p">(</span><span class="n">translate_sentence</span><span class="p">,</span> <span class="n">source_vocab_to_int</span><span class="p">)</span>

<span class="n">loaded_graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">loaded_graph</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="c1"># Load saved model</span>
    <span class="n">loader</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">import_meta_graph</span><span class="p">(</span><span class="n">load_path</span> <span class="o">+</span> <span class="s1">&#39;.meta&#39;</span><span class="p">)</span>
    <span class="n">loader</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">load_path</span><span class="p">)</span>

    <span class="n">input_data</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;input:0&#39;</span><span class="p">)</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;predictions:0&#39;</span><span class="p">)</span>
    <span class="n">target_sequence_length</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;target_sequence_length:0&#39;</span><span class="p">)</span>
    <span class="n">source_sequence_length</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;source_sequence_length:0&#39;</span><span class="p">)</span>
    <span class="n">keep_prob</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;keep_prob:0&#39;</span><span class="p">)</span>

    <span class="n">translate_logits</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="p">[</span><span class="n">translate_sentence</span><span class="p">]</span><span class="o">*</span><span class="n">batch_size</span><span class="p">,</span>
                                         <span class="n">target_sequence_length</span><span class="p">:</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">translate_sentence</span><span class="p">)</span><span class="o">*</span><span class="mi">2</span><span class="p">]</span><span class="o">*</span><span class="n">batch_size</span><span class="p">,</span>
                                         <span class="n">source_sequence_length</span><span class="p">:</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">translate_sentence</span><span class="p">)]</span><span class="o">*</span><span class="n">batch_size</span><span class="p">,</span>
                                         <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})[</span><span class="mi">0</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Input&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;  Word Ids:      </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">translate_sentence</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;  English Words: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">([</span><span class="n">source_int_to_vocab</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">translate_sentence</span><span class="p">]))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Prediction&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;  Word Ids:      </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">translate_logits</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;  French Words: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">target_int_to_vocab</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">translate_logits</span><span class="p">])))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>INFO:tensorflow:Restoring parameters from checkpoints/dev
Input
  Word Ids:      [39, 99, 208, 129, 141, 130, 85]
  English Words: [&#39;he&#39;, &#39;saw&#39;, &#39;a&#39;, &#39;old&#39;, &#39;yellow&#39;, &#39;truck&#39;, &#39;.&#39;]

Prediction
  Word Ids:      [196, 139, 225, 51, 316, 216, 1]
  French Words: il aimait le camion vert . &lt;EOS&gt;
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Imperfect-Translation">Imperfect Translation<a class="anchor-link" href="#Imperfect-Translation">&#182;</a></h2><p>You might notice that some sentences translate better than others.  Since the dataset you're using only has a vocabulary of 227 English words of the thousands that you use, you're only going to see good results using these words.  For this project, you don't need a perfect translation. However, if you want to create a better translation model, you'll need better data.</p>
<p>You can train on the <a href="http://www.statmt.org/wmt10/training-giga-fren.tar">WMT10 French-English corpus</a>.  This dataset has more vocabulary and richer in topics discussed.  However, this will take you days to train, so make sure you've a GPU and the neural network is performing well on dataset we provided.  Just make sure you play with the WMT10 corpus after you've submitted this project.</p>
<h2 id="Submitting-This-Project">Submitting This Project<a class="anchor-link" href="#Submitting-This-Project">&#182;</a></h2><p>When submitting this project, make sure to run all the cells before saving the notebook. Save the notebook file as "dlnd_language_translation.ipynb" and save it as a HTML file under "File" -&gt; "Download as". Include the "helper.py" and "problem_unittests.py" files in your submission.</p>

</div>
</div>
</div>
    </div>
  </div>
</body>

 


</html>
